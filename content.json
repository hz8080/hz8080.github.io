{"meta":{"title":"土川的自留地","subtitle":"via fennecs.huang@gmail.com","description":"我是黄土川，是兄弟，就来砍我。","author":"土川","url":"https://htchz.cc","root":"/"},"pages":[{"title":"关于","date":"2020-05-07T07:50:37.832Z","updated":"2020-05-07T07:50:37.832Z","comments":false,"path":"about/index.html","permalink":"https://htchz.cc/about/index.html","excerpt":"","text":"邮箱：fennecs.huang@gmail.com Telegram：https://t.me/orzhtc 评论模块需要梯子~ 2020: 《Linux防火墙》✅ 2019: 《Redis设计与实现》✅· 《TCP/IP详解 卷一》✅ 《每天5分钟玩转Kubernetes》✅ 《Docker技术入门与实践》✅ 《Go语言实战》✅ 2018: 《Java 8 实战》✅ 《Netty实战》✅ 《Java NIO》✅ 2017: 《HTTP权威指南》✅ 《JAVA并发编程实战》✅ 《Effective Java》✅ 《深入理解Java虚拟机》✅ 《Head First设计模式》✅"},{"title":"分类","date":"2019-08-15T14:48:32.947Z","updated":"2018-12-17T09:14:15.000Z","comments":false,"path":"categories/index.html","permalink":"https://htchz.cc/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2019-08-15T14:48:33.087Z","updated":"2018-12-17T09:13:02.000Z","comments":false,"path":"tags/index.html","permalink":"https://htchz.cc/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"[Redis]scan命令实现","slug":"Redis-scan命令实现","date":"2020-07-14T07:07:35.000Z","updated":"2020-07-14T10:05:21.256Z","comments":true,"path":"3055836750.html","link":"","permalink":"https://htchz.cc/3055836750.html","excerpt":"","text":"如果要在redis查找遍历key，keys命令会阻塞，是不能用的，这时就要用scan命令。 scan命令支持传入cursor、match pattern、count、type(6.0新增type)，根据游标，返回count数量的符合条件的key，以及新游标。注意这个count只是一个期望值，看源码就知道为什么不是确切值。 db是由dict组成的，set、hash、ziplist也是有dict类型的，dict发生扩容和缩容的话，如果按自然数的方法去遍历，扩容会重复遍历，缩容会遗漏遍历。 假设dict稳定状态下，dict size从8变成16，刚访问过index为3的桶，接下来就应该遍历4-15桶，由于原先0-3号的桶的key有一部分挪到8-11中（+8），后面就会重复遍历到。 假设dict size从8变成4，刚访问过index为3的桶，那么接下来就是遍历结束了，这样原先4-7号的桶就会漏掉（-4）。 如果在扩容缩容情况下，需要遍历两条数组，同样会遇到上面的问题。 看看redis是怎么解决的。 redis不采用自然数顺序遍历，而是采用高位顺序遍历，也就是对游标前进的方式是酱紫的：用对应数组的掩码将游标的值截断（准确地说不是截断，可以先用截断理解） —&gt; 左右翻转 -&gt; 自增 -&gt; 左右翻转回来。 这个算法的原理是，数组扩容是*2，那么每次扩容，旧数组的元素哈希值&amp; new_mask得到下标，要么在原来的桶，要么是原来桶的index*2，具体表现为最高位分别是0和1。那么从高位起开始遍历的话，如果去掉最高位，其实遍历的顺序和旧数组是一样的。 举个例子，原来的顺序是 000 100 010 110那么扩容后，顺序是 (0)000 (1)000 (0)100 (1)100 (0)010 (1)010 (0)110 (1)1001. 遍历实现代码基于6.0，主要分为两部分，一部分是dict非rehash状态，一部分是rehash状态。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990// 这个函数将游标v的元素放到privdata，并用算法推进cursor，unsigned long dictScan(dict *d, unsigned long v, dictScanFunction *fn, dictScanBucketFunction* bucketfn, void *privdata)&#123; dictht *t0, *t1; const dictEntry *de, *next; unsigned long m0, m1; if (dictSize(d) == 0) return 0; /* Having a safe iterator means no rehashing can happen, see _dictRehashStep. * This is needed in case the scan callback tries to do dictFind or alike. */ d-&gt;iterators++; if (!dictIsRehashing(d)) &#123; t0 = &amp;(d-&gt;ht[0]); m0 = t0-&gt;sizemask; /* Emit entries at cursor */ if (bucketfn) bucketfn(privdata, &amp;t0-&gt;table[v &amp; m0]); de = t0-&gt;table[v &amp; m0]; while (de) &#123; next = de-&gt;next; fn(privdata, de); de = next; &#125; /* Set unmasked bits so incrementing the reversed cursor * operates on the masked bits */ v |= ~m0; /* Increment the reverse cursor */ v = rev(v); v++; v = rev(v); &#125; else &#123; t0 = &amp;d-&gt;ht[0]; t1 = &amp;d-&gt;ht[1]; /* Make sure t0 is the smaller and t1 is the bigger table */ if (t0-&gt;size &gt; t1-&gt;size) &#123; t0 = &amp;d-&gt;ht[1]; t1 = &amp;d-&gt;ht[0]; &#125; m0 = t0-&gt;sizemask; m1 = t1-&gt;sizemask; /* Emit entries at cursor */ if (bucketfn) bucketfn(privdata, &amp;t0-&gt;table[v &amp; m0]); de = t0-&gt;table[v &amp; m0]; while (de) &#123; next = de-&gt;next; fn(privdata, de); de = next; &#125; /* Iterate over indices in larger table that are the expansion * of the index pointed to by the cursor in the smaller table */ do &#123; /* Emit entries at cursor */ if (bucketfn) bucketfn(privdata, &amp;t1-&gt;table[v &amp; m1]); de = t1-&gt;table[v &amp; m1]; while (de) &#123; next = de-&gt;next; fn(privdata, de); de = next; &#125; // 这里曾经有个bug，参考下面美团链接 /* Increment the reverse cursor not covered by the smaller mask.*/ v |= ~m1; v = rev(v); v++; v = rev(v); // 这个(m0 ^ m1)就是前面说到的高位，我认为这个循环只会执行两次，小数组的一个桶下标对应大数组的两个桶下标 /* Continue while bits covered by mask difference is non-zero */ &#125; while (v &amp; (m0 ^ m1)); &#125; /* undo the ++ at the top */ d-&gt;iterators--; return v;&#125; 在非rehash状态，用掩码定位计算cursor对应的桶，用一个循环取出桶下所有entry。 在rehash状态，需要确定大小数组，循环取出小数组的桶的entry，对于大数组，遍历两个桶的所有entry，并推进cursor 2. 游标推进cursor推进的算法是 12345678// 这里将非掩码部分置1，如上面说的并非截断v |= ~m1;// 翻转v = rev(v);// 自增v++;// 翻转回来v = rev(v); rev函数 1234567891011/* Function to reverse bits. Algorithm from: * http://graphics.stanford.edu/~seander/bithacks.html#ReverseParallel */static unsigned long rev(unsigned long v) &#123; unsigned long s = CHAR_BIT * sizeof(v); // bit size; must be power of 2 unsigned long mask = ~0UL; while ((s &gt;&gt;= 1) &gt; 0) &#123; mask ^= (mask &lt;&lt; s); v = ((v &gt;&gt; s) &amp; mask) | ((v &lt;&lt; s) &amp; ~mask); &#125; return v;&#125; 大意是，unsigned long是32位，即把前16位和后16位交换，然后16位里，前8位和后8位交换。。。以此类推，总共5次。 想吐槽这个老哥不是不屑于这种位运算魔法吗 = = 3. scanGenericCommand这个方法是scan命令的实现，源代码比较长，注释写的很详细，大约有四步：Step 1: Parse options. 这一步是把参数校验Step 2: Iterate the collection. 这一步是提取出目标的dict，调用前面的遍历方法。Step 3: Filter elements. 这一步是根据match过滤或根据type过滤。Step 4: Reply to the client. 回复客户端 主要看第二步 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/* Step 2: Iterate the collection. * * Note that if the object is encoded with a ziplist, intset, or any other * representation that is not a hash table, we are sure that it is also * composed of a small number of elements. So to avoid taking state we * just return everything inside the object in a single call, setting the * cursor to zero to signal the end of the iteration. *//* Handle the case of a hash table. */ht = NULL;if (o == NULL) &#123; ht = c-&gt;db-&gt;dict;&#125; else if (o-&gt;type == OBJ_SET &amp;&amp; o-&gt;encoding == OBJ_ENCODING_HT) &#123; ht = o-&gt;ptr;&#125; else if (o-&gt;type == OBJ_HASH &amp;&amp; o-&gt;encoding == OBJ_ENCODING_HT) &#123; ht = o-&gt;ptr; count *= 2; /* We return key / value for this type. */&#125; else if (o-&gt;type == OBJ_ZSET &amp;&amp; o-&gt;encoding == OBJ_ENCODING_SKIPLIST) &#123; zset *zs = o-&gt;ptr; ht = zs-&gt;dict; count *= 2; /* We return key / value for this type. */&#125;if (ht) &#123; void *privdata[2]; /* We set the max number of iterations to ten times the specified * COUNT, so if the hash table is in a pathological state (very * sparsely populated) we avoid to block too much time at the cost * of returning no or very few elements. */ long maxiterations = count*10; /* We pass two pointers to the callback: the list to which it will * add new elements, and the object containing the dictionary so that * it is possible to fetch more data in a type-dependent way. */ privdata[0] = keys; privdata[1] = o; do &#123; cursor = dictScan(ht, cursor, scanCallback, NULL, privdata); &#125; while (cursor &amp;&amp; maxiterations-- &amp;&amp; listLength(keys) &lt; (unsigned long)count);&#125; else if (o-&gt;type == OBJ_SET) &#123; int pos = 0; int64_t ll; while(intsetGet(o-&gt;ptr,pos++,&amp;ll)) listAddNodeTail(keys,createStringObjectFromLongLong(ll)); cursor = 0;&#125; else if (o-&gt;type == OBJ_HASH || o-&gt;type == OBJ_ZSET) &#123; unsigned char *p = ziplistIndex(o-&gt;ptr,0); unsigned char *vstr; unsigned int vlen; long long vll; while(p) &#123; ziplistGet(p,&amp;vstr,&amp;vlen,&amp;vll); listAddNodeTail(keys, (vstr != NULL) ? createStringObject((char*)vstr,vlen) : createStringObjectFromLongLong(vll)); p = ziplistNext(o-&gt;ptr,p); &#125; cursor = 0;&#125; else &#123; serverPanic(\"Not handled encoding in SCAN.\");&#125; 注意遍历停止的条件是cursor &amp;&amp; maxiterations &gt; 0 &amp;&amp; listlength(keys) &lt; count，maxiterations = count*10；如果需要返回key/value，count *= 2。 结合后面的过滤，所以说返回结果的长度不是严格按照我们传入的count的值，有可能超了一丢丢，有可能遍历了10倍count数量的桶没几个元素，也有可能找到很多被过滤了一大堆。 4. 参考 美团针对Redis Rehash机制的探索和实践 Redis二进制反转算法分析","categories":[{"name":"redis","slug":"redis","permalink":"https://htchz.cc/categories/redis/"}],"tags":[]},{"title":"[Mysql]两阶段提交和崩溃恢复","slug":"Mysql-两阶段提交和崩溃恢复","date":"2020-06-05T03:15:08.000Z","updated":"2020-06-05T17:04:55.591Z","comments":true,"path":"2934732838.html","link":"","permalink":"https://htchz.cc/2934732838.html","excerpt":"","text":"1. 两阶段提交innodb和bin log需要进行两阶段提交(Two-Phase Commit Protocol，2PC)，目的是为了保证日志一致性，要么都存在，要么都不存在。 要说明的是，两阶段提交不止redo log和binlog有关，undo log也是参与者。 XID是事务根据事务第一条query生成的id，通过XID将redo log和binlog关联起来。在上一篇的binlog日志里也能看到XID的身影。 两阶段提交，其实就是innodb prepare，写binlog，innodb commit； 具体是， prepare阶段，redo log写入根据事务提交时的刷盘策略决定是否刷盘，然后将log segment(不是回滚段！！！)标为TRX_UNDO_PREPARED；binlog不做任何事 commit阶段，binlog写入binlog日志；接着innodb将修改undo log segment状态，并在redo log写入一个commit log。 如果没有两阶段提交，redo log和binlog各写各的，中间发生崩溃，就会出现不一致的情况。 先写binlog，再写redo log：如果redo log没写成功，就会造成崩溃恢复的时候，主库没有、从库有的情况，主从不一致。 先写redo log，再写binlog：如果binlog没写成功，就会造成崩溃恢复的时候，主库有、从库没有的情况，主从不一致。 说白了，为了保证事务，总是得做一些冗余的操作，例如tcp多次握手挥手，都是通过冗余操作来保证两个业务之间一致。 1.1. redo log和binlog顺序不一致的问题两阶段的提交不只如此，如果只是像上面那样，还会出现主从不一致的情况。 1.1.1. 热备问题T1 (--prepare--binlog[pos100]--------------------------------------------commit) T2 (-----prepare-----binlog[pos200]----------commit) T3 (--------prepare-------binlog[pos300]------commit) online-backup(----------------------------------------------backup------------)假设3个事务如上，那么 redo log prepare的顺序：T1 --&gt; T2 --&gt; T3 binlog的写入顺序： T1 --&gt; T2 --&gt; T3 redo log commit的顺序： T2 --&gt; T3 --&gt; T1可以看到redo log提交的顺序和bin log不一致了，这是不允许的，会导致主从不一致。 online-backup表示热备，因为从库在建立的时候需要对主库进行一次备份。当T2，T3提交后，这时热备来读位置，读到最后一个提交的事务T3，由于这个阶段不是读binlog的，所以T1没有被复制到，接下来的binlog复制从T3开始，所以会漏掉T1的数据。 1.1.2. 复制问题《MySQL5.7 核心技术揭秘：MySQL Group commit》（见参考）举了一个例子，就是有一行数据，x=1，y=1T1:x=y+1,y=x+1;T2:y=x+1,x=y+1; 文章说这两个事务颠倒执行出来的结果不一样。但是在我看来，这两个事务是没法颠倒的。事务为了防止回滚覆盖，对一条记录加X锁修改后，只有事务提交之后才能释放X锁，所以这两个事务是没办法同时处于2PC的，肯定是T1 2PC完，T2才开始2PC。才疏学浅，可能理解有误，欢迎指出。 所以早期的mysql用prepare_commit_mutex锁来发起2PC保证顺序，这在高并发下是很耗费性能的。一个事务要获取锁才能发起prepare，知道commit之后才释放锁。除了锁竞争，另一方面，sync_binlog=1的情况下，每次2PC需要刷盘binlog刷盘，这不仅增大了磁盘压力，也延长了占有锁的时长。 于是mysql5.6引入了组提交。 1.2. 组提交组提交是通过一个机制保证binlog顺序和commit顺序一致。 加入组提交之后，2PC的过程稍微变了。在将commit阶段细分，保证commit顺序和写binlog一致。 这个过程每个阶段都用了一个队列来存储，先到的线程是list的leader，后到的加入链表成为follower， prepare阶段，事务获取prepare_commit_mutex，然后刷盘，设置prepare状态，然后释放锁。 commit阶段分成三个阶段： Flush stage: leader获得Lock_log mutex锁，将队列里的binlog写入文件缓冲 Sync stage:leader释放Lock_log mutex，持有Lock_sync mutex, 如果sync_binlog为1，进行sync操作 Commit stage: leader释放Lock_sync mutex，持有Lock_commit mutex，遍历队列，逐一进行commit。 每个阶段的队列长度不是一致的，可能Flush阶段的leader会在Sync阶段追加进前一个队列，成为follower，但是follower永远是follower。 网上的这个图很形象。 在Sync stage阶段，有两个参数可以影响组提交： binlog_group_commit_sync_delay=N:这个参数表明在Sync stage等待多少μs后可以刷盘，等的越久，就越可能合并后来的队列，一次刷更多日志，但是相应的，事务响应就变慢。 binlog_group_commit_sync_no_delay_count=N:当队列的事务个数达到N，就进行刷盘。 组提交优点： 将本该串行的过程变成可并行的过程 虽然prepare_commit_mutex没有去除，但是占用的时间变短了，变成1/4 通过队列保证顺序一致 合并刷盘 2. 崩溃恢复2.1. 未开启binlog从redo log读到last checkpoint lsn，然后从这个位置开始重新应用redo log，不管是提交还是未提交状态。由于undo log会记录成redo log，所以构造出undo log之后，可以通过undo log回滚未提交的事务。 2.2. 开启binlog先和上面执行一样的逻辑，由于多了binlog，为了和从库保证一致，需要提取最后一个binlog文件的XID，接着检查处于prepare状态的redo log，如果redo log的XID不在binlog里，则回滚，如果在，提交redo log。 3. 参考 《MySQL5.7 核心技术揭秘：MySQL Group commit》","categories":[],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://htchz.cc/tags/Mysql/"}]},{"title":"[Mysql]漫游bin log","slug":"Mysql-bin-log","date":"2020-05-26T01:51:00.000Z","updated":"2020-06-05T09:00:10.794Z","comments":true,"path":"2414692924.html","link":"","permalink":"https://htchz.cc/2414692924.html","excerpt":"","text":"binlog是server层的日志，对于innodb来说，只有binlog写完后，才能提交redo log。binlog记录逻辑语句，只会记录写类似于sql的日志。binlog主要的作用 崩溃恢复 主从复制 1. 组织结构1.1. 文件binlog的相关配置可以执行show variables like &#39;%bin%&#39;;查看 12345678910111213141516171819202122232425262728293031323334mysql&gt; show variables like '%bin%';+--------------------------------------------+---------------------------------+| Variable_name | Value |+--------------------------------------------+---------------------------------+| bind_address | * || binlog_cache_size | 32768 || binlog_checksum | CRC32 || binlog_direct_non_transactional_updates | OFF || binlog_error_action | ABORT_SERVER || binlog_format | ROW || binlog_group_commit_sync_delay | 0 || binlog_group_commit_sync_no_delay_count | 0 || binlog_gtid_simple_recovery | ON || binlog_max_flush_queue_time | 0 || binlog_order_commits | ON || binlog_row_image | FULL || binlog_rows_query_log_events | OFF || binlog_stmt_cache_size | 32768 || binlog_transaction_dependency_history_size | 25000 || binlog_transaction_dependency_tracking | COMMIT_ORDER || innodb_api_enable_binlog | OFF || innodb_locks_unsafe_for_binlog | OFF || log_bin | ON || log_bin_basename | /data/mysql3306/mysql-bin || log_bin_index | /data/mysql3306/mysql-bin.index || log_bin_trust_function_creators | ON || log_bin_use_v1_row_events | OFF || log_statements_unsafe_for_binlog | ON || max_binlog_cache_size | 18446744073709547520 || max_binlog_size | 536870912 || max_binlog_stmt_cache_size | 18446744073709547520 || sql_log_bin | ON || sync_binlog | 1 |+--------------------------------------------+---------------------------------+ 执行show master status;可以看到当前写入的二进制文件的名字和位置。 1234567mysql&gt; show master status;+------------------+-----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+-----------+--------------+------------------+-------------------+| mysql-bin.000930 | 178613715 | | mysql,test | |+------------------+-----------+--------------+------------------+-------------------+1 row in set (0.10 sec) binlog主要有两种文件： 二进制日志索引文件（文件名后缀为.index）用于记录所有有效的的二进制文件。 二进制日志文件（文件名后缀为.****）记录数据库所有的DDL和DML语句事件 如上输出，二进制日志文件存放的basename是”/data/mysql3306/mysql-bin.****”，二进制日志索引文件路径是”/data/mysql3306/mysql-bin.index”, 具体如下 1234567891011121314[root@dev_test63 mysql3306]# ls -l mysql-bin*-rw-r----- 1 mysql mysql 538582976 5月 22 01:17 mysql-bin.000919-rw-r----- 1 mysql mysql 536879010 5月 22 12:03 mysql-bin.000920-rw-r----- 1 mysql mysql 536885288 5月 22 20:03 mysql-bin.000921-rw-r----- 1 mysql mysql 536871917 5月 23 05:05 mysql-bin.000922-rw-r----- 1 mysql mysql 536871391 5月 23 21:40 mysql-bin.000923-rw-r----- 1 mysql mysql 536895385 5月 24 07:03 mysql-bin.000924-rw-r----- 1 mysql mysql 536945072 5月 25 00:03 mysql-bin.000925-rw-r----- 1 mysql mysql 536904757 5月 25 09:03 mysql-bin.000926-rw-r----- 1 mysql mysql 536871742 5月 25 19:28 mysql-bin.000927-rw-r----- 1 mysql mysql 536870960 5月 26 04:34 mysql-bin.000928-rw-r----- 1 mysql mysql 536871255 5月 26 19:33 mysql-bin.000929-rw-r----- 1 mysql mysql 153202413 5月 27 00:22 mysql-bin.000930-rw-r----- 1 mysql mysql 228 5月 26 19:33 mysql-bin.index sync_binlog是用来表示同步刷binlog，如果数据库繁忙可能会造成磁盘io压力大 参数为0时，并不是立即fsync文件到磁盘，而是依赖于操作系统的fsync机制； 参数为1时，立即fsync文件到磁盘； 参数大于1时，则达到指定提交次数后，统一fsync到磁盘。 因此只有当sync_binlog参数为1时，才是最安全的，当其不为1时，都存在binlog未fsync到磁盘的风险，若此时发生断电等故障，就有可能出现此事务并未刷出到磁盘。 sql_log_bin表示开启binlog，开关都需要重启mysqlmysql-bin.index这个文件很简单，只是记录了当前的binlog列表 12345678910111213[root@dev_test63 mysql3306]# cat mysql-bin.index./mysql-bin.000919./mysql-bin.000920./mysql-bin.000921./mysql-bin.000922./mysql-bin.000923./mysql-bin.000924./mysql-bin.000925./mysql-bin.000926./mysql-bin.000927./mysql-bin.000928./mysql-bin.000929./mysql-bin.000930 而binlog是一个二进制文件集合，每个binlog文件以一个4字节的魔数0xfe62696e开头（后3字节其实就是”bin”） 接着是一组Events，Event由header组成，header记录了创建时间、服务器标识等，data是数据。一个binlog文件里，第一个event描述binlog的格式，最后一个binlog描述下一个binlog文件的信息。 1.2. rotation当下面三种情况发生时，binlog会rotate新文件： 实例停止或重启时 flush logs 命令； 当前binlog &gt; max_binlog_size(像上面的配置是512M) 如果有一个大事务执行时，很可能会发生一个binlog文件稍大于max_binlog_size 2. 模式binlog有三种记录模式，分别是statement，row，mixed，通过binlog_format来指定，可以在运行时指定。 2.1. statementstatement记录的是原语句，你执行什么语句就会记录什么语句。这在主从复制的时候就会出现一些问题： 这里提一个问题：为什么大多数数据库的默认隔离级别是RC，而innodb是RR呢： 这是一个历史遗留问题，网上也可以找到很多解释，大体就是：在mysql5.1.5之前只有statement模式，如果事务用RC隔离级别，就会可能出现主从不一致的情况。 现在已经不能在statement模式下执行RC事务了，会报下面的错误： Cannot execute statement: impossible to write to binary log since BINLOG_FORMAT = STATEMENT and at least one table uses a storage engine limited to row-based logging. InnoDB is limited to row-logging when transaction isolation level is READ COMMITTED or READ UNCOMMITTED. 假设RC允许，那么假设student表有score字段， 事务A 事务B begin; begin; delete from student where score &lt; 6; / / insert into student(score) values(1); / commit; commit; / 在RR级别下，事务B的语句会阻塞，因为事务A会给满足条件的列加上X锁，给间隙加上gap锁，所以事务B是会被阻塞的。在RC级别下，事务B的语句是不会阻塞的，因此先于事务A提交，提交完成写入binlog，接着A提交写入binlog， 所以在binlog里是这样的（只是举个🌰）： 12insert into student(age) values(1);delete from student where age &lt; 6; 这样binlog被从库消费之后就主从就不一致。 2.2. rowrow是记录到每一行的逻辑语句，比如执行update student set name = &#39;土川&#39; where age &lt; 10的sql，就会生成n条记录。 这样可以避免statement产生的问题，缺点就是日志量太大，可能会产生io压力。 2.3. mixedmixed模式是由mysql自行判断使用哪种模式。转换条件传送门 新版本的MySQL对row level模式也被做了优化，并不是所有的修改都会以row level来记录，像遇到表结构变更的时候就会以statement模式来记录，如果sql语句确实就是update或者delete等修改数据的语句，那么还是会记录所有行的变更；因此，现在一般使用row level即可。 3. binlog内容3.1. mysqlbinlogmysqlbinlog是mysql提供的一个查看binlog的工具，通过该工具可以将二进制文件解析为文本供我们进行阅读，还可以查看远程服务器上的binlog，可以指定时间或偏移量作为start、stop来作为查询条件。如果指定的偏移量不是一个event的起始偏移量，则会报错。 当前msyql是row模式，执行mysqlbinlog -v --start-datetime=&quot;2020-05-25 09:59:59&quot; --stop-datetime=&quot;2020-05-25 10:00:00&quot; mysql-bin.000927 --base64-output=decode-rows，--base64-output=decode-rows为了解码row格式，-v详细输出语句。截取一部分如下 123456789101112131415161718192021222324252627282930# at 26237733#200525 9:59:59 server id 3306 end_log_pos 26237798 CRC32 0xbcd552f0 GTID [commit=no]SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 26237798#200525 9:59:59 server id 3306 end_log_pos 26237883 CRC32 0x5558cbbe Query thread_id=43976966 exec_time=0 error_code=0SET TIMESTAMP=1590371999/*!*/;BEGIN/*!*/;# at 26237883#200525 9:59:59 server id 3306 end_log_pos 26237968 CRC32 0x8f9f400f Table_map: `superq_db`.`superq_trigger_registry` mapped to number 96550# at 26237968#200525 9:59:59 server id 3306 end_log_pos 26238162 CRC32 0x560afdaa Update_rows: table id 96550 flags: STMT_END_F### UPDATE `superq_db`.`superq_trigger_registry`### WHERE### @1=15093### @2='EXECUTOR'### @3='job-executor-saber'### @4='172.88.2.128:19012'### @5='172.88.2.128:10099'### @6=1590371989### SET### @1=15093### @2='EXECUTOR'### @3='job-executor-saber'### @4='172.88.2.128:19012'### @5='172.88.2.128:10099'### @6=1590371999# at 26238162#200525 9:59:59 server id 3306 end_log_pos 26238193 CRC32 0x1e662746 Xid = 3290666026COMMIT/*!*/; # at xxxx：一个event的开头， #200525 9:59:59：时间，20年5月25日，9时59分59秒 server id 3306：server编号 end_log_pos 26237798：下一个事件开始的位置（即当前事件的结束位置+1） CRC32 0xbcd552f0：CRC32是校验和的算法，在上面配置清单里binlog_checksum可以看到，后面跟着的是32位校验和。 Query：event type，具体可以翻阅Event Classes and Types thread_id=43976966：线程id exec_time=0：执行时间 error_code=0：错误码，0表示无错误 Xid = 3290666026：表示redo log和binlog做XA的Xid 3.1.1. 结构体前面说到，event分为header和data，事实上，binlog 事件的结构主要有3个版本： v1: Used in MySQL 3.23 v3: Used in MySQL 4.0.2 though 4.1 v4: Used in MySQL 5.0 and up 现在基本用的是v4版本。 12345678910111213141516171819+=====================================+| event | timestamp 0 : 4 || header +----------------------------+| | type_code 4 : 1 || +----------------------------+| | server_id 5 : 4 || +----------------------------+| | event_length 9 : 4 || +----------------------------+| | next_position 13 : 4 || +----------------------------+| | flags 17 : 2 || +----------------------------+| | extra_headers 19 : x-19 |+=====================================+| event | fixed part x : y || data +----------------------------+| | variable part |+=====================================+ 上面用offset : length描述了各个属性的位置，如果事件头的长度是 x 字节，那么事件体的长度为 (event_length - x) 字节；设事件体中 fixed part 的长度为 y 字节，那么 variable part 的长度为 (event_length - (x + y)) 字节 3.1.2. binlog-checksum校验和功能是为了防止传输过程中发生差错，主从不一致。 关于binlog-checksum有三个参数，分别是 binlog_checksum：默认值是CRC32，可以设置为NONE master_verify_checksum：主库校验event校验和，默认为0，在master thread进行dump的时候校验，在SHOW BINLOG EVENTS校验 slave_sql_verify_checksum：从库校验event校验和，默认为1，当IO thread把event写入到relay log（从库读取到的binlog生成relay log）的时候校验。 mysqlbinlog可以加上--verify-binlog-checksum参数，打印有问题的sql。 如果校验失败会报错，可以用pt-table-checksum工具进行修正，关于更多，另行了解。 3.2. SHOW BINLOG EVENTS这个是mysql命令，也是用来阅读binlog。使用方式是SHOW BINLOG EVENTS [IN &#39;log_name&#39;] [FROM pos] [LIMIT [offset,] row_count]，中括号都是可选项。 3.3. GTID可以在日志里看到GTID的字眼，GTID即Global Transaction ID，全局事务id，由server_uuid:transaction_id组成，是在mysql5.6引进的一个特性。 组复制插件MGRmysql官方的一个高可用插件，使用了PAXOS协议。在这种一致性协议中需要有一个全局增长的command index，GTID就承担了这个角色。 执行show variables like &#39;%gtid%&#39;;，输出 12345678910111213+----------------------------------+-----------+| Variable_name | Value |+----------------------------------+-----------+| binlog_gtid_simple_recovery | ON || enforce_gtid_consistency | OFF || gtid_executed_compression_period | 1000 || gtid_mode | OFF || gtid_next | AUTOMATIC || gtid_owned | || gtid_purged | || session_track_gtids | OFF |+----------------------------------+-----------+8 rows in set (0.02 sec) gtid_mode其实是OFF状态。 关于更多，另行了解。 4. 主从复制主从复制有基于binlog和基于GTID两种方式。基于binlog的复制模式的基本流程是： master事务提交，将记录变更写入binlog slave的io进程连接master，从指定位置或从0开始请求日志 master返回日志给slave，并带上binlog名称和下一个binlog消费位置 slave接收到日志，将日志追加到relay log末端，并记录binlog名称和binlog消费位置，下次请求使带上。 slave的sql进程不断读relay log，执行sql。 如果slave开启了binlog，又会将执行的sql变更记入binlog；如果slave又是其他slave的master，就会执行一样的逻辑。 在slave上执行，show slave status\\G，部分输出如下 12345678910111213141516171819202122232425mysql&gt; show slave status\\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 11.198.116.79 Master_User: replicator Master_Port: 3018 Connect_Retry: 60 Master_Log_File: mysql-bin.000831 Read_Master_Log_Pos: 1151797 Relay_Log_File: slave-relay.002490 Relay_Log_Pos: 313 Relay_Master_Log_File: mysql-bin.000831 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 1151797 Relay_Log_Space: 769 如果Read_Master_Log_Pos和Exec_Master_Log_Pos一致，表示从库已经追赶上主库。 在主库执行show master status\\G，可以看到主库当前正在写入的binlog和位置。 5. 参考 《Event Structure》 《MySQL为什么默认隔离级别为可重复读？》 《10分钟学会Mysql之Binlog》","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://htchz.cc/categories/Mysql/"}],"tags":[]},{"title":"[Mysql]漫游redo log","slug":"Mysql-redo-log","date":"2020-05-19T14:00:05.000Z","updated":"2020-06-05T09:01:05.959Z","comments":true,"path":"1559835943.html","link":"","permalink":"https://htchz.cc/1559835943.html","excerpt":"","text":"redo log负责记录物理数据页，所以无论执行多少次都是幂等的；而binlog是记录逻辑数据，执行多次就可能重复数据。 数据结构是一个环形数组，innodb将未写入磁盘的页叫做脏页，redo log的作用就是记录脏页的数据。 在宕机恢复时，一个事务是否持久化是根据redo log刷盘情况决定的。如果一个事务的redo log已经全部刷入磁盘，那么这个事务是有效的，反之需要根据undo log回滚。 redo log在硬盘中是分成多块来存储的，以ib_logfile[number]命名。 执行SHOW GLOBAL VARIABLES LIKE &quot;innodb_log%&quot;;， 1234567891011+-----------------------------+-----------+| Variable_name | Value |+-----------------------------+-----------+| innodb_log_buffer_size | 67108864 || innodb_log_checksums | ON || innodb_log_compressed_pages | ON || innodb_log_file_size | 536870912 || innodb_log_files_in_group | 4 || innodb_log_group_home_dir | ./ || innodb_log_write_ahead_size | 8192 |+-----------------------------+-----------+ innodb_log_files_in_group指定了redo log文件被分为几部分，每一部分的文件大小都是一样的，当写入ib_logfile3后，又继续写入ib_logfile0，如此循环。 这是在磁盘里的文件， 1234567[root@dev_test63 mysql3306]# ll ib*-rw-r----- 1 mysql mysql 683671552 5月 20 01:25 ibdata1-rw-r----- 1 mysql mysql 536870912 5月 20 01:24 ib_logfile0-rw-r----- 1 mysql mysql 536870912 5月 19 11:10 ib_logfile1-rw-r----- 1 mysql mysql 536870912 5月 20 01:24 ib_logfile2-rw-r----- 1 mysql mysql 536870912 5月 20 01:25 ib_logfile3-rw-r----- 1 mysql mysql 79691776 5月 20 01:01 ibtmp1 ibtmp1是临时表空间，ibdata1是共享表空间。 1. 为什么要有redo log: redo log是顺序写入的，而数据页落盘是随机存储。 延迟刷脏页可以起到合并多次修改的作用，mysql的最小存储单位是页，一个页有多行，如果每次修改一行就要更新整个页，并不是那么能接收。 有了redo log之后，对于一行数据，首先更新buffer pool（在这之前还有undo log），然后再写入log buffer。 2. 组织结构由于redo记录的是物理变更，比如在“第100表空间第100页偏移量1024写入4个字节balabala”，而不是描述第几行改成什么样，一行记录变更涉及的物理页可能有很多，所以可能产生一条redo log，也有可能是多条redo log，这个和undo log不同。 2.1. redo log这是一条redo log的通用结构 type：redo log的类型，可能是基础类型，也可能是复杂类型 Space ID：表空间id page number：页号 data：redo log内容 具体type的类型有很多，参考底部链接，其中包括undo log对应的redo logMLOG_UNDO_INSERT。一个操作产生的redo log可能是一个，也可能是一组redo log。 2.2. log block组织redo log的是log block，一个log block是存储redo log的基本单位，和页有点类似。 log block header：存放block信息 log block body：存放多条redo log log block trailer：存放block的校验值，用于正确性校验 log buffer和log file都是以log block为基本操作单位，redo log在log block里顺序写入。 2.3. mtrMini-Transaction，即mtr， 前面说到一个操作可能产生一组redo log，那么这组redo log是需要保证事务性的，innodb使用mtr这种比transaction更小粒度的事务，来保证一组redo的事务性。 mtr开启后，会定位到要修改的page的位置，对索引加锁；之后执行一系列写操作，期间产生的redo log会暂存在mtr对象中；mtr提交时，需要把暂存的redo log组放入log buffer中，然后把修改的脏页放入flush list，之后释放page的锁。 3. 刷盘策略这里有几个概念 buffer pool：指在内存中的数据页，innodb需要把物流数据页读到内存中进行修改。 log buffer：指redo log的buffer，属于进程。 redo log file：指内存中的redo log文件，属于操作系统，待fsync到磁盘中。 redo log刷盘时机如下： 有事务提交时，根据事务提交时的刷盘策略决定是否刷盘 innodb_flush_log_at_timeout默认值为1，也就是1s内如果没发生刷盘，需要进行刷盘 当log buffer中已经使用的内存超过一半时 当到达checkpoint时 3.1. 事务提交时的刷盘策略innodb_flush_log_at_trx_commit指定了redo log的事务提交刷盘策略，分别三个值0：每次提交事务，不会将log buffer写入redo log file，而是由master thread每秒将log buffer写入redo log file，并调用fsync落盘1：每次提交事务，将log buffer写入redo log file，同时调用fsync落盘，是最严格也是性能最差的策略2: 每次提交事务，将log buffer写入redo log file，每秒调用fsync落盘 0和2看起来有点相似。区别在于，前者没有将log buffer同步写入redo log file，要知道redo log file是文件，所以0没同步写入文件，性能会比2高，但mysql崩溃时，会丢失日志；而2同步写入文件，已经将日志提交到操作系统了，只有操作系统宕机了才会丢失日志。 我们线上数据库innodb_flush_log_at_trx_commit的值是1，有一次同事清理数据时做了个全表更新，redo log疯狂刷盘，从而导致数据库缓慢，于是运维关闭了双1（innodb_flush_log_at_trx_commit和sync_binlog），暂停了清理脚本，才得以恢复。 4. LSNLog sequence number是一个8字节的不断增长的数字，表示日志编号，起到一个类似版本的作用，很多地方都有这个LSN，最终需要这n个地方的LSN达到一致。 通过LSN可以获得： 数据页的版本信息。 写入的日志总量，通过LSN开始号码和结束号码可以计算出写入的日志量。 可知道检查点的位置。 执行SHOW ENGINE INNODB STATUS;可以看到和LSN有关的信息： 123456789---LOG---Log sequence number 1509428892Log flushed up to 1509428892Pages flushed up to 1509300590Last checkpoint at 15093005810 pending log flushes, 0 pending chkp writes3554874 log i/o's done, 0.00 log i/o's/second Log sequence number是redo log buffer的LSNlog flushed up to是刷到redo log file在硬盘中的LSN；pages flushed up to是已经刷到磁盘数据页上的LSNlast checkpoint at是上一次检查点所在位置的LSN 可以看到LSN不是完全一致，测试环境db是空闲的，Log sequence number和log flushed up to是相同的，pages flushed up to落后，这是因为脏页很少的话可以暂时不刷到磁盘。 一般来说，log sequence number &gt; log flushed up to 和 pages flushed up to &gt; last checkpoint at 可能会出现数据页刷盘快于redo log刷盘的情况，这时checkpoint是有机制保护数据慢于日志，所以会暂停数据页刷盘，等待日志刷盘进度超过数据刷盘。 由于记录物理数据页，如果在一个事务里把a更新成b，又把b更新为a，会不会保存到redo log里的？ 试验过后，执行SHOW ENGINE INNODB STATUS\\G，可以看到Log sequence number有增加； 5. checkpoint由于redo log相当于给数据页做了个备份，所以事务提交时并不一定要把数据页落盘。但是：1：buffer pool是有限的，2：redo log buffer是有限的。所以需要一个时机，将buffer pool里的数据落盘，同时清除redo log buffer里已经落盘的数据页，这个时机就是checkpoint。数据库重启后的恢复，只需要从checkpoint lsn算起，checkpoint lsn之前的数据都是认为已经持久化的。 checkpoint的目的很简单，即把数据页落盘，但是什么时候、刷多少页到磁盘、从哪里取脏页都有些不同。 checkpoint_lsn是指checkpoint发生刷盘之后，记录此次checkpoint的lsn到redo log file的第一个文件头可以理解为管理数据页缓冲的数据结构，需要保证FLUSH列表：LRU的有两种Checkpoint，分别为：Sharp Checkpoint、Fuzzy Checkpoint。 Sharp Checkpoint是全部刷盘，发生在切换redo log文件或者数据库关闭的时候，需要把buffer pool的数据页全刷盘。 MySQL停止时是否将脏数据和脏日志刷入磁盘，由变量innodb_fast_shutdown={ 0|1|2 }控制，默认值为1，即停止时忽略所有flush操作，在下次启动的时候再flush，实现fast shutdown。 Fuzzy Checkpoint是部分刷盘，分为四种。 5.1. master thread checkpoint由master线程控制，每1秒，每10秒刷入一定比例的脏页到磁盘，异步。 5.2. flush_lru_list checkpoint从MySQL5.6开始可通过innodb_page_cleaners变量指定专门负责脏页刷盘的page cleaner线程的个数，该线程的目的是为了保证lru_list表有可用的空闲页。 5.3. async/sync flush checkpoint：同步刷盘/异步刷盘。例如还有非常多的脏页没刷到磁盘(非常多是多少，有比例控制)，这时候会选择同步刷到磁盘，但这很少出现；如果脏页不是很多，可以选择异步刷到磁盘，如果脏页很少，可以暂时不刷脏页到磁盘。 这里有四个配置 12345678innodb_log_files_in_group=4innodb_log_file_size=4G总文件大小: 17179869184log_sys-&gt;max_modified_age_async = 12175607164 (71%)log_sys-&gt;max_modified_age_sync = 13045293390 (76%)log_sys-&gt;max_checkpoint_age_async = 13480136503 (78%)log_sys-&gt;max_checkpoint_age = 13914979615 (81%) 设，checkpoint_age = log_lsn - last_checkpoint_lsn，max_modified_age = log_lsn - 脏页最小lsn 当max_modified_age &gt; max_modified_age_asyncs，需要flush_list取出脏页，异步刷盘当max_modified_age &gt; max_modified_age_sync，需要flush_list取出脏页，同步刷盘 当checkpoint_age &gt; max_checkpoint_age_async，可以无需等待checkpoint完成当checkpoint_age &gt; max_checkpoint_age，需要同步等待checkpoint完成 5.4. dirty page too much checkpoint脏页太多时强制触发检查点，目的是为了保证缓存有足够的空闲空间。脏页比例由变量 innodb_max_dirty_pages_pct 控制，MySQL 5.6默认的值为75，即当脏页占缓冲池的75%后，就强制刷一部分脏页到磁盘。 关于上面提到的列表： lru_list：是一个使用了最近最少使用算法的列表，可以理解为管理数据页缓冲的数据结构。flush_list：lru的的脏页会放进这个列表，但是不会从lru移除，所以脏页会存在两个地方。flush_list里的脏页会根据lsn最为排序依据，保证lsn小的先落盘。free_list：free_list如果没有空闲页可以分配，就会从lru_list批量淘汰数据页以供使用。 6. redo log太大和太小可以看到，async/sync flush checkpoint这种类型的checkpoint其实是和log_file的大小有关的。如果log_file小了，会使checkpoint变多，影响innodb性能；如果log_file大了，两次checkpoint跨度大，在恢复的时候可能就会等待太久（挂了跑路吧😄）。 具体多大应该结合实际测试。 7. 两阶段提交 崩溃恢复另外讲。 8. 参考 《详细分析MySQL事务日志(redo log和undo log)》 《InnoDB log file 设置多大合适？》 《MySQL运维内参》节选 | InnoDB日志管理机制（五） 《Redo Log——第一篇》 《MySQL · 引擎特性 · InnoDB redo log漫游》","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://htchz.cc/categories/Mysql/"}],"tags":[]},{"title":"[Mysql]漫游undo log","slug":"Mysql-undo-log","date":"2020-05-10T01:51:00.000Z","updated":"2020-06-05T09:00:41.138Z","comments":true,"path":"1791523990.html","link":"","permalink":"https://htchz.cc/1791523990.html","excerpt":"Innodb学会是不可能学会的，这辈子都学不会的。","text":"Innodb学会是不可能学会的，这辈子都学不会的。 innodb是一个日志先行（Write-ahead logging）的存储引擎，这也是大部分关系型数据库的特点。而像redis这样的nosql就是数据为先，再进行落盘。 undo log和redo log和binlog，这三个log是mysql及innodb的关键。这三种日志都会刷盘，其中： undo log: 事务原子性和多版本控制MVCC（事务隔离） redo log: 事务持久性，宕机恢复 binlog: 宕机恢复，主从同步 可以看出三个日志在对应功能上需要相互协作。undo log和redo log是事务日志；redo log要等binlog写入成功才能commit；undo Log保证事务的原子性，redo log保证事务的持久性。 网上大多都是讲undo log能做什么，但没几篇讲清楚undo log组织结构。innodb最小存储粒度是页page，而页就分为FIL_PAGE_INDEX索引页（索引即数据）和FIL_PAGE_UNDO_LOGundo页。 部分概念是关于MVCC的，需要配合[Mysql]Innodb的快照读实现食用，本文不做讨论。 undo log就是个历史版本，落盘后不和redo log存在一起。 1. 表空间InnoDB存储引擎提供二种数据库表的存储方式 系统表空间：所有数据上放在一起，物理文件可以拆成多个文件。 独占表空间：每个表有自己的物理文件，性能更好。 关于更多不在讨论范围。 2. 结构层次Rollback Segment（rseg）称为回滚段。Mysql5.6之前undo默认记录到系统表空间（ibdata），如果开启了 innodb_file_per_table ，将放在每个表的.ibd文件中。5.6之后还可以创建独立的undo表空间，8之后更是默认打开独立undo表空间，最低数量为2，这样才能保证至少一个undo表空间进行truncate，一个undo表空间继续使用。独立undo表空间的文件格式是undo001，undo002…… 每个rollback Segment中默认有1024个undo log segment，mysql5.5后1个undo表空间支持128个rollback Segment。0号rollback Segment默认在系统表空间ibdata中，1-32rollback Segment在临时表空间，33～128在独立undo表空间中（没有打开则在系统表空间ibdata中，这样系统表空间会太大），所以1个表空间最多支持96*1024个事务，超了就报错啦。 一个undo log segment称为undo log或undo slot或undo；一个undo log对象对应多个undo log record，也就是记录的历史版本。 一个undo log segment有一个page链表，undo log record就是放在page中的，当一个page不足以放下新的undo log record时，会分配新的page，放到链表尾部。 一个undo log segment其实是一个页叫undo log header page，有INSERT/UPDATE两个类型。这个页有一项内容TRX_UNDO_PAGE_LIST是一个链表，即undo page链表。 简单来说，结构是这样的： rollback segments(128) undo log segments(1024) undo page(N） undo record undo record … A collection of undo logs. Undo log segments exists within rollback segments. An undo log segment might contain undo logs from multiple transactions. An undo log segment can only be used by one transaction at a time but can be reused after it is released at transaction commit or rollback——mysql#undo_log_segment 一个rollback Segment可以被多个事务使用。而一个undo log segment只能被一个事务占有。由于undo log segment区分插入和更新，又区分临时表和普通表，所以一个事务至多占有四个undo log segment。 2.1. 头这张图里， Undo Log Segment Header：是undo log的第一页，不存放record undo log header：图里Undo Log Segment Header的TRX_UNDO_LAST_LOG属性指向了一个undo page，每一个undo page都有undo log header描述这个undo page的信息。 undo page header：图里没有，这个header类似于数据页的page header。 3. 写undo log过程3.1. 分配回滚段当读写事务开启或只读事务转化为读写事务时，会为一个事务分配事务id和一个回滚段（只读事务的id是0）。 分配逻辑： 轮询（环形缓冲，同redo log）选取一个可用的回滚段； 选取的回滚段引用计数+1（多对一），防止被回收（truncate）。 临时表使用临时表回滚段，特点是不用写redo log，普通表使用的普通回滚段需要写redo log。 3.2. 使用回滚段数据变更时，insert和update分别写相似但不同的undo log。 临时表不用写redo log 操作时未分配undo log statement，则对变更类型分配对应的undo log statement 分配undo log statement时，如果缓存列表有可用的undo log statement，取出来使用。 redo log有许多种类型，这里是一种type为MLOG_UNDO_INSERT的日志，保证undo log是有效的。 3.3. 写入undo loginsert的undo record长这样 type_cmpl：undo log类型，purge时用 undo no：事务编号 table id：表id update的undo record长这样 DATA_ROLL_PTR：该行对应的前一个历史版本的指针，从而构建一个历史版本的链表 type_cmpl：undo log类型，辅助purge线程清理 (posN,lenN,u_old_colN)[]：字段旧值，只需要记录被更新的字段 (pos,len,colN)[]：被更新的二级索引，回滚的时候需要 undo no：事务编号 table id：表id 事务no和事务id还是有些不同的，事务编号是用来排序的，在事务提交之前通过全局计数器生成，目的是为了放入histroy list有序，方便purge清理。 不同类型的undo record下有些属性没有，例如索引没变化的情况下，(pos,len,colN)[]就没记录。 (其实我不知道记unique key干嘛的) 3.4. undo log类型purge线程在对待undo log时，会根据undo log的类型做不同的动作，下面分为三类，括号里是动作 插入： TRX_UNDO_INSERT_REC：表示新增记录（主键记入日志） TRX_UNDO_UPD_DEL_REC：当表中有一条被标记为删除的记录和要插入的数据主键相同时，实际是更新这条被标记删除的记录。（主键记入日志） 更新： TRX_UNDO_UPD_EXIST_REC：（将主键和被更新了的字段内容记入日志） 删除： TRX_UNDO_DEL_MARK_REC：（主键记入日志）标记删除 3.5. 插入插入时构建的undo log，包括undo类型，undo no，table id，主键各列信息。 insert undo log在事务提交后就会被删除。 3.6. 更新更新时构建的undo log，包括undo类型，undo no，table id，主键各列信息，data_trx_id、data_roll_pointer，被更新的二级索引，n_updated，字段旧值。 MVCC那篇讲过，每行记录都有三个隐藏字段，所以记录的old_trx_id、old_roll_pointer会被记入undo log，old trx_id表示修改的事务id，old_roll_pointer指向前一个undo record。 如果要更新一行记录的主键，需要删除记录（delete_mark置1，不能同步删除，为了MVCC），再插入新记录，所以会有TRX_UNDO_DEL_MARK_REC和TRX_UNDO_INSERT_REC两条日志。 对于二级索引的更新都是删除+插入。 如果更新一行前后的存储空间不一样大，也需要删除（同步删除）再插入。 3.7. 删除删除一条记录，其实分两个阶段， prepare阶段：将delete标志位置1，构造undo log purge阶段：这个发生在事务提交后，将记录移动到垃圾链表，等待复用。 垃圾链表是指数据页上的一个属性PAGE_FREE，指向一个链表的头节点，可以参阅文章底部的链接。 删除属于更新，所以他们的undo log是同一个数据结构，不过删除类型的undo log少了n_updated和字段旧值，以及被更新的二级索引。 3.8. 事务prepare事务开始的阶段，需要将undo log header page的事务状态TRX_UNDO_STATE设置为TRX_UNDO_PREPARED 3.9. 事务提交先说一下history list，show engine innodb status执行这个命令我们可以看到history list 123456789101112*** WE ROLL BACK TRANSACTION (1)------------TRANSACTIONS------------Trx id counter 2915975770Purge done for trx's n:o &lt; 2915975770 undo n:o &lt; 0 state: running but idleHistory list length 47LIST OF TRANSACTIONS FOR EACH SESSION:---TRANSACTION 421366361910208, not started0 lock struct(s), heap size 1136, 0 row lock(s)---TRANSACTION 421366361903824, not started0 lock struct(s), heap size 1136, 0 row lock(s) 这个值表示还有多少undo log没被清理，这个值太大的话，说明有undo log由于有大事务存在而无法被清理。 Undo Log Segment Header有个TRX_UNDO_STATE，事务提交时，TRX_UNDO_STATE有三种值， 如果当前的undo log只占一个page，且占用大小使用不足其3/4时(TRX_UNDO_PAGE_REUSE_LIMIT)，则状态设置为TRX_UNDO_CACHED，该undo对象会随后加入到undo cache list上； 如果事务类型是TRX_UNDO_INSERT_REC，则状态设置为TRX_UNDO_TO_FREE 如果不满足上面的，就需要purge线程去清理，状态设置为TRX_UNDO_TO_PURGE 对于update undo对象需要放入history list上，具体是将当前undo加入到回滚段header的TRX_RSEG_HISTORY链表上。 如果update undo只有普通表，则给History list length+1，如果还有临时表，则+2，然后唤醒purge线程。 如果update undo需要缓存，则放入回滚段的update_undo_cached链表上；否则释放undo对象内存。 对于insert undo在事务释放锁、从读写事务链表清除、关闭read view后才进行，也就是等所有后事都办完才清理。 如果insert undo需要缓存，则放入回滚段的insert_undo_cached链表上；否则释放undo对象内存。和update undo不同的是，insert undo不需要放入hisotry list。 事务提交后，回滚段的引用计数-1。 tip1：由于cache的原因，即使db空闲中，history list的长度一般都不会是0。tip2：insert undo的重用是直接reset，而update undo的重用是会和上一个事务的undo page共存的，具体是undo page上的undo log header有TRX_UNDO_NEXT_LOG 和TRX_UNDO_PREV_LOG来表示事务在页面中的偏移量的 3.10. 清理 purgepurge发生在事务commit时。update undo会被放入history list中，当没有活跃的事务作用于undo log时，会被purge线程清理。如何判断有没有活跃的事务作用于undo log?innodb会快克隆一个活跃的最老的read view，所有在这个read view之前的undo log都是可以清理的。 purge线程从history list批量取到undo log后，对于in-place更新，需要看需不需要清理二级索引；对于删除操作，需要将删除记录放入数据页垃圾链表PAGE_FREE中。 3.11. 回滚事务回滚只需要拿到undo log的进行逆向操作就可以了。 对于标记删除的记录清理delete_mark；对于更新，将数据回滚到最老版本，回滚索引；对于插入操作，直接删除聚集索引（后）和二级索引（先）。 3.12. 持久化todo 3.13. 崩溃恢复其他篇。 4. 后记由于insert和update的种种区别，以至于undo log segment需要分成两种。 5. 参考 《MySQL · 引擎特性 · InnoDB undo log 漫游》 《innodb源码分析之page结构解析》 《MySQL 5.7 Reference Manual 14.6.7 Undo Logs》 《InnoDB undo log》","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://htchz.cc/categories/Mysql/"}],"tags":[]},{"title":"[网络]端口转发","slug":"网络-利用iptables转发流量","date":"2020-05-01T15:53:39.000Z","updated":"2020-07-07T07:03:07.209Z","comments":true,"path":"2735588161.html","link":"","permalink":"https://htchz.cc/2735588161.html","excerpt":"","text":"之前买的GGC家的HK vps，从去年开始电信访问一直丢包，丢包率一上去，带宽再大速度也是提不上去（[网络]TCP拥塞控制那些事）。 于是想到买个nat机中转一下流量。 (2核384内存，适合用来中转流量) 1. iptables端口转发nat到手后，机器镜像用的是centos7，关闭firewall，把iptables装上。 123456# 关闭 firewalldsystemctl disable firewalld --now# 装iptablesyum install iptables-services# 开机启动systemctl enable iptables.service --now 接着开启ipv4转发，默认iptables是关闭ipv4转发 123456# 临时开启 ipv4 转发echo 1 &gt; /proc/sys/net/ipv4/ip_forward# 永久开启 ipv4 转发echo 'net.ipv4.ip_forward = 1' &gt;&gt; /etc/sysctl.conf# 使生效sysctl -p 接着是加iptables规则，需要在nat表加入一条DNAT和一条SNAT，DNAT是修改目的地址，转发流量到HK vps；SNAT是修改源地址，保证流量回到这台机上（只有这台机知道怎么回到我家）。 假设NAT机监听10086端口，HK vps的ip是104.104.104.104，ss服务端口是10010，NAT机内网地址是192.168.1.10 12345678910# DNATiptables -t nat -A PREROUTING -p tcp -m tcp --dport 10086 -j DNAT --to-destination 104.104.104.104:10010# SNAT，--to-source ip[:port] port可以不指定，会是随机的iptables -t nat -A POSTROUTING -p tcp -m tcp -d 104.104.104.104 --dport 10010 -j SNAT --to-source 192.168.1.10# 应用iptablesservice iptables save# 重启systemctl restart iptables# 看下nat表iptables -nL -t nat 此外，nat机要开放10086端口。 最后一步，在nat控制面板的NAT转发策略创建策略，创建一个映射到该机器10086的策略，就能拿到公网ip和端口了。 2. firewall端口转发firewall的会简单一些 12345678# 允许防火墙伪装IPfirewall-cmd --add-masquerade --permanent# 检查是否允许伪装IPfirewall-cmd --query-masquerade # 添加转发规则firewall-cmd --permanent --zone=public --add-forward-port=port=10086:proto=tcp:toport=10010:toaddr=104.104.104.104# 开放监听端口firewall-cmd --zone=public --add-port=10086/tcp --permanent","categories":[{"name":"网络","slug":"网络","permalink":"https://htchz.cc/categories/网络/"}],"tags":[{"name":"iptables","slug":"iptables","permalink":"https://htchz.cc/tags/iptables/"}]},{"title":"[JVM]JVM中三色标记法","slug":"JVM-JVM中三色标记法","date":"2020-03-17T14:53:15.000Z","updated":"2020-04-02T08:07:09.175Z","comments":true,"path":"2394647798.html","link":"","permalink":"https://htchz.cc/2394647798.html","excerpt":"","text":"三色标记算法是描述追踪式回收器的一种有用的方法，利用它可以推演回收器的正确性。对象分成三种类型: 黑色:根对象，或者该对象与它的子对象都被扫描 灰色:对象本身被扫描,但还没扫描完该对象中的子对象 白色:未被扫描对象，扫描完成所有对象之后，最终为白色的为不可达对象，即垃圾对象 根对象被置为黑色，子对象被置为灰色。继续由灰色遍历,将已扫描了子对象的对象置为黑色。 遍历了所有可达的对象后，所有可达的对象都变成了黑色。不可达的对象即为白色，需要被清理。这看起来很美好，但是如果在标记过程中，应用程序也在运行，那么对象的指针就有可能改变。这样的话，我们就会遇到一个问题：对象丢失问题 我们看下面一种情况，当垃圾收集器扫描到下面情况时： 12A.c=CB.c=null 这样，对象的状态图变成如下情形：这时候垃圾收集器再标记扫描的时候就会下图成这样： 显然，C是白色的，也就是漏标了，会被当成垃圾回收掉，这对程序来说是不可以接受的。 漏标的情况只会发生在白色对象中，且满足以下任意一个条件： 并发标记时，应用线程给一个黑色对象的引用类型字段赋值了该白色对象 并发标记时，应用线程删除所有灰色对象到该白色对象的引用 事实上，方法1是CMS的实现关键，方法2是G1的实现关键，有关实现就移步[JVM]CMS和[JVM]G1","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"GC","slug":"GC","permalink":"https://htchz.cc/tags/GC/"},{"name":"JVM","slug":"JVM","permalink":"https://htchz.cc/tags/JVM/"}]},{"title":"[JVM]内存模型","slug":"JVM-内存模型","date":"2020-03-17T06:28:45.000Z","updated":"2020-06-15T03:57:27.881Z","comments":true,"path":"93872510.html","link":"","permalink":"https://htchz.cc/93872510.html","excerpt":"补个内存模型笔记。","text":"补个内存模型笔记。 JVM 内存共分为虚拟机栈、堆、方法区（jdk8是元空间，在jvm之外）、PC寄存器（程序计数器）、本地方法栈五个部分。这是jdk7的实现，方法区其实就是永久代。这是jdk8的实现，永久代废除，将类信息放到本地内存中，也就是放在jvm外。 1. 虚拟机栈线程私有。一个线程一个虚拟机栈 一个栈里有多个帧，栈帧包含局部变量表、操作数栈、动态链接、方法出口等。线程调用方法时会创建栈帧入栈，结束方法时会出栈。 栈深度超过限制会StackOverflowError，栈帧申请时内存不足会报OutOfMemoryError。 1.1. 局部变量表用于存放局部变量和方法参数的引用，使用索引进行访问。 这个表的组成单位是slot，32位的jvm会使用32位的slot，这也就是为什么long/double在32jvm不是线程安全的。 被虚拟机栈引用的对象，属于GCROOT，不会回收。如果一个方法很长，但是一个大对象不再被使用，可以设置为将大对象的变量赋值为null来帮助gc。（长方法你就该优化一下了） 1.2. 操作数栈也是存放基本数据类型或引用的，只能进行出栈/压栈，使用场景如发起方法调用的时候放参数，算术运算的中间值 1.3. 动态链接一个引用，指向方法区的方法，由于java多态特性，编译后大多数不能确定哪个方法的调用，只能在运行时才能将符号引用转换为直接引用。 1.4. 方法返回值如果方法是正常退出（没有异常）且有返回值，调用方需要从这里取到返回值，并在栈帧的操作数栈进行压栈。 2. PC寄存器（程序计数器）线程私有。一个线程一个PC寄存器，也叫程序计数器。 PC寄存器存放了线程当前执行的指令的地址，用于上下文切换后恢复线程上下文。 如果当前执行的是native方法，那么PC寄存器为空。 3. 本地方法栈线程私有。一个线程一个本地方法栈。 类似于虚拟机栈，只不过表示的是native方法。 栈深度超过限制会StackOverflowError，栈帧申请时内存不足会报OutOfMemoryError。 4. 堆线程共享。GC区域。 5. 方法区(元空间)线程共享。主要用于存储类的信息、常量池、静态变量、及时编译器编译后的代码等数据。方法区逻辑上属于堆内存。这就给gc带来了负担，因为这些基本都是不变的对象。 jdk8将这部分挪到堆外内存，称为元空间（Metaspace） 5.1. 方法区，元空间与永久代方法区是jvm规范，Hotspot以前用永久代实现，放在了堆内存里。jdk8完全废除了永久代，将这些数据放到了本地内存。 主要原因是: 常量存在永久代中，容易出现性能问题和内存溢出。 类及方法的信息等比较难确定其大小，因此对于永久代的大小指定比较困难，太小容易出现永久代溢出，太大则容易导致老年代溢出。比如jsp生成动态类，这是比较难预测的。 永久代会为 GC 带来不必要的复杂度，并且回收效率偏低，毕竟这些东西是一直不变的。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://htchz.cc/tags/JVM/"}]},{"title":"[k8s]istio自动注入失败","slug":"k8s-istio自动注入失败","date":"2020-02-26T16:05:20.000Z","updated":"2020-02-26T17:25:53.347Z","comments":true,"path":"855478903.html","link":"","permalink":"https://htchz.cc/855478903.html","excerpt":"查了我一天喵的","text":"查了我一天喵的 1. 过程istio两种注入模式，一种是执行istioctl kube-inject将目标deployment的yaml先修改，也就是手动注入sidecar和initContainer，另一种就是在pod被部署的时候，利用k8s的webhook机制，进行自动注入。 在自动注入前，要在部署容器的namespace打上istio-injection: enabled标签，这样才会自动注入，同时，还可以指定template的注解:sidecar.istio.io/inject: true来做更小粒度的控制。 在使用bookinfo的demo过程中，自动注入并没有生效，甚至连pod都没有create。 执行kubectl describe deployment productpage查看其中一个deployment，发现只有一个事件， Scaled up replica set productpage-v1-596598f447 to 1，然后就没有然后了。 执行kubectl describe replicaset productpage-v1-596598f447，显示failed calling webhook “sidecar-injector.istio.io”: Post https://istio-sidecar-injector.istio-system.svc:443/inject?timeout=30s: context deadline exceeded`， 查看apiserver的日志，一直提示 &quot;sidecar-injector.istio.io&quot;: Post https://istio-sidecar-injector.istio-system.svc:443/inject?timeout=30s: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)查看controller-manager的日志，一直提示 Event(v1.ObjectReference{Kind:&quot;HorizontalPodAutoscaler&quot;, Namespace:&quot;istio-system&quot;, Name:&quot;istio-telemetry&quot;, UID:&quot;da322eac-127a-4c78-89e6-db614d697949&quot;, APIVersion:&quot;autoscaling/v2beta2&quot;, ResourceVersion:&quot;10847941&quot;, FieldPath:&quot;&quot;}): type: &apos;Warning&apos; reason: &apos;FailedComputeMetricsReplicas&apos; invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: no metrics returned from resource metrics API看起来是在说找不到metrics api？ 上官网，Istio / Sidecar Injection Problems没有一个描述是符合的。github issue也没有提到要安装metrics-server。 最后找到一篇博客，里面提到 于是乖乖安装metrics-server，然后注入sidecar的pod就成功创建了 = = 其实一早就看到关于metrics api的报错，但是我认为那是收集监控数据的，于是没鸟他，还是图样了。 2. demo","categories":[{"name":"容器","slug":"容器","permalink":"https://htchz.cc/categories/容器/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://htchz.cc/tags/k8s/"},{"name":"istio","slug":"istio","permalink":"https://htchz.cc/tags/istio/"}]},{"title":"[Java代理]Spring的cglib与final方法的坑","slug":"Java代理-spring的cglib与final方法的坑","date":"2020-01-12T05:51:39.000Z","updated":"2020-07-01T12:23:51.850Z","comments":true,"path":"4249712641.html","link":"","permalink":"https://htchz.cc/4249712641.html","excerpt":"","text":"1. 前言cglib是采用生成目标类subclass方式来代理目标类的，所以如果目标类的方法是final的话，就会直接调用目标类的方法。Spring的cglib代理实现有点坑，就是生成的代理对象是没有调用父类构造函数的，这个代理对象的成员变量不会初始化。 2. nullSpring的aop是基于代理的，而采用cglib的实现下，对于一个bean，假设只代理一次的情况下（增强一次），内存实际是有两个对象，一个代理对象，一个目标对象。当我们调用代理对象的非fianl方法，代理对象调用完切面逻辑，不是调用自己父类方法，而是调用目标对象的目标方法；如果调用代理对象的final方法，代理对象会直接调用目标方法。 看下面的例子： 12345678910111213141516171819202122232425262728293031public class DefaultRunner implements Runner &#123; protected final Logger log = LoggerFactory.getLogger(getClass()); @Override public final void run(String name) &#123; log.info(\"I'm &#123;&#125;\", name); &#125;&#125;public class CglibProxy implements MethodInterceptor &#123; private Enhancer enhancer = new Enhancer();· @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; objects[0] = \"hijacked!\"; return methodProxy.invokeSuper(o, objects); &#125; public Object newProxy(Class klass) &#123; enhancer.setSuperclass(klass); enhancer.setCallback(new CglibProxy()); return enhancer.create(); &#125;&#125;@Testpublic void testCglib() &#123; CglibProxy cglibProxy = new CglibProxy(); DefaultRunner runner = (DefaultRunner) cglibProxy.newProxy(DefaultRunner.class); runner.run(\"proxy\");&#125; 如果我们调用代理对象的runner.run(&quot;Tony&quot;)，日志输出的将会是“I’m Tony”而不是“I’m hijacked!”。 而Spring使用org.springframework.aop.framework.CglibAopProxy对目标对象进行代理，我的程序在调用一个fianl方法的时候，报了一个NPE异常，debug进去一看，成员变量logger居然是null。事实上，Spring的CglibAopProxy生成的代理对象的成员变量都是null，因为从Spring设计上，代理类只负责增强逻辑，然后再调用目标对象的方法，所以并没有初始化成员变量的必要。 实际上我也不需要这个对象被代理。。手动new一个对象就正常了。 3. 为什么没有初始化成员变量？我们在反射生成代理对象的时候，会调用构造方法。如果子类无参构造函数没有写super()，编译的时候，是会写进一句super()的。 但是由于是代理类是用子节码生成的，所以代理类构造函数是没有调用super()的，故没有初始化成员变量。 4. 参考 Spring AOP避坑指南","categories":[{"name":"Proxy","slug":"Proxy","permalink":"https://htchz.cc/categories/Proxy/"}],"tags":[{"name":"AOP","slug":"AOP","permalink":"https://htchz.cc/tags/AOP/"},{"name":"BUG","slug":"BUG","permalink":"https://htchz.cc/tags/BUG/"}]},{"title":"[Mysql]Innodb的快照读实现","slug":"Mysql-Innodb的快照读实现","date":"2019-12-11T14:08:30.000Z","updated":"2020-06-05T09:01:20.519Z","comments":true,"path":"3647734067.html","link":"","permalink":"https://htchz.cc/3647734067.html","excerpt":"","text":"1. 前言有一次面试，面试官问我：mysql事务隔离级别有哪些？我：balabala……面试官问：那可重复读是怎么实现的？我：emm。。第一次读会有快照。。面试官：嗯。。我：。。。 然后呢，然后就不知道啦。 事实上，Innodb的RC和RR隔离级别下，读有快照读（snapshot read）和当前读（current read）之分，当前读就是SELECT ... LOCK IN SHARE MODE和SELECT ... FOR UPDATE，快照读就是普通的SELECT操作。 快照读的实现，利用了undo log和read view。 快照读不是在读的时候生成快照，而是在写的时候保留了快照。 快照读实现了Multi-Version Concurrent Control（多版本并发控制），简称MVCC，指对于同一个记录，不同的事务会有不同的版本，不同版本互不影响，最后事务提交时根据版本先后确定能否提交。 但是，Innodb的读写事务会加排他锁，不同版本其实是串行的，所以首先要指出的是，Innodb事务快照读不是严格的MVCC实现。 2. 实现2.1. 隐藏字段Innodb每一行都有三个隐藏字段，分别是DB_ROW_ID、DB_TRX_ID、DB_ROLL_PTR。 DB_ROW_ID：如果表没有设置主键，用来作为记录的主键，因为Innodb使用聚簇索引的方式存储，记录必须有主键。DB_TRX_ID：记录修改这行记录事务的id。DB_ROLL_PTR：指向这行记录的前一个版本。 2.2. undo log多版本其实是用undo log来实现的，undo log听起来是做回滚使用的，没错，但是事务提交后undo log可不会立刻清除，它作为历史版本存在着。只有当前没有事务依赖在这行记录上时，mysql的清理线程才会清理掉无用的undo log。 insert操作的undo log在事务回滚或提交后就会删除，因为只有回滚会用到。update、delete的undo log需要保留（可见delete只是逻辑删除，其实也是个update操作，逻辑删除后由后台线程清理）。 下面假设有一条记录如下，column_1、column_2初始值为1和2。假设这时有个三个事务ABC，A,C事务开始，对这条记录的查询结果如下： column_1 column_2 1 2 接着A事务执行更新column_1为11；具体过程是：给记录加X锁，复制记录为undo_log_1，然后再将记录的column_1改为11，DB_TRX_ID为A，DB_ROLL_PTR指向前一个版本。 虽然数据行和undo log画的一样，但实际undo log有自己的数据结构。 A事务提交，释放X锁。 接着B开启事务，执行更新column_2为22；具体过程是：给记录加X锁，复制A事务更新完的记录为undo_log_2，然后再将记录的column_2改为22，DB_TRX_ID为B，DB_ROLL_PTR指向前一个版本。然后B事务提交。 注意！！如果A事务没有提交，X锁是不会释放的，那么B事务对这行记录执行update为了获取X锁会阻塞住的，而MVCC标准各个版本应该是不会相互影响的，所以说Innodb事务快照读不是严格的MVCC实现。 那么问题来了，C事务这时执行第二次查询，查询结果会是什么呢。 2.3. read view光有多版本还不够，需要一个机制对undo log进行可见性判断，决定当前事务读到的是哪个版本，这个机制就是通过read view完成， read view是对当前系统中活跃的所有事务列表的封装，注意是所有事务，而不是作用于目标行的事务。 read view最早的事务id记为up_limit_id，最迟的事务id记为low_limit_id（low_limit_id = 未开启的事务id = 当前最大事务id+1），活跃事务id列表记为descriptors。 RC和RR的区别就是，RR在第一次查询会创建新的read view，RC是每次查询都创建read view。 如果记录上的trx_id小于read_view_t-&gt;up_limit_id，则说明这条记录的最后修改在readview创建之前，因此这条记录可以被看见。 如果记录上的trx_id大于等于read_view_t-&gt;low_limit_id，则说明这条记录的最后修改在readview创建之后，因此这条记录肯定不可以被看见。 如果记录上的trx_id在up_limit_id和low_limit_id之间，且trx_id在read_view_t-&gt;descriptors之中，则表示这条记录的最后修改是在readview创建之后，被另外一个活跃事务所修改，所以这条记录也不可以被看见。如果trx_id不在read_view_t-&gt;descriptors之中，则表示这条记录的最后修改在readview创建之前，所以可以看到。 基于上述判断，如果记录不可见，则尝试使用undo去构建老的版本(row_vers_build_for_consistent_read)，直到找到可以被看见的记录或者解析完所有的undo。 上一节里，假设事务隔离级别是RR，事务id大小顺序是：X &lt; C &lt; A &lt; B &lt; D(D是未开启的事务Id)，事务都是读写事务（只读事务不会加入read view） 那么C事务第一次查询创建一个read view，up_limit_id为C，low_limit_id为B，descriptors为{C，A}，这时记录的DB_TRX_ID是X，A &gt; X，说明记录可见。 当A事务更新完毕B事务更新完毕后，C事务执行第二次查询，read view还是最开始的那个，此时记录的DB_TRX_ID是B，&gt;= low_limit_id， 因此这条记录肯定不可以被看见，需要沿着历史版本找。 记录的前一个版本的DB_TRX_ID是A，在up_limit_id和low_limit_id之间, 且在descriptors之间，所以此版本还是不可以被看见，继续往历史版本找。 前一个版本的DB_TRX_ID是X，&lt; up_limit_id, 所以该版本可见，所以C事务第二次查询结果依旧是： column_1 column_2 1 2 这就做到了可重复读。 如果是RC呢？ C事务执行第二次查询，创建新的read view，up_limit_id为C，low_limit_id为D，descriptors为{C}，此时记录的DB_TRX_ID是B，在up_limit_id和low_limit_id之间，但是不在在descriptors之中，所以记录是可见的，也就是说C事务可以读到B事务提交的结果，这就是RC快照读的实现。 2.4. 幻读RR级别下，在一个事务里，如果全程只进行快照读操作，那么是不会发生幻读的，也不会加锁；如果事务进行快照读又进行了写操作，那么就会发生幻读。 也就是说：RR的幻读只发生在写操作中 可以用当前读解决幻读。 2.5. 聚簇索引聚簇索引在更新主键的时候，会删掉旧记录，插入带有新主键的记录。 2.6. 二级索引二级索引是没有隐藏字段的，所以没有undo log，只有一个标志位。 如果一个update语句更新到了二级索引，旧二级索引delete_mark置1，插入新二级索引。查询的时候，要判断可见性怎么办？根据二级索引找到聚簇索引（无视delete_mark），再从聚簇索引开始可见性判断，找到可见记录，如果可见记录和二级索引维护的结果一致（索引值和主键值一样），就返回记录，否则返回空。 这样效率比较低，比如student表里age是二级索引，查询条件是age=10，满足这个条件的age-&gt;student_id的二级索引会有多个，事务事务需要遍历所有age=10的索引进行可见性判断才能拿到旧值。 于是innodb给二级索引加了个MAX_TRX_ID记录最后更新二级索引的事务，如果当前事务read_view的 up_limit_id &gt; MAX_TRX_ID，说明在创建read_view时最后一次更新二级索引的事务已经结束，就可以无视delete_mark=1的二级索引。如果MAX_TRX_ID失效，依旧要遍历所有age=10的二级索引。 2.7. 题外话在InnoDB里面有两种事务模式，一种是读写事务，就是会对数据进行修改的事务，另外一种是只读事务，仅仅对数据进行读取。开启一个读写事务要做的事比开启一个只读事务多许多，需要分配回滚段来记录undo log，需要把读写事务加入到全局读写事务链表，把事务id加入活跃读写事务数组中，所以你的事务没有写操作的话，声明为只读事务是个不错的优化。 5.6 如果要开始只读事务，需要显式指明事务模式为只读； 5.7如果不指明事务模式，mysql会初始化为只读事务，如果发生写操作，再将事务提升为读写事务，分配回滚段，分配事务id（只读事务也有id啦），加入读写事务链表。5.7如果一次read view使用完后，没有新的读写事务创建，那么可以给下一个事务复用。 还有性能，由于读是不加锁的，RR似乎比RC开销小，那是不是RR的性能比RC好？事实是不一定的，在写的时候，RR为了防止幻读，加入了gap和next-key锁，这通常是RR会造成死锁，导致RR比RC差的原因。 3. 后记在这之前，不明白为什么事务可以临时指定隔离级别，临时指定不需要其他事务配合么，现在应该懂了😎，不过事务还有好多不懂😎 4. 参考 《MySQL · 引擎特性 · InnoDB 事务系统》 《MySQL InnoDB MVCC深度分析》","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://htchz.cc/categories/Mysql/"}],"tags":[{"name":"事务","slug":"事务","permalink":"https://htchz.cc/tags/事务/"}]},{"title":"[Redis]《Redis设计与实现》","slug":"Redis -《Redis设计与实现》","date":"2019-12-03T01:01:33.000Z","updated":"2020-07-14T07:09:34.390Z","comments":true,"path":"1473130276.html","link":"","permalink":"https://htchz.cc/1473130276.html","excerpt":"","text":"1. 前言《Redis设计与实现》第二版基于redis3.0，现在6.0都快出了。现在redis和书里有些内容已经不一致了，不过用来探索redis是挺好的。 2. 碎碎念2.1. 编码现在的redis已经增加了quicklist、stream编码。 quicklist是ziplist和linkedlist的整合，作为list的唯一编码，其思想就是将ziplist分段，ziplist内存碎片少但每次操作都要申请内存，将ziplist分段，并用操作性能比较好的双向链表把段串起来，这算是时间与空间的折中。 stream编码用于消息队列，没有去了解。 2.2. 字典字典expand/resize是redis的一个大话题。 字典执行BGSAVE或BGREWRITEAOF时负载因子必须达到5才能进行扩容，执行BGSAVE或BGREWRITEAOF时不能进行缩容。 之所以，是因为BGSAVE或BGREWRITEAOF使用了copy-on-write，也就是写时复制。执行BGSAVE或BGREWRITEAOF时redis会fork子进程，这时候如果进行一个内存的拷贝（保证数据一致性），那么内存的浪费是很大的。使用写时复制，会将父进程的内存设置为只读，将内存和子进程共享，由于内存是分页机制，当某一页内存要发生写操作时，会发生中断，操作系统会把这一页内存复制出来进行修改。 因此，为了减少写操作导致内存页复制，redis才有了在上面的策略。 2.3. 下个2的幂redis在expand/resize都将新数组的长度设置为2的幂，这是因为把数组长度设置为2的幂，就可以把取模运算转化为位运算，java里也是这么做。 redis作者使用了这么一个算法来求给定一个数的下个2的幂 123456789101112/* Our hash table capability is a power of two */static unsigned long _dictNextPower(unsigned long size)&#123; unsigned long i = DICT_HT_INITIAL_SIZE; if (size &gt;= LONG_MAX) return LONG_MAX + 1LU; while(1) &#123; if (i &gt;= size) return i; i *= 2; &#125;&#125; 很简单的循环，不过有人给他提出可以用位运算：传送门，java里用的也是这个算法，HashMap的tableSizeFor()。 作者说不错，但是没必要，这种位运算的魔法对现实来说都是假的，只会把代码搞复杂😮 2.4. EMBSTR书里的REDIS_ENCODING_EMBSTR支持最大长度39字节，而现在最大支持44字节，原因是3.2版本之后sdshdr变了。REDIS_ENCODING_EMBSTR使用sdshdr8来表示，原来的sdshdr需要8字节，现在使用sdshdr8只需要三字节，那么：44 + 1（&#39;\\0&#39;）+ 3 + 16(robj) = 64，刚好是64字节，可以达到64字节内存对齐。 作者一度用着44的限制，写着39的注释，让我一度迷惑。 2.5. 多线程redis6.0加入了多线程，不知道和阿里云的多线程redis有什么区别，看起来都是在io线程并行，工作线程串行。 2.6. raftredis sentinel和redis cluster选举都是采用raft协议的选举方式：同一个term里，一人一票；当得到majority的票时选举成功，当票被瓜分选举失败开始新一轮。 在sentinel模式下，负责故障转移的sentinel是通过raft选举出来的：只需要先发起投票的sentinel节点就能拿到票。接着领头sentinel在从节点中选出复制偏移量最大的从节点作为新master；如果从节点的复制偏移量一致，则选取服务器id较小的那个。 在cluster模式下，从节点晋升为主节点比sentinel模式复杂一些，需要得到majority主节点的票。在选举过程，当candidate收到投票请求时，判断投票请求是否过期、candidate是否有选票，比较主从复制偏移量，符合的话那就投给那个节点。 2.7. LFUredis4.0新增了lfu策略来淘汰key 123456789typedef struct redisObject &#123; unsigned type:4; unsigned encoding:4; unsigned lru:LRU_BITS; /* LRU time (relative to global lru_clock) or * LFU data (least significant 8 bits frequency * and most significant 16 bits access time). */ int refcount; void *ptr;&#125; robj; 通过redis.conf的设置，unsigned lru:LRU_BITS的有不同的表示。当表示lfu时，这个字段用8位来当作计数器，用16位当时间戳，16位长度只有两个字节，所以存的时间是以秒位单位。 在redis里lfu策略下，如果一个key被访问，那么计数器会增加，不过这种增加是需要乘上一个概率的，计数器越大，计数增加的几率越小；而同时key还要根据时间戳判断要不要衰减计数器，以此调整计数。 在这种策略下，redis会为key初始化一个5的计数器，防止key刚被初始化就被淘汰。 2.8. BITSET位图用来统计是很不错的一个数据类型，在redis里位图也是一个sdshdr，redis将一个字符用作8位，并把位图从低位往高位存储（sdshdr用buf数组存储字符串，当sdshdr表示位图时，buf数组从左往右是从低位到高位），这样当位图需要扩大的时候，只需要在buf数组尾部增加字符就可以了。 位图的统计的是一个有趣的问题，也就是统计一个二进制数的1有多少个。 暴力法不考虑，要说的是两个方法，查表法还有variable-precision SWAR算法 2.8.1. 查表法查表法就是预先给出各个数的二进制的1的数量，对于比较小的数字，这是一个速度最快的方法。 2.8.2. variable-precision SWAR算法这个方法采用位运算，而且还不占额外内存 123456789101112int swar(uint32_t i)&#123; //计算每两位二进制数中1的个数 i = ( i &amp; 0x55555555) + ((i &gt;&gt; 1) &amp; 0x55555555); //计算每四位二进制数中1的个数 i = (i &amp; 0x33333333) + ((i &gt;&gt; 2) &amp; 0x33333333); //计算每八位二进制数中1的个数 i = (i &amp; 0x0F0F0F0F) + ((i &gt;&gt; 4) &amp; 0x0F0F0F0F); //将每八位二进制数中1的个数和相加，并移至最低位八位 i = (i * 0x01010101) &gt;&gt; 24); return i;&#125; 对于一个32位的数，通过位运算归并1的数量到4个字节中，最后用一个乘法汇总4个字节的1的数量到高8位，这个乘法过程如下： 12345678910111213 00000001 00000010 00000011 00000100 x 00000001 00000001 00000001 00000001------------------------------------------------------------------- 00000001 00000010 00000011 00000100 00000001 00000010 00000011 00000100 00000001 00000010 00000011 00000100 00000001 00000010 00000011 00000100------------------------------------------------------------------- |00001010|·······no sense bit······· 最后右移24位得到这8位的值。 2.8.3. redis bitcountredis采用查法和variable-precision SWAR算法结合的方法来实现bitcount。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253size_t redisPopcount(void *s, long count) &#123; size_t bits = 0; unsigned char *p = s; uint32_t *p4; static const unsigned char bitsinbyte[256] = &#123;0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,4,5,5,6,5,6,6,7,5,6,6,7,6,7,7,8&#125;; /* Count initial bytes not aligned to 32 bit. */ while((unsigned long)p &amp; 3 &amp;&amp; count) &#123; bits += bitsinbyte[*p++]; count--; &#125; /* Count bits 28 bytes at a time */ p4 = (uint32_t*)p; while(count&gt;=28) &#123; uint32_t aux1, aux2, aux3, aux4, aux5, aux6, aux7; aux1 = *p4++; aux2 = *p4++; aux3 = *p4++; aux4 = *p4++; aux5 = *p4++; aux6 = *p4++; aux7 = *p4++; count -= 28; aux1 = aux1 - ((aux1 &gt;&gt; 1) &amp; 0x55555555); aux1 = (aux1 &amp; 0x33333333) + ((aux1 &gt;&gt; 2) &amp; 0x33333333); aux2 = aux2 - ((aux2 &gt;&gt; 1) &amp; 0x55555555); aux2 = (aux2 &amp; 0x33333333) + ((aux2 &gt;&gt; 2) &amp; 0x33333333); aux3 = aux3 - ((aux3 &gt;&gt; 1) &amp; 0x55555555); aux3 = (aux3 &amp; 0x33333333) + ((aux3 &gt;&gt; 2) &amp; 0x33333333); aux4 = aux4 - ((aux4 &gt;&gt; 1) &amp; 0x55555555); aux4 = (aux4 &amp; 0x33333333) + ((aux4 &gt;&gt; 2) &amp; 0x33333333); aux5 = aux5 - ((aux5 &gt;&gt; 1) &amp; 0x55555555); aux5 = (aux5 &amp; 0x33333333) + ((aux5 &gt;&gt; 2) &amp; 0x33333333); aux6 = aux6 - ((aux6 &gt;&gt; 1) &amp; 0x55555555); aux6 = (aux6 &amp; 0x33333333) + ((aux6 &gt;&gt; 2) &amp; 0x33333333); aux7 = aux7 - ((aux7 &gt;&gt; 1) &amp; 0x55555555); aux7 = (aux7 &amp; 0x33333333) + ((aux7 &gt;&gt; 2) &amp; 0x33333333); bits += ((((aux1 + (aux1 &gt;&gt; 4)) &amp; 0x0F0F0F0F) + ((aux2 + (aux2 &gt;&gt; 4)) &amp; 0x0F0F0F0F) + ((aux3 + (aux3 &gt;&gt; 4)) &amp; 0x0F0F0F0F) + ((aux4 + (aux4 &gt;&gt; 4)) &amp; 0x0F0F0F0F) + ((aux5 + (aux5 &gt;&gt; 4)) &amp; 0x0F0F0F0F) + ((aux6 + (aux6 &gt;&gt; 4)) &amp; 0x0F0F0F0F) + ((aux7 + (aux7 &gt;&gt; 4)) &amp; 0x0F0F0F0F))* 0x01010101) &gt;&gt; 24; &#125; /* Count the remaining bytes. */ p = (unsigned char*)p4; while(count--) bits += bitsinbyte[*p++]; return bits;&#125; 首先对于位图需要4字节对齐，因为redis里的SWAR算法一次操作4个字节，保证字节对齐可以提高内存读取速度，然后源码里有这么一段 12345/* Count initial bytes not aligned to 32 bit. */while((unsigned long)p &amp; 3 &amp;&amp; count) &#123; bits += bitsinbyte[*p++]; count--;&#125; 这段我看了半天看不懂，最后在stackoverflowHow Do I check a Memory address is 32 bit aligned in C找到答案，大概意思就是地址结尾是0b100的倍数，也就是&amp; 0b11 = 0，那么这个地址就是可以4字节对齐的。所以如果(unsigned long)p &amp; 3为true，说明地址不对齐，就要指针前进一个字节，并通过查表法计算这个字节的1的数量。 接着同时计算连续的28个字节，每4字节使用一次SWAR算法，再把7次结果汇总。 最后余下不足28字节的再用查表法计算。整个bitcount的过程就是这样。 统计一个位数组中非0位的数量，数学上称作：”Hanmming Weight“(汉明重量)。 2.9. AOF即使开启appendfsync always配置，redis还是可能丢数据。 AOF主要靠aof_buf和AOF文件。 都说redis是基于事件循环的。在一次事件循环里，每个写事件redis都会追加到aof_buf中；每次事件循环后，redis都会把aof_buf的内容写进AOF文件里。但是AOF文件是不会实时刷入硬盘的，而appendfsync配置具体就是刷盘时机。开启appendfsync always配置后，每个事件循环都会进行刷盘，在这个模式下redis宕机，也会至多丢失一个事件循环的命令。 题外话，innodb日志系统也有log buffer和log file，类似于aof_buf和AOF文件，而innodb_flush_log_at_trx_commit这个配置控制的也是log file刷盘策略，不过innodb可以做到不丢数据，而redis不行。 3. 参考 【Redis学习笔记】bitcount分析","categories":[{"name":"redis","slug":"redis","permalink":"https://htchz.cc/categories/redis/"}],"tags":[]},{"title":"[分布式]手撕raft","slug":"分布式-手撕raft","date":"2019-10-03T08:27:57.000Z","updated":"2020-02-23T04:26:12.496Z","comments":true,"path":"1823228532.html","link":"","permalink":"https://htchz.cc/1823228532.html","excerpt":"","text":"1. 前言Raft作为一个简单的一致性算法，实现一下还是挺好玩的。代码基于6.824 lab-raft，6.824是麻省理工的分布式课程的一个编号，里面有4个lab，第二个就是raft协议的实现，第三个是基于raft协议的kv存储设计，有待实现（oh我居然在做麻省理工的课程设计）。该lab要求使用go实现算法，并提供了一个具有故障模拟功能的RPC，即通过模拟网络，在单台机器我们就可以运行raft算法。 做实验前，你应该熟读raft论文，这里是中文版 2. 实现参照raft论文和lab提示，整体利用channel作为事件驱动、mutex保证线程安全，写出一个raft算法骨架还是比较容易的。不过在跑test的时候，小小的细节不对就会导致test failed。raft-lab提供了17个test，检验了各种情况下的一致性，模拟了各种奇葩网络变化（网络变成这样还是跑路吧），要求4分钟内pass。 2.1. 数据结构参照论文，定义几个数据结构 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869const ( Follower = iota Candidate Leader HeartbeatInterval = 100 * time.Millisecond)type ApplyMsg struct &#123; CommandValid bool Command interface&#123;&#125; CommandIndex int&#125;type LogEntry struct &#123; Term int Command interface&#123;&#125;&#125;type AppendEntriesArgs struct &#123; Term int LeaderId int PrevLogIndex int PrevLogTerm int Entries []LogEntry LeaderCommit int&#125;type AppendEntriesReply struct &#123; Term int Success bool NextIndex int&#125;type Raft struct &#123; currentTerm int mu sync.Mutex // Lock to protect shared access to this peer's state peers []*labrpc.ClientEnd // RPC end points of all peers persister *Persister // Object to hold this peer's persisted state me int // this peer's index into peers[] state int // 0:Follower 1:Candidate 2:Leader votedFor int // 这个实验用index来代替节点 voteCount int commitIndex int lastApplied int currentLeaderId int log []LogEntry nextIndex []int matchIndex []int applyCh chan ApplyMsg heartbeatCh chan bool leaderCh chan bool commitCh chan bool&#125;type RequestVoteArgs struct &#123; // Your data here (2A, 2B). Term int CandidateId int // 这个实验用index来代替节点 LastLogIndex int LastLogTerm int&#125;type RequestVoteReply struct &#123; // Your data here (2A). VoteGranted bool // 是否支持 Term int&#125; 小声bb，AppendEntriesReply论文是没有返回nextIndex的，而是由leader自己去减一重试，这其实是比较慢的，在设置了网络故障unreliable的test中，单纯的减一重试会导致raft集群在一定时间内不能达到一致。让follower过滤掉同一个term的index，并返回应该尝试的nextIndex，虽然会导致一次复制的日志变多，不过提高了集群达到一致的速度。 2.2. 一些封装1234567891011121314151617// 获取锁/释放锁的封装，可以在利用`runtime.Caller`打印获取锁的调用点，虽然性能损失比较大。func (rf *Raft) Lock() &#123; rf.mu.Lock()&#125;func (rf *Raft) Unlock() &#123; rf.mu.Unlock()&#125;// 字如其名func (rf *Raft) getLastLogTerm() int &#123; return rf.log[len(rf.log)-1].Term&#125;func (rf *Raft) getLastLogIndex() int &#123; return len(rf.log) - 1&#125; 2.3. raft实例初始化123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960func Make(peers []*labrpc.ClientEnd, me int, persister *Persister, applyCh chan ApplyMsg) *Raft &#123; rf := &amp;Raft&#123;&#125; rf.peers = peers rf.persister = persister rf.me = me // Your initialization code here (2A, 2B, 2C). rf.state = Follower rf.currentTerm = 0 rf.votedFor = -1 rf.currentLeaderId = -1 // 初始化空白日志 rf.log = append(rf.log, LogEntry&#123;Term: 0&#125;) rf.applyCh = applyCh rf.heartbeatCh = make(chan bool, 100) rf.leaderCh = make(chan bool, 100) rf.commitCh = make(chan bool, 100) // initialize from state persisted before a crash rf.readPersist(persister.ReadRaftState()) // 初始化随机数资源库 rand.Seed(time.Now().UnixNano()) go func() &#123; for &#123; switch rf.state &#123; case Follower: select &#123; case &lt;-rf.heartbeatCh: // 这是lab要求心跳 case &lt;-time.After(time.Duration(rand.Int63()%333+550) * time.Millisecond): rf.state = Candidate &#125; case Leader: rf.broadcastAppendEntries() time.Sleep(HeartbeatInterval) case Candidate: go rf.broadcastVote() select &#123; case &lt;-time.After(time.Duration(rand.Int63()%300+500) * time.Millisecond): //随机投票超时是必须的，为了防止票被瓜分完。 case &lt;-rf.heartbeatCh: rf.state = Follower case &lt;-rf.leaderCh: &#125; &#125; &#125; &#125;() go func() &#123; for &#123; &lt;-rf.commitCh rf.applyMsg(applyCh) &#125; &#125;() return rf&#125; 这个方法返回一个raft实例，读取持久化数据，起了两个goroutine。 goroutine1是raft三种状态的转化，这里的超时时间不宜设的太短（太短指论文里的时间），在lab文档里有指出为了配合test，选举超时时间应该larger than the paper’s 150 to 300 milliseconds goroutine2应用已提交日志。 在初始化channel的时候应该设置缓冲大于1。多余的事件并不会导致系统不一致，但是若由于channel缓冲不够而导致阻塞，就会使raft节点死锁。 2.4. votedFor清空时机一次rpc，无论是发起端还是接收端，只要收到更大的term，就要调整自己的状态，发生下面变化： 123rf.votedFor = -1rf.state = Followerrf.currentTerm = remoteTerm 可以看到state会变成Follower。 假设一种情景，ABC三个节点下，A为leader，此时C发生分区，那么C一定会不断循环进行超时选举，C的term会一直增大，当C网络恢复重新加入集群后会继续发投票请求rpc。由于C的投票请求rpc中的term较大，集群就会调整currentTerm以及state，已有leader会废掉。而问题是，C的请求投票是无意义的，却使集群进行了一次选举。针对这个问题有个preVote方案，就是在投票前调研一下自己是否有投票必要，如果没必要，就不发起投票。这篇文章暂无涉及preVote。 2.5. 投票发起与接收2.5.1. broadcastVote() 发起投票123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354func (rf *Raft) broadcastVote() &#123; rf.Lock() rf.currentTerm++ rf.voteCount = 1 rf.votedFor = rf.me vote := &amp;RequestVoteArgs&#123; Term: rf.currentTerm, CandidateId: rf.me, LastLogIndex: rf.getLastLogIndex(), LastLogTerm: rf.getLastLogTerm(), &#125; rf.persist() rf.Unlock() for i := 0; i &lt; len(rf.peers); i++ &#123; if rf.state != Candidate &#123; // 发送 break &#125; if vote.CandidateId == i &#123; // 自己的票已经给自己了 continue &#125; go func(server int) &#123; var reply RequestVoteReply ok := rf.sendRequestVote(server, vote, &amp;reply) if !ok &#123; return &#125; rf.Lock() defer rf.Unlock() // 一般来说，reply.Term &gt; rf.currentTerm 的情况下 reply.VoteGranted 不会为true if reply.Term &gt; rf.currentTerm &#123; rf.votedFor = -1 rf.state = Follower rf.currentTerm = reply.Term rf.persist() &#125; if reply.VoteGranted &#123; rf.voteCount++ if rf.state == Candidate &amp;&amp; rf.voteCount &gt; len(rf.peers)/2 &#123; rf.becomeLeader() &#125; &#125; &#125;(i) &#125;&#125;func (rf *Raft) sendRequestVote(server int, args *RequestVoteArgs, reply *RequestVoteReply) bool &#123; ok := rf.peers[server].Call(\"Raft.RequestVote\", args, reply) return ok&#125; 在接收到投票reply后，查看票根是否过半，如果过半转化为leader。 1234567891011// 没有加锁，外部调用已经加锁了func (rf *Raft) becomeLeader() &#123; rf.state = Leader rf.nextIndex = make([]int, len(rf.peers)) rf.matchIndex = make([]int, len(rf.peers)) // 初始化为0 for i := 0; i &lt; len(rf.peers); i++ &#123; rf.nextIndex[i] = rf.getLastLogIndex() + 1 &#125; rf.leaderCh &lt;- true // 结束选举阻塞&#125; 2.5.2. RequestVote 接收投票12345678910111213141516171819202122232425262728293031323334353637func (rf *Raft) RequestVote(args *RequestVoteArgs, reply *RequestVoteReply) &#123; rf.Lock() defer rf.Unlock() defer rf.persist() // Your code here (2A, 2B). reply.VoteGranted = false reply.Term = rf.currentTerm // 过期的投票请求 if rf.currentTerm &gt; args.Term &#123; return &#125; // 如果发起方的term比接收方大 // adjust current term if rf.currentTerm &lt; args.Term &#123; rf.currentTerm = args.Term rf.state = Follower rf.votedFor = -1 &#125; upToDate := false if args.LastLogTerm &gt; rf.getLastLogTerm() &#123; upToDate = true &#125; if args.LastLogTerm == rf.getLastLogTerm() &amp;&amp; args.LastLogIndex &gt;= rf.getLastLogIndex() &#123; upToDate = true &#125; if (rf.votedFor == -1 || rf.votedFor == args.CandidateId) &amp;&amp; // 保证有票 upToDate &#123; reply.VoteGranted = true rf.state = Follower rf.votedFor = args.CandidateId rf.heartbeatCh &lt;- true return &#125;&#125; 1，进行投票后要发送心跳rf.heartbeatCh &lt;- true，不然节点会由Follower超时，从而使集群选举循环下去。2，判断日志是否较新要满足其中一个条件：一，term较大，二，term一样，但日志index比较大 2.6. 日志复制与接收2.6.1. broadcastAppendEntries 广播日志/心跳日志复制lab文档要求一秒不能超过10次。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455func (rf *Raft) broadcastAppendEntries() &#123; rf.Lock() defer rf.Unlock() N := rf.commitIndex for i := rf.commitIndex + 1; i &lt;= rf.getLastLogIndex(); i++ &#123; // 1 是leader本身 num := 1 for j := range rf.peers &#123; // 只能提交本term的，一旦提交了本term的，旧term也算提交了 if rf.me != j &amp;&amp; rf.matchIndex[j] &gt;= i &amp;&amp; rf.log[i].Term == rf.currentTerm &#123; num++ &#125; &#125; if num &gt; len(rf.peers)/2 &#123; N = i &#125; &#125; if N != rf.commitIndex &#123; rf.commitIndex = N rf.commitCh &lt;- true &#125; for i := 0; i &lt; len(rf.peers); i++ &#123; if rf.state != Leader &#123; break &#125; if i == rf.me &#123; // 不用给自己心跳 continue &#125; var args AppendEntriesArgs args.Term = rf.currentTerm args.LeaderCommit = rf.commitIndex args.LeaderId = rf.me args.PrevLogIndex = rf.nextIndex[i] - 1 args.PrevLogTerm = rf.log[args.PrevLogIndex].Term args.Entries = make([]LogEntry, len(rf.log[args.PrevLogIndex+1:])) // 复制 copy(args.Entries, rf.log[args.PrevLogIndex+1:]) go func(i int, args AppendEntriesArgs) &#123; var reply AppendEntriesReply ok := rf.sendAppendEntries(i, &amp;args, &amp;reply) if !ok &#123; return &#125; rf.handleAppendEntriesReply(&amp;args, &amp;reply, i) &#125;(i, args) &#125;&#125;func (rf *Raft) sendAppendEntries(server int, args *AppendEntriesArgs, reply *AppendEntriesReply) bool &#123; ok := rf.peers[server].Call(\"Raft.AppendEntries\", args, reply) return ok&#125; 每次发送日志前，leader从matchIndex[]里统计出应该commit的index，如果index前进，发送commit事件。统计时要判断rf.log[i].Term == rf.currentTerm，也就是说只能提交自己term的log，一旦提交了自己term的log，之前term未被提交的log也算提交了。这个在论文有提到。 下面是复制日志的响应代码，也很直白。 123456789101112131415161718192021222324252627282930// reply 为 false， 如果不是任期问题，就是日志不匹配func (rf *Raft) handleAppendEntriesReply(args *AppendEntriesArgs, reply *AppendEntriesReply, i int) &#123; rf.Lock() defer rf.Unlock() if rf.state != Leader &#123; // 获取锁后校验自己的状态 return &#125; if args.Term != rf.currentTerm &#123; return &#125; if reply.Term &gt; rf.currentTerm &#123; rf.votedFor = -1 rf.currentTerm = reply.Term rf.state = Follower rf.persist() return &#125; if reply.Success &#123; // len(args.Entries) == 0 就是心跳了，不用处理 if len(args.Entries) &gt; 0 &#123; rf.matchIndex[i] = args.PrevLogIndex + len(args.Entries) rf.nextIndex[i] = rf.matchIndex[i] + 1 &#125; &#125; else &#123; rf.nextIndex[i] = reply.NextIndex // 直接采用follower的建议 &#125;&#125; 2.6.2. AppendEntries 接收日志12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455func (rf *Raft) AppendEntries(args *AppendEntriesArgs, reply *AppendEntriesReply) &#123; rf.Lock() defer rf.Unlock() defer rf.persist() reply.Success = false // 告诉老term的节点该更新啦 if rf.currentTerm &gt; args.Term &#123; reply.Term = rf.currentTerm return &#125; // 心跳 rf.heartbeatCh &lt;- true // adjust current term if args.Term &gt; rf.currentTerm &#123; rf.currentTerm = args.Term rf.state = Follower rf.votedFor = -1 &#125; reply.Term = rf.currentTerm // 这坨是在日志不匹配的情况下，对leader的NextIndex建议 if rf.getLastLogIndex() &lt; args.PrevLogIndex &#123; reply.NextIndex = rf.getLastLogIndex() + 1 return &#125; else if rf.log[args.PrevLogIndex].Term != args.PrevLogTerm &#123; term := rf.log[args.PrevLogIndex].Term if args.PrevLogTerm != term &#123; for i := args.PrevLogIndex - 1; i &gt;= 0; i-- &#123; if rf.log[i].Term != term &#123; reply.NextIndex = i + 1 break &#125; &#125; return &#125; &#125; reply.Success = true reply.NextIndex = rf.getLastLogIndex() + 1 // 删除已存在日志 rf.log = rf.log[:args.PrevLogIndex+1] // 附加新日志 rf.log = append(rf.log, args.Entries...) if args.LeaderCommit &gt; rf.commitIndex &#123; rf.commitIndex = Min(args.LeaderCommit, rf.getLastLogIndex()) rf.commitCh &lt;- true &#125; return&#125; 这理主要是NextIndex建议值的计算。 2.7. 将提交的日志应用至状态机12345678910111213func (rf *Raft) applyMsg(applyCh chan ApplyMsg) &#123; rf.Lock() defer rf.Unlock() for i := rf.lastApplied + 1; i &lt;= rf.commitIndex; i++ &#123; msg := ApplyMsg&#123; true, rf.log[i].Command, i, &#125; applyCh &lt;- msg rf.lastApplied = i &#125;&#125; 应用过程其实是由test去管理的，我们只要负责把需要应用的日志放入chan ApplyMsg。 2.8. 持久化12345678910111213141516171819202122func (rf *Raft) persist() &#123; // Your code here (2C). // Example: w := new(bytes.Buffer) e := gob.NewEncoder(w) e.Encode(rf.currentTerm) e.Encode(rf.votedFor) e.Encode(rf.log) data := w.Bytes() rf.persister.SaveRaftState(data)&#125;func (rf *Raft) readPersist(data []byte) &#123; if data == nil || len(data) &lt; 1 &#123; // bootstrap without any state? return &#125; r := bytes.NewBuffer(data) d := gob.NewDecoder(r) d.Decode(&amp;rf.currentTerm) d.Decode(&amp;rf.votedFor) d.Decode(&amp;rf.log)&#125; 两个持久化函数，持久化了currentTerm当前term,votedFor得票者,log日志数组，当这三个属性变化时，都执行一次rf.persist()就没错啦。 3. 后记表面是在贴代码，实际就是在贴代码。 由于实验是并发过程，一旦test failed是不容易按线性的过程来分析的。我的方法是多打日志，以及利用net/http/pprof包对程序的goroutine、mutex状态进行分析。 实现完以后我感觉又变强了（并没有）。","categories":[{"name":"分布式","slug":"分布式","permalink":"https://htchz.cc/categories/分布式/"}],"tags":[{"name":"raft","slug":"raft","permalink":"https://htchz.cc/tags/raft/"}]},{"title":"[k8s]k8s部署踩坑","slug":"k8s-k8s部署踩坑","date":"2019-08-25T06:06:02.000Z","updated":"2020-02-26T16:06:20.434Z","comments":true,"path":"2102019255.html","link":"","permalink":"https://htchz.cc/2102019255.html","excerpt":"","text":"1. 前言自己搭个k8s集群，踩了一些坑 2. 镜像kubeadm init命令会去k8s.gcr.io拉镜像，这个地址是得挂代理才能上的（可以指定地址忽略代理），可以用kubeadm config images pull尝试一下，十有八九是不行。不想挂代理的话，用下面这个方法。 先执行kubeadm config images list列出镜像，输出信息中有两行WARN是获取版本timeout可以不理会。 接着把列出来的信息放到下面的bash脚本中，运行脚本就把镜像下载好啦(其实就是从阿里云下镜像改tag)。 123456789101112131415images=( # 下面的镜像应该去除\"k8s.gcr.io\"的前缀，版本换成上面获取到的版本kube-apiserver:v1.15.3kube-controller-manager:v1.15.3kube-scheduler:v1.15.3kube-proxy:v1.15.3pause:3.1etcd:3.3.10coredns:1.3.1)for imageName in $&#123;images[@]&#125; ; do docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName k8s.gcr.io/$imageName docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/$imageNamedone 3. token和ca-cert-hash在master进行kubeadm init后会输出token和ca-cert-hash，这个要记住，如果忘记了虽然可以执行kubeadm token list获取token，但是ca-cert-hash是不会输出的，忘记ca-cert-hash只能重新执行kubeadm token create从输出中拿到。 4. ip转发在node主机执行kubeadm join的时候，报 [ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1`意思是没有开启ipv4转发，设置一下就好了：echo 1 &gt; /proc/sys/net/ipv4/ip_forward 5. 时间同步在node主机执行kubeadm join的时候，一直卡住，加上--v=2可以输出详细信息，输出了一个信息 I0824 21:58:46.950161 16866 token.go:146] [discovery] Failed to request cluster info, will try again: [Get https://192.168.0.113:6443/api/v1/namespaces/kube-public/configmaps/cluster-info: x509: certificate has expired or is not yet valid]`但是我的证书没过期呀，在一个issue里一位老哥说是不是几台机器时间没同步，我在node主机上执行date，果然时间和master差了好久，用于是ntp命令同步了一下时间。 12yum install -y ntpdatentpdate cn.pool.ntp.org 6. hostname在node主机执行kubeadm join的时候，要用--node-name指定节点名字，如果不指定，会用hostname，如果你和我一样主机是用vmware克隆出来的，几台机器的hostname都是一样的，就会执行kubeadm join成功，kubectl get nodes只有一台master(三台机hostname都是master)，kubectl get pods --namespace kube-system的pod也都只有一份。 7. 网桥地址重复failed to set bridge addr: &quot;cni0&quot; already has an IP address different from 10.244.1.1/24，执行ip link delete cin0删除cni0网桥。 8. dashboard 404错误输入token后显示的是404，执行kubectl logs发现找不到某些Resource，查看iusse，dashboard v1.X和新版的k8s不兼容，升到v2.x就好了。不过v2.x还没有正式版。 #","categories":[{"name":"容器","slug":"容器","permalink":"https://htchz.cc/categories/容器/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://htchz.cc/tags/k8s/"},{"name":"deploy","slug":"deploy","permalink":"https://htchz.cc/tags/deploy/"}]},{"title":"[网络]在浏览器输入一个url到页面展现发生了什么","slug":"网络-在浏览器输入一个url到页面展现发生了什么","date":"2019-08-20T17:01:46.000Z","updated":"2020-06-11T04:10:48.382Z","comments":true,"path":"334107480.html","link":"","permalink":"https://htchz.cc/334107480.html","excerpt":"","text":"1. 前言被问起的时候总是两三句话就结束了。这一次想好好总结，描述我所知道的流程。 2. 过程2.1. DNS向DNS发起请求，通常是udp协议，获得域名对应的ip地址。 查找顺序是：浏览器缓存 -&gt; 操作系统缓存 -&gt; 路由器缓存 -&gt; ISP的DNS缓存 -&gt; 根服务器 2.2. ARP如果不是同一网络的地址，按照路由表找下一跳的ip，通过广播ARP请求获得下一跳mac地址，将报文发往此地址。 目标网络的网关接收到此报文后，同样发起ARP广播请求，寻找目标ip对应的mac地址，将报文发往此地址。 2.3. TCP三次握手发送端随机选择一个端口和接收端端口之间发起三次握手，之后建立起TCP连接。 Linux执行sysctl -a|grep ip_local_port_range可以看到随机端口选择范围 2.4. MSS协商与TCP分段MSS，Maximum Segment Size，TCP报文数据不能大于这个值，MSS = MTU - IP首部长度，20 - TCP首部长度，20 为了得出路径最小MSS，TCP一端设置IP报文\bDF标志（Don’t Fragment flag）告诉IP层不要分片，这样IP必须分片的时候，就会传回一个ICMP差错报文。 高级的ICMP差错报文会返回发生差错的MTU大小，如果ICMP差错报文没有带回MTU大小，需要发送端不断减少MSS并重发报文，得出合适的MSS。注意，一段时间后TCP会重新协商路径最小MSS，调整路径最小MSS。 将一个数据分组根据MSS拆成多个TCP报文，这就是TCP分段。 2.5. HTTP建立起连接之后，发送HTTP报文。HTTP由请求行、请求头、请求主体组成。 请求行只有一行，由方法，path，协议版本，以一个\\r\\n结束。 请求头由多对key-value组织而成，以一个\\r\\n换行，以两个\\r\\n结束。 请求主体，包含请求的数据/响应数据。 http1.1版本加入了Connection:Keep-Alive,使得一个TCP连接可以复用多次，而不是一个请求建立起一次连接。http2版本加入TCP多路复用。虽然http1.1版本可以复用TCP连接，但是一次只能发一个HTTP请求报文，想要并行发起多个请求，追能多建立TCP连接，而浏览器一般会限制并发6～8个连接，其余请求只能排队。加入TCP多路复用之后，减少了连接；此外http2采用了二进制传输，头部压缩大幅提高了性能。虽然二进制传输在调试过程不是很方便，但是调试工具都会帮我们转成明文格式展示。 更多信息http2可参见再谈HTTP2性能提升之背后原理—HTTP2历史解剖。本站也有启用http2。 2.6. HTTPS如果启用用HTTPS，客户端会校验服务端的证书，根据证书和服务器协商一个对称加密算法和一个密钥，这一部分是RSA非对称加密，之后客户端和服务端会使用这个算法和密钥进行数据加密传输。HTTPS的原理出门左转TLS完全指南（一）：TLS和安全通信，这文章讲了HTTPS的部分内容，主要内容是证书方面的内容；还有一部分内容看图解SSL/TLS协议，主要补充了用DH算法代替RSA进行密钥交换，避免了密钥在网络中传输。 2.7. TCP拥塞控制TCP需要拥塞控制逻辑使用网络不好的情况，详见TCP拥塞控制那些事。 2.8. 应用关于应用层, 大多数是请求走cdn-&gt; 2.9. TCP四次挥手发送端和接收端之间进行四次挥手断开连接，接着主动断开的端口进入FIN_WAIT_1，收到ACK报文后进入FIN_WAIT_2,收到接收端的FIN报文后最终会进入TIME_WAIT状态， 默认保持2MSL的不可用时间，防止相同五元组的连接建立后，收到上一代连接的重复报文，而产生混乱。被动断开的端口先进入CLOSE_WAIT，由服务器执行断开后发送FIN报文进入LAST_ACK状态，收到客户端ACK报文进入CLOSED状态。 3. 后记这个问题能反映出对计算机的网络的了解，其实算是一个能扯很久的问题。","categories":[{"name":"网络","slug":"网络","permalink":"https://htchz.cc/categories/网络/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"https://htchz.cc/tags/TCP/"},{"name":"HTTP","slug":"HTTP","permalink":"https://htchz.cc/tags/HTTP/"}]},{"title":"[分布式]Raft和ZAB的异同","slug":"分布式-Raft和ZAB的异同","date":"2019-08-18T11:28:38.000Z","updated":"2020-06-18T14:22:32.262Z","comments":true,"path":"3841980432.html","link":"","permalink":"https://htchz.cc/3841980432.html","excerpt":"","text":"1. 前言为了学习etcd,先学习了解一下Raft协议，想总结一下Raft和zookeeper的ZAB协议协议的异同。 ZAB是对PAXOS算法的改进（没看过PASXOS，好像没有leader概念，我直接看的ZAB），增加了leader、follower、learner的角色。 Raft自称是比PAXOS更容易理解的一致性算法，和ZAB一样有leader、follower，而且一个强leader的算法。 2. 时间Raft：使用任期term表示一个选举轮次。 ZAB：使用electionEpoch表示一个选举轮次。 3. 选举3.1. 投票Raft：忽略上一轮投票。选举过程只能进行一次投票，如果投过票了，收到投票请求就会无视。这样越早发起投票的人越有可能当leader；同时，也可能出现每个节点都没有收到majority的投票，出现投票被瓜分的情况。Raft采用设置随机的选举超时时间来解决投票被瓜分。 ZAB：忽略上一轮投票。每次收到投票请求都会进行判定，然后若自己的投票有变，会重新通知所有节点。这样不会出现投票被瓜分，但是时间会比Raft多很多，导致服务可用性降低。 3.2. 投票pkRaft：term大的胜出，相同时index大的胜出 ZAB：electionEpoch大的胜出，相同时zxid大的胜出 3.3. 投票结果Raft：每个节点都只有自己的投票结果，如果发现自己投票过半，要通知所有节点，并发送心跳，心跳间隔 &lt; 选举超时时间. ZAB：每个节点保存所有节点的票根信息，每个节点收到投票请求后都会检查是否有过半的票根，如果有，会和leader建立起一个连接，leader会发送心跳。 3.4. 选举结束Raft：选举完可以立刻提供服务，对于节点不一致的问题，Raft靠接下来附加条目RPC来逐渐修复。按论文说的5台节点的集群，重新选举完成的时间平均是35ms，最长是150ms（选举超时时间配置为12-24ms）。 ZAB：选举完得完成日志同步才能对外提供服务，而且ZAB的选举可能长达秒级的时间，导致服务可用性降低。 4. 分区容错性当 可用节点 &gt; N/2，Raft和ZAB的集群都是可用的。 5. 客户端请求5.1. 读（针对读请求落到follower的情况）Raft：Raft的读其实有几个方案 强一致读：转发给leader；leader插入一个空日志获得readIndex；心跳广播(确认自己是leader，才能拥有最新日志)；等待状态机applyIndex经过readIndex（同步最新日志条目）；返回给follower；返回给客户端； 在follower读：从leader获得readIndex；等待applyIndex经过readIndex；查询自身状态机；（从leader获得readIndex时，leader也要进行心跳广播） 折中方案：leader在接受到majority心跳响应后一段时间内不广播，这是论文作者不推荐的，因为“响应后一段时间内”这个时间可能是不准确的。 ZAB：follower直接返回，如果一个follower和leader未同步完成，follower返回的是脏数据，如果要保证数据最新，需要客户端调用sync()方法同步数据，正常情况下ZAB只保证最终一致性。 5.2. 写5.2.1. 主要流程Raft: 转发给leader; leader将请求封装为entries，写入日志，得到在日志中的index，连同entries发送给followers，注意这可以是批量的 follower执行接收逻辑，如果成功写入文件，返回true leader收到过半成功回复就更新committIndex，把entries应用到状态机中，回复客户端 leader下次心跳会带上committIndex的值用leaderCommit表示，followers发现leaderCommit大于自己维护的committIndex，就令 commitIndex 等于 leaderCommit 和 新日志条目索引值中较小的一个 ZAB：典型的两阶段提交 转发给leader leader封装为一个proposal，写入日志，发送给followers follower执行接收逻辑，如果成功写入文件，返回true leader收到过半成功回复就提交proposal，同时广播一个commit消息，通知followers提交提议 5.2.2. 接收逻辑Raft：如果prevLogIndex和prevLogTerm不匹配，返回false，由leader调整，从而达到在写请求再同步数据的目的 ZAB：没有什么特别的，接收到proposal写入文件，接收到commit提交日志 6. 旧leader数据这个是指旧leader崩溃后，新leader对旧数据的处理 Raft：保守，过半或未过半日志都是未提交。只能提交当前term的日志，如果提交了当前日志，那么旧term的日志也会被一波提交（旧term的日志只能被间接提交）。允许出现未提交的数据被覆盖。 ZAB：激进，过半或未过半日志都被提交，由zookeeper选举完成后的数据同步完成。 7. leader假死Raft：leader和follower是没有连接的。旧leader假死后，新leader诞生，旧leader复活后发送带有旧term的RPCs，follower收到之后返回新term给旧leader，旧leader更新term，加入follower大军。 ZAB：leader和follower存在连接。旧leader假死后，连接断开，旧leader进入LOOKING状态，从集群中学习投票结果/重新选举，最终找到leader建立起连接。 8. 请求异常Raft：重试，Raft要保证RPCs是幂等的。 ZAB：follower和leader断开连接，重新加入集群 9. 挂了的机器加入一个选举完成的集群（不是新加机器）Raft：leader会对follower进行RPCs重试，所以恢复的follower会收到leader的心跳请求。 ZAB：恢复的follower会学习集群中的投票结果，可以识别到leader 10. 日志复制的顺序Raft：由leader维护log顺序。如果follower重启，不会阻塞leader写入请求，会按照leader顺序追赶日志；如果leader挂了，新leader也可以将旧term、新term日志按顺序提交。 ZAB：由leader维护log顺序。如果follower重启，会获取leader读锁，leader阻塞写入请求，接着追赶差异，获取leader已提交proposal和未提交proposal，然后再释放leader读锁；如果leader重启，新leader选举后会进行数据同步 11. 集群成员变更集群配置不能一下子全切换，否则同一个时期可能会出现两个leader。Raft：使用两阶段变更。旧配置为C-old，新配置为C-new，C-old-new表示中间配置。配置变更命令由客户端发起，leader以log传播C-old-new，等C-old-new提交之后，再广播C-new配置，这时不在C-new里的机器就要自觉退出。Raft论文参与者后来还提出一个一阶段变更，提出限制一次变更只能添加或删除一个成员来简化问题，如果要变更多个成员，需要执行多次成员变更。 ZAB：3.5版本以前是停机的，但停机变更也有问题，3.5开始使用了动态变更成员，出门左转Zab协议中的动态成员变更，比Raft难理解😐，反正我是看不下去😐。 12. 总结Raft是在想解决PAXOS过于复杂的缺点的背景下提出来的一个一致性算法，之前也看过ZAB协议，感觉Raft可用性比ZAB高很多。 不过有个问题让我迷惑是，在两阶段成员变更方案里，如果提交了C-old-new后，还有旧的Server1，Server2没有复制到，Server1，Server2的配置还是C-old这时候Server1，Server2发生了网络分区，那么这两台服务器还是可以产生基于C-old的leader，而Server3，Server4，Server5形成另一个majority，也可以产生一个leader，不一样还会出现双leader问题么？若使用一阶段成员变更，就可以阻止多个majority产生，杜绝这种情况吧。 很有兴趣实现一个Raft算法。 13. 参考 \b寻找一种易于理解的一致性算法（扩展版）Raft论文汉化 In Search of an Understandable Consensus Algorithm(Extended Version)Raft论文原版 Raft对比ZAB协议","categories":[{"name":"分布式","slug":"分布式","permalink":"https://htchz.cc/categories/分布式/"}],"tags":[{"name":"一致性算法","slug":"一致性算法","permalink":"https://htchz.cc/tags/一致性算法/"},{"name":"raft","slug":"raft","permalink":"https://htchz.cc/tags/raft/"},{"name":"ZAB","slug":"ZAB","permalink":"https://htchz.cc/tags/ZAB/"}]},{"title":"[网络]TCP拥塞控制那些事","slug":"网络-TCP拥塞控制那些事","date":"2019-08-15T02:05:00.000Z","updated":"2020-06-08T09:53:39.710Z","comments":true,"path":"3284953854.html","link":"","permalink":"https://htchz.cc/3284953854.html","excerpt":"","text":"1. 前言看完了《TCP/IP详解 卷一》，对TCP/IP协议簇的认知多了一些。总结一下TCP窗口有关的慢启动、拥塞避免、快速重传、快速恢复的概念。 2. TCP滑动窗口窗口有两种，通告窗口(Receiver Window,rwnd)和拥塞窗口(Congestion Window,cwnd)。 通告窗口：通告窗口表明了接收端当前的接受能力。TCP在发送端和接收端都是有缓冲区的，通告窗口声明了当前接收端的缓冲区还能接收的字节大小。这个数值会在TCP报文里携带。 拥塞窗口：拥塞窗口不被TCP报文传输，是发送端基于拥塞避免算法算出来的一个窗口。这个窗口限制了发送方的发送速率避免网络拥塞。 两个窗口共同组成了一个滑动窗口。简单来说，通告窗口是强制限制，拥塞窗口是自发限制。 有一点要注意的是，窗口的单位用字节表示，但是拥塞窗口的调整总是以一个MSS的倍数来调整。 这里用书上的图描述滑动窗口，当一个TCP发送方发送数据的时候就会查看可用窗口能否发送（如果启用了Nagle算法，可用窗口必须大于等于一个MSS，发送方才发送数据） 上面是抓包得到的一个报文，Win=2027是一个通告窗口，表示服务器的缓冲区还能接受2027字节的数据。 3. 拥塞控制上图是一个tcp刚开始传输数据时的速率变化走向。 拥塞避免、慢启动、快速重传、快速恢复这四个词其实并不能单独分开讲。当一个连接的网络情况不好的时候，就会丢包或超时，这时就要降低发送方的发送速率防止恶化，这种就是拥塞控制。 这种机制涉及到cwnd和ssthresh两个指标，ssthresh是一个区分慢启动和拥塞避免的阈值，当拥塞发生时，分两种情况超时：ssthresh = cwnd / 2（最小为2MSS），cwnd = 1MSS，进入慢启动丢包：ssthresh = cwnd / 2（最小为2MSS），cwnd = ssthresh + 3MSS，进入快速重传 4. 慢启动慢启动其实是发送速率重新计算，cwnd 初始值为一个数据报大小，ssthresh初始值为65535，是一个然后在到达阈值之前，每接收到一个新的ACK，cwnd就会增加一个报文段的大小，这样子慢启动其实是以指数增加速率. 5. 拥塞控制上图是一个tcp刚开始传输数据时的速率变化走向。 拥塞避免、慢启动、快速重传、快速恢复这四个词其实并不能单独分开讲。当一个连接的网络情况不好的时候，就会丢包或超时，这时就要降低发送方的发送速率防止恶化，这种就是拥塞控制。 这种机制涉及到cwnd和ssthresh两个指标，ssthresh是一个区分慢启动和拥塞避免的阈值，当拥塞发生时，分两种情况超时：ssthresh = cwnd / 2（最小为2MSS），cwnd = 1MSS，进入慢启动丢包：进入快速重传 5.1. 慢启动慢启动其实是发送速率重新计算，cwnd 初始值为一个数据报大小，ssthresh初始值为65535，是一个然后在到达阈值之前，每接收到一个新的ACK，cwnd就会增加一个报文段的大小，这样子慢启动其实是以指数增加网速到一个比较平衡的水平。 5.2. 拥塞避免当cwnd大于等于ssthresh时进入拥塞避免状态，在一个RTT内无论收到多少ACK都只将cwnd增加一个报文大小，从时间上来看网速线性增加。 5.3. 快速重传和快速恢复快速重传指，当收到重复的3个ACK报文时（duplicate ack），设置ssthresh = cwnd / 2（最小为2MSS），cwnd = ssthresh + 3MSS，然后进入快速恢复阶段。 暂停发送新的报文，重传丢失报文。 接下来每收到重复的ACK时，将cwnd增加一个报文大小。如果cwnd大于未确认报文大小（报文丢失后我们还在发新的报文，未确认报文指丢失报文到最后一个报文之间报文总大小），可以发送新报文。 接下来如果收到新的ACK报文，将cwnd设置为ssthresh，也就是网速降为一半，并进入拥塞避免阶段。 总的来说，网速一直处于一个动态调整的过程，一个连接上cwnd随时间的变化如图所示 还有一点，上面关于cwnd的比较其实还要考虑rwnd的值，如果rwnd&gt;cwnd，应取rwnd去比较，毕竟两者决定了可用窗口大小。 6. 后记TCP拥塞控制其实还有很多改进未去了解。比如当收到重复的3个ACK报文时，其实不一定只丢了一个报文，所以网速可能指数下降，不能达到快速恢复的目的。","categories":[{"name":"网络","slug":"网络","permalink":"https://htchz.cc/categories/网络/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"https://htchz.cc/tags/TCP/"}]},{"title":"[FCM]用FCM做一个跨设备消息同步工具","slug":"FCM-用FCM做一个跨设备消息同步工具","date":"2019-05-18T03:00:00.000Z","updated":"2019-05-20T07:45:55.000Z","comments":true,"path":"2379284348.html","link":"","permalink":"https://htchz.cc/2379284348.html","excerpt":"Fcm真是个好东西，希望你也有。","text":"Fcm真是个好东西，希望你也有。 1. 需求背景作为一个穷人，手持不了iPhone(滑稽)，当同时使用着macOS、windows、安卓三个平台时，我面临着几个问题： 传文件。对于传文件，有许多方案，我偏向于用Feem或者共享文件夹，都是局域网传输，又快又不用经过第三方服务器。 复制文本。iPhone和mac之间有通用剪切板，win10和iPhone、安卓之间有微软小娜。 通知同步。主要是手机通知，上班工作时，听到手机推送的声音想知道时什么东西又懒得去看手机。 短信验证码。电脑上用短信验证码场景并不是很多，不过我们公司的线上服务器登录时需要短信验证码的二次验证，这时候去解锁手机、看验证码、一个一个输入终端。。。妈蛋很烦。 于是找了一堆，AirDroid、Pushbullet等等，在到处讲隐私的今天，我觉得把自己的剪切板、短信、通知就这么发送给人家总是有点不安（不过用fcm也是把数据给号称‘不作恶’口号的谷歌）。偶然看到了剪纸云，是个收费软件，不过看了简介说是用FCM做的，找了下FCM的接入指北，自己做一个同步工具。 2. 整体流程 数据的流向如图，终端把要同步的数据发到自己的应用服务器，应用服务器载把数据发到FCM，交由FCM推送到设备组。 对于每一台设备，当应用与FCM建立起连接后可以得到一个fcm token，这个token就是这台设备这个应用的id了。 至于设备组id，我是用Firebase-Auth的userId作为设备组id的。 程序主要流程是： 客户端启动时获取fcm token，持久化存储（这个fcm token除非把应用删了和我不知道的情况，否则万年不更新一次，当然fcm sdk提供了更新的回调，我们要实现这个方法。） 客户端登录，拉起谷歌的OAuth2.0授权（Chrome插件用的clientId模式），登录成功后获取到firebase-auth的userId，持久化存储 登录成功后把userId和fcm token发送到应用服务器保存，维护双向关系，完成注册。 客户端每次发送同步数据时，带上时间戳、同步类型、fcm token等内容。 客户端接受到fcm推送时，见机行事。 同步数据的数据结构 字段 说明 type 短信、通知、剪切板 time 毫秒时间戳，也作为分片id（其实是偷懒） text 文本内容 head 额外内容，主要是为了存通知的通知标题 fcm_token 设备id mark 分片的标识，8位整数，高位起第一位表示是否分片，第二位表示是否还有分片，余下6位表示分片顺序 3. 服务端服务端用go写的，框架使用gin，数据库用redis。 主要维护两个关系。 设备id到设备组id的关系 设备组id到所有设备id的关系 第一个直接用redis的kv模型，第二个用redis的哈希模型。 当服务器接收到客户端的同步请求时，推送到fcm有两种方式。 使用fcm的设备组管理，fcm设备组管理需要新建设备组，把fcm token添加到设备组，发送同步数据时，带上fcm设备组id，fcm就会把同步数据推送到所有组。对于已经失效的fcm token，fcm设备组管理会自己清理。 自己维护设备组，遍历设备组的设备，一个个带上fcm token推到fcm。如果接收到fcm token无效的响应，就从redis把fcm token的kv关系、哈希关系删除。 使用fcm的设备组管理的好处是只需要维护设备id到设备组id的关系，对于一些无效的fcm token由fcm自己去管理，不足的是目前fcm设备组管理没有提供API获取设备组的设备组列表，而且一发就是发全部，客户端发消息出去，待会又收到自己的消息。此外，fcm设备组管理在go没有sdk。。。 所以我决定自己管理设备组。 这里有一个☝️剪切板的问题，当发送到fcm的payload大于4kb的时候，会返回 400; reason: request contains an invalid argument; code: invalid-argument; details: Request contains an invalid argument.也就是说，我们要控制好数据大小。作为ctrl cv工程师，如果要从mac往windows复制1000行代码怎么办？答案是分片。 正如ip分片和tcp分段为了解决报文的大小限制，我们要在应用层进行分片重组。不过这个由于是应用层的分片要简单的多。 应用服务器接收到同步数据后，如果text文本大于4kb，则进行分片，mark高位第一位置0，否则置1直接推到FCM。 第二步，由于json是个文本协议，我们分片的时候有两种方案，第一种转换为字节分片，第二种转换为rune分片（rune是go的数据类型，可以表示一个utf8字符），一个rune的大小是4个字节，为了防止达到限制，rune分片大小应为1000个rune，不过这样就可能会导致一次payload利用率不高，毕竟1000个汉字是1000个rune，至少占3000字节，1000个字母也是1000个rune，占1000个字节；好处是在客户端可以直接使用。如果使用字节分片，客户端接收到分片后需要转换为字节数组，组合字节数组，再将字节数组转换为字符串，炒鸡麻烦。 接下来在分片mark高位起低6位设置好分片顺序，只要简单的0，1，2..这样就好了（不同于ip分片，ip分片使用的是数据偏移量作为位置索引）。如果是最后一片分片，mark高位起第二位要置1表示没有更多分片。 接下来利用sdk推送到fcm就好了。应用服务器的接入fcm有多种方式，文档真是傻瓜式教程。 4. 客户端客户端写Chrome拓展和android。主要流程是 根据接收到的数据类型处理，（1）通知直接显示，（2）短信显示并且检验有没有验证码，有则将验证码提取放入剪切板，（3）剪切板进行分片判断 如果不是分片，直接放入剪切板，否则进行重组。 重组需要一个全局哈希表，key为时间戳，也是分片id（这里用时间戳是偷懒，毕竟一个人1毫秒内也不能复制两次叭）；value是维护分片的数据结构FragHold，如下 字段 说明 count 整型 length 整型 text 数组 当第一个分片到来时，将分片time作为key，初始化一个FragHold。每次到达一个分片，FragHold.count加1，当最后一个分片到来，FragHold.length可以确定。如果FragHold的count == length，那么分片重组完成，直接对数组一个join操作得到一篇完整的千字文，又可以愉快地ctrl cv了。 此外起一个定时任务，不断将全局哈希表里过期的FragHold剔除，毕竟这个是没有超时重传的，一旦丢了就再复制一次呗。 5. 结语这里要说一下在设备组管理遇到的问题，一开始我也是用fcm的设备组管理，导致发送方会接收到自己发送的消息。这个本来无所谓，根据消息的fcm_token判断一下，如果等于自己的fcm_token，就不处理。但是js客户端是用service worker来处理，当service worker重新唤醒时，因为查询indexedDB和调用fcm接口都要在第二轮事件循环才能拿到自己的fcm_token, 而service worker被唤醒后的第一个事件循环就要处理消息了，所以第一次被唤醒时是不知道自己fcm_token的。 还有一点，fcm js要求你必须对收到的push弹窗，否则他会帮你弹窗，有知道怎么解决的告诉我一下。。。","categories":[{"name":"Firebase","slug":"Firebase","permalink":"https://htchz.cc/categories/Firebase/"}],"tags":[{"name":"数据分片","slug":"数据分片","permalink":"https://htchz.cc/tags/数据分片/"}]},{"title":"[Dubbo]Dubbo SPI 机制","slug":"Dubbo-Dubbo的SPI","date":"2019-03-25T03:44:00.000Z","updated":"2020-06-13T08:53:55.080Z","comments":true,"path":"2436052280.html","link":"","permalink":"https://htchz.cc/2436052280.html","excerpt":"","text":"1. 前言之前一篇[Java基础]Java的SPI机制讲到Java spi的缺陷是在查找所需实现的时候，会实例化无关的实现，那么这篇看看Dubbo是怎么规避这个问题的。 2. Dubbo spi的特点1234567891011@Documented@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.TYPE&#125;)public @interface SPI &#123; /** * default extension name */ String value() default \"\";&#125; 由于配置文件是以key-value配置的，这里可以为SPI接口指定一个默认实现的key Dubbo spi有以下特点 不需要遍历所有实例化所有实现类 增加了对扩展点IoC和AOP的支持，一个扩展点可以直接setter注入其它扩展点。 3. Demo接口,需要加上org.apache.dubbo.common.extension.SPI注解 1234@SPIpublic interface Runner &#123; void run(String name);&#125; 两个实现 1234567891011121314151617public class DefaultRunner implements Runner &#123; private Logger log = LoggerFactory.getLogger(getClass()); @Override public void run(String name) &#123; log.info(\"I'm a DefaultRunner\"); &#125;&#125;public class ExcitedRunner implements Runner &#123; private Logger log = LoggerFactory.getLogger(getClass()); @Override public void run(String name) &#123; log.info(\"I'm a ExcitedRunner!\"); &#125;&#125; 在资源目录META-INF/dubbo下创建文件com.htc.learning.api.Runner 内容是一行一行的键值对，value是实现类，我们只要通过key就能直接拿到所需类。 12default=com.htc.learning.api.impl.DefaultRunnerexcited=com.htc.learning.api.impl.ExcitedRunner 测试方法 12345678@Testpublic void dubboSpiTest() &#123; ExtensionLoader&lt;Runner&gt; extensionLoader = ExtensionLoader.getExtensionLoader(Runner.class); Runner defaultRunner = extensionLoader.getExtension(\"default\"); defaultRunner.run(\"htc\"); Runner excitedRunner = extensionLoader.getExtension(\"excited\"); excitedRunner.run(\"htc\");&#125; 输出 2019-03-23 12:20:50.681 INFO --- [ main] com.htc.learning.api.impl.DefaultRunner : I&apos;m a DefaultRunner 2019-03-23 12:20:50.681 INFO --- [ main] com.htc.learning.api.impl.ExcitedRunner : I&apos;m a ExcitedRunner!4. 原理4.1. getExtensionLoaderDubbo spi与java spi的ServiceLoader对应的，是ExtensionLoader。不同于ServiceLoader的load方法每次返回都要实例化一个对象，ExtensionLoader每次getExtensionLoader会进行缓存。 1234567891011121314151617181920public static &lt;T&gt; ExtensionLoader&lt;T&gt; getExtensionLoader(Class&lt;T&gt; type) &#123; if (type == null) &#123; throw new IllegalArgumentException(\"Extension type == null\"); &#125; if (!type.isInterface()) &#123; throw new IllegalArgumentException(\"Extension type(\" + type + \") is not interface!\"); &#125; if (!withExtensionAnnotation(type)) &#123; throw new IllegalArgumentException(\"Extension type(\" + type + \") is not extension, because WITHOUT @\" + SPI.class.getSimpleName() + \" Annotation!\"); &#125; ExtensionLoader&lt;T&gt; loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); if (loader == null) &#123; EXTENSION_LOADERS.putIfAbsent(type, new ExtensionLoader&lt;T&gt;(type)); loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); &#125; return loader;&#125; ExtensionLoader构造函数 1234private ExtensionLoader(Class&lt;?&gt; type) &#123; this.type = type; objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension());&#125; 其中objectFactory是一个接口,与IOC相关，该接口根据type和name找到一个bean，这个bean可以是Spring的bean，也可以是一个dubbo spi实现类。 12345678910111213@SPIpublic interface ExtensionFactory &#123; /** * Get extension. * * @param type object type. * @param name object name. * @return object instance. */ &lt;T&gt; T getExtension(Class&lt;T&gt; type, String name);&#125; 可以看出，这是也是一个SPI接口，接下来调用的getExtensionLoader逻辑就是通过他实现的。 4.2. getExtension12345678910111213141516171819202122232425262728public T getExtension(String name) &#123; if (name == null || name.length() == 0) throw new IllegalArgumentException(\"Extension name == null\"); if (\"true\".equals(name)) &#123; // 获取默认的拓展实现类 return getDefaultExtension(); &#125; // Holder，顾名思义，用于持有目标对象 Holder&lt;Object&gt; holder = cachedInstances.get(name); if (holder == null) &#123; cachedInstances.putIfAbsent(name, new Holder&lt;Object&gt;()); holder = cachedInstances.get(name); &#125; Object instance = holder.get(); // 双重检查 if (instance == null) &#123; synchronized (holder) &#123; instance = holder.get(); if (instance == null) &#123; // 创建拓展实例 instance = createExtension(name); // 设置实例到 holder 中 holder.set(instance); &#125; &#125; &#125; return (T) instance;&#125; 123456789101112131415161718192021222324252627282930private T createExtension(String name) &#123; // 从配置文件中加载所有的拓展类，可得到“配置项名称”到“配置类”的映射关系表 Class&lt;?&gt; clazz = getExtensionClasses().get(name); if (clazz == null) &#123; throw findException(name); &#125; try &#123; T instance = (T) EXTENSION_INSTANCES.get(clazz); if (instance == null) &#123; // 通过反射创建实例 EXTENSION_INSTANCES.putIfAbsent(clazz, clazz.newInstance()); instance = (T) EXTENSION_INSTANCES.get(clazz); &#125; // 向实例中注入依赖 injectExtension(instance); Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses; if (wrapperClasses != null &amp;&amp; !wrapperClasses.isEmpty()) &#123; // 循环创建 Wrapper 实例 for (Class&lt;?&gt; wrapperClass : wrapperClasses) &#123; // 将当前 instance 作为参数传给 Wrapper 的构造方法，并通过反射创建 Wrapper 实例。 // 然后向 Wrapper 实例中注入依赖，最后将 Wrapper 实例再次赋值给 instance 变量 instance = injectExtension( (T) wrapperClass.getConstructor(type).newInstance(instance)); &#125; &#125; return instance; &#125; catch (Throwable t) &#123; throw new IllegalStateException(\"...\"); &#125;&#125; 这里按逻辑可以拆分成四步 getExtensionClasses()获取接口的所有实现类。这个方法会在很多地方被调用，保证所有类被获取到。由于多次调用缓存也是必须的。 实例化目标类的对象。 IOC注入。注入其他SPI实现。 AOP实现。如果需要，把对象实例包裹在Wrapper中。 4.2.1. getExtensionClasses12345678910111213141516private Map&lt;String, Class&lt;?&gt;&gt; getExtensionClasses() &#123; // 从缓存中获取已加载的拓展类 Map&lt;String, Class&lt;?&gt;&gt; classes = cachedClasses.get(); // 双重检查 if (classes == null) &#123; synchronized (cachedClasses) &#123; classes = cachedClasses.get(); if (classes == null) &#123; // 加载拓展类 classes = loadExtensionClasses(); cachedClasses.set(classes); &#125; &#125; &#125; return classes;&#125; 典型的双重校验，这里的缓存key是实现类的key，值就是实现类了。如果缓存为null，调用loadExtensionClasses初始化缓存。 123456789101112131415161718192021222324252627// synchronized in getExtensionClassesprivate Map&lt;String, Class&lt;?&gt;&gt; loadExtensionClasses() &#123; final SPI defaultAnnotation = type.getAnnotation(SPI.class); if (defaultAnnotation != null) &#123; // 如果设置了默认实现，就缓存以下这个默认实现的key String value = defaultAnnotation.value(); if ((value = value.trim()).length() &gt; 0) &#123; String[] names = NAME_SEPARATOR.split(value); if (names.length &gt; 1) &#123; throw new IllegalStateException(\"more than 1 default extension name on extension \" + type.getName() + \": \" + Arrays.toString(names)); &#125; if (names.length == 1) &#123; cachedDefaultName = names[0]; &#125; &#125; &#125; Map&lt;String, Class&lt;?&gt;&gt; extensionClasses = new HashMap&lt;String, Class&lt;?&gt;&gt;(); loadDirectory(extensionClasses, DUBBO_INTERNAL_DIRECTORY, type.getName()); loadDirectory(extensionClasses, DUBBO_INTERNAL_DIRECTORY, type.getName().replace(\"org.apache\", \"com.alibaba\")); loadDirectory(extensionClasses, DUBBO_DIRECTORY, type.getName()); loadDirectory(extensionClasses, DUBBO_DIRECTORY, type.getName().replace(\"org.apache\", \"com.alibaba\")); loadDirectory(extensionClasses, SERVICES_DIRECTORY, type.getName()); loadDirectory(extensionClasses, SERVICES_DIRECTORY, type.getName().replace(\"org.apache\", \"com.alibaba\")); return extensionClasses;&#125; java spi的配置只能放在一个目录META-INF/services/,dubbo spi的配置可以放在三个目录 12345private static final String SERVICES_DIRECTORY = \"META-INF/services/\";private static final String DUBBO_DIRECTORY = \"META-INF/dubbo/\";private static final String DUBBO_INTERNAL_DIRECTORY = DUBBO_DIRECTORY + \"internal/\"; 这里的依赖我用的是apache-dubbo，相对于alibaba-dubbo三个目录，估计为了兼容，apache-dubbo版本的loadDirectory方法进行了一个包名的替换。 1234567891011121314151617181920212223private void loadDirectory(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, String dir) &#123; // fileName = 文件夹路径 + type 全限定名 String fileName = dir + type.getName(); try &#123; Enumeration&lt;java.net.URL&gt; urls; ClassLoader classLoader = findClassLoader(); // 根据文件名加载所有的同名文件 if (classLoader != null) &#123; urls = classLoader.getResources(fileName); &#125; else &#123; urls = ClassLoader.getSystemResources(fileName); &#125; if (urls != null) &#123; while (urls.hasMoreElements()) &#123; java.net.URL resourceURL = urls.nextElement(); // 加载资源 loadResource(extensionClasses, classLoader, resourceURL); &#125; &#125; &#125; catch (Throwable t) &#123; logger.error(\"...\"); &#125;&#125; 接下来“真·读取配置文件” 123456789101112131415161718192021222324252627282930313233343536373839404142private void loadResource(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, ClassLoader classLoader, java.net.URL resourceURL) &#123; try &#123; BufferedReader reader = new BufferedReader( new InputStreamReader(resourceURL.openStream(), \"utf-8\")); try &#123; String line; // 按行读取配置内容 while ((line = reader.readLine()) != null) &#123; // 定位 # 字符 final int ci = line.indexOf('#'); if (ci &gt;= 0) &#123; // 截取 # 之前的字符串，# 之后的内容为注释，需要忽略 line = line.substring(0, ci); &#125; line = line.trim(); if (line.length() &gt; 0) &#123; try &#123; String name = null; int i = line.indexOf('='); if (i &gt; 0) &#123; // 以等于号 = 为界，截取键与值 name = line.substring(0, i).trim(); line = line.substring(i + 1).trim(); &#125; if (line.length() &gt; 0) &#123; // 加载类，并通过 loadClass 方法对类进行缓存 loadClass(extensionClasses, resourceURL, Class.forName(line, true, classLoader), name); &#125; &#125; catch (Throwable t) &#123; IllegalStateException e = new IllegalStateException(\"Failed to load extension class...\"); &#125; &#125; &#125; &#125; finally &#123; reader.close(); &#125; &#125; catch (Throwable t) &#123; logger.error(\"Exception when load extension class...\"); &#125;&#125; 读完配置文件，下面不单是对类进行加载，而且还对Adaptive、Wrapper类进行缓存。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455private void loadClass(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, java.net.URL resourceURL, Class&lt;?&gt; clazz, String name) throws NoSuchMethodException &#123; if (!type.isAssignableFrom(clazz)) &#123; throw new IllegalStateException(\"Error when load extension class(interface: \" + type + \", class line: \" + clazz.getName() + \"), class \" + clazz.getName() + \"is not subtype of interface.\"); &#125; // 只能有一个自适应实现类 if (clazz.isAnnotationPresent(Adaptive.class)) &#123; if (cachedAdaptiveClass == null) &#123; cachedAdaptiveClass = clazz; &#125; else if (!cachedAdaptiveClass.equals(clazz)) &#123; throw new IllegalStateException(...); &#125; &#125; else if (isWrapperClass(clazz)) &#123; Set&lt;Class&lt;?&gt;&gt; wrappers = cachedWrapperClasses; if (wrappers == null) &#123; cachedWrapperClasses = new ConcurrentHashSet&lt;Class&lt;?&gt;&gt;(); wrappers = cachedWrapperClasses; &#125; wrappers.add(clazz); &#125; else &#123; clazz.getConstructor(); if (name == null || name.length() == 0) &#123; name = findAnnotationName(clazz); if (name.length() == 0) &#123; throw new IllegalStateException(...); &#125; &#125; String[] names = NAME_SEPARATOR.split(name); if (names != null &amp;&amp; names.length &gt; 0) &#123; Activate activate = clazz.getAnnotation(Activate.class); if (activate != null) &#123; cachedActivates.put(names[0], activate); &#125; else &#123; // support com.alibaba.dubbo.common.extension.Activate com.alibaba.dubbo.common.extension.Activate oldActivate = clazz.getAnnotation(com.alibaba.dubbo.common.extension.Activate.class); if (oldActivate != null) &#123; cachedActivates.put(names[0], oldActivate); &#125; &#125; for (String n : names) &#123; if (!cachedNames.containsKey(clazz)) &#123; cachedNames.put(clazz, n); &#125; Class&lt;?&gt; c = extensionClasses.get(n); if (c == null) &#123; extensionClasses.put(n, clazz); // 实现类重复报错 &#125; else if (c != clazz) &#123; throw new IllegalStateException(...); &#125; &#125; &#125; &#125;&#125; 要注意的几点： @Adaptive注解是标明一个SPI实现类是属于自适应类，一个SPI接口只能有一个自适应实现，这从代码逻辑可以看出来，如果!cachedAdaptiveClass.equals(clazz)则报错。具体这个自适应类可以做什么，下面会说。 Wrapper类是AOP类 这里还有一个@Active注解，标明实现类的激活条件，是一种条件机制。 4.2.2. IOC1234567891011121314151617181920212223242526272829303132333435private T injectExtension(T instance) &#123; try &#123; if (objectFactory != null) &#123; for (Method method : instance.getClass().getMethods()) &#123; if (method.getName().startsWith(\"set\") &amp;&amp; method.getParameterTypes().length == 1 &amp;&amp; Modifier.isPublic(method.getModifiers())) &#123; /** * Check &#123;@link DisableInject&#125; to see if we need auto injection for this property */ if (method.getAnnotation(DisableInject.class) != null) &#123; continue; &#125; Class&lt;?&gt; pt = method.getParameterTypes()[0]; if (ReflectUtils.isPrimitives(pt)) &#123; continue; &#125; try &#123; String property = method.getName().length() &gt; 3 ? method.getName().substring(3, 4).toLowerCase() + method.getName().substring(4) : \"\"; Object object = objectFactory.getExtension(pt, property); if (object != null) &#123; method.invoke(instance, object); &#125; &#125; catch (Exception e) &#123; logger.error(\"fail to inject via method \" + method.getName() + \" of interface \" + type.getName() + \": \" + e.getMessage(), e); &#125; &#125; &#125; &#125; &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; return instance;&#125; dubbo的IOC目前只对setter方法支持，如果set的方法参数只有一个，那么就拿参数类型pt和setProperty的property去objectFactory找。objectFactory是ExtensionFactory接口，有两个实现， 上面提到ExtensionLoader构造函数 1234private ExtensionLoader(Class&lt;?&gt; type) &#123; this.type = type; objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension());&#125; 这里的getAdaptiveExtension()是什么？ 4.2.3. @AdaptivegetAdaptiveExtension()的实现如下， 12345678910111213141516171819202122232425public T getAdaptiveExtension() &#123; Object instance = cachedAdaptiveInstance.get(); if (instance == null) &#123; if (createAdaptiveInstanceError == null) &#123; synchronized (cachedAdaptiveInstance) &#123; // 这是前面spi load class缓存的 instance = cachedAdaptiveInstance.get(); if (instance == null) &#123; try &#123; // 到这里说明没有自适应扩展类,需要动态创建 instance = (); cachedAdaptiveInscreateAdaptiveExtensiontance.set(instance); &#125; catch (Throwable t) &#123; createAdaptiveInstanceError = t; throw new IllegalStateException(...); &#125; &#125; &#125; &#125; else &#123; throw new IllegalStateException(...); &#125; &#125; return (T) instance;&#125; dubbo的Adaptive机制如下 如果一个SPI接口实现类存在自适应实现，那么直接拿这个类； 否则动态创建自适应类(手动拼接代码字符，并转为字节码，加载到jvm中)，由于dubbo是以url为协议的，所以创建的自适应代码是根据url中的内容决定使用那种实现。 当 Adaptive 注解在类上时，Dubbo 不会为该类生成代理类。注解在方法（接口方法）上时，Dubbo 则会为该方法生成代理逻辑。Adaptive 注解在类上的情况很少，在 Dubbo 中，仅有两个类被 Adaptive 注解了，分别是 AdaptiveCompiler 和 AdaptiveExtensionFactory。此种情况，表示拓展的加载逻辑由人工编码完成。更多时候，Adaptive 是注解在接口方法上的，表示拓展的加载逻辑需由框架自动生成。 下面是alibaba dubbo 的中文注释 12345678910111213141516171819202122232425@Documented@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)public @interface Adaptive &#123; /** * 从&#123;@link URL&#125;的Key名，对应的Value作为要Adapt成的Extension名。 * &lt;p&gt; * 如果&#123;@link URL&#125;这些Key都没有Value，使用 用 缺省的扩展（在接口的&#123;@link SPI&#125;中设定的值）。&lt;br&gt; * 比如，&lt;code&gt;String[] &#123;\"key1\", \"key2\"&#125;&lt;/code&gt;，表示 * &lt;ol&gt; * &lt;li&gt;先在URL上找key1的Value作为要Adapt成的Extension名； * &lt;li&gt;key1没有Value，则使用key2的Value作为要Adapt成的Extension名。 * &lt;li&gt;key2没有Value，使用缺省的扩展。 * &lt;li&gt;如果没有设定缺省扩展，则方法调用会抛出&#123;@link IllegalStateException&#125;。 * &lt;/ol&gt; * &lt;p&gt; * 如果不设置则缺省使用Extension接口类名的点分隔小写字串。&lt;br&gt; * 即对于Extension接口&#123;@code com.alibaba.dubbo.xxx.YyyInvokerWrapper&#125;的缺省值为&lt;code&gt;String[] &#123;\"yyy.invoker.wrapper\"&#125;&lt;/code&gt; * * @see SPI#value() */ String[] value() default &#123;&#125;;&#125; 也就是说，如果@Adaptive上的key从url获取不到，就以@SPI上的默认扩展值作为key去url找，如果@SPI都没默认值，就将接口类名用.分隔，作为接口缺省值（这么奇怪的key吗 =。=） 以下面代码为例， 123456789101112@SPI(\"dubbo\")public interface Protocol &#123; int getDefaultPort(); @Adaptive &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException; @Adaptive &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException; void destroy();&#125; 1Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); 这里会返回一个Protocol$Adaptive类，因为Protocol没有一个自适应实现类，所以dubbo动态生成了一个自适应类，通过debug得 12345678910111213141516171819202122232425262728293031323334353637package org.apache.dubbo.rpc;import org.apache.dubbo.common.extension.ExtensionLoader;public class Protocol$Adaptive implements org.apache.dubbo.rpc.Protocol &#123; public void destroy() &#123; throw new UnsupportedOperationException(\"method public abstract void org.apache.dubbo.rpc.Protocol.destroy() of interface org.apache.dubbo.rpc.Protocol is not adaptive method!\"); &#125; public int getDefaultPort() &#123; throw new UnsupportedOperationException(\"method public abstract int org.apache.dubbo.rpc.Protocol.getDefaultPort() of interface org.apache.dubbo.rpc.Protocol is not adaptive method!\"); &#125; public org.apache.dubbo.rpc.Exporter export(org.apache.dubbo.rpc.Invoker arg0) throws org.apache.dubbo.rpc.RpcException &#123; if (arg0 == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument == null\"); if (arg0.getUrl() == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument getUrl() == null\"); org.apache.dubbo.common.URL url = arg0.getUrl(); // 这里默认使用dubbo String extName = (url.getProtocol() == null ? \"dubbo\" : url.getProtocol()); if (extName == null) throw new IllegalStateException(\"Fail to get extension(org.apache.dubbo.rpc.Protocol) name from url(\" + url.toString() + \") use keys([protocol])\"); org.apache.dubbo.rpc.Protocol extension = (org.apache.dubbo.rpc.Protocol) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.Protocol.class).getExtension(extName); return extension.export(arg0); &#125; public org.apache.dubbo.rpc.Invoker refer(java.lang.Class arg0, org.apache.dubbo.common.URL arg1) throws org.apache.dubbo.rpc.RpcException &#123; if (arg1 == null) throw new IllegalArgumentException(\"url == null\"); org.apache.dubbo.common.URL url = arg1; // 这里默认使用dubbo String extName = (url.getProtocol() == null ? \"dubbo\" : url.getProtocol()); if (extName == null) throw new IllegalStateException(\"Fail to get extension(org.apache.dubbo.rpc.Protocol) name from url(\" + url.toString() + \") use keys([protocol])\"); org.apache.dubbo.rpc.Protocol extension = (org.apache.dubbo.rpc.Protocol) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.Protocol.class).getExtension(extName); return extension.refer(arg0, arg1); &#125;&#125; 这里Protocol$Adaptive代码里，如果接口方法没有设置@Adaptive注解，以抛异常处理。 在生成的方法中，以protocol为key去url里查找这个key的值，如果url里没有设置，就以Protocol接口上的@SPI注解默认值——“dubbo”作为自适应类要找的扩展的name。 创建code代码太长，不贴。 拿ExtensionFactory来说，他有三个实现（有一个废弃的） 一个自适应实现类，以@Adaptive标注 1234567891011121314151617181920212223242526@Adaptivepublic class AdaptiveExtensionFactory implements ExtensionFactory &#123; private final List&lt;ExtensionFactory&gt; factories; public AdaptiveExtensionFactory() &#123; ExtensionLoader&lt;ExtensionFactory&gt; loader = ExtensionLoader.getExtensionLoader(ExtensionFactory.class); List&lt;ExtensionFactory&gt; list = new ArrayList&lt;ExtensionFactory&gt;(); for (String name : loader.getSupportedExtensions()) &#123; list.add(loader.getExtension(name)); &#125; factories = Collections.unmodifiableList(list); &#125; @Override public &lt;T&gt; T getExtension(Class&lt;T&gt; type, String name) &#123; for (ExtensionFactory factory : factories) &#123; T extension = factory.getExtension(type, name); if (extension != null) &#123; return extension; &#125; &#125; return null; &#125;&#125; 一个用于获取dubbo Spi实现类 1234567891011121314public class SpiExtensionFactory implements ExtensionFactory &#123; @Override public &lt;T&gt; T getExtension(Class&lt;T&gt; type, String name) &#123; if (type.isInterface() &amp;&amp; type.isAnnotationPresent(SPI.class)) &#123; ExtensionLoader&lt;T&gt; loader = ExtensionLoader.getExtensionLoader(type); if (!loader.getSupportedExtensions().isEmpty()) &#123; return loader.getAdaptiveExtension(); &#125; &#125; return null; &#125;&#125; 一个是用于获取Spring的bean，代码太长不贴 4.2.4. @Active@Active注解用于实现类上，表示一些激活条件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@Documented@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)public @interface Activate &#123; /** * Activate the current extension when one of the groups matches. The group passed into * &#123;@link ExtensionLoader#getActivateExtension(URL, String, String)&#125; will be used for matching. * * @return group names to match * @see ExtensionLoader#getActivateExtension(URL, String, String) */ String[] group() default &#123;&#125;; /** * Activate the current extension when the specified keys appear in the URL's parameters. * &lt;p&gt; * For example, given &lt;code&gt;@Activate(\"cache, validation\")&lt;/code&gt;, the current extension will be return only when * there's either &lt;code&gt;cache&lt;/code&gt; or &lt;code&gt;validation&lt;/code&gt; key appeared in the URL's parameters. * &lt;/p&gt; * * @return URL parameter keys * @see ExtensionLoader#getActivateExtension(URL, String) * @see ExtensionLoader#getActivateExtension(URL, String, String) */ String[] value() default &#123;&#125;; /** * Relative ordering info, optional * Deprecated since 2.7.0 * * @return extension list which should be put before the current one */ @Deprecated String[] before() default &#123;&#125;; /** * Relative ordering info, optional * Deprecated since 2.7.0 * * @return extension list which should be put after the current one */ @Deprecated String[] after() default &#123;&#125;; /** * Absolute ordering info, optional * * @return absolute ordering info */ int order() default 0;&#125; 同样由于dubbo是面向url的协议，所以这些激活条件需要通过url匹配。 在加载类的时候，有这么几行代码，以扩展名字为key，以扩展上的注解为值进行map缓存。 1234567891011// org.apache.dubbo.common.extension.ExtensionLoader#loadClassActivate activate = clazz.getAnnotation(Activate.class);if (activate != null) &#123; cachedActivates.put(names[0], activate);&#125; else &#123; // support com.alibaba.dubbo.common.extension.Activate com.alibaba.dubbo.common.extension.Activate oldActivate = clazz.getAnnotation(com.alibaba.dubbo.common.extension.Activate.class); if (oldActivate != null) &#123; cachedActivates.put(names[0], oldActivate); &#125;&#125; 获取激活的的扩展可以通过以下方法调用 123456789101112131415161718192021222324252627282930313233public List&lt;T&gt; getActivateExtension(URL url, String key) &#123; return getActivateExtension(url, key, null);&#125;/** * This is equivalent to &lt;pre&gt; * getActivateExtension(url, values, null); * &lt;/pre&gt; * * @param url url * @param values extension point names * @return extension list which are activated * @see #getActivateExtension(com.alibaba.dubbo.common.URL, String[], String) */public List&lt;T&gt; getActivateExtension(URL url, String[] values) &#123; return getActivateExtension(url, values, null);&#125;/** * This is equivalent to &lt;pre&gt; * getActivateExtension(url, url.getParameter(key).split(\",\"), null); * &lt;/pre&gt; * * @param url url * @param key url parameter key which used to get extension point names * @param group group * @return extension list which are activated. * @see #getActivateExtension(com.alibaba.dubbo.common.URL, String[], String) */public List&lt;T&gt; getActivateExtension(URL url, String key, String group) &#123; String value = url.getParameter(key); return getActivateExtension(url, value == null || value.length() == 0 ? null : Constants.COMMA_SPLIT_PATTERN.split(value), group);&#125; 这些方法的具体实现如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * Get activate extensions. * * @param url url * @param values extension point names * @param group group * @return extension list which are activated * @see com.alibaba.dubbo.common.extension.Activate */public List&lt;T&gt; getActivateExtension(URL url, String[] values, String group) &#123; List&lt;T&gt; exts = new ArrayList&lt;T&gt;(); List&lt;String&gt; names = values == null ? new ArrayList&lt;String&gt;(0) : Arrays.asList(values); if (!names.contains(Constants.REMOVE_VALUE_PREFIX + Constants.DEFAULT_KEY)) &#123; getExtensionClasses(); for (Map.Entry&lt;String, Activate&gt; entry : cachedActivates.entrySet()) &#123; String name = entry.getKey(); Activate activate = entry.getValue(); if (isMatchGroup(group, activate.group())) &#123; T ext = getExtension(name); if (!names.contains(name) &amp;&amp; !names.contains(Constants.REMOVE_VALUE_PREFIX + name) &amp;&amp; isActive(activate, url)) &#123; exts.add(ext); &#125; &#125; &#125; // order 值越小越靠前 Collections.sort(exts, ActivateComparator.COMPARATOR); &#125; List&lt;T&gt; usrs = new ArrayList&lt;T&gt;(); for (int i = 0; i &lt; names.size(); i++) &#123; String name = names.get(i); if (!name.startsWith(Constants.REMOVE_VALUE_PREFIX) &amp;&amp; !names.contains(Constants.REMOVE_VALUE_PREFIX + name)) &#123; if (Constants.DEFAULT_KEY.equals(name)) &#123; if (usrs.size() &gt; 0) &#123; exts.addAll(0, usrs); usrs.clear(); &#125; &#125; else &#123; T ext = getExtension(name); usrs.add(ext); &#125; &#125; &#125; if (usrs.size() &gt; 0) &#123; exts.addAll(usrs); &#125; return exts;&#125; 123456789101112131415161718private boolean isActive(String[] keys, URL url) &#123; if (keys.length == 0) &#123; return true; &#125; // 两次for循环 for (String key : keys) &#123; for (Map.Entry&lt;String, String&gt; entry : url.getParameters().entrySet()) &#123; String k = entry.getKey(); String v = entry.getValue(); // 如果key存在且对应的value不为空 if ((k.equals(key) || k.endsWith(\".\" + key)) &amp;&amp; ConfigUtils.isNotEmpty(v)) &#123; return true; &#125; &#125; &#125; return false;&#125; 匹配条件的逻辑是，先匹配组，再匹配键，键只要都存在值，那么即匹配成功。当注解上order值越小，这个实现类的排序越靠前。 关于排序，这里的一个具体例子是Dubbo服务的过滤器往往加上了@Active注解，这时候如果要设置过滤器的处理顺序，就可以通过该注解上的order属性设置。 5. 结束语还差Wrapper机制没看，wrapper就是一种aop机制，通过手工编码的方式完成aop。关于下面那段话我也没看到具体的例子。 如果扩展点加载失败，连扩展点的名称都拿不到了。比如：JDK标准的ScriptEngine，通过getName();获取脚本类型的名称，但如果RubyScriptEngine因为所依赖的jruby.jar不存在，导致RubyScriptEngine类加载失败，这个失败原因被吃掉了，和ruby对应不起来，当用户执行ruby脚本时，会报不支持ruby，而不是真正失败的原因。 6. 参考 Apache Dubbo SPI","categories":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://htchz.cc/categories/Dubbo/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"https://htchz.cc/tags/OOP/"}]},{"title":"[Java代理]Cglib代理","slug":"Java代理-cglib代理","date":"2019-03-10T06:03:00.000Z","updated":"2019-08-15T16:08:49.216Z","comments":true,"path":"3922793788.html","link":"","permalink":"https://htchz.cc/3922793788.html","excerpt":"","text":"1. Cglib CGLIB是一个强大的高性能的代码生成包。CGLIB包的底层是通过使用一个小而快的字节码处理框架ASM，来转换字节码并生成新的类。除了CGLIB包，脚本语言例如Groovy和BeanShell，也是使用ASM来生成java的字节码。当然不鼓励直接使用ASM，因为它要求你必须对JVM内部结构包括class文件的格式和指令集都很熟悉。 2. Demo直接上Demo～ 1234567891011/** * 目标类 */public class RunnerDefault implements Runner &#123; private Logger log = LoggerFactory.getLogger(getClass()); @Override public void run(String name) &#123; log.info(&quot;run: &quot; + name); &#125;&#125; 指定Callback的顺序 123456789public class CglibCallbackFilter implements CallbackFilter &#123; @Override public int accept(Method method) &#123; if (&quot;toString&quot;.equals(method.getName())) &#123; return 1; &#125; return 0; &#125;&#125; 代理逻辑及生成代理的封装 1234567891011121314151617// 拦截所有方法public class CglibProxy implements MethodInterceptor &#123; private Enhancer enhancer = new Enhancer(); @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; objects[0] = &quot;cglib &quot; + objects[0]; return methodProxy.invokeSuper(o, objects); &#125; public Object newProxy(Class klass) &#123; enhancer.setSuperclass(klass); enhancer.setCallbackFilter(new CglibCallbackFilter()); enhancer.setCallbacks(new Callback[]&#123;new CglibProxy(), new CglibStringProxy()&#125;); return enhancer.create(); &#125;&#125; 123456789// 为了拦截toString方法public class CglibStringProxy implements MethodInterceptor &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; logger.info(\"toString hijacked\"); return null; &#125;&#125; 测试类 123456789@Testpublic void testCglib() &#123; // 生成class文件 System.setProperty(DebuggingClassWriter.DEBUG_LOCATION_PROPERTY, \"./\"); CglibProxy cglibProxy = new CglibProxy(); RunnerDefault runner = (RunnerDefault) cglibProxy.newProxy(RunnerDefault.class); runner.run(\"proxy\"); runner.toString();&#125; 输出: 2019-03-07 16:48:44.248 INFO --- [ main] RunnerDefault$$EnhancerByCGLIB$$5b557d48 : run: cglib proxy 2019-03-07 16:48:44.254 INFO --- [ main] com.htc.learning.proxy.CglibStringProxy : toString hijacked 也可以不配置CallbackFilter，只能配一个Callback，Enhancer会把单个的Callback转为数组,并且把CallbackFilter设置为ALL_ZERO，固定返回0 下面是上面test执行过程中生成的文件 3. NamingPolicy上面的RunnerDefault$$EnhancerByCGLIB$$16487fc是cglib命名而来的，默认实现类是net.sf.cglib.core.DefaultNamingPolicy命名规则如下： 目标ClassName + &quot;$$&quot; + 使用cglib处理的ClassName + &quot;ByCGLIB&quot; + &quot;$$&quot; + key的hashcode4. Key和缓存4.1. KeyFactory先看KeyFactory，这个类可以生成一个代理类，这个代理类对于给定的参数，每次调用返回的对象的equals、hashcode方法都是返回相同的值。由于cglib的配置项比较多，所以使用这个类用于生成缓存key的。 目标类需要提供一个public Object newInstance(...)的声明，参数数量类型随意。 下面是cglib 12345678910111213141516public class KeySample &#123; private interface MyFactory &#123; public Object newInstance(int a, char[] b, String d); &#125; public static void main(String[] args) &#123; // 源码没有这一行，加上这一行，cglib的debug模式打开，就可以输出生成代理类的class文件了。 System.setProperty(DebuggingClassWriter.DEBUG_LOCATION_PROPERTY, \"./\"); MyFactory f = (MyFactory)KeyFactory.create(MyFactory.class); Object key1 = f.newInstance(20, new char[]&#123; 'a', 'b' &#125;, \"hello\"); Object key2 = f.newInstance(20, new char[]&#123; 'a', 'b' &#125;, \"hello\"); Object key3 = f.newInstance(20, new char[]&#123; 'a', '_' &#125;, \"hello\"); System.out.println(key1.equals(key2));// true System.out.println(key2.equals(key3));// false &#125;&#125; 三次生成的是不同对象。key1和key2是相等的，key2和key3是不等的。追踪代码可以看到KeyFactory重写了代理类的equals、hashcode 123456789101112131415161718192021222324252627282930313233343536// net.sf.cglib.core.KeyFactory.Generator#generateClass...// hash codee = ce.begin_method(Constants.ACC_PUBLIC, HASH_CODE, null);int hc = (constant != 0) ? constant : PRIMES[(int)(Math.abs(seed) % PRIMES.length)];int hm = (multiplier != 0) ? multiplier : PRIMES[(int)(Math.abs(seed * 13) % PRIMES.length)];e.push(hc);for (int i = 0; i &lt; parameterTypes.length; i++) &#123; e.load_this(); e.getfield(getFieldName(i)); EmitUtils.hash_code(e, parameterTypes[i], hm, customizers);&#125;e.return_value();e.end_method();// equalse = ce.begin_method(Constants.ACC_PUBLIC, EQUALS, null);Label fail = e.make_label();e.load_arg(0);e.instance_of_this();e.if_jump(e.EQ, fail);for (int i = 0; i &lt; parameterTypes.length; i++) &#123; e.load_this(); e.getfield(getFieldName(i)); e.load_arg(0); e.checkcast_this(); e.getfield(getFieldName(i)); EmitUtils.not_equals(e, parameterTypes[i], fail, customizers);&#125;e.push(1);e.return_value();e.mark(fail);e.push(0);e.return_value();e.end_method();... 4.2. 代理缓存所有cglib代理类的缓存都存在于net.sf.cglib.core.AbstractClassGenerator的static变量里， 123private static volatile Map&lt;ClassLoader, ClassLoaderData&gt; CACHE = new WeakHashMap&lt;ClassLoader, ClassLoaderData&gt;();private static final boolean DEFAULT_USE_CACHE = Boolean.parseBoolean(System.getProperty(\"cglib.useCache\", \"true\")); 这个缓存是一个WeakHashMap，key和jdk代理一样，也是以ClassLoader为为key，至于ClassLoaderData是一个关于interfaces的封装，到最底层其实是一个ConcurrentHashMap。看net.sf.cglib.core.AbstractClassGenerator#create的代码 1234567891011121314151617181920212223242526272829protected Object create(Object key) &#123; try &#123; ClassLoader loader = getClassLoader(); Map&lt;ClassLoader, ClassLoaderData&gt; cache = CACHE; ClassLoaderData data = cache.get(loader); // 维护多线程 if (data == null) &#123; synchronized (AbstractClassGenerator.class) &#123; cache = CACHE; data = cache.get(loader); if (data == null) &#123; Map&lt;ClassLoader, ClassLoaderData&gt; newCache = new WeakHashMap&lt;ClassLoader, ClassLoaderData&gt;(cache); data = new ClassLoaderData(loader); newCache.put(loader, data); CACHE = newCache; &#125; &#125; &#125; this.key = key; // 这里发生了二级缓存的put操作 Object obj = data.get(this, getUseCache()); if (obj instanceof Class) &#123; return firstInstance((Class) obj); &#125; return nextInstance(obj); &#125; catch (...) &#123; ... &#125;&#125; 看net.sf.cglib.core.AbstractClassGenerator.ClassLoaderData#get方法 12345678910public Object get(AbstractClassGenerator gen, boolean useCache) &#123; // 不使用缓存直接生成 if (!useCache) &#123; return gen.generate(ClassLoaderData.this); &#125; else &#123; // 底层是去ConcurrentHashMap拿 Object cachedValue = generatedClasses.get(gen); return gen.unwrapCachedValue(cachedValue); &#125;&#125; 前面说到二级缓存其实是ConcurrentHashMap,那么key，value分别是什么？key是AbstractClassGenerator子类决定的，比如KeyFactory使用的是目标类名；至于value又有jdk代理的味道——value值不是固定的，可能是生成的代理类，也可能是一个FutureTask，多个线程下多个FutureTask调用get()只会有一个在执行，避免了重复生成字节码。 1234567891011121314151617181920212223242526272829303132333435363738394041protected V createEntry(final K key, KK cacheKey, Object v) &#123; FutureTask&lt;V&gt; task; boolean creator = false; if (v != null) &#123; // Another thread is already loading an instance task = (FutureTask&lt;V&gt;) v; &#125; else &#123; task = new FutureTask&lt;V&gt;(new Callable&lt;V&gt;() &#123; public V call() throws Exception &#123; return loader.apply(key); &#125; &#125;); Object prevTask = map.putIfAbsent(cacheKey, task); if (prevTask == null) &#123; // creator does the load creator = true; task.run(); &#125; else if (prevTask instanceof FutureTask) &#123; task = (FutureTask&lt;V&gt;) prevTask; &#125; else &#123; return (V) prevTask; &#125; &#125; V result; try &#123; result = task.get(); &#125; catch (InterruptedException e) &#123; throw new IllegalStateException(\"Interrupted while loading cache item\", e); &#125; catch (ExecutionException e) &#123; Throwable cause = e.getCause(); if (cause instanceof RuntimeException) &#123; throw ((RuntimeException) cause); &#125; throw new IllegalStateException(\"Unable to load cache item\", cause); &#125; if (creator) &#123; map.put(cacheKey, result); &#125; return result;&#125; 5. EnhancerEnhancer是CGLib中的一个字节码增强器，一般我们都用这个来进行生成cglib代理类。 123456789101112131415private Class[] interfaces;private CallbackFilter filter;private Callback[] callbacks;// 回调逻辑的类型，包括 MethodInterceptor|NoOp|LazyLoader|Dispatcher|InvocationHandler|FixedValueprivate Type[] callbackTypes;private boolean validateCallbackTypes;// create()是否只生成代理类,而不是返回一个对象,如果只生成代理类，callback不能设置，会报错private boolean classOnly;private Class superclass;private Class[] argumentTypes;private Object[] arguments;// 是否使用工厂类private boolean useFactory = true;private Long serialVersionUID;private boolean interceptDuringConstruction = true; 下面是创建逻辑 123456789101112131415private Object createHelper() &#123; // 这里进行一些配置校验，比如设置了多个Callback但是没有设置filter preValidate(); // 这里KEY_FACTORY是KeyFactory实例 Object key = KEY_FACTORY.newInstance((superclass != null) ? superclass.getName() : null, ReflectUtils.getNames(interfaces), filter == ALL_ZERO ? null : new WeakCacheKey&lt;CallbackFilter&gt;(filter), callbackTypes, useFactory, interceptDuringConstruction, serialVersionUID); this.currentKey = key; Object result = super.create(key); return result;&#125; Object result = super.create(key);又是跳到上面提到过的net.sf.cglib.core.AbstractClassGenerator#create 123456789101112131415161718192021222324252627protected Object create(Object key) &#123; try &#123; ClassLoader loader = getClassLoader(); Map&lt;ClassLoader, ClassLoaderData&gt; cache = CACHE; ClassLoaderData data = cache.get(loader); if (data == null) &#123; synchronized (AbstractClassGenerator.class) &#123; cache = CACHE; data = cache.get(loader); if (data == null) &#123; Map&lt;ClassLoader, ClassLoaderData&gt; newCache = new WeakHashMap&lt;ClassLoader, ClassLoaderData&gt;(cache); data = new ClassLoaderData(loader); newCache.put(loader, data); CACHE = newCache; &#125; &#125; &#125; this.key = key; Object obj = data.get(this, getUseCache()); if (obj instanceof Class) &#123; return firstInstance((Class) obj); &#125; return nextInstance(obj); &#125; catch (...) &#123; ... &#125;&#125; 如上一小节提到，这里面是有缓存的。 5.1. 代理主流程net.sf.cglib.proxy.Enhancer#generateClass方法负责生成代理，主要是通过CallbackFilter为不同的Method提供不同的Callback 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596public void generateClass(ClassVisitor v) throws Exception &#123; Class sc = (superclass == null) ? Object.class : superclass; if (TypeUtils.isFinal(sc.getModifiers())) throw new IllegalArgumentException(\"Cannot subclass final class \" + sc.getName()); List constructors = new ArrayList(Arrays.asList(sc.getDeclaredConstructors())); filterConstructors(sc, constructors); // Order is very important: must add superclass, then // its superclass chain, then each interface and // its superinterfaces. List actualMethods = new ArrayList(); List interfaceMethods = new ArrayList(); final Set forcePublic = new HashSet(); // 看下面代码 getMethods(sc, interfaces, actualMethods, interfaceMethods, forcePublic); // 这里把actualMethods中，非abstract,非native,非synchronized方法的修饰符全部变成final，将转化后的方法信息MethodInfo列表 记录在methods中 List methods = CollectionUtils.transform(actualMethods, new Transformer() &#123; public Object transform(Object value) &#123; Method method = (Method)value; int modifiers = Constants.ACC_FINAL | (method.getModifiers() &amp; ~Constants.ACC_ABSTRACT &amp; ~Constants.ACC_NATIVE &amp; ~Constants.ACC_SYNCHRONIZED); if (forcePublic.contains(MethodWrapper.create(method))) &#123; modifiers = (modifiers &amp; ~Constants.ACC_PROTECTED) | Constants.ACC_PUBLIC; &#125; return ReflectUtils.getMethodInfo(method, modifiers); &#125; &#125;); ClassEmitter e = new ClassEmitter(v); // 这个currentData不知道是干嘛的 if (currentData == null) &#123; e.begin_class(Constants.V1_2, Constants.ACC_PUBLIC, getClassName(), Type.getType(sc), (useFactory ? TypeUtils.add(TypeUtils.getTypes(interfaces), FACTORY) : TypeUtils.getTypes(interfaces)), Constants.SOURCE_FILE); &#125; else &#123; e.begin_class(Constants.V1_2, Constants.ACC_PUBLIC, getClassName(), null, new Type[]&#123;FACTORY&#125;, Constants.SOURCE_FILE); &#125; List constructorInfo = CollectionUtils.transform(constructors, MethodInfoTransformer.getInstance()); e.declare_field(Constants.ACC_PRIVATE, BOUND_FIELD, Type.BOOLEAN_TYPE, null); e.declare_field(Constants.ACC_PUBLIC | Constants.ACC_STATIC, FACTORY_DATA_FIELD, OBJECT_TYPE, null); if (!interceptDuringConstruction) &#123; e.declare_field(Constants.ACC_PRIVATE, CONSTRUCTED_FIELD, Type.BOOLEAN_TYPE, null); &#125; e.declare_field(Constants.PRIVATE_FINAL_STATIC, THREAD_CALLBACKS_FIELD, THREAD_LOCAL, null); e.declare_field(Constants.PRIVATE_FINAL_STATIC, STATIC_CALLBACKS_FIELD, CALLBACK_ARRAY, null); if (serialVersionUID != null) &#123; e.declare_field(Constants.PRIVATE_FINAL_STATIC, Constants.SUID_FIELD_NAME, Type.LONG_TYPE, serialVersionUID); &#125; // 根据callbackTypes增加属性，名字为CGLIB$CALLBACK_xx(xx是序号) for (int i = 0; i &lt; callbackTypes.length; i++) &#123; e.declare_field(Constants.ACC_PRIVATE, getCallbackField(i), callbackTypes[i], null); &#125; // This is declared private to avoid \"public field\" pollution e.declare_field(Constants.ACC_PRIVATE | Constants.ACC_STATIC, CALLBACK_FILTER_FIELD, OBJECT_TYPE, null); if (currentData == null) &#123; // 为目标方法配置Callback emitMethods(e, methods, actualMethods); emitConstructors(e, constructorInfo); &#125; else &#123; emitDefaultConstructor(e); &#125; emitSetThreadCallbacks(e); emitSetStaticCallbacks(e); emitBindCallbacks(e); if (useFactory || currentData != null) &#123; int[] keys = getCallbackKeys(); emitNewInstanceCallbacks(e); emitNewInstanceCallback(e); emitNewInstanceMultiarg(e, constructorInfo); emitGetCallback(e, keys); emitSetCallback(e, keys); emitGetCallbacks(e); emitSetCallbacks(e); &#125; e.end_class();&#125; 5.2. 获取要代理的方法123456789101112131415161718192021222324252627private static void getMethods(Class superclass, Class[] interfaces, List methods, List interfaceMethods, Set forcePublic)&#123; // 下面这一坨是把目标类的方法，接口方法的信息（类型是 MethodInfo）都加入到methods列表里 ReflectUtils.addAllMethods(superclass, methods); List target = (interfaceMethods != null) ? interfaceMethods : methods; if (interfaces != null) &#123; for (int i = 0; i &lt; interfaces.length; i++) &#123; if (interfaces[i] != Factory.class) &#123; ReflectUtils.addAllMethods(interfaces[i], target); &#125; &#125; &#125; if (interfaceMethods != null) &#123; if (forcePublic != null) &#123; forcePublic.addAll(MethodWrapper.createSet(interfaceMethods)); &#125; methods.addAll(interfaceMethods); &#125; // 过滤static方法 CollectionUtils.filter(methods, new RejectModifierPredicate(Constants.ACC_STATIC)); // 根据布尔值决定是否过滤protected的方法，过滤private方法 CollectionUtils.filter(methods, new VisibilityPredicate(superclass, true)); // 过滤重复 CollectionUtils.filter(methods, new DuplicatesPredicate(methods)); // 过滤final方法 CollectionUtils.filter(methods, new RejectModifierPredicate(Constants.ACC_FINAL));&#125; 针对demo的RunnerDefault，获取到的最终方法为 5.3. 为目标方法配置Callback123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144// methods的类型是MethodInfo，主要是改了原方法的modifiers// actualMethods的类型Methodprivate void emitMethods(final ClassEmitter ce, List methods, List actualMethods) &#123; CallbackGenerator[] generators = CallbackInfo.getGenerators(callbackTypes); Map groups = new HashMap(); final Map indexes = new HashMap(); final Map originalModifiers = new HashMap(); final Map positions = CollectionUtils.getIndexMap(methods); final Map declToBridge = new HashMap(); Iterator it1 = methods.iterator(); Iterator it2 = (actualMethods != null) ? actualMethods.iterator() : null; while (it1.hasNext()) &#123; MethodInfo method = (MethodInfo)it1.next(); Method actualMethod = (it2 != null) ? (Method)it2.next() : null; // 获取 index int index = filter.accept(actualMethod); if (index &gt;= callbackTypes.length) &#123; throw new IllegalArgumentException(\"Callback filter returned an index that is too large: \" + index); &#125; originalModifiers.put(method, new Integer((actualMethod != null) ? actualMethod.getModifiers() : method.getModifiers())); // 把index放入map indexes.put(method, new Integer(index)); List group = (List)groups.get(generators[index]); if (group == null) &#123; groups.put(generators[index], group = new ArrayList(methods.size())); &#125; group.add(method); // Optimization: build up a map of Class -&gt; bridge methods in class // so that we can look up all the bridge methods in one pass for a class. if (TypeUtils.isBridge(actualMethod.getModifiers())) &#123; Set bridges = (Set)declToBridge.get(actualMethod.getDeclaringClass()); if (bridges == null) &#123; bridges = new HashSet(); declToBridge.put(actualMethod.getDeclaringClass(), bridges); &#125; bridges.add(method.getSignature()); &#125; &#125; final Map bridgeToTarget = new BridgeMethodResolver(declToBridge, getClassLoader()).resolveAll(); Set seenGen = new HashSet(); CodeEmitter se = ce.getStaticHook(); se.new_instance(THREAD_LOCAL); se.dup(); se.invoke_constructor(THREAD_LOCAL, CSTRUCT_NULL); se.putfield(THREAD_CALLBACKS_FIELD); final Object[] state = new Object[1]; CallbackGenerator.Context context = new CallbackGenerator.Context() &#123; public ClassLoader getClassLoader() &#123; return Enhancer.this.getClassLoader(); &#125; public int getOriginalModifiers(MethodInfo method) &#123; return ((Integer)originalModifiers.get(method)).intValue(); &#125; public int getIndex(MethodInfo method) &#123; return ((Integer)indexes.get(method)).intValue(); &#125; // 根据index获取对应的Callback（从DeclaredField获取） public void emitCallback(CodeEmitter e, int index) &#123; emitCurrentCallback(e, index); &#125; public Signature getImplSignature(MethodInfo method) &#123; return rename(method.getSignature(), ((Integer)positions.get(method)).intValue()); &#125; public void emitLoadArgsAndInvoke(CodeEmitter e, MethodInfo method) &#123; // If this is a bridge and we know the target was called from invokespecial, // then we need to invoke_virtual w/ the bridge target instead of doing // a super, because super may itself be using super, which would bypass // any proxies on the target. Signature bridgeTarget = (Signature)bridgeToTarget.get(method.getSignature()); if (bridgeTarget != null) &#123; // checkcast each argument against the target's argument types for (int i = 0; i &lt; bridgeTarget.getArgumentTypes().length; i++) &#123; e.load_arg(i); Type target = bridgeTarget.getArgumentTypes()[i]; if (!target.equals(method.getSignature().getArgumentTypes()[i])) &#123; e.checkcast(target); &#125; &#125; e.invoke_virtual_this(bridgeTarget); Type retType = method.getSignature().getReturnType(); // Not necessary to cast if the target &amp; bridge have // the same return type. // (This conveniently includes void and primitive types, // which would fail if casted. It's not possible to // covariant from boxed to unbox (or vice versa), so no having // to box/unbox for bridges). // TODO: It also isn't necessary to checkcast if the return is // assignable from the target. (This would happen if a subclass // used covariant returns to narrow the return type within a bridge // method.) if (!retType.equals(bridgeTarget.getReturnType())) &#123; e.checkcast(retType); &#125; &#125; else &#123; e.load_args(); e.super_invoke(method.getSignature()); &#125; &#125; public CodeEmitter beginMethod(ClassEmitter ce, MethodInfo method) &#123; CodeEmitter e = EmitUtils.begin_method(ce, method); if (!interceptDuringConstruction &amp;&amp; !TypeUtils.isAbstract(method.getModifiers())) &#123; Label constructed = e.make_label(); e.load_this(); e.getfield(CONSTRUCTED_FIELD); e.if_jump(e.NE, constructed); e.load_this(); e.load_args(); e.super_invoke(); e.return_value(); e.mark(constructed); &#125; return e; &#125; &#125;; for (int i = 0; i &lt; callbackTypes.length; i++) &#123; CallbackGenerator gen = generators[i]; if (!seenGen.contains(gen)) &#123; seenGen.add(gen); final List fmethods = (List)groups.get(gen); if (fmethods != null) &#123; try &#123; gen.generate(ce, context, fmethods); gen.generateStatic(se, context, fmethods); &#125; catch (RuntimeException x) &#123; throw x; &#125; catch (Exception x) &#123; throw new CodeGenerationException(x); &#125; &#125; &#125; &#125; se.return_value(); se.end_method();&#125; 这里代码没有看的很细，了解了大概。 一个方法只会有一个Callback。 这一节，最后看一下代理出来的类的代码 12345678910111213public final void run(String var1) &#123; MethodInterceptor var10000 = this.CGLIB$CALLBACK_0; if (var10000 == null) &#123; CGLIB$BIND_CALLBACKS(this); var10000 = this.CGLIB$CALLBACK_0; &#125; if (var10000 != null) &#123; var10000.intercept(this, CGLIB$run$0$Method, new Object[]&#123;var1&#125;, CGLIB$run$0$Proxy); &#125; else &#123; super.run(var1); &#125;&#125; 其中 12345// CGLIB$run$0$Method Method CGLIB$run$0$Method = ReflectUtils.findMethods(new String[]&#123;\"run\", \"(Ljava/lang/String;)V\"&#125;, (var1 = Class.forName(\"com.htc.learning.api.impl.RunnerDefault\")).getDeclaredMethods())[0];// CGLIB$run$0$ProxyMethodProxy CGLIB$run$0$Proxy = MethodProxy.create(var1, var0, \"(Ljava/lang/String;)V\", \"run\", \"CGLIB$run$0\"); 所以逻辑是这样的，代理类将调用转发给一个Callback，在Callback里，如果要执行目标类的目标方法，即调用net.sf.cglib.proxy.MethodProxy#invokeSuper 等等，MethodProxy是什么 此外从生成的类里，我们可以看除了Enhancer和KeyFactory的增强类之外，还生成了三个类 第二个是我们的代理类，那么其余两个是干嘛的，FastClass又是什么? 6. MethodProxy与Fastclass6.1. 为什么要有MethodProxy、Fastclass我们配置代理的时候，并没有传入一个目标类实例，而是传入目标类的class，这时我们要去调用目标方法的时候，如果每次都靠反射，那就没有直接调用一个对象来的快。 没错每次都靠反射说的就是你jdk代理。 6.2. MethodProxyMethodProxy表明了一个方法到另一个方法的映射，我们看一下代理类run方法的代码 1234567891011121314public final void run(String var1) &#123; MethodInterceptor var10000 = this.CGLIB$CALLBACK_0; if (var10000 == null) &#123; CGLIB$BIND_CALLBACKS(this); var10000 = this.CGLIB$CALLBACK_0; &#125; if (var10000 != null) &#123; // CGLIB$run$0$Proxy 即是 MethodProxy var10000.intercept(this, CGLIB$run$0$Method, new Object[]&#123;var1&#125;, CGLIB$run$0$Proxy); &#125; else &#123; super.run(var1); &#125;&#125; 其中, 123Class var0 = Class.forName(\"com.htc.learning.api.impl.RunnerDefault$$EnhancerByCGLIB$$5b557d48\"); Class var1 = Class.forName(\"com.htc.learning.api.impl.RunnerDefault\")CGLIB$run$0$Proxy = MethodProxy.create(var1, var0, \"(Ljava/lang/String;)V\", \"run\", \"CGLIB$run$0\"); 再其中，&quot;CGLIB$run$0&quot;是Enhancer代理类里的一个已经生成的方法， 123final void CGLIB$run$0(String var1) &#123; super.run(var1);&#125; MethodProxy的create方法， 1234567public static MethodProxy create(Class c1, Class c2, String desc, String name1, String name2) &#123; MethodProxy proxy = new MethodProxy(); proxy.sig1 = new Signature(name1, desc); proxy.sig2 = new Signature(name2, desc); proxy.createInfo = new MethodProxy.CreateInfo(c1, c2); return proxy;&#125; 这一段就是说c1的方法name1,对应的代理方法是实现类c2的方法name2。再具体一点，RunnerDefault的run方法，对应的就是com.htc.learning.api.impl.RunnerDefault$$EnhancerByCGLIB$$5b557d48的CGLIB$run$0方法，这两个签名没有依赖，MethodProxy利用这两个签名，提供两种不同的目标方法调用， 6.3. FastClass上面只是创建了一个关联关系，接下来看net.sf.cglib.proxy.MethodProxy#invokeSuper 12345678910111213141516171819202122232425262728293031323334353637383940public Object invokeSuper(Object obj, Object[] args) throws Throwable &#123; try &#123; this.init(); MethodProxy.FastClassInfo fci = this.fastClassInfo; // f2是Enhancer代理类，i2是配置好的可以调用到目标方法的索引，invoke根据索引，使用switch块直接调用方法，而不是利用反射 return fci.f2.invoke(fci.i2, obj, args); &#125; catch (InvocationTargetException var4) &#123; throw var4.getTargetException(); &#125;&#125;private void init() &#123; // 单例模式，防止重复创建 if (this.fastClassInfo == null) &#123; synchronized(this.initLock) &#123; if (this.fastClassInfo == null) &#123; MethodProxy.CreateInfo ci = this.createInfo; MethodProxy.FastClassInfo fci = new MethodProxy.FastClassInfo(); fci.f1 = helper(ci, ci.c1); fci.f2 = helper(ci, ci.c2); fci.i1 = fci.f1.getIndex(this.sig1); fci.i2 = fci.f2.getIndex(this.sig2); this.fastClassInfo = fci; this.createInfo = null; &#125; &#125; &#125;&#125;private static FastClass helper(MethodProxy.CreateInfo ci, Class type) &#123; Generator g = new Generator(); g.setType(type); g.setClassLoader(ci.c2.getClassLoader()); g.setNamingPolicy(ci.namingPolicy); g.setStrategy(ci.strategy); g.setAttemptLoad(ci.attemptLoad); // 进去代码后可以看到使用了缓存，所以不会重复生成FastClass return g.create();&#125; 123456789private static class FastClassInfo &#123; FastClass f1; FastClass f2; int i1; int i2; private FastClassInfo() &#123; &#125;&#125; 这个参数命令实在有点难懂，梳理一下，针对run方法， 参数 说明 c1 RunnerDefault f1 RunnerDefault$$FastClassByCGLIB$$a60a67a3 i1 目标类run的索引 c2 RunnerDefault$$EnhancerByCGLIB$$5b557d48 (Enhancer代理类) f2 RunnerDefault$$EnhancerByCGLIB$$5b557d48$$FastClassByCGLIB$$9f176e41（Enhancer代理类的一个快速查找类） i2 Enhancer代理类调用run的索引 下面是RunnerDefault$$FastClassByCGLIB$$a60a67a3的部分代码(如果是RunnerDefault$$EnhancerByCGLIB$$5b557d48$$FastClassByCGLIB$$9f176e41switch块会更大，因为RunnerDefault$$EnhancerByCGLIB$$5b557d48的方法更多) 1234567891011121314151617181920212223242526public int getIndex(Signature var1) &#123; String var10000 = var1.toString(); switch(var10000.hashCode()) &#123; case -1717138348: if (var10000.equals(\"run(Ljava/lang/String;)V\")) &#123; return 0; &#125; break; case 1826985398: if (var10000.equals(\"equals(Ljava/lang/Object;)Z\")) &#123; return 1; &#125; break; case 1913648695: if (var10000.equals(\"toString()Ljava/lang/String;\")) &#123; return 2; &#125; break; case 1984935277: if (var10000.equals(\"hashCode()I\")) &#123; return 3; &#125; &#125; return -1;&#125; 1234567891011121314151617181920212223// 注意这的var2是Enhancer代理类public Object invoke(int var1, Object var2, Object[] var3) throws InvocationTargetException &#123; RunnerDefault var10000 = (RunnerDefault)var2; int var10001 = var1; try &#123; switch(var10001) &#123; case 0: var10000.run((String)var3[0]); return null; case 1: return new Boolean(var10000.equals(var3[0])); case 2: return var10000.toString(); case 3: return new Integer(var10000.hashCode()); &#125; &#125; catch (Throwable var4) &#123; throw new InvocationTargetException(var4); &#125; throw new IllegalArgumentException(\"Cannot find matching method/constructor\");&#125; 6.4. StackOverflowError如果我们写Callback的时候，把invokeSuper写成invoke会怎么样，答案是：栈溢出。MethodProxy的invoke方法是这样的， 123456789public Object invoke(Object obj, Object[] args) throws Throwable &#123; try &#123; this.init(); MethodProxy.FastClassInfo fci = this.fastClassInfo; return fci.f1.invoke(fci.i1, obj, args); &#125; catch (...) &#123; ... &#125;&#125; 这里的obj是Enhancer代理类，而f1是RunnerDefault$$FastClassByCGLIB$$a60a67a3，所以又会索引到Enhancer代理类的代理run方法，接着又执行上面的invoke,balabala…陷入死循环。 6.5. invoke与invokeSuper那是不是invoke不能被调用了？不是，上面说到MethodProxy利用这两个签名，提供两种不同的目标方法调用，所以，invoke是另一种调用目标方法的姿势。 写Callback的时候， 12345@Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; objects[0] = \"cglib \" + objects[0]; return methodProxy.invokeSuper(o, objects); &#125; 传入的Object o是Enhancer代理类，而我们不能执行methodProxy.invoke(o, objects)陷入死循环，所以我们在Callback需要保存一个目标类实例的引用target，然后methodProxy.invoke(target, objects)。 6.6. 总结MethodProxy与Fastclass提供了一个 Signature -&gt; index -&gt; invoke的机制。 7. 缺陷如果理解了FastClass，那么很容猜测cglib的性能瓶颈在于，当目标类的方法很多的时候，switch块就是一个很慢的查找，这个查找是有优化空间的。此外，cglib代理的创建时间会比jdk代理的创建更耗时间，不过我觉得这都不是事。 8. 参考 cglib demo以及Enhancer源码解析","categories":[{"name":"Proxy","slug":"Proxy","permalink":"https://htchz.cc/categories/Proxy/"}],"tags":[{"name":"AOP","slug":"AOP","permalink":"https://htchz.cc/tags/AOP/"}]},{"title":"[Java代理]Jdk代理","slug":"Java代理-jdk代理","date":"2019-03-04T16:16:00.000Z","updated":"2019-08-15T16:08:49.215Z","comments":true,"path":"68869360.html","link":"","permalink":"https://htchz.cc/68869360.html","excerpt":"","text":"1. 前言相比静态代理需要手动写代理类，动态代理可以通过抽象代码完成对一定规则的类的代理，生成的代理类直接以字节码的形式存在于内存中。Spring里Aop的实现使用了两种动态代理方案，一种是jdk代理，一种是cglib代理。 jdk代理是从目标类的接口生成实现类，cglib是继承目标类生成子类。 2. Demo123456/** * 接口 */public interface Runner &#123; void run(String name);&#125; 123456789101112/** * 接口实现类 * created by Huang.Zhen on 2019-02-22 */public class RunnerDefault implements Runner &#123; private Logger log = LoggerFactory.getLogger(getClass()); @Override public void run(String name) &#123; log.info(\"run: \" + name); &#125;&#125; 1234567891011121314151617181920212223242526272829/** * 代理类 * created by Huang Zhen on 2019-02-22 */public class JdkProxyHandler implements InvocationHandler &#123; private Logger log = LoggerFactory.getLogger(getClass()); private Object target; // 保存目标类的引用 public JdkProxyHandler(Object target) &#123; this.target = target; &#125; /** * 对newProxyInstance方法的封装 * @return 代理类 */ public Object getProxy() &#123; // 生成代理类 return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this); &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; args[0] = \"jdk \" + args[0]; return method.invoke(target, args); &#125;&#125; 用下面的代码获取代理类并运行 12345@Testpublic void testJdk() &#123; Runner runner = (Runner) new JdkProxyHandler(new RunnerDefault()).getProxy(); runner.run(\"proxy\");&#125; 输出 2019-03-01 16:02:17.623 INFO --- [ main] com.htc.learning.api.impl.RunnerDefault : run: jdk proxy3. 原理3.1. 怎么生成代理类class文件直捣Proxy.newProxyInstance方法， 1234/* * Look up or generate the designated proxy class. */Class&lt;?&gt; cl = getProxyClass0(loader, intfs); 进入getProxyClass0，从proxyClassCache字面上理解，jdk代理是有缓存的 1234// If the proxy class defined by the given loader implementing// the given interfaces exists, this will simply return the cached copy;// otherwise, it will create the proxy class via the ProxyClassFactoryreturn proxyClassCache.get(loader, interfaces); 进入get方法。可以看到出现了jdk8级别的代码，说明jdk8里jdk代理又被优化了 1234567891011// create subKey and retrieve the possible Supplier&lt;V&gt; stored by that// subKey from valuesMap// subKeyFactory 其实是 java.lang.reflect.Proxy.ProxyClassFactoryObject subKey = Objects.requireNonNull(subKeyFactory.apply(key, parameter));Supplier&lt;V&gt; supplier = valuesMap.get(subKey);...V value = supplier.get();if (value != null) &#123; return value;&#125;... 进入java.lang.reflect.Proxy.ProxyClassFactory#apply方法 1234567.../* * Generate the specified proxy class. */byte[] proxyClassFile = ProxyGenerator.generateProxyClass( proxyName, interfaces, accessFlags);... 123456789101112131415161718192021222324252627282930public static byte[] generateProxyClass(final String var0, Class&lt;?&gt;[] var1, int var2) &#123; ProxyGenerator var3 = new ProxyGenerator(var0, var1, var2); // 生成字节码的方法，不想看 final byte[] var4 = var3.generateClassFile(); // 这里可以通过命令行参数设置要不要存储生成的class文件 if (saveGeneratedFiles) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; try &#123; int var1 = var0.lastIndexOf(46); Path var2; if (var1 &gt; 0) &#123; Path var3 = Paths.get(var0.substring(0, var1).replace('.', File.separatorChar)); Files.createDirectories(var3); var2 = var3.resolve(var0.substring(var1 + 1, var0.length()) + \".class\"); &#125; else &#123; var2 = Paths.get(var0 + \".class\"); &#125; Files.write(var2, var4, new OpenOption[0]); return null; &#125; catch (IOException var4x) &#123; throw new InternalError(\"I/O exception saving generated file: \" + var4x); &#125; &#125; &#125;); &#125; return var4;&#125; 以往都是说jdk代理比cglib性能差，其实优化到现在都没差多少了，更多的时候是从两者的特性按需求采取不同的。 3.2. 缓存jdk代理获取Class的时候使用了缓存 1234567891011private static Class&lt;?&gt; getProxyClass0(ClassLoader loader, Class&lt;?&gt;... interfaces) &#123; if (interfaces.length &gt; 65535) &#123; throw new IllegalArgumentException(\"interface limit exceeded\"); &#125; // If the proxy class defined by the given loader implementing // the given interfaces exists, this will simply return the cached copy; // otherwise, it will create the proxy class via the ProxyClassFactory return proxyClassCache.get(loader, interfaces);&#125; proxyClassCache的声明是这样的 12345/** * a cache of proxy classes */ private static final WeakCache&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt; proxyClassCache = new WeakCache&lt;&gt;(new KeyFactory(), new ProxyClassFactory()); 主要的成员变量 123456789101112131415// 引用队列private final ReferenceQueue&lt;K&gt; refQueue = new ReferenceQueue&lt;&gt;();// 缓存本存// the key type is Object for supporting null keyprivate final ConcurrentMap&lt;Object, ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt;&gt; map = new ConcurrentHashMap&lt;&gt;();// 反向索引，用来快速判断一个对象是否存在缓存里private final ConcurrentMap&lt;Supplier&lt;V&gt;, Boolean&gt; reverseMap = new ConcurrentHashMap&lt;&gt;();// 两个二元运算方法// subKeyFactory = new KeyFactory()private final BiFunction&lt;K, P, ?&gt; subKeyFactory;// valueFactory = new ProxyClassFactory()private final BiFunction&lt;K, P, V&gt; valueFactory; 这里里的缓存map的value又是一个ConcurrentMap,说明这个缓存是一个二级缓存。 字段名 说明 一级缓存key 一个CacheKey类型的对象，以ClassLoader作为hash 一级缓存value 一级缓存 字段名 说明 二级缓存key 以interfaces为key 二级缓存value Supplier接口，可能是CacheValue 或者 代理工厂对象 看代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// 在Proxy类的代码中，key是ClassLoader，parameter是interface数组public V get(K key, P parameter) &#123; Objects.requireNonNull(parameter); expungeStaleEntries(); Object cacheKey = CacheKey.valueOf(key, refQueue); // lazily install the 2nd level valuesMap for the particular cacheKey // 初始化二级缓存，用了双重校验，保证所有线程拿到的是同一个实例 ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt; valuesMap = map.get(cacheKey); if (valuesMap == null) &#123; ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt; oldValuesMap = map.putIfAbsent(cacheKey, valuesMap = new ConcurrentHashMap&lt;&gt;()); if (oldValuesMap != null) &#123; valuesMap = oldValuesMap; &#125; &#125; // create subKey and retrieve the possible Supplier&lt;V&gt; stored by that // subKey from valuesMap Object subKey = Objects.requireNonNull(subKeyFactory.apply(key, parameter)); Supplier&lt;V&gt; supplier = valuesMap.get(subKey); Factory factory = null; while (true) &#123; if (supplier != null) &#123; // supplier might be a Factory or a CacheValue&lt;V&gt; instance V value = supplier.get(); if (value != null) &#123; return value; &#125; &#125; // else no supplier in cache // or a supplier that returned null (could be a cleared CacheValue // or a Factory that wasn't successful in installing the CacheValue) // lazily construct a Factory if (factory == null) &#123; factory = new Factory(key, parameter, subKey, valuesMap); &#125; if (supplier == null) &#123; supplier = valuesMap.putIfAbsent(subKey, factory); if (supplier == null) &#123; // successfully installed Factory supplier = factory; &#125; // else retry with winning supplier &#125; else &#123; if (valuesMap.replace(subKey, supplier, factory)) &#123; // successfully replaced // cleared CacheEntry / unsuccessful Factory // with our Factory supplier = factory; &#125; else &#123; // retry with current supplier supplier = valuesMap.get(subKey); &#125; &#125; &#125;&#125; 这里的代码主要是维护Map.put操作多线程下的一些同步，防止重复实例化。虽然map是ConcurrentHashMap,但重复put还是得避免的。 二级缓存Map的value为Supplier类型，第一次访问是 Factory对象，第二次访问就可能是CacheValue，因为Factory存有二级缓存map的引用，会把value从this（Factory本身）替换为CacheValue 其实不太明白这种机制,可能为了提高并发性能？先返回值，再为值构造缓存。 3.3. 缓存过期机制CacheKey是一个WeakReference，当gc时就会被清理掉引用的对象，这时需要把CacheKey从Map里remove，下面这个方法在WeakCache执行读操作的时候会执行一遍。 123456private void expungeStaleEntries() &#123; CacheKey&lt;K&gt; cacheKey; while ((cacheKey = (CacheKey&lt;K&gt;)refQueue.poll()) != null) &#123; cacheKey.expungeFrom(map, reverseMap); &#125;&#125; CacheValue也是虚引用。 3.4. InvocationHandler注入代理类已经生成了，我们写的InvocationHandler还没有注入，所以生成代理类的时候是不包含代理逻辑的。 我们回到Proxy.newProxyInstance方法，这时已经获取到class， 123456789101112...final Constructor&lt;?&gt; cons = cl.getConstructor(constructorParams);final InvocationHandler ih = h;if (!Modifier.isPublic(cl.getModifiers())) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; cons.setAccessible(true); return null; &#125; &#125;);&#125;return cons.newInstance(new Object[]&#123;h&#125;); InvocationHandler是通过构造参数注入的。 3.5. 代理class文件的内容我们生成基本的class文件只需要给一个自定义类名和一个目标类就可以了。 123456789101112131415@Test public void saveJdkProxyClass() throws IOException &#123; String path = \"./$Proxy0.class\"; byte[] classFile = ProxyGenerator.generateProxyClass(\"$Proxy0\", RunnerDefault.class.getInterfaces()); FileOutputStream out = null; try &#123; out = new FileOutputStream(path); out.write(classFile); out.flush(); &#125; finally &#123; if (out != null) &#123; out.close(); &#125; &#125; &#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374//// Source code recreated from a .class file by IntelliJ IDEA// (powered by Fernflower decompiler)//import com.htc.learning.api.Runner;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.lang.reflect.UndeclaredThrowableException;public final class $Proxy0 extends Proxy implements Runner &#123; private static Method m1; private static Method m2; private static Method m3; private static Method m0; public $Proxy0(InvocationHandler var1) throws &#123; super(var1); &#125; public final boolean equals(Object var1) throws &#123; try &#123; return (Boolean)super.h.invoke(this, m1, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final String toString() throws &#123; try &#123; return (String)super.h.invoke(this, m2, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final void run(String var1) throws &#123; try &#123; super.h.invoke(this, m3, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final int hashCode() throws &#123; try &#123; return (Integer)super.h.invoke(this, m0, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; static &#123; try &#123; m1 = Class.forName(\"java.lang.Object\").getMethod(\"equals\", Class.forName(\"java.lang.Object\")); m2 = Class.forName(\"java.lang.Object\").getMethod(\"toString\"); m3 = Class.forName(\"com.htc.learning.api.Runner\").getMethod(\"run\", Class.forName(\"java.lang.String\")); m0 = Class.forName(\"java.lang.Object\").getMethod(\"hashCode\"); &#125; catch (NoSuchMethodException var2) &#123; throw new NoSuchMethodError(var2.getMessage()); &#125; catch (ClassNotFoundException var3) &#123; throw new NoClassDefFoundError(var3.getMessage()); &#125; &#125;&#125; 那么cglib方案的代理类class文件又要怎么获取呢，下篇再说。 可以看到字节码里每个目标方法都有一个同名的代理方法包着，代理逻辑已经写在InvocationHandler，代理方法直接调用InvocationHandler就可以了。 4. 从代理类获取原始对象的Class在Spring里，bean被代理是很常见的，假如我们要获取目标bean上的注解，这时候我们拿到的如果是代理类，是获取不到的目标bean上的注解的。所以这时我们得从代理类获取原始对象，再获得对应的Class。 4.1. 我的做法在InvocationHandler实现类里，把目标类对象放入了一个target成员变量，然后当我们拿到代理类后，通过调用java.lang.reflect.Proxy#getInvocationHandler方法，再通过反射即可获取到原始对象target。 4.2. Spring的做法Spring有一个AopProxyUtils的工具，其中有个方法可以获取到jdk代理或cglib代理的原始对象。关于这个工具更多使用参考AopProxyUtils详解 12345678910111213141516 // candidate即传入的代理类实例public static Class&lt;?&gt; ultimateTargetClass(Object candidate) &#123; Assert.notNull(candidate, \"Candidate object must not be null\"); Object current = candidate; Class&lt;?&gt; result = null; // Spring的代理类都实现了 TargetClassAware，调用getTargetClass()可获取到目标对象，注意，这里不一定是原始对象，因为可能切面切了很多次，生成了很多层的代理类，这也是为什么需要一个while循环 while (current instanceof TargetClassAware) &#123; result = ((TargetClassAware) current).getTargetClass(); current = getSingletonTarget(current); &#125; if (result == null) &#123; // 如果是cglib代理，则获取对象父类，否则是jdk代理，直接获取对象类型 result = (AopUtils.isCglibProxy(candidate) ? candidate.getClass().getSuperclass() : candidate.getClass()); &#125; return result;&#125; 123456789public static Object getSingletonTarget(Object candidate) &#123; if (candidate instanceof Advised) &#123; TargetSource targetSource = ((Advised) candidate).getTargetSource(); if (targetSource instanceof SingletonTargetSource) &#123; return ((SingletonTargetSource) targetSource).getTarget(); &#125; &#125; return null;&#125; 这里的代码逻辑看起来不难，但是涉及了Spring Aop的接口概念，所以具体调用我也不太懂是干嘛的。 Spring在代理逻辑中拦截了getTargetClass()等切面方法，将这些方法转发给Advised去执行。 5. 缺陷从class文件看，由于代理类继承了Proxy类（其实这个类看起来也只有一个java.lang.reflect.Proxy#getInvocationHandler比较通用的方法，其实我觉得这个InvocationHandler可以通过反射拿到，不懂为什么非要继承这个类，喵？），导致jdk代理不能通过继承目标类来达到代理的目的。 6. 关于SpringSpring有个属性是proxy-target-class，默认值是false，表示默认使用jdk代理，这时使用常常会发生类型转换的错误，因为最终bean的class已经不是最初的bean的类型。在Springboot里，proxy-target-class使用spring.aop.proxy-target-class属性来配置，默认为true，即都使用cglib来代理。如果配置为false，Springboot会对实现接口的bean使用jdk代理，对于没有实现接口的类依旧使用cglib代理。 7. 参考 AopProxyUtils详解","categories":[{"name":"Proxy","slug":"Proxy","permalink":"https://htchz.cc/categories/Proxy/"}],"tags":[{"name":"AOP","slug":"AOP","permalink":"https://htchz.cc/tags/AOP/"}]},{"title":"[NIO]linux的I/O多路复用","slug":"NIO-linux的I-O多路复用","date":"2019-01-30T18:07:00.000Z","updated":"2019-12-10T08:01:45.304Z","comments":true,"path":"3010153098.html","link":"","permalink":"https://htchz.cc/3010153098.html","excerpt":"","text":"1. 前言上篇提到i/o多路复用，是通过单进程监听多个文件描述的状态，达到减少线程阻塞的目的。 内核（kernel）利用文件描述符（file descriptor）来访问文件。 文件描述符是非负整数。 打开现存文件或新建文件时(包括socket被打开)，内核会返回一个文件描述符。 读写文件也需要使用文件描述符来指定待读写的文件。在linux环境下，进入/proc目录可以看到许多代表文件描述符的文件夹。 linux i/o多路复用的系统调用接口有三种，分别是 select,poll,epoll。 2. 接口作为一个学java的，了解一下java底层调用的函数，还是挺有助于理解的。 2.1. i/o多路复用原理linux(2.6+)内核的事件wakeup callback机制，是linux i/o多路复用的原理。内核管理一个process的睡眠队列，当socket事件发生的时候，唤醒队列的process，调用callback函数完成通知。总体上会涉及两大逻辑：（1）睡眠等待逻辑；（2）唤醒逻辑。 1.睡眠等待逻辑：涉及select、poll、epoll_wait的阻塞等待逻辑 select、poll、epoll_wait陷入内核，判断监控的socket是否有关心的事件发生了，如果没，则为当前process构建一个wait_entry节点，然后插入到监控socket的sleep_list 进入循环的schedule直到关心的事件发生了 关心的事件发生后，将当前process的wait_entry节点从socket的sleep_list中删除。 2.唤醒逻辑。 socket的事件发生了，然后socket顺序遍历其睡眠队列，依次调用每个wait_entry节点的callback函数 直到完成队列的遍历或遇到某个wait_entry节点是排他的才停止。 一般情况下callback包含两个逻辑：1.wait_entry自定义的私有逻辑；2.唤醒的公共逻辑，主要用于将该wait_entry的process放入CPU的就绪队列，让CPU随后可以调度其执行。 2.2. select12345678#include &lt;sys/select.h&gt;#include &lt;sys/time.h&gt;int select(int max_fd, fd_set *readset, fd_set *writeset, fd_set *exceptset, struct timeval *timeout)FD_ZERO(int fd, fd_set* fds) //清空集合FD_SET(int fd, fd_set* fds) //将给定的描述符加入集合FD_ISSET(int fd, fd_set* fds) //将给定的描述符从文件中删除 FD_CLR(int fd, fd_set* fds) //判断指定描述符是否在集合中 select 方法的第一个参数max_fd指待测试的fd（fd即文件描述符，一个socket会有一个文件描述符）个数，它的值是待测试的最大文件描述符加1，文件描述符从0开始到max_fd-1都将被测试。中间三个参数readset、writeset和exceptset指定要让内核测试读、写和异常条件的fd集合，如果不需要测试的可以设置为NULL。 select被调用的时候，被监控的readset(假设对socket的读事件感兴趣)会从用户空间复制到内核空间，然后遍历监听的socket，如果在超时或者有一个或多个socket产生了读事件，那么select唤醒线程，注意这里只是唤醒，并没有返回就绪的fd，接下来线程要再次遍历readset，收集可读事件。 select的问题是： 监听的socket数量有限，为了减少fd拷贝的性能损耗，限定了1024个文件描述符 线程被唤醒的时候，需要再次遍历fd列表。 2.3. poll12345678#include &lt;poll.h&gt;int poll(struct pollfd fds[], nfds_t nfds, int timeout);typedef struct pollfd &#123; int fd; // 需要被检测或选择的文件描述符 short events; // 对文件描述符fd上感兴趣的事件 short revents; // 文件描述符fd上当前实际发生的事件*/&#125; pollfd_t; poll换了个数据结构，解决了select其中一个问题：监听的数量有限。但实际上并有解决拷贝的性能损耗和需要再次遍历fd列表获取就绪事件。 2.4. epoll1234#include &lt;sys/epoll.h&gt;int epoll_create(int size);int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); epoll不是一个方法，而是由三个函数组成; epoll_create创建了一个epoll的fd，参数size表明内核要监听的描述符数量 epoll_ctl用来对fd集合进行修改，参照select，poll每次调用都是将所有fd集合复制，鉴于fd集合的变化不频繁，其实每次全量复制过去是没必要的。 epoll_wait相当于前两种i/o多路复用调用，该函数等待事件的就绪，成功时返回就绪的事件数目，调用失败时返回 -1，等待超时返回 0，events指针指向了就绪的集合。 epoll通过epoll_ctl来对监控的fds集合来进行增、删、改，那么必须涉及到fd的快速查找问题，于是，一个低时间复杂度的增、删、改、查的数据结构来组织被监控的fds集合是必不可少的了。在linux 2.6.8之前的内核，epoll使用hash来组织fds集合，于是在创建epoll fd的时候，epoll需要初始化hash的大小。于是epoll_create(int size)有一个参数size，以便内核根据size的大小来分配hash的大小。在linux 2.6.8以后的内核中，epoll使用红黑树来组织监控的fds集合，于是epoll_create(int size)的参数size实际上已经没有意义了。 epoll解决了select、poll的主要问题： 没有最大并发连接的限制，能打开的fd上限远大于1024 采用回调的方式，效率提升。只有活跃可用的fd才会调用callback函数，也就是说 epoll 只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，epoll的效率就会远远高于select和poll。 epoll对文件描述符的操作有两种模式：LT(level trigger，水平触发)和ET(Edge trigger，边缘触发)。 LT:这次事件没处理，下次还告诉你。ET:这次事件没处理，下次不告诉你。 3. java nio在linux环境下，java nio 底层调用是epoll，这里有个博主写了一个基于epoll实现的web服务器，在linux下编译完成后，可以浏览器访问8080端口，观察输出。 另外，java使用的模式是水平触发。传送门 4. 结束语作为linux门外汉，了解的不是很深入。 5. 参考 大话 Select、Poll、Epoll 基于epoll实现简单的web服务器","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"NIO","slug":"NIO","permalink":"https://htchz.cc/tags/NIO/"}],"author":"土川"},{"title":"[NIO]五个I/O模型","slug":"NIO-IO模型","date":"2019-01-27T14:35:00.000Z","updated":"2019-01-31T07:24:21.000Z","comments":true,"path":"2990610001.html","link":"","permalink":"https://htchz.cc/2990610001.html","excerpt":"","text":"1. 前言不先了解一下Linux的IO模型，看java的nio真是一脸懵逼。。 2. linux的io模型2.1. Blocking (I/O阻塞IO模型)刚学java的时候想必学的都是阻塞IO传输，底层调用就是上面的图锁展示的过程，进程调用recvfrom，进入阻塞状态，然后系统将数据从网卡/硬盘读取到内核，由从内核复制到用户态，最终返回给进程，进程继续运行。 这是比较耗时和浪费CPU的做法，需要阻塞数据到达，数据复制 2.2. Nonblocking I/O（非阻塞IO模型）底层轮询调用recvfrom，系统会立刻返回读取结果，如果读取不到数据，则开启下一次调用，直到数据返回。 这种模式不用阻塞数据到达，需要阻塞数据复制。但是处于轮询状态的进程又是另一种意义上的阻塞，所以其实效率没有提高多少。 2.3. I/O Multiplexing(多路复用)Unix/Linux 环境下的 I/O 复用模型包含三组系统调用，分别是 select、poll 和 epoll，在历史上依次出现。select 有三个文件描述符集（readfds），分别是可读文件描述符集（writefds）、可写文件描述符集和异常文件描述符集（exceptfds）。进程将文件描述符（socket也有文件描述符表示）注册到感兴趣的文件描述符集中， 在这种模式下，select先被调用，进程处于阻塞状态，直至一个或多个事件返回。然后使用recvfrom读取数据。 这种模式需要阻塞数据到达，数据复制。但是BIO由于一次只等待一个数据到达，所以性能上多路复用更优。 2.4. Signal-Driven I/O（信号驱动I/O）进程告诉内核，某个socket 的某个事件发生时，向进程发送信号。接收到信号后，对应的函数回去处理事件。 这种模式不用阻塞数据到达，需要阻塞数据复制 想想，如果数据复制完再通知进程，不就不用阻塞了。于是有下面的异步IO的模型出现。 2.5. Asynchronous I/O （异步I/O）这就是信号驱动I/O的升级版，完全异步，进程无阻塞。对于大部分平台来说，底层利用的还是非异步模型结合回调函数来实现。 遗憾的是，linux的网络IO中是不存在异步IO的，linux的网络IO处理的第二阶段总是阻塞等待数据copy完成的。真正意义上的网络异步IO是Windows下的IOCP（IO完成端口）模型。 3. 对比 4. 总结 Unix网络编程」中说道，按照POSIX标准中的术语，同步指的是I/O动作会导致用户进程阻塞，异步则刚好相反。按照这种分类，上边5种I/O模型中，只有AIO一种是异步的，其他都是同步的。 但是这些只是相对的，程序往往是多线程运行，拿Java来说，主线程调用select操作是阻塞的，但是数据复制这个阻塞过程放到子线程中，对主线程来说没有影响。这也是为什么java的NIO称为同步非阻塞IO。 5. 参考 IO复用","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"NIO","slug":"NIO","permalink":"https://htchz.cc/tags/NIO/"}],"author":"土川"},{"title":"[Java基础]SimpleDateFormat线程安全的问题","slug":"Java基础-SimpleDateFormat线程安全","date":"2018-12-25T10:19:00.000Z","updated":"2019-08-15T16:08:49.213Z","comments":true,"path":"3683368056.html","link":"","permalink":"https://htchz.cc/3683368056.html","excerpt":"今天把SimpleDateFormat设置为static，老哥说你错了，你真的错了。","text":"今天把SimpleDateFormat设置为static，老哥说你错了，你真的错了。 1. 前言SimpleDateFormat是个线程不安全的类，不可以在多线程里面使用。 2. 代码123456789101112131415private static int num = 4;private static ExecutorService executorService = Executors.newFixedThreadPool(num);private static SimpleDateFormat simpleDateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");public static void main(String[] args) &#123; IntStream.range(0, num).parallel().forEach(a -&gt; executorService.submit(() -&gt; &#123; try &#123; System.out.println(simpleDateFormat.parse(\"2017-12-13 15:17:27\")); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;)); executorService.shutdown();&#125; 这个程序会这么报： 1234567891011121314151617181920212223242526272829303132java.lang.NumberFormatException: multiple points at java.base/jdk.internal.math.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1890) at java.base/jdk.internal.math.FloatingDecimal.parseDouble(FloatingDecimal.java:110) at java.base/java.lang.Double.parseDouble(Double.java:543) at java.base/java.text.DigitList.getDouble(DigitList.java:169) at java.base/java.text.DecimalFormat.parse(DecimalFormat.java:2128) at java.base/java.text.SimpleDateFormat.subParse(SimpleDateFormat.java:2240) at java.base/java.text.SimpleDateFormat.parse(SimpleDateFormat.java:1541) at java.base/java.text.DateFormat.parse(DateFormat.java:393) at com.htc.learning.main.SimpleDateFormatTest.lambda$main$0(SimpleDateFormatTest.java:18) at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) at java.base/java.lang.Thread.run(Thread.java:834)java.lang.NumberFormatException: multiple points at java.base/jdk.internal.math.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1890) at java.base/jdk.internal.math.FloatingDecimal.parseDouble(FloatingDecimal.java:110) at java.base/java.lang.Double.parseDouble(Double.java:543) at java.base/java.text.DigitList.getDouble(DigitList.java:169) at java.base/java.text.DecimalFormat.parse(DecimalFormat.java:2128) at java.base/java.text.SimpleDateFormat.subParse(SimpleDateFormat.java:2240) at java.base/java.text.SimpleDateFormat.parse(SimpleDateFormat.java:1541) at java.base/java.text.DateFormat.parse(DateFormat.java:393) at com.htc.learning.main.SimpleDateFormatTest.lambda$main$0(SimpleDateFormatTest.java:18) at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) at java.base/java.lang.Thread.run(Thread.java:834)Wed Dec 13 15:17:27 CST 2017Tue Dec 13 15:17:27 CST 12 这段代码有时报错，有时能正常输出，但也不是正确输出。 3. SimpleDateFormat的类图结构可以看到内部维护了一个Calendar类，归根到底就是这个家伙线程不安全。 4. 源码看parse(String)方法， 12345678910111213141516171819202122public Date parse(String text, ParsePosition pos)&#123; // 解析字符串将每步的执行结果放入CalendarBuilder的实例calb中 ... Date parsedDate; try &#123; parsedDate = calb.establish(calendar).getTime(); // If the year value is ambiguous, // then the two-digit year == the default start year if (ambiguousYear[0]) &#123; if (parsedDate.before(defaultCenturyStart)) &#123; parsedDate = calb.addYear(100).establish(calendar).getTime(); &#125; &#125; &#125; // An IllegalArgumentException will be thrown by Calendar.getTime() // if any fields are out of range, e.g., MONTH == 17. catch (IllegalArgumentException e) &#123; ... &#125; return parsedDate;&#125; 看calb.establish(calendar).getTime(),这里传入的是一个成员变量，每个SimpleDateFormat使用一个Calendar实例 12345678Calendar establish(Calendar cal) &#123; ... // reset日期对象cal的属性值 cal.clear(); // 使用calb中中属性设置cal ... // return cal; 由于多个线程使用的是同一个Calendar，就会出现一些奇奇怪怪的错误。 那么format()呢 12345678910111213141516public StringBuffer format(Date date, StringBuffer toAppendTo, FieldPosition pos) &#123; pos.beginIndex = pos.endIndex = 0; return format(date, toAppendTo, pos.getFieldDelegate()); &#125; // Called from Format after creating a FieldDelegate private StringBuffer format(Date date, StringBuffer toAppendTo, FieldDelegate delegate) &#123; // Convert input date to time field list calendar.setTime(date); ... return toAppendTo; &#125; 主要看这里calendar.setTime(date);,同样的原因，calendar被并发操作，最后多个线程会输出同样的值。 5. 解决方案 每个线程一个SimpleDateFormat实例，不过我觉得这样没必要。 使用Apache的FastDateFormat类，这是一个线程安全类 FastDateFormat也是依赖Calendar，不过每次方法调用都会实例化一次，避免多线程操作同一个Calendar。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}]},{"title":"[Java基础]Java的SPI机制","slug":"Java基础-Java的SPI机制","date":"2018-11-29T08:04:00.000Z","updated":"2019-07-18T09:55:56.000Z","comments":true,"path":"754409717.html","link":"","permalink":"https://htchz.cc/754409717.html","excerpt":"","text":"1. 为什么要SPISPI, Service Provider Interface, 简单来说就是调用方提供接口，接入方提供实现。比如一个应用程序调用JDBC的接口，你要是使用mysql，就得提供mysql提供的jdbc实现。这和我们定义接口然后写实现类差不多，只不过实现类是可以在jar/war外提供。 2. 原理java的实现无非是读取文件，按类名加载。 2.1. 调用方定义接口123public interface Name &#123; String getName();&#125; 2.2. 第三方实现接口123456public class HtcName implements Name &#123; @Override public String getName() &#123; return \"htc\"; &#125;&#125; 123456public class DefaultName implements Name &#123; @Override public String getName() &#123; return \"default\"; &#125;&#125; 2.3. 声明第三方实现在CLASSPATH下建META-INF/services,这个路径是java的代码写死的。然后新建一个文件，文件名为接口名。 文件的内容就是声明要加载的实现类。 com.htc.learning.api.impl.DefaultName com.htc.learning.api.impl.HtcName2.4. 调用方加载实现类使用ServiceLoader类加载实现类，他会搜索CLASSPATH下的所有的”META-INF/services/com.htc.learning.api.Name”文件，获取所有声明一一加载。注意,类的实例化发生在遍历的时候 12345678public class SpiTest &#123; public static void main(String[] args) &#123; ServiceLoader&lt;Name&gt; serviceLoader = ServiceLoader.load(Name.class); for (Name name : serviceLoader) &#123; System.out.println(name.getName()); &#125; &#125;&#125; 3. 源码看看ServiceLoader.load(Name.class)做了什么事。 1234public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) &#123; ClassLoader cl = Thread.currentThread().getContextClassLoader(); return ServiceLoader.load(service, cl);&#125; 这里使用了线程上下文类加载器，因为内置Spi接口都是由Bootstrap类加载器加载，Bootstrap类加载器又加载不了第三方实现类，所以要使用线程上下文类加载器（默认是App类加载器） 进入方法后，获取了ClassLoader,接下来继续进入ServiceLoader.load(service, cl);方法。 12345public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service, ClassLoader loader)&#123; return new ServiceLoader&lt;&gt;(service, loader);&#125; 返回了一个实例，那么查看他的构造方法。 1234567891011public void reload() &#123; providers.clear(); lookupIterator = new LazyIterator(service, loader);&#125;private ServiceLoader`(Class&lt;S&gt; svc, ClassLoader cl) &#123; service = Objects.requireNonNull(svc, \"Service interface cannot be null\"); loader = (cl == null) ? ClassLoader.getSystemClassLoader() : cl; acc = (System.getSecurityManager() != null) ? AccessController.getContext() : null; reload();&#125; 到这里，完全没有任何实例化的代码。 前面说到是实例化发生在遍历的时候，在构造函数里也有实例化一个LazyIterator的类，我们转到ServiceLoader的iterator()方法。 123456789101112131415161718192021222324public Iterator&lt;S&gt; iterator() &#123; return new Iterator&lt;S&gt;() &#123; Iterator&lt;Map.Entry&lt;String,S&gt;&gt; knownProviders = providers.entrySet().iterator(); public boolean hasNext() &#123; if (knownProviders.hasNext()) return true; return lookupIterator.hasNext(); &#125; public S next() &#123; if (knownProviders.hasNext()) return knownProviders.next().getValue(); return lookupIterator.next(); &#125; public void remove() &#123; throw new UnsupportedOperationException(); &#125; &#125;;&#125; 先是hasNext(),有一个knownProviders的变量，它从providers属性获得，这个属性是一个LinkedHashMap&lt;String,S&gt;，起到一个缓存的作用，保证实现类只被加载一次。我们可以不关注缓存，看lookupIterator.hasNext()。lookupIterator在上面lookupIterator = new LazyIterator(service, loader);被赋值了的，下面是LazyIterator的代码 12345678910public boolean hasNext() &#123; if (acc == null) &#123; return hasNextService(); &#125; else &#123; PrivilegedAction&lt;Boolean&gt; action = new PrivilegedAction&lt;Boolean&gt;() &#123; public Boolean run() &#123; return hasNextService(); &#125; &#125;; return AccessController.doPrivileged(action, acc); &#125;&#125; 这里有java SecurityManager的管理，直接看hasNextService()的代码就好了。 123456789101112131415161718192021222324252627private boolean hasNextService() &#123; //nextName在上一次查询提前缓存实现类的名字，做到快速判断 if (nextName != null) &#123; return true; &#125; if (configs == null) &#123; try &#123; // 这里的 PREFIX 就是 \"META-INF/services/\" String fullName = PREFIX + service.getName(); if (loader == null) configs = ClassLoader.getSystemResources(fullName); else configs = loader.getResources(fullName); &#125; catch (IOException x) &#123; fail(service, \"Error locating configuration files\", x); &#125; &#125; while ((pending == null) || !pending.hasNext()) &#123; if (!configs.hasMoreElements()) &#123; return false; &#125; pending = parse(service, configs.nextElement()); &#125; // 提前缓存实现类的名字，下一次查询做到快速判断 nextName = pending.next(); return true;&#125; 接下来看next()操作。 12345public S next() &#123; if (knownProviders.hasNext()) return knownProviders.next().getValue(); return lookupIterator.next();&#125; 转到lookupIterator.next() 12345678910public S next() &#123; if (acc == null) &#123; return nextService(); &#125; else &#123; PrivilegedAction&lt;S&gt; action = new PrivilegedAction&lt;S&gt;() &#123; public S run() &#123; return nextService(); &#125; &#125;; return AccessController.doPrivileged(action, acc); &#125;&#125; 看nextService() 12345678910111213141516171819202122232425262728private S nextService() &#123; // 这里会执行hasNextService()的判断 if (!hasNextService()) throw new NoSuchElementException(); String cn = nextName; nextName = null; Class&lt;?&gt; c = null; try &#123; c = Class.forName(cn, false, loader); &#125; catch (ClassNotFoundException x) &#123; fail(service, \"Provider \" + cn + \" not found\"); &#125; if (!service.isAssignableFrom(c)) &#123; fail(service, \"Provider \" + cn + \" not a subtype\"); &#125; try &#123; S p = service.cast(c.newInstance()); providers.put(cn, p); return p; &#125; catch (Throwable x) &#123; fail(service, \"Provider \" + cn + \" could not be instantiated\", x); &#125; throw new Error(); // This cannot happen&#125; 实际上nextService()没参与遍历，实现类的遍历是交给了hasNextService()并把遍历到的ClassName存放到nextName属性，nextService()只负责把nextName实例化，并且放入缓存中。 4. 缺点java的SPI是有缺点的，这也是dubbo为什么要实现自己的SPI机制。 JDK 标准的 SPI 会一次性实例化扩展点所有实现，如果有扩展实现初始化很耗时，但如果没用上也加载，会很浪费资源。 5. 题外话我们java程序加载数据库驱动的时候，利用的就是java的spi机制。如果我们引入了多个数据库的jdbc驱动jar，那么java怎么知道加载哪一个呢。 我们我的数据库驱动是由java.sql.DriverManager管理的，现在看他的一个getDriver()方法， 123456789101112131415161718192021222324252627@CallerSensitivepublic static Driver getDriver(String url) throws SQLException &#123; ... // who understands the given URL. for (DriverInfo aDriver : registeredDrivers) &#123; // If the caller does not have permission to load the driver then // skip it. if(isDriverAllowed(aDriver.driver, callerClass)) &#123; try &#123; // 就是这一行！ if(aDriver.driver.acceptsURL(url)) &#123; // Success! println(\"getDriver returning \" + aDriver.driver.getClass().getName()); return (aDriver.driver); &#125; &#125; catch(SQLException sqe) &#123; // Drop through and try the next driver. &#125; &#125; else &#123; println(\" skipping: \" + aDriver.driver.getClass().getName()); &#125; &#125; ...&#125; 看if(aDriver.driver.acceptsURL(url))这一行，DriverManager用连接的url对每一个驱动进行尝试，尝试得通就是这个驱动没跑了。。。 6. 结束语无。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"https://htchz.cc/tags/OOP/"}],"author":"土川"},{"title":"[Dubbo]探索dubbo2.6.3版本之前的一个问题","slug":"碧油鸡-探索dubbo2-6-3版本之前的一个问题","date":"2018-10-20T02:55:00.000Z","updated":"2020-01-12T06:32:46.524Z","comments":true,"path":"1632594101.html","link":"","permalink":"https://htchz.cc/1632594101.html","excerpt":"由于dubbo版本较低遇到了一个诡异的问题。","text":"由于dubbo版本较低遇到了一个诡异的问题。 1. 场景dubbo的RpcContext存放了一个attachments属性，用于隐式传递参数，每次发起调用之后会clear清空。 使用了cat监控之后，可以在dubbo服务调用之间传递一个id作为链路跟踪。而这个参数就是在Comsumer发起请求前放入attachments，在Provider接收到请求后从attachments拿出。 测试环境调用某服务会出现这个id时有时无的情况，于是分析日志，发现没有这个id的情况下，dubbo协议走的是hessian协议。原来此服务提供了hessian访问，于是客户端会随机走dubbo或者hessian协议。 为什么hessian协议会丢attachments？这个id是通过实现dubbo的Filter塞进去的，理论上Filter应该是协议无关的。通过debug发现，在发送请求之前的RpcContext.attachments里也的确是有这个id。 2. 探索2.1. dubbo协议dubbo的consumer调用抽象为Invoker和Invocation，在Invoker执行invoke方法之前，需要执行负载均衡、重试计数、拦截器调用链，最后执行抽象类AbstractInvoker.invoke方法，继而调用不同协议的doInvoke方法 看看dubbo协议的doInvoke方法， 可以看到请求是由一个HeaderExchangeClient去发起，这里的的channel是一个nettyClient，而request的内容如下：dubbo协议的实现是利用socket长连接，将整个request对象发送过去的,没有丢attachments 2.2. hessian协议hessian协议下是通过com.caucho.hessian.client.HessianProxy#invoke来发起请求，这个方法签名如下： 1public Object invoke(Object proxy, Method method, Object[] args) 第一个参数不知道是干嘛的，第二个参数和第三个参数分别是调用服务的方法对象和参数。反正这个方法是没地方放attchments这种隐式参数含义的东西。 debug看他的调用栈， 定位到这个com.alibaba.dubbo.rpc.proxy.AbstractProxyInvoker#invoke方法 123456789public Result invoke(Invocation invocation) throws RpcException &#123; try &#123; return new RpcResult(doInvoke(proxy, invocation.getMethodName(), invocation.getParameterTypes(), invocation.getArguments())); &#125; catch (InvocationTargetException e) &#123; return new RpcResult(e.getTargetException()); &#125; catch (Throwable e) &#123; throw new RpcException(\"Failed to invoke remote proxy method \" + invocation.getMethodName() + \" to \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125;&#125; 可以看到，从这里开始 1return new RpcResult(doInvoke(proxy, invocation.getMethodName(), invocation.getParameterTypes(), invocation.getArguments())); 就把invocation里的attachments丢了 3. 解决方法dubbo版本至少升级直2.6.3，这个版本对提供了对hessian协议的attachments支持。 下面是部分代码， 12345678910111213public class DubboHessianURLConnectionFactory extends HessianURLConnectionFactory &#123; @Override public HessianConnection open(URL url) throws IOException &#123; HessianConnection connection = super.open(url); RpcContext context = RpcContext.getContext(); for (String key : context.getAttachments().keySet()) &#123; connection.addHeader(Constants.DEFAULT_EXCHANGER + key, context.getAttachment(key)); &#125; return connection; &#125;&#125; dubbo通过继承hessian库的类，在处理URL的时候把attachments放到header里去了，接收请求时再从header里拿出来。","categories":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://htchz.cc/categories/Dubbo/"}],"tags":[{"name":"BUG","slug":"BUG","permalink":"https://htchz.cc/tags/BUG/"}],"author":"土川"},{"title":"[Java基础]正确使用CompletableFuture","slug":"Java基础-正确使用CompletableFuture","date":"2018-10-12T05:36:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"1193009570.html","link":"","permalink":"https://htchz.cc/1193009570.html","excerpt":"用不好可就搞笑了哦","text":"用不好可就搞笑了哦 1. 前言这个类是jdk8提供的类，在这个类之前的其他Future实现类，存在一些缺点，比如缺少一些任务完成的通知机制。 于是CompletableFuture诞生了，他提供了任务回调的机制，还可以简洁的组合两个任务；更可以聚合n个任务，在任何一个任务完成的全部任务完成后进行某种操作。关于它的特性不多说。 jdk8里的ParallelStream和CompletableFuture的出现让java的异步编程变的更为自然灵活。 2. 线程池那些事jdk1.7老李设计了ForkJoinPool框架，核心就是任务窃取算法。ForkJoinPool有个通用线程池，他的工作线程数在多核环境下默认是Runtime.getRuntime().availableProcessors() - 1,也就“机器cpu的线程数 - 1“（减一可能是最佳实践吧）， 1234public static ForkJoinPool commonPool() &#123; // assert common != null : \"static init error\"; return common;&#125; ParallelStream新任务是只能提交到这个线程池的，而CompletableFuture默认使用这个线程池，但是也支持自己提供线程池。 可以看到runAsync和supplyAsync有重载方法提供Executor。 那么我们什么时候要提供线程池呢，这里看《java8实战》的一段话， 并行——使用流还是CompletableFutures?集合进行并行计算有两种方式:要么将其转化为并行流，利用map这样的操作开展工作，要么枚举出集合中的每一个元素，创建新的线程，在CompletableFuture内对其进行操作。后者提供了更多的灵活性，你可以调整线程池的大小，而这能帮助你确保整体的计算不会因为线程都在等待I/O而发生阻塞。我们对使用这些API的建议如下。 如果你进行的是计算密集型的操作，并且没有I/O，那么推荐使用Stream接口，因为实现简单，同时效率也可能是最高的(如果所有的线程都是计算密集型的，那就没有必要创建比处理器核数更多的线程)。 如果你并行的工作单元还涉及等待I/O的操作(包括网络连接等待)，那么使用CompletableFuture灵活性更好，你可以像前文讨论的那样，依据等待/计算，或者 W/C的比率设定需要使用的线程数。这种情况不使用并行流的另一个原因是，处理流的流水线中如果发生I/O等待，流的延迟特性(流的中间操作会在一起执行)会让我们很难判断到底什么时候触发了等待。 简单地说，ForkJoinPool通用线程池的线程数比较少，不适合用来进行需要I/O等待的任务。如果用CompletableFuture提交一些需要I/O等待的任务，需要提供一个自定义的Executor。 下面用程序演示一下， 12345678910111213141516171819202122232425262728public class CompletableTest &#123; public static void main(String[] args) &#123; ExecutorService service = Executors.newFixedThreadPool(100); Stopwatch stopwatch = Stopwatch.createUnstarted(); stopwatch.start(); // 不提供Executor，Uninterruptibles.sleepUninterruptibly(1, TimeUnit.SECONDS)模拟网络I/O 1秒 CompletableFuture.allOf( IntStream.rangeClosed(1, 100).boxed() .map(a -&gt; CompletableFuture.runAsync(() -&gt; Uninterruptibles.sleepUninterruptibly(1, TimeUnit.SECONDS))) .toArray(CompletableFuture[]::new)) .join(); System.out.println(\"elapsed with ForkJoinPool:\" + stopwatch.stop().elapsed(TimeUnit.MILLISECONDS) + \" ms\"); stopwatch.reset().start(); // 提供Executor CompletableFuture.allOf( IntStream.rangeClosed(1, 100).boxed() .map(a -&gt; CompletableFuture.runAsync(() -&gt; Uninterruptibles.sleepUninterruptibly(1, TimeUnit.SECONDS), service)) .toArray(CompletableFuture[]::new)) .join(); System.out.println(\"elapsed with Executor:\" + stopwatch.stop().elapsed(TimeUnit.MILLISECONDS) + \" ms\"); service.shutdown(); &#125;&#125; elapsed with ForkJoinPool:15100 ms elapsed with Executor:1019 ms我的电脑是8线程，那么ForkJoinPool通用线程池就是 (8 - 1 = 7 )个线程， 可以看到100个任务执行了15秒 ( 约等于 100 / 7)。所以使用CompletableFuture的时候要注意这点。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}],"author":"土川"},{"title":"[分布式]接口限流","slug":"分布式-接口限流","date":"2018-09-29T07:51:00.000Z","updated":"2020-06-30T08:47:42.817Z","comments":true,"path":"2168043814.html","link":"","permalink":"https://htchz.cc/2168043814.html","excerpt":"尝试一下用lua脚本执行redis命令","text":"尝试一下用lua脚本执行redis命令 1. 前言对于应用内部的服务限流，熔断器Hystrix，作出很好的实践。最近开源的Sentinel也是一个不错的选择。 不过对于集群接口限流，好像没有什么框架。常用的限流算法就是：漏桶算法和令牌桶算法。本文将利用redis和lua脚本实现令牌桶算法，同时通过spring来驱动脚本。Guava提供了一个RateLimiter，我们也看一下。 当然还可以用计数器方法，如设定一个计数key，一秒过期，一秒内达到n次就拒绝服务。 2. 两个算法Google了十几个中文博客，每一篇都是一样的，都说两种算法能限制速率，但是漏桶算法不能应对突发流量而令牌桶可以，又没说为什么。在我看来，两种算法的算法不过是“一正一反”，本质是一样的。无奈英语渣看了一下维基百科”LeakyBucket”词条，Overview里提到，有两种版本的漏桶算法： 2.1. 漏桶算法（LeakyBucket） as a meter（作为计量器） as a queue（作为调度队列） 第一种版本是令牌桶算法的镜像实现，也就是描述起来不一样，原理一样。只要元素能放进桶，就是允许通过。 第二种版本是把桶作为队列，只有元素漏出桶，这个元素才算通过。因为漏桶的速率是恒定的，所以能起到流量整形的作用。 漏桶算法指一定速率漏水，流量进来的时候是把水加入桶里，当水&gt; 容量的时候拒绝服务（或者其他策略balabala）。 两个重要参数： 漏水速率 桶容量 下面是计量器版本伪代码： 12345678910111213141516171819double rate; // leak rate in calls/sdouble burst; // bucket size in callslong refreshTime; // time for last water refreshdouble water; // water count at refreshTimerefreshWater() &#123; long now = getTimestamp(); //计算两次请求之间流失的水并相减 water = max(0, water- (now - refreshTime)*rate); refreshTime = now;&#125;bool check() &#123; refreshWater(); if (water &lt; burst) &#123; // 水桶还没满,继续加1 water ++; return true; &#125; else &#123; return false; &#125;&#125; 2.2. 令牌桶算法（TokenBucket） 令牌桶算法是网络流量整形（Traffic Shaping）和速率限制（Rate Limiting）中最常使用的一种算法。典型情况下，令牌桶算法用来控制发送到网络上的数据字节数目，并允许突发数据的发送，用令牌数量代表字节数量。 两个重要参数： 发牌速率 令牌桶容量 对于令牌不足的情况，对流量可以进行三种方式的处理： 丢弃数据包 放入等待队列直至令牌足够 进行标记，过载情况下可以进行丢弃 令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务(或者其他策略balabala)。从原理上看，令牌桶算法和漏桶算法是相反的，一个“进水”，一个是“漏水”。 丢弃数据包的实现看楼下lua脚本 Guava的RateLimiter就是使用了令牌桶算法。 3. redis实现redis在2.6之后内置了对lua脚本的支持。通过lua脚本我们可以执行一些复杂的逻辑操作，同时保证整个操作过程的原子性。 lua脚本写在客户端，下面是一个lua脚本，应该很容易理解 12345678910111213141516171819202122232425262728293031323334353637383940--token_bucket.lua--keys和argv都是数组--tonumber()方法是转整数--local表示本地变量，速度比全局变量快--..表示拼接字符串local key = KEYS[1];--local limit = tonumber(ARGV[1]);local step = tonumber(ARGV[2]);local interval = tonumber(ARGV[3]);local nowTime = tonumber(ARGV[4]);local lastClearTimeKey = 'lastTimeOf' .. keylocal lastClearTime = redis.call('GET', lastClearTimeKey);local existKey = redis.call('EXISTS', key);if existKey == 1 then local diff = tonumber(nowTime) - tonumber(lastClearTime); local value = tonumber(redis.call('GET', key)); if diff &gt; interval then local maxValue = value + diff / interval * step; if maxValue &gt; step then value = step; else value = maxValue; end redis.call('SET', lastClearTimeKey, nowTime); redis.call('SET', key, math.floor(value)); end if value &lt;= 0 then return 0; else redis.call('DECR', key); endelse redis.call('SET', key, step - 1); redis.call('SET', lastClearTimeKey, nowTime);endreturn 1; 4. 使用spring驱动由于使用的是spring-boot，redis-server在本地，所以只要引入spring-data-redis和jedis,其他配置默认 12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-redis&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt; 设置序列化器 1234567891011@Bean@SuppressWarnings(\"unchecked\")public RedisTemplate redisTemplate(RedisConnectionFactory redisConnectionFactory) &#123; RedisTemplate redisTemplate = new RedisTemplate(); redisTemplate.setConnectionFactory(redisConnectionFactory); // 设置键的序列化器 redisTemplate.setKeySerializer(new StringRedisSerializer()); // 默认Serializer,RedisTemplate在序列化key、反序列化返回值的时候找不到设置的Serializer会使用默认Serializer，而默认的默认Serializer是JdkSerializationRedisSerializer，这个会转成很难看的码可能导致lua执行出错 redisTemplate.setDefaultSerializer( new GenericJackson2JsonRedisSerializer()); return redisTemplate;&#125; 脚本的抽象类是DefaultRedisScript, 使用RedisTemplate调用。keys是List类型，argvs是数组类型，不可以搞混。 123456789101112131415161718public class RedisScriptService &#123; private final static Logger log = LoggerFactory.getLogger(RedisScriptService.class); @Resource private RedisTemplate redisTemplate; public void counterConsume(String key, int limit, int step, int interval) &#123; DefaultRedisScript&lt;Long&gt; consumeRedisScript = new DefaultRedisScript&lt;&gt;(); consumeRedisScript.setResultType(Long.class); consumeRedisScript.setScriptSource(new ResourceScriptSource(new ClassPathResource(\"script/token_bucket.lua\")));//加载lua脚本文件 List&lt;Object&gt; keyList = new LinkedList&lt;&gt;(); keyList.add(key);//通过KEYS[1]取值 for (int i = 0; i &lt; 15; i++) &#123; log.info(\"result:\" + redisTemplate.execute(consumeRedisScript, keyList, new Object[]&#123;limit, step, interval, System.currentTimeMillis()&#125;).toString()); &#125; &#125;&#125; 2018-09-30 16:23:17.066 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:1 2018-09-30 16:23:17.067 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:1 2018-09-30 16:23:17.067 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:1 2018-09-30 16:23:17.068 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:1 2018-09-30 16:23:17.069 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:1 2018-09-30 16:23:17.070 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:1 2018-09-30 16:23:17.071 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:1 2018-09-30 16:23:17.072 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:1 2018-09-30 16:23:17.072 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:1 2018-09-30 16:23:17.073 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:1 2018-09-30 16:23:17.074 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:0 2018-09-30 16:23:17.075 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:0 2018-09-30 16:23:17.076 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:0 2018-09-30 16:23:17.077 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:0 2018-09-30 16:23:17.078 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:0result的1是通过，0是不通过。 键没有设置过期，可以优化。 5. Guava RateLimiterGuava RateLimiter实现了令牌桶算法。这里有一个中文版的官方文档：Guava官方文档，主要就是声明发牌速率，然后需要判断能否获取令牌，则调用tryAcquire()或tryAcquire(int)方法；需要阻塞直至令牌足够，则调用acquire()或acquire(int)。 5.1. qps限制器假设我们要限制每秒处理task或者qps的值，代码： 1234567891011121314public class RateLimiterTest &#123; public static void main(String[] args) &#123; RateLimiter rateLimiter = RateLimiter.create(5); IntStream.range(0, 15).forEach((a) -&gt; &#123; if (a == 5) &#123; SleepUtil.sleep(2000); &#125; System.out.println(rateLimiter.acquire()); if ((a + 1) % 5 == 0) &#123; System.out.println(); &#125; &#125;); &#125;&#125; 0.0// 0令牌，还不用阻塞 0.143213 0.196686 0.198948 0.199056 0.0// 停了2秒，发了5个令牌 0.0 0.0 0.0 0.0 0.0// 0令牌，还不用阻塞 0.199505 0.198738 0.197634 0.196273示例里先实例一个限流器，速率为1秒5次，通过acquire()阻塞获得令牌，总调用15次，并返回等待时间。第5次acquire()完的时候，挂起2秒。 从输出来看，第一次取得令牌是不用等待的。 挂起2秒后，接下来的5次不用阻塞，再接下来的5次除了以第一次发生了阻塞(第一次)，也就是2秒内只发了5个令牌，不会累积。 为什么看起来0令牌的情况下，第一次调用阻塞时间都是0呢？那是因为RateLimiter可以预消费（acquire()实际上是调用acquire(1), 这和调用acquire(1000) 将得到相同的限制效果，如果存在这样的调用的话），但会影响下一次请求的，也就是说，如果一个高开销的任务抵达一个空闲的RateLimiter，它会被马上许可，但是下一个请求会经历额外的限制，从而来偿付高开销任务。 此外需注意：RateLimiter 并不提供公平性的保证，没有先来先得的概念。 这个类其实实现了令牌不足下多种应对策略 require()属于流量整形的实现 tryRequire()属于服务限流的实现 6. 后记除此之外，nginx也有限流模块，一种是限制连接数，一种是使用令牌桶算法，具体效果没实战。 7. 参考 Leaky bucket","categories":[{"name":"分布式","slug":"分布式","permalink":"https://htchz.cc/categories/分布式/"}],"tags":[{"name":"服务限流","slug":"服务限流","permalink":"https://htchz.cc/tags/服务限流/"}],"author":"土川"},{"title":"[Golang基础]Goroutine调度","slug":"Golang基础-Goroutine调度","date":"2018-09-28T06:48:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"2747343217.html","link":"","permalink":"https://htchz.cc/2747343217.html","excerpt":"摘抄自小米运维","text":"摘抄自小米运维 1. 前言随着服务器硬件迭代升级，配置也越来越高。为充分利用服务器资源，并发编程也变的越来越重要。在开始之前，需要了解一下并发(concurrency)和并行(parallesim)的区别。 并发: 逻辑上具有处理多个同时性任务的能力。 并行: 物理上同一时刻执行多个并发任务。 通常所说的并发编程，也就是说它允许多个任务同时执行，但实际上并不一定在同一时刻被执行。在单核处理器上，通过多线程共享CPU时间片串行执行(并发非并行)。而并行则依赖于多核处理器等物理资源，让多个任务可以实现并行执行(并发且并行)。 多线程或多进程是并行的基本条件，但单线程也可以用协程(coroutine)做到并发。简单将Goroutine归纳为协程并不合适，因为它运行时会创建多个线程来执行并发任务，且任务单元可被调度到其它线程执行。这更像是多线程和协程的结合体，能最大限度提升执行效率，发挥多核处理器能力。 Go编写一个并发编程程序很简单，只需要在函数之前使用一个Go关键字就可以实现并发编程。 12345func main() &#123; go func()&#123; fmt.Println(\"Hello,World!\") &#125;()&#125; 2. Go调度器组成Go语言虽然使用一个 Go 关键字即可实现并发编程，但Goroutine被调度到后端之后，具体的实现比较复杂。先看看调度器有哪几部分组成。 G M P 2.1. GG是 Go routine的缩写，相当于操作系统中的进程控制块，在这里就是Goroutine的控制结构，是对Goroutine的抽象。其中包括执行的函数指令及参数；G保存的任务对象；线程上下文切换，现场保护和现场恢复需要的寄存器(SP、IP)等信息。 Go不同版本Goroutine默认栈大小不同。 12345678910111213141516171819202122// Go1.11版本默认stack大小为2KB_StackMin = 2048 // 创建一个g对象,然后放到g队列// 等待被执行func newproc1(fn *funcval, argp *uint8, narg int32, callergp *g, callerpc uintptr) &#123; _g_ := getg() _g_.m.locks++ siz := narg siz = (siz + 7) &amp;^ 7 _p_ := _g_.m.p.ptr() newg := gfget(_p_) if newg == nil &#123; // 初始化g stack大小 newg = malg(_StackMin) casgstatus(newg, _Gidle, _Gdead) allgadd(newg) &#125; // 以下省略&#125; 2.2. MM是一个线程或称为Machine，对应操作系统线程。所有M是有线程栈的。如果不对该线程栈提供内存的话，系统会给该线程栈提供内存(不同操作系统提供的线程栈大小不同)。当指定了线程栈，则M.stack→G.stack，M的PC寄存器指向G提供的函数，然后去执行。 1234567891011121314type m struct &#123; /* 1. 所有调用栈的Goroutine,这是一个比较特殊的Goroutine。 2. 普通的Goroutine栈是在Heap分配的可增长的stack,而g0的stack是M对应的线程栈。 3. 所有调度相关代码,会先切换到该Goroutine的栈再执行。 */ g0 *g curg *g // M当前绑定的结构体G // SP、PC寄存器用于现场保护和现场恢复 vdsoSP uintptr vdsoPC uintptr // 省略…&#125; 2.3. PP(Processor)是一个抽象的概念，它存在的意义是为了限制并发任务的数量，并不是物理CPU的抽象。所以当P有任务时需要创建或者唤醒一个系统线程来执行它队列里的任务。所以P/M需要进行绑定，构成一个执行单元。 P决定了同时可以并发任务的数量，可通过GOMAXPROCS限制同时执行用户级任务的操作系统线程。可以通过runtime.GOMAXPROCS进行指定。在Go1.5之后GOMAXPROCS被默认设置可用的核数，而之前则默认为1。 1234567891011121314// 自定义设置GOMAXPROCS数量func GOMAXPROCS(n int) int &#123; /* 1. GOMAXPROCS设置可执行的CPU的最大数量,同时返回之前的设置。 2. 如果n &lt; 1,则不更改当前的值。 */ ret := int(gomaxprocs) stopTheWorld(\"GOMAXPROCS\") // startTheWorld启动时,使用newprocs。 newprocs = int32(n) startTheWorld() return ret&#125; 123456789101112131415161718192021222324252627282930313233343536373839// 默认P被绑定到所有CPU核上// P == cpu.coresfunc getproccount() int32 &#123; const maxCPUs = 64 * 1024 var buf [maxCPUs / 8]byte // 获取CPU Core r := sched_getaffinity(0, unsafe.Sizeof(buf), &amp;buf[0]) n := int32(0) for _, v := range buf[:r] &#123; for v != 0 &#123; n += int32(v &amp; 1) v &gt;&gt;= 1 &#125; &#125; if n == 0 &#123; n = 1 &#125; return n&#125;// 一个进程默认被绑定在所有CPU核上,返回所有CPU core。// 获取进程的CPU亲和性掩码系统调用// rax 204 ; 系统调用码// system_call sys_sched_getaffinity; 系统调用名称// rid pid ; 进程号// rsi unsigned int len // rdx unsigned long *user_mask_ptrsys_linux_amd64.s:TEXT runtime·sched_getaffinity(SB),NOSPLIT,$0 MOVQ pid+0(FP), DI MOVQ len+8(FP), SI MOVQ buf+16(FP), DX MOVL $SYS_sched_getaffinity, AX SYSCALL MOVL AX, ret+24(FP) RET 3. 调度过程首先创建一个G对象，G对象保存到P本地队列或者是全局队列。P此时去唤醒一个M。P继续执行它的执行序。M寻找是否有空闲的P，如果有则将该G对象移动到它本身。接下来M执行一个调度循环(调用G对象-&gt;执行-&gt;清理线程→继续找新的Goroutine执行)。 M执行过程中，随时会发生上下文切换。当发生上线文切换时，需要对执行现场进行保护，以便下次被调度执行时进行现场恢复。Go调度器M的栈保存在G对象上，只需要将M所需要的寄存器(SP、PC等)保存到G对象上就可以实现现场保护。当这些寄存器数据被保护起来，就随时可以做上下文切换了，在中断之前把现场保存起来。如果此时G任务还没有执行完，M可以将任务重新丢到P的任务队列，等待下一次被调度执行。当再次被调度执行时，M通过访问G的vdsoSP、vdsoPC寄存器进行现场恢复(从上次中断位置继续执行)。 当M从队列中拿到一个可执行的G后，首先会去检查一下P队列中是否还有等待的G，如果还有等待的G，并且也还有空闲的P，此时就会通知runtime分配一个新的M（如果有在睡觉的OS线程，则直接唤醒它，没有的话则生成一个新的OS线程）来分担任务。 如果某个M发现队列为空之后，会首先从全局队列中取一个G来处理。如果全局队列也空了，则会随机从别的P那里直接截取一半的队列过来（偷窃任务），如果发现所有的P都没有可供偷窃的G了，该M就会陷入沉睡。 这种协作调度回导致全剧队列会响应得慢一丢丢，但是在总体上这种调度将处理器的机器性能充分发挥。 3.1. P 队列通过上图可以发现，P有两种队列：本地队列和全局队列。 本地队列： 当前P的队列，本地队列是Lock-Free，没有数据竞争问题，无需加锁处理，可以提升处理速度。 全局队列： 全局队列为了保证多个P之间任务的平衡。所有M共享P全局队列，为保证数据竞争问题，需要加锁处理。相比本地队列处理速度要低于全局队列。 3.2. 上线文切换简单理解为当时的环境即可，环境可以包括当时程序状态以及变量状态。例如线程切换的时候在内核会发生上下文切换，这里的上下文就包括了当时寄存器的值，把寄存器的值保存起来，等下次该线程又得到cpu时间的时候再恢复寄存器的值，这样线程才能正确运行。 对于代码中某个值说，上下文是指这个值所在的局部(全局)作用域对象。相对于进程而言，上下文就是进程执行时的环境，具体来说就是各个变量和数据，包括所有的寄存器变量、进程打开的文件、内存(堆栈)信息等。 3.3. 线程清理Goroutine被调度执行必须保证P/M进行绑定，所以线程清理只需要将P释放就可以实现线程的清理。什么时候P会释放，保证其它G可以被执行。P被释放主要有两种情况。 主动释放： 最典型的例子是，当执行G任务时有系统调用，当发生系统调用时M会处于Block状态。调度器会设置一个超时时间，当超时时会将P释放。 被动释放： 如果发生系统调用，有一个专门监控程序，进行扫描当前处于阻塞的P/M组合。当超过系统程序设置的超时时间，会自动将P资源抢走。去执行队列的其它G任务。","categories":[{"name":"Golang基础","slug":"Golang基础","permalink":"https://htchz.cc/categories/Golang基础/"}],"tags":[{"name":"goroutine","slug":"goroutine","permalink":"https://htchz.cc/tags/goroutine/"}],"author":"土川"},{"title":"[Java基础]ForkJoinPool","slug":"Java基础-ForkJoinPool","date":"2018-09-20T09:01:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"2843017067.html","link":"","permalink":"https://htchz.cc/2843017067.html","excerpt":"jdk8的parallerStream的实现依赖这种线程池。这个类带上注释3478行，表示很慌。","text":"jdk8的parallerStream的实现依赖这种线程池。这个类带上注释3478行，表示很慌。 1. 前言设计这个线程池的原因不是为了取代ThreadPoolExecutor，ForkJoinPool 最适合的是计算密集型的任务，如果存在 I/O，线程间同步，sleep() 等会造成线程长时间阻塞的情况时，最好配合使用 ManagedBlocker。 2. 使用例子核心思想就是拆分任务，这很快排的原理是一样的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889package com.htc.learning.main;import java.util.concurrent.ForkJoinPool;import java.util.concurrent.RecursiveAction;import java.util.concurrent.RecursiveTask;import java.util.stream.LongStream;public class ForkJoinPoolTest &#123; public static void main(String[] args) &#123; long[] numbers = LongStream.rangeClosed(1, 100).toArray(); fork(numbers); forkAndJoin(numbers); &#125; private static void fork(long[] numbers) &#123; ForkJoinPool pool = ForkJoinPool.commonPool(); pool.invoke(new PrintTask(0, numbers.length -1 , numbers)); &#125; private static void forkAndJoin(long[] numbers) &#123; ForkJoinPool pool = ForkJoinPool.commonPool(); long sum = pool.invoke(new SumTask(0, numbers.length - 1, numbers)); System.out.println(\"sum is :\" + sum); &#125;&#125;// 这是没有join结果的class PrintTask extends RecursiveAction &#123; // 小任务的打印量 private static final int THRESHOLD = 10; private int start; private int end; private long[] list; public PrintTask(int start, int end, long[] List) &#123; this.start = start; this.end = end; this.list = List; &#125; @Override protected void compute() &#123; if (end - start &lt; THRESHOLD) &#123; for (int i = start; i &lt;= end; i++) &#123; System.out.print(list[i] + \",\"); &#125; System.out.println(); &#125; else &#123; int middle = (start + end) / 2; PrintTask leftTask = new PrintTask(start, middle, list); PrintTask rightTask = new PrintTask(middle + 1, end, list); leftTask.fork(); rightTask.fork(); &#125; &#125;&#125;// 这是join结果的class SumTask extends RecursiveTask&lt;Long&gt; &#123; // 小任务的计算量 private static final int THRESHOLD = 10; private int start; private int end; private long[] list; public SumTask(int start, int end, long[] list) &#123; this.start = start; this.end = end; this.list = list; &#125; @Override protected Long compute() &#123; if (end - start &lt; THRESHOLD) &#123; long sum = 0; for (int i = start; i &lt;= end; i++) &#123; sum += list[i]; &#125; return sum; &#125; else &#123; int middle = (start + end) / 2; SumTask leftTask = new SumTask(start, middle, list); SumTask rightTask = new SumTask(middle + 1, end, list); leftTask.fork(); rightTask.fork(); return leftTask.join() + rightTask.join(); &#125; &#125;&#125; 运行结果 结果很乱，可以看出fork()是异步的，如果使用join()阻塞的话，可以将计算变为同步。 3. 原理老李的论文 分治。这个从使用方式就可以看出来。 工作窃取（work-stealing）。 每个工作队列一个线程。 那么为什么需要使用工作窃取算法呢？假如我们需要做一个比较大的任务，我们可以把这个任务分割为若干互不依赖的子任务，为了减少线程间的竞争，于是把这些子任务分别放到不同的队列里，并为每个队列创建一个单独的线程来执行队列里的任务，线程和队列一一对应，比如A线程负责处理A队列里的任务。但是有的线程会先把自己队列里的任务干完，而其他线程对应的队列里还有任务等待处理。干完活的线程与其等着，不如去帮其他线程干活，于是它就去其他线程的队列里窃取一个任务来执行。而在这时它们会访问同一个队列，所以为了减少窃取任务线程和被窃取任务线程之间的竞争，通常会使用双端队列，被窃取任务线程永远从双端队列的头部拿任务执行，而窃取任务的线程永远从双端队列的尾部拿任务执行。 工作窃取算法的优点是充分利用线程进行并行计算，并减少了线程间的竞争，其缺点是在某些情况下还是存在竞争，比如双端队列里只有一个任务时。并且消耗了更多的系统资源，比如创建多个线程和多个双端队列。 据说ForkJoinPool在jdk7和jdk8的实现不一样。现在是jdk8的时代，我暂时不去看jdk7的实现啦。 ForkJoinPool 的每个工作线程都维护着一个工作队列（WorkQueue），这是一个双端队列（Deque），里面存放的对象是任务（ForkJoinTask）。 每个工作线程在运行中产生新的任务（通常是因为调用了 fork()）时，会放入工作队列的队尾，并且工作线程在处理自己的工作队列时，使用的是 LIFO 方式，也就是说每次从队尾取出任务来执行。 每个工作线程在处理自己的工作队列同时，会尝试窃取一个任务（或是来自于刚刚提交到 pool 的任务，或是来自于其他工作线程的工作队列），窃取的任务位于其他线程的工作队列的队首，也就是说工作线程在窃取其他工作线程的任务时，使用的是 FIFO 方式。 在遇到 join() 时，如果需要 join 的任务尚未完成，则会先处理其他任务，并等待其完成。（其实我不理解这句话，什么叫遇到join()时） 在既没有自己的任务，也没有可以窃取的任务时，进入休眠。 那么fork()每次调用都会创建一个线程吗，答案并不是，对于ForkJoinPool构造函数给出线程数就创建多少线程。那么join()也会阻塞吗，不一定，具体我们后面看源码实现。 4. 概念 ForkJoinPool: 用于执行ForkJoinTask任务的执行池,不再是传统执行池 Worker+Queue 的组合模式,而是维护了一个队列数组WorkQueue,这样在提交任务和线程任务的时候大幅度的减少碰撞。] WorkQueue: 双向列表,用于任务的有序执行,如果WorkQueue用于自己的执行线程Thread,线程默认将会从top端选取任务用来执行 - LIFO。因为只有owner的Thread才能从top端取任务,所以在设置变量时, int top; 不需要使用 volatile。 ForkJoinWorkThread: 用于执行任务的线程,用于区别使用非ForkJoinWorkThread线程提交的task;启动一个该Thread,会自动注册一个WorkQueue到Pool,这里规定,拥有Thread的WorkQueue只能出现在WorkQueue数组的奇数位 ForkJoinTask: 任务, 它比传统的任务更加轻量，不再对是RUNNABLE的子类,提供fork/join方法用于分割任务以及聚合结果。 为了充分施展并行运算,该框架实现了复杂的 worker steal算法,当任务处于等待中,thread通过一定策略,不让自己挂起，充分利用资源，当然，它比其他语言的协程要重一些。 5. sun.misc.Contended打开ForkJoinPool，第一行就是这么个注解： 12@sun.misc.Contendedpublic class ForkJoinPool extends AbstractExecutorService &#123;...&#125; 度娘一下，看到了一个叫缓存行的东西，这个注解就是为了解决缓存行的伪共享False Sharing 缓存系统中是以缓存行（cache line）为单位存储的。缓存行是2的整数幂个连续字节，一般为32-256个字节。最常见的缓存行大小是64个字节。当多线程修改互相独立的变量时，如果这些变量共享同一个缓存行，就会无意中影响彼此的性能，这就是伪共享。缓存行上的写竞争是运行在SMP系统中并行线程实现可伸缩性最重要的限制因素。有人将伪共享描述成无声的性能杀手，因为从代码中很难看清楚是否会出现伪共享。 看图：在缓存行L3 Cache里有x，y，线程1想去修改x，线程2想去修改y，那么这行缓存行就会称谓竞争对象，竞争的过程就会产生性能的损耗。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class FalseSharing implements Runnable &#123; public final static int NUM_THREADS = 4; // change public final static long ITERATIONS = 500L * 1000L * 1000L; private final int arrayIndex; // 这里分别换成不同的类的数组，使用数组是为了内存连续 private static VolatileLong3[] longs = new VolatileLong3[NUM_THREADS]; static &#123; for (int i = 0; i &lt; longs.length; i++) &#123; longs[i] = new VolatileLong3(); &#125; &#125; public FalseSharing(final int arrayIndex) &#123; this.arrayIndex = arrayIndex; &#125; public static void main(final String[] args) throws Exception &#123; long start = System.nanoTime(); runTest(); System.out.println(\"duration = \" + (System.nanoTime() - start)); &#125; private static void runTest() throws InterruptedException &#123; Thread[] threads = new Thread[NUM_THREADS]; for (int i = 0; i &lt; threads.length; i++) &#123; threads[i] = new Thread(new FalseSharing(i)); &#125; for (Thread t : threads) &#123; t.start(); &#125; for (Thread t : threads) &#123; t.join(); &#125; &#125; public void run() &#123; long i = ITERATIONS + 1; while (0 != --i) &#123; longs[arrayIndex].value = i; &#125; &#125; public final static class VolatileLong &#123; public volatile long value = 0L; &#125; // long padding避免false sharing // 按理说jdk7以后long padding应该被优化掉了，但是从测试结果看padding仍然起作用 public final static class VolatileLong2 &#123; volatile long p0, p1, p2, p3, p4, p5, p6; public volatile long value = 0L; volatile long q0, q1, q2, q3, q4, q5, q6; &#125; // jdk8新特性，Contended注解避免false sharing // Restricted on user classpath // Unlock: -XX:-RestrictContended @sun.misc.Contended public final static class VolatileLong3 &#123; public volatile long value = 0L; &#125; &#125; 替换三种声明，测试结果如下 VolatileLong: duration = 31605817365 VolatileLong2:duration = 3725651254 VolatileLong3:duration = 3762335746VolatileLong2的原理：缓冲行有64字节，那么在属性value前面排列7个long，后面排列7个long，放到内存的时候，value无论如何都会和周围的long成员组成一个8个long，即64字节，从而避免缓存行的竞争。 而jdk8提供了@sun.misc.Contended注解后就不用写的这么麻烦了(也是填充了字节，具体看Java8使用@sun.misc.Contended避免伪共享)。 6. 基本说明6.1. ForkJoinPoolForkJoinPool有超多的常量,下面是一部分 123456789101112131415161718192021222324252627282930313233343536373839404142434445/* * Bits and masks for field ctl, packed with 4 16 bit subfields: * AC: Number of active running workers minus target parallelism * TC: Number of total workers minus target parallelism * SS: version count and status of top waiting thread * ID: poolIndex of top of Treiber stack of waiters * * When convenient, we can extract the lower 32 stack top bits * (including version bits) as sp=(int)ctl. The offsets of counts * by the target parallelism and the positionings of fields makes * it possible to perform the most common checks via sign tests of * fields: When ac is negative, there are not enough active * workers, when tc is negative, there are not enough total * workers. When sp is non-zero, there are waiting workers. To * deal with possibly negative fields, we use casts in and out of * \"short\" and/or signed shifts to maintain signedness. * * Because it occupies uppermost bits, we can add one active count * using getAndAddLong of AC_UNIT, rather than CAS, when returning * from a blocked join. Other updates entail multiple subfields * and masking, requiring CAS. */ // Lower and upper word masksprivate static final long SP_MASK = 0xffffffffL;private static final long UC_MASK = ~SP_MASK;// Active countsprivate static final int AC_SHIFT = 48;private static final long AC_UNIT = 0x0001L &lt;&lt; AC_SHIFT;private static final long AC_MASK = 0xffffL &lt;&lt; AC_SHIFT;// Total countsprivate static final int TC_SHIFT = 32;private static final long TC_UNIT = 0x0001L &lt;&lt; TC_SHIFT;private static final long TC_MASK = 0xffffL &lt;&lt; TC_SHIFT;private static final long ADD_WORKER = 0x0001L &lt;&lt; (TC_SHIFT + 15); // sign// runState bits: SHUTDOWN must be negative, others arbitrary powers of twoprivate static final int RSLOCK = 1;private static final int RSIGNAL = 1 &lt;&lt; 1;private static final int STARTED = 1 &lt;&lt; 2;private static final int STOP = 1 &lt;&lt; 29;private static final int TERMINATED = 1 &lt;&lt; 30;private static final int SHUTDOWN = 1 &lt;&lt; 31; runstate：如果执行 runState &amp; RSLOCK ==0 就能直接说明,目前的运行状态没有被锁住,其他情况一样。 config：parallelism， mode。parallelism是构造函数的参数，表示并行等级，不等于工作队列的数量。需要注意一下它的界限，最大是0x7fff。 1static final int MAX_CAP = 0x7fff; // max #workers - 1 ctl：ctl是Pool的状态变量,类型是long - 说明有64位,每个部分都有不同的作用。我们使用十六进制来标识ctl，依次说明不同部分的作用。（这和普通线程池一样） 以下是构造函数，可以看到ctl的初始化，我们把ctl标识为4部分，0x xxxx-1 xxxx-2 xxxx-3 xxxx-4 1234567891011121314151617/** * Creates a &#123;@code ForkJoinPool&#125; with the given parameters, without * any security checks or parameter validation. Invoked directly by * makeCommonPool. */private ForkJoinPool(int parallelism, ForkJoinWorkerThreadFactory factory, UncaughtExceptionHandler handler, int mode, String workerNamePrefix) &#123; this.workerNamePrefix = workerNamePrefix; this.factory = factory; this.ueh = handler; this.config = (parallelism &amp; SMASK) | mode; long np = (long)(-parallelism); // offset ctl counts this.ctl = ((np &lt;&lt; AC_SHIFT) &amp; AC_MASK) | ((np &lt;&lt; TC_SHIFT) &amp; TC_MASK);&#125; 1号16位，表示AC(Active counts)并行数的负数。当ctl变成正数的时候表示线程数达到阈值了。(为什么不能用正数，然后负数的时候就表示达到阈值？？) 2号16位，表示TC(Total counts)并行数。Total counts等于挂起的线程数+AC，(也是用负数表示) 3号16位，表示SS，后32位标识idle workers 前面16位第一位标识是active的还是inactive的,其他为是版本标识。 4号16位，表示ID(Index)，标识idle workers在WorkQueue[]数组中的index。这里需要说明的是,ctl的后32位其实只能表示一个idle workers，那么我们如果有很多个idle worker要怎么办呢？老李使用的是stack的概念来保存这些信息。后32位标识的是栈顶的那个,我们能从栈顶中的变量stackPred追踪到下一个idle worker 6.2. WorkQueueWorkQueue是一个双向列表,存放任务task。WorkQueue类也用了@sun.misc.Contended注解 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@sun.misc.Contended static final class WorkQueue &#123; /** * Capacity of work-stealing queue array upon initialization. * Must be a power of two; at least 4, but should be larger to * reduce or eliminate cacheline sharing among queues. * Currently, it is much larger, as a partial workaround for * the fact that JVMs often place arrays in locations that * share GC bookkeeping (especially cardmarks) such that * per-write accesses encounter serious memory contention. */ static final int INITIAL_QUEUE_CAPACITY = 1 &lt;&lt; 13; /** * Maximum size for queue arrays. Must be a power of two less * than or equal to 1 &lt;&lt; (31 - width of array entry) to ensure * lack of wraparound of index calculations, but defined to a * value a bit less than this to help users trap runaway * programs before saturating systems. */ static final int MAXIMUM_QUEUE_CAPACITY = 1 &lt;&lt; 26; // 64M // Instance fields volatile int scanState; // versioned, &lt;0: inactive; odd:scanning int stackPred; // pool stack (ctl) predecessor int nsteals; // number of steals int hint; // randomization and stealer index hint int config; // pool index and mode volatile int qlock; // 1: locked, &lt; 0: terminate; else 0 volatile int base; // index of next slot for poll int top; // index of next slot for push ForkJoinTask&lt;?&gt;[] array; // the elements (initially unallocated) final ForkJoinPool pool; // the containing pool (may be null) final ForkJoinWorkerThread owner; // owning thread or null if shared volatile Thread parker; // == owner during call to park; else null volatile ForkJoinTask&lt;?&gt; currentJoin; // task being joined in awaitJoin volatile ForkJoinTask&lt;?&gt; currentSteal; // mainly used by helpStealer WorkQueue(ForkJoinPool pool, ForkJoinWorkerThread owner) &#123; this.pool = pool; this.owner = owner; // Place indices in the center of array (that is not yet allocated) base = top = INITIAL_QUEUE_CAPACITY &gt;&gt;&gt; 1; &#125; ... &#125; static final int SCANNING = 1; // false when running tasks static final int INACTIVE = 1 &lt;&lt; 31; // must be negative scanState:负数表示inactive; 奇数表示scanning。如果WorkQueue没有属于自己的owner(下标为偶数的都没有),该值为 inactive 也就是一个负数。如果有自己的owner，该值的初始值为其在WorkQueue[]数组中的下标，也肯定是个奇数。如果这个值，变成了偶数，说明该队列所属的Thread正在执行TaskstackPred: 记录前任的 idle workerconfig：index | mode。 如果下标为偶数的WorkQueue,则其mode是共享类型。如果有自己的owner 默认是 LIFO。mode是由ForkJoinPool其中一个构造函数传进来的， 1234567891011121314151617181920212223242526272829303132333435/** * Creates a &#123;@code ForkJoinPool&#125; with the given parameters. * * @param parallelism the parallelism level. For default value, * use &#123;@link java.lang.Runtime#availableProcessors&#125;. * @param factory the factory for creating new threads. For default value, * use &#123;@link #defaultForkJoinWorkerThreadFactory&#125;. * @param handler the handler for internal worker threads that * terminate due to unrecoverable errors encountered while executing * tasks. For default value, use &#123;@code null&#125;. * @param asyncMode if true, * establishes local first-in-first-out scheduling mode for forked * tasks that are never joined. This mode may be more appropriate * than default locally stack-based mode in applications in which * worker threads only process event-style asynchronous tasks. * For default value, use &#123;@code false&#125;. * @throws IllegalArgumentException if parallelism less than or * equal to zero, or greater than implementation limit * @throws NullPointerException if the factory is null * @throws SecurityException if a security manager exists and * the caller is not permitted to modify threads * because it does not hold &#123;@link * java.lang.RuntimePermission&#125;&#123;@code (\"modifyThread\")&#125; */public ForkJoinPool(int parallelism, ForkJoinWorkerThreadFactory factory, UncaughtExceptionHandler handler, boolean asyncMode) &#123; this(checkParallelism(parallelism), checkFactory(factory), handler, asyncMode ? FIFO_QUEUE : LIFO_QUEUE, \"ForkJoinPool-\" + nextPoolId() + \"-worker-\"); checkPermission();&#125; 英文不太ok，看了注释应该是，asyncMode下工作线程在处理本地任务时也使用 FIFO 顺序。这种模式下的 ForkJoinPool 更接近于是一个消息队列，而不是用来处理递归式的任务。stackoverflow有个回答举了个例子，可以明显看到asyncMode的先进先出的执行方式。我想你的ForkJoinPool不是私有的，那就设置成异步模式吧。 qlock：队列锁base：worker steal的偏移量,因为其他的线程都可以偷该队列的任务,所有base使用volatile标识。top:owner执行任务的偏移量。parker:如果 owner 挂起，则使用该变量做记录currentJoin:当前正在join等待结果的任务。currentSteal:当前执行的任务是steal过来的任务，该变量做记录。 6.3. ForkJoinTask这是个抽象类,我们声明的任务是他的子类，下面是他的状态 12345678/** The run status of this task */volatile int status; // accessed directly by pool and workersstatic final int DONE_MASK = 0xf0000000; // mask out non-completion bitsstatic final int NORMAL = 0xf0000000; // must be negativestatic final int CANCELLED = 0xc0000000; // must be &lt; NORMALstatic final int EXCEPTIONAL = 0x80000000; // must be &lt; CANCELLEDstatic final int SIGNAL = 0x00010000; // must be &gt;= 1 &lt;&lt; 16static final int SMASK = 0x0000ffff; // short bits for tags 如果status &lt; 0，表示任务已经结束((s &gt;&gt;&gt; 16) != 0)表示需要signal其他线程 6.4. ForkJoinWorkerThread这就是工作线程的封装，继承自Thread类。 12345678910111213141516171819202122public class ForkJoinWorkerThread extends Thread &#123; /* * ForkJoinWorkerThreads are managed by ForkJoinPools and perform * ForkJoinTasks. For explanation, see the internal documentation * of class ForkJoinPool. * * This class just maintains links to its pool and WorkQueue. The * pool field is set immediately upon construction, but the * workQueue field is not set until a call to registerWorker * completes. This leads to a visibility race, that is tolerated * by requiring that the workQueue field is only accessed by the * owning thread. * * Support for (non-public) subclass InnocuousForkJoinWorkerThread * requires that we break quite a lot of encapsulation (via Unsafe) * both here and in the subclass to access and set Thread fields. */ final ForkJoinPool pool; // the pool this thread works in final ForkJoinPool.WorkQueue workQueue; // work-stealing mechanics ...&#125; 从代码中我们可以清楚地看到，ForkJoinWorkThread持有ForkJoinPool和ForkJoinPool.WorkQueue的引用，以表明该线程属于哪个线程池，它的工作队列是哪个 7. 重场戏7.1. 通用ForkJoinPool的初始化ForkJoinPool类的static代码块初始化了一个全局通用的ForkJoinPool，这是老李推荐的使用方式，不用自己new new new。 1234public static ForkJoinPool commonPool() &#123; // assert common != null : \"static init error\"; return common;&#125; 123456789101112131415161718192021222324252627282930313233343536373839/** * Creates and returns the common pool, respecting user settings * specified via system properties. */private static ForkJoinPool makeCommonPool() &#123; int parallelism = -1; ForkJoinWorkerThreadFactory factory = null; UncaughtExceptionHandler handler = null; try &#123; // ignore exceptions in accessing/parsing properties String pp = System.getProperty (\"java.util.concurrent.ForkJoinPool.common.parallelism\"); String fp = System.getProperty (\"java.util.concurrent.ForkJoinPool.common.threadFactory\"); String hp = System.getProperty (\"java.util.concurrent.ForkJoinPool.common.exceptionHandler\"); if (pp != null) parallelism = Integer.parseInt(pp); if (fp != null) factory = ((ForkJoinWorkerThreadFactory)ClassLoader. getSystemClassLoader().loadClass(fp).newInstance()); if (hp != null) handler = ((UncaughtExceptionHandler)ClassLoader. getSystemClassLoader().loadClass(hp).newInstance()); &#125; catch (Exception ignore) &#123; &#125; if (factory == null) &#123; if (System.getSecurityManager() == null) factory = defaultForkJoinWorkerThreadFactory; else // use security-managed default factory = new InnocuousForkJoinWorkerThreadFactory(); &#125; if (parallelism &lt; 0 &amp;&amp; // default 1 less than #cores (parallelism = Runtime.getRuntime().availableProcessors() - 1) &lt;= 0) parallelism = 1; if (parallelism &gt; MAX_CAP) parallelism = MAX_CAP; return new ForkJoinPool(parallelism, factory, handler, LIFO_QUEUE, \"ForkJoinPool.commonPool-worker-\");&#125; 有几个参数可以通过java -D指定，如果不指定，那么使用默认参数构造，并行数默认情况是计算机处理器数-1 7.2. 任务提交我们提交的任务，不管是Runnable,Callable，ForkJoinTask，最终都会变成封装为ForkJoinTask。 由于实现了ExecutorService，自然实现了submit(task)、execute(task)方法，而他自己还又一个invoke(task)的方法，这么多个执行，什么时候用什么呢。 12345678910111213141516171819public void execute(ForkJoinTask&lt;?&gt; task) &#123; if (task == null) throw new NullPointerException(); externalPush(task);&#125;public &lt;T&gt; ForkJoinTask&lt;T&gt; submit(ForkJoinTask&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); externalPush(task); return task;&#125;public &lt;T&gt; T invoke(ForkJoinTask&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); externalPush(task); return task.join();&#125; 可以看到execute(task)和普通线程池一样无返回，submit(task)返回了一个ForkJoinTask,而invoke(task)返回直接调用join()阻塞，知道计算得出结果返回。 这几个都是调用externalPush(task);方法，和普通线程池一样，在提交任务的过程中会视情况增加工作线程，和普通线程池不一样的是还要同时增加工作队列。 注意：工作线程和工作队列的不是一对一关系 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * Tries to add the given task to a submission queue at * submitter's current queue. Only the (vastly) most common path * is directly handled in this method, while screening for need * for externalSubmit. * * @param task the task. Caller must ensure non-null. */final void externalPush(ForkJoinTask&lt;?&gt; task) &#123; WorkQueue[] ws; WorkQueue q; int m; // 取得一个随机探查数，可能为0也可能为其它数 // 利用这个数提交到任务队列数组中的随机一个队列 int r = ThreadLocalRandom.getProbe(); int rs = runState; // 他喵的这个if有够复杂 // SQMASK = 0x007e，也就是0000 0000 0111 1110，与这个数与出来的结果，只能是个偶数 // 如果（（任务队列数组非空）且（数组长度&gt;=1）且（数组长度-1与随机数与0x007e得出来的下标处有工作队列）且（随机数!=0）且（线程池在运行）且（获取锁成功）） if ((ws = workQueues) != null &amp;&amp; (m = (ws.length - 1)) &gt;= 0 &amp;&amp; (q = ws[m &amp; r &amp; SQMASK]) != null &amp;&amp; r != 0 &amp;&amp; rs &gt; 0 &amp;&amp; U.compareAndSwapInt(q, QLOCK, 0, 1)) &#123; ForkJoinTask&lt;?&gt;[] a; int am, n, s;// am=数组长度，n=top-base，s=top if ((a = q.array) != null &amp;&amp; // 感觉这个不为true的情况只能是==，不会&lt; (am = a.length - 1) &gt; (n = (s = q.top) - q.base)) &#123; // ABASE是利用Unsafe得到的队列base属性内存地址，因为用Unsafe加入队列，所以要计算出top的内存地址 int j = ((am &amp; s) &lt;&lt; ASHIFT) + ABASE; // 以下三个原子操作首先是将task放入队列, U.putOrderedObject(a, j, task); // 然后将“q”这个submission queue的top标记+1,记得queue的owner线程是默认从top拿的任务 U.putOrderedInt(q, QTOP, s + 1); // 解锁 U.putIntVolatile(q, QLOCK, 0); // 如果条件成立，说明这时处于active的工作线程可能还不够，调用signalWork方法 if (n &lt;= 1) signalWork(ws, q); return; &#125; // 可能上面没有解锁，保证能解锁。 // 这不会解锁了其他小偷吗 = = U.compareAndSwapInt(q, QLOCK, 1, 0); &#125; externalSubmit(task);&#125; 我注意到了这个方法ThreadLocalRandom.getProbe()，这是个一个包级别的方法，只有concurrent包才能用他。这个方法返回一个随机数，而且是固定的，但是如果没执行ThreadLocalRandom.localInit();，调用结果会是0。 把他的源码复制出来后执行得出来的结论。 也就是说，主线程执行externalPush的时候，由于ThreadLocalRandom.getProbe();返回一直0，是直接进入externalSubmit(task) 那坨if块主要做的是按线程给的随机数随机放入workqueue数组中队列，随机方式是m &amp; r &amp; SQMASK，(数组大小-1)与随机数与偶数掩码 入队的方式是放到随机队列的top位置，利用Unsafe来操作，真是🐂🍺，而队列owner拿的时候也是从top拿。 externalSubmit(task)的代码很长。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778private void externalSubmit(ForkJoinTask&lt;?&gt; task) &#123; int r; // initialize caller's probe if ((r = ThreadLocalRandom.getProbe()) == 0) &#123; ThreadLocalRandom.localInit(); r = ThreadLocalRandom.getProbe(); &#125; for (;;) &#123; WorkQueue[] ws; WorkQueue q; int rs, m, k; boolean move = false; if ((rs = runState) &lt; 0) &#123; tryTerminate(false, false); // help terminate throw new RejectedExecutionException(); &#125; // 如果条件成立，就说明当前ForkJoinPool类中，还没有任何队列，所以要进行队列初始化 else if ((rs &amp; STARTED) == 0 || // initialize ((ws = workQueues) == null || (m = ws.length - 1) &lt; 0)) &#123; int ns = 0; // 阻塞等待 rs = lockRunState(); try &#123; if ((rs &amp; STARTED) == 0) &#123; U.compareAndSwapObject(this, STEALCOUNTER, null, new AtomicLong()); // create workQueues array with size a power of two int p = config &amp; SMASK; // ensure at least 2 slots int n = (p &gt; 1) ? p - 1 : 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; n = (n + 1) &lt;&lt; 1; workQueues = new WorkQueue[n]; ns = STARTED; &#125; &#125; finally &#123; unlockRunState(rs, (rs &amp; ~RSLOCK) | ns); &#125; &#125; else if ((q = ws[k = r &amp; m &amp; SQMASK]) != null) &#123; if (q.qlock == 0 &amp;&amp; U.compareAndSwapInt(q, QLOCK, 0, 1)) &#123; ForkJoinTask&lt;?&gt;[] a = q.array; int s = q.top; boolean submitted = false; // initial submission or resizing try &#123; // locked version of push if ((a != null &amp;&amp; a.length &gt; s + 1 - q.base) || (a = q.growArray()) != null) &#123; int j = (((a.length - 1) &amp; s) &lt;&lt; ASHIFT) + ABASE; U.putOrderedObject(a, j, task); U.putOrderedInt(q, QTOP, s + 1); submitted = true; &#125; &#125; finally &#123; U.compareAndSwapInt(q, QLOCK, 1, 0); &#125; // 方法的唯一出口 if (submitted) &#123; signalWork(ws, q); return; &#125; &#125; move = true; // move on failure &#125; // 即上面的队列==null且runstate没有被锁住 else if (((rs = runState) &amp; RSLOCK) == 0) &#123; // create new queue q = new WorkQueue(this, null); q.hint = r; q.config = k | SHARED_QUEUE; q.scanState = INACTIVE; rs = lockRunState(); // publish index if (rs &gt; 0 &amp;&amp; (ws = workQueues) != null &amp;&amp; k &lt; ws.length &amp;&amp; ws[k] == null) ws[k] = q; // else terminated unlockRunState(rs, rs &amp; ~RSLOCK); &#125; else move = true; // move if busy if (move) // 重新获取一个随机数 r = ThreadLocalRandom.advanceProbe(r); &#125;&#125; 总结： 如果hash之后的队列已经存在 lock住队列,将数据塞到top位置。如果该队列任务很少(n &lt;= 1)也会调用signalWork 如果第一次提交(或者是hash之后的队列还未初始化),调用externalSubmit 第一遍循环: (runState不是开始状态): 1.lock; 2.创建数组WorkQueue[n]，这里的n是根据parallelism初始化的; 3. runState设置为开始状态。 第二遍循环:(根据ThreadLocalRandom.getProbe()hash后的数组中相应位置的WorkQueue未初始化): 初始化WorkQueue,通过这种方式创立的WorkQueue均是SUBMISSIONS_QUEUE(owner为null),scanState为INACTIVE 第三遍循环: 找到刚刚创建的WorkQueue,lock住队列,将数据塞到arraytop位置。如添加成功，就用调用接下来要摊开讲的重要的方法signalWork。 7.2.1. parallelism初始化关于parallelism，我们浓缩一下代码 123456789101112131415161718......// SMASK是一个常量，即 00000000 00000000 11111111 11111111static final int SMASK = 0xffff;......// 这是config的来源// mode是ForkJoinPool构造函数中设定的asyncMode，如果为LIFO，则mode为0，否则为1&lt;&lt;16(FIFO_QUEUE),也就是说，config中低16位代表并行度// parallelism 为技术人员设置的（或者程序自行设定的）并发等级this.config = (parallelism &amp; SMASK) | mode;......// ensure at least 2 slots// 取config的低16位int p = config &amp; SMASK; // n这个变量就是要计算的WorkQueue数组的大小int n = (p &gt; 1) ? p - 1 : 1;......n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4;n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; n = (n + 1) &lt;&lt; 1;...... 这么多位操作，在java.util.HashMap#tableSizeFor(本博客有)里也有出现过，tableSizeFor是为了计算出最接近且大于给定的构造容量的2幂数，而这里的位操作，比tableSizeFor多了一个n = (n + 1) &lt;&lt; 1;的计算，也就是计算出最接近且大于给定的构造容量的2幂数——然后在*2，ForkJoinPool中的这些WorkQueue和工作线程ForkJoinWorkerThread并不是一对一的关系，而是随时都有多余ForkJoinWorkerThread数量的WorkQueue元素。而这个ForkJoinPool中的WorkQueue数组中，索引位为非奇数的工作队列用于存储从外部提交到ForkJoinPool中的任务，也就是所谓的submissions queue；索引位为偶数的工作队列用于存储归并计算过程中等待处理的子任务，也就是task queue。 我们看signalWork(ws, q)做了什么，这个会触发构造新队列和新线程 12345678910111213141516171819202122232425262728293031323334/** * Tries to create or activate a worker if too few are active. * * @param ws the worker array to use to find signallees * @param q a WorkQueue --if non-null, don't retry if now empty */final void signalWork(WorkQueue[] ws, WorkQueue q) &#123; // c是ctl，sp是ctl低32位 long c; int sp, i; WorkQueue v; Thread p; while ((c = ctl) &lt; 0L) &#123; // too few active if ((sp = (int)c) == 0) &#123; // no idle workers if ((c &amp; ADD_WORKER) != 0L) // too few workers tryAddWorker(c); break; &#125; if (ws == null) // unstarted/terminated break; if (ws.length &lt;= (i = sp &amp; SMASK)) // terminated break; if ((v = ws[i]) == null) // terminating break; int vs = (sp + SS_SEQ) &amp; ~INACTIVE; // next scanState int d = sp - v.scanState; // screen CAS long nc = (UC_MASK &amp; (c + AC_UNIT)) | (SP_MASK &amp; v.stackPred); if (d == 0 &amp;&amp; U.compareAndSwapLong(this, CTL, c, nc)) &#123; v.scanState = vs; // activate v if ((p = v.parker) != null) U.unpark(p); break; &#125; if (q != null &amp;&amp; q.base == q.top) // no more work break; &#125;&#125; 这个方法主要就是一个while循环循环，当ctl小于0的时候才要进行创建和激活新线程。 如果sp等于0，表示没有空闲线程。此时(c &amp; ADD_WORKER) != 0L即TC符号位是1，TC是个负数，表示worker还可以增加。 12// ADD_WORKER是一个第48位为1，其余为0的64数，可以区分TC的符号位private static final long ADD_WORKER = 0x0001L &lt;&lt; (TC_SHIFT + 15); // sign 下面看tryAddWorker(c), 1234567891011121314151617181920private void tryAddWorker(long c) &#123; boolean add = false; do &#123; // new ctl long nc = ((AC_MASK &amp; (c + AC_UNIT)) | (TC_MASK &amp; (c + TC_UNIT))); if (ctl == c) &#123; int rs, stop; // check if terminating if ((stop = (rs = lockRunState()) &amp; STOP) == 0) add = U.compareAndSwapLong(this, CTL, c, nc); unlockRunState(rs, rs &amp; ~RSLOCK); if (stop != 0) break; if (add) &#123; createWorker(); break; &#125; &#125; &#125; while (((c = ctl) &amp; ADD_WORKER) != 0L &amp;&amp; (int)c == 0);&#125; 我们首先需要使用ctl来记录我们增加的线程, ctl编号-1的16位和编号-2的16位均需要加1,表示active的worker(AC)加一，总的worker(TC)加一。成功后我们将调用createWorker。 12345678910111213141516private boolean createWorker() &#123; ForkJoinWorkerThreadFactory fac = factory; Throwable ex = null; ForkJoinWorkerThread wt = null; try &#123; if (fac != null &amp;&amp; (wt = fac.newThread(this)) != null) &#123; wt.start(); return true; &#125; &#125; catch (Throwable rex) &#123; ex = rex; &#125; // 跑到这里来要注销线程 deregisterWorker(wt, ex); return false;&#125; 看fac.newThread(this)怎么实例化一个线程 123456static final class DefaultForkJoinWorkerThreadFactory implements ForkJoinWorkerThreadFactory &#123; public final ForkJoinWorkerThread newThread(ForkJoinPool pool) &#123; return new ForkJoinWorkerThread(pool); &#125;&#125; 123456protected ForkJoinWorkerThread(ForkJoinPool pool) &#123; // Use a placeholder until a useful name can be set in registerWorker super(\"aForkJoinWorkerThread\"); this.pool = pool; this.workQueue = pool.registerWorker(this);&#125; 看pool.registerWorker(this); 12345678910111213141516171819202122232425262728293031323334353637final WorkQueue registerWorker(ForkJoinWorkerThread wt) &#123; UncaughtExceptionHandler handler; wt.setDaemon(true); // configure thread if ((handler = ueh) != null) wt.setUncaughtExceptionHandler(handler); WorkQueue w = new WorkQueue(this, wt); int i = 0; // assign a pool index int mode = config &amp; MODE_MASK; int rs = lockRunState(); try &#123; WorkQueue[] ws; int n; // skip if no array if ((ws = workQueues) != null &amp;&amp; (n = ws.length) &gt; 0) &#123; int s = indexSeed += SEED_INCREMENT; // unlikely to collide int m = n - 1; i = ((s &lt;&lt; 1) | 1) &amp; m; // odd-numbered indices if (ws[i] != null) &#123; // collision int probes = 0; // step by approx half n int step = (n &lt;= 4) ? 2 : ((n &gt;&gt;&gt; 1) &amp; EVENMASK) + 2; while (ws[i = (i + step) &amp; m] != null) &#123; if (++probes &gt;= n) &#123; workQueues = ws = Arrays.copyOf(ws, n &lt;&lt;= 1); m = n - 1; probes = 0; &#125; &#125; &#125; w.hint = s; // use as random seed w.config = i | mode; w.scanState = i; // publication fence ws[i] = w; &#125; &#125; finally &#123; unlockRunState(rs, rs &amp; ~RSLOCK); &#125; wt.setName(workerNamePrefix.concat(Integer.toString(i &gt;&gt;&gt; 1))); return w;&#125; 我们使用ForkJoinWorkerThreadFactory来产生一个ForkJoinWorkerThread类型的线程，该线程将会把自己注册到Pool上,怎么注册的呢？实现在方法registerWorker,前文我们已经提及,拥有线程的WorkQueue只能出现在数组的奇数下标处。所以线程首先,创建一个新的WorkQueue，其次在数组WorkQueue[]寻找奇数下标尚未初始化的位置,如果循环的次数大于数组长度,还可能需要对数组进行扩容，然后，设置这个WorkQueue的 config 为 index | mode (下标和模式),scanState为 index (下标&gt;0)。最后启动这个线程。线程的处理我们接下来的章节介绍。 回到signalWork方法,如果(sp = (int)c) == 0不成立，表示又空闲线程，那么不用新增worker，直接唤醒工作队列的owner 我们上文说过SP的高16位SS,标记inactive和版本控制,我们将SS设置为激活状态并且版本加一。ID的16位我们之前也说过,放置了挂起线程栈的index所以我们可以根据这个index拿到WorkQueue——意味着就是这个WorkQueue的Owner线程被挂起了。 worker什么时候挂起？ 我们将要把栈顶挂起线程唤醒,意味着我们要讲下一个挂起的线程的信息记录到ctl上。前文也说在上一个挂起的线程的index信息在这个挂起的线程的stackPred。利用cas进行更新。 123456789int vs = (sp + SS_SEQ) &amp; ~INACTIVE; // next scanStateint d = sp - v.scanState; // screen CASlong nc = (UC_MASK &amp; (c + AC_UNIT)) | (SP_MASK &amp; v.stackPred);if (d == 0 &amp;&amp; U.compareAndSwapLong(this, CTL, c, nc)) &#123; v.scanState = vs; // activate v if ((p = v.parker) != null) U.unpark(p); break;&#125; 7.3. 工作线程的运行Thread添加完成之后，执行wt.start();，这个方法会使得run()方法开始运行。 看ForkJoinWorkerThread的run()方法。 123456789101112131415161718192021public void run() &#123; if (workQueue.array == null) &#123; // only run once Throwable exception = null; try &#123; onStart(); // 看节里 pool.runWorker(workQueue); &#125; catch (Throwable ex) &#123; exception = ex; &#125; finally &#123; try &#123; onTermination(exception); &#125; catch (Throwable ex) &#123; if (exception == null) exception = ex; &#125; finally &#123; pool.deregisterWorker(this, exception); &#125; &#125; &#125;&#125; 123456789101112131415/** * Top-level runloop for workers, called by ForkJoinWorkerThread.run. */final void runWorker(WorkQueue w) &#123; w.growArray(); // allocate queue int seed = w.hint; // initially holds randomization hint int r = (seed == 0) ? 1 : seed; // avoid 0 for xorShift for (ForkJoinTask&lt;?&gt; t;;) &#123; if ((t = scan(w, r)) != null) w.runTask(t); else if (!awaitWork(w, r)) break; r ^= r &lt;&lt; 13; r ^= r &gt;&gt;&gt; 17; r ^= r &lt;&lt; 5; // xorshift 随机数算法 &#125;&#125; 工作线程先尝试scan窃取任务并执行，否则执行awaitWork()，如果awaitWork()返回false，break结束死循环。 7.3.1. scan又是一个长长的方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556private ForkJoinTask&lt;?&gt; scan(WorkQueue w, int r) &#123; WorkQueue[] ws; int m; if ((ws = workQueues) != null &amp;&amp; (m = ws.length - 1) &gt; 0 &amp;&amp; w != null) &#123; int ss = w.scanState; // initially non-negative for (int origin = r &amp; m, k = origin, oldSum = 0, checkSum = 0;;) &#123; WorkQueue q; ForkJoinTask&lt;?&gt;[] a; ForkJoinTask&lt;?&gt; t; int b, n; long c; if ((q = ws[k]) != null) &#123; if ((n = (b = q.base) - q.top) &lt; 0 &amp;&amp; (a = q.array) != null) &#123; // non-empty long i = (((a.length - 1) &amp; b) &lt;&lt; ASHIFT) + ABASE; if ((t = ((ForkJoinTask&lt;?&gt;) U.getObjectVolatile(a, i))) != null &amp;&amp; q.base == b) &#123; if (ss &gt;= 0) &#123; if (U.compareAndSwapObject(a, i, t, null)) &#123; q.base = b + 1; if (n &lt; -1) // signal others signalWork(ws, q); return t; &#125; &#125; else if (oldSum == 0 &amp;&amp; // try to activate w.scanState &lt; 0) tryRelease(c = ctl, ws[m &amp; (int)c], AC_UNIT); &#125; if (ss &lt; 0) // refresh ss = w.scanState; r ^= r &lt;&lt; 1; r ^= r &gt;&gt;&gt; 3; r ^= r &lt;&lt; 10; origin = k = r &amp; m; // move and rescan oldSum = checkSum = 0; continue; &#125; checkSum += b; &#125; if ((k = (k + 1) &amp; m) == origin) &#123; // continue until stable if ((ss &gt;= 0 || (ss == (ss = w.scanState))) &amp;&amp; oldSum == (oldSum = checkSum)) &#123; if (ss &lt; 0 || w.qlock &lt; 0) // already inactive break; int ns = ss | INACTIVE; // try to inactivate long nc = ((SP_MASK &amp; ns) | (UC_MASK &amp; ((c = ctl) - AC_UNIT))); w.stackPred = (int)c; // hold prev stack top U.putInt(w, QSCANSTATE, ns); if (U.compareAndSwapLong(this, CTL, c, nc)) ss = ns; else w.scanState = ss; // back out &#125; checkSum = 0; &#125; &#125; &#125; return null;&#125; 因为我们的WorkQueue是有owner线程的队列，我们可以知道以下信息: config = index | mode scanState = index &gt; 0我们首先通过随机数r来寻找窃取队列。 如果我们准备偷取的队列刚好有任务(也有可能是owner自己的那个队列)； 从队列的队尾即base位置取到任务返回 base + 1 如果我们遍历了一圈(((k = (k + 1) &amp; m) == origin))都没有偷到,我们就认为当前的active线程过剩了,我们准备将当前的线程(即owner)挂起,我们首先 index | INACTIVE 形成 ctl的后32位;并行将AC减一。其次，将原来的挂起的栈顶的index记录到stackPred中。 继续遍历如果仍然一无所获,将跳出循环；如果偷到了一个任务,我们将使用tryRelease激活。 7.3.2. runTask获取到任务之后，执行 12345678910111213141516final void runTask(ForkJoinTask&lt;?&gt; task) &#123; if (task != null) &#123; scanState &amp;= ~SCANNING; // mark as busy // 执行窃取来的任务 (currentSteal = task).doExec(); U.putOrderedObject(this, QCURRENTSTEAL, null); // release for GC // 这里执行自己的线程的任务 execLocalTasks(); ForkJoinWorkerThread thread = owner; if (++nsteals &lt; 0) // collect on overflow transferStealCount(pool); scanState |= SCANNING; if (thread != null) thread.afterTopLevelExec(); &#125;&#125; 首先scanState &amp;= ~SCANNING;标识该线程处于繁忙状态。 执行偷取的Task。 调用execLocalTasks对线程所属的WorkQueue内的任务进行执行,按config设置的mode进行FIFO或者LIFO执行。1234567891011121314151617181920final void execLocalTasks() &#123; int b = base, m, s; ForkJoinTask&lt;?&gt;[] a = array; if (b - (s = top - 1) &lt;= 0 &amp;&amp; a != null &amp;&amp; (m = a.length - 1) &gt;= 0) &#123; if ((config &amp; FIFO_QUEUE) == 0) &#123; for (ForkJoinTask&lt;?&gt; t;;) &#123; if ((t = (ForkJoinTask&lt;?&gt;)U.getAndSetObject (a, ((m &amp; s) &lt;&lt; ASHIFT) + ABASE, null)) == null) break; U.putOrderedInt(this, QTOP, s); t.doExec(); if (base - (s = top - 1) &gt; 0) break; &#125; &#125; else pollAndExecAll(); &#125;&#125; 7.3.3. awaitWorkscan不到任务的时候，就执行挂起，如果挂起返回false，表示线程池终止。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152private boolean awaitWork(WorkQueue w, int r) &#123; if (w == null || w.qlock &lt; 0) // w is terminating return false; for (int pred = w.stackPred, spins = SPINS, ss;;) &#123; if ((ss = w.scanState) &gt;= 0) break; else if (spins &gt; 0) &#123; r ^= r &lt;&lt; 6; r ^= r &gt;&gt;&gt; 21; r ^= r &lt;&lt; 7; if (r &gt;= 0 &amp;&amp; --spins == 0) &#123; // randomize spins WorkQueue v; WorkQueue[] ws; int s, j; AtomicLong sc; if (pred != 0 &amp;&amp; (ws = workQueues) != null &amp;&amp; (j = pred &amp; SMASK) &lt; ws.length &amp;&amp; (v = ws[j]) != null &amp;&amp; // see if pred parking (v.parker == null || v.scanState &gt;= 0)) spins = SPINS; // continue spinning &#125; &#125; else if (w.qlock &lt; 0) // recheck after spins return false; else if (!Thread.interrupted()) &#123; long c, prevctl, parkTime, deadline; int ac = (int)((c = ctl) &gt;&gt; AC_SHIFT) + (config &amp; SMASK); if ((ac &lt;= 0 &amp;&amp; tryTerminate(false, false)) || (runState &amp; STOP) != 0) // pool terminating return false; if (ac &lt;= 0 &amp;&amp; ss == (int)c) &#123; // is last waiter prevctl = (UC_MASK &amp; (c + AC_UNIT)) | (SP_MASK &amp; pred); int t = (short)(c &gt;&gt;&gt; TC_SHIFT); // shrink excess spares if (t &gt; 2 &amp;&amp; U.compareAndSwapLong(this, CTL, c, prevctl)) return false; // else use timed wait parkTime = IDLE_TIMEOUT * ((t &gt;= 0) ? 1 : 1 - t); deadline = System.nanoTime() + parkTime - TIMEOUT_SLOP; &#125; else prevctl = parkTime = deadline = 0L; Thread wt = Thread.currentThread(); U.putObject(wt, PARKBLOCKER, this); // emulate LockSupport w.parker = wt; if (w.scanState &lt; 0 &amp;&amp; ctl == c) // recheck before park U.park(false, parkTime); U.putOrderedObject(w, QPARKER, null); U.putObject(wt, PARKBLOCKER, null); if (w.scanState &gt;= 0) break; if (parkTime != 0L &amp;&amp; ctl == c &amp;&amp; deadline - System.nanoTime() &lt;= 0L &amp;&amp; U.compareAndSwapLong(this, CTL, c, prevctl)) return false; // shrink pool &#125; &#125; return true;&#125; 如果ac还没到达阈值,但是TC&gt;2说明现在仍然运行中的线程和挂起的线程加一起处于过剩状态,我们将放弃该线程的挂起,直接让它执行结束，不再循环执行任务。 否则，我们计算一个挂起的时间，等到了时间之后(或者被外部唤醒),线程醒了之后,如果发现自己状态是active状态(w.scanState &gt;= 0),则线程继续回去scan任务，如果挂起时间结束，自己还是inactive状态,。线程也会执行结束，不再循环执行任务。 7.4. 任务执行任务的执行是调用了task.doExec()方法，可以在runTask(task)方法看到 12345678910111213final int doExec() &#123; int s; boolean completed; if ((s = status) &gt;= 0) &#123; try &#123; completed = exec(); &#125; catch (Throwable rex) &#123; return setExceptionalCompletion(rex); &#125; if (completed) s = setCompletion(NORMAL); &#125; return s;&#125; 以RecursiveTask为例， 1234protected final boolean exec() &#123; result = compute(); return true;&#125; 最终调用了我们重写的compute()方法。 7.4.1. forkfork()像叉子把新任务提交， 12345678public final ForkJoinTask&lt;V&gt; fork() &#123; Thread t; if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) ((ForkJoinWorkerThread)t).workQueue.push(this); else ForkJoinPool.common.externalPush(this); return this;&#125; 如果当前线程是工作线程,直接push到自己所拥有的队列的top位置。 如果是非工作线程,就是一个提交到通用pool的过程。 7.4.2. joinjoin是等待任务完成 123456public final V join() &#123; int s; if ((s = doJoin() &amp; DONE_MASK) != NORMAL) reportException(s); return getRawResult();&#125; 如果得到的结果异常，则抛出异常； 如果得到的正常，则获取返回值。 看doJoin()， 123456789private int doJoin() &#123; int s; Thread t; ForkJoinWorkerThread wt; ForkJoinPool.WorkQueue w; return (s = status) &lt; 0 ? s : ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) (w = (wt = (ForkJoinWorkerThread)t).workQueue). tryUnpush(this) &amp;&amp; (s = doExec()) &lt; 0 ? s : wt.pool.awaitJoin(w, this, 0L) : externalAwaitDone();&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041/** * Helps and/or blocks until the given task is done or timeout. * * @param w caller * @param task the task * @param deadline for timed waits, if nonzero * @return task status on exit */final int awaitJoin(WorkQueue w, ForkJoinTask&lt;?&gt; task, long deadline) &#123; int s = 0; if (task != null &amp;&amp; w != null) &#123; ForkJoinTask&lt;?&gt; prevJoin = w.currentJoin; U.putOrderedObject(w, QCURRENTJOIN, task); // 这里好像是jdk8什么不得了的东西，晚点再看 CountedCompleter&lt;?&gt; cc = (task instanceof CountedCompleter) ? (CountedCompleter&lt;?&gt;)task : null; for (;;) &#123; if ((s = task.status) &lt; 0) break; if (cc != null) helpComplete(w, cc, 0); else if (w.base == w.top || w.tryRemoveAndExec(task)) helpStealer(w, task); if ((s = task.status) &lt; 0) break; long ms, ns; if (deadline == 0L) ms = 0L; else if ((ns = deadline - System.nanoTime()) &lt;= 0L) break; else if ((ms = TimeUnit.NANOSECONDS.toMillis(ns)) &lt;= 0L) ms = 1L; if (tryCompensate(w)) &#123; task.internalWait(ms); U.getAndAddLong(this, CTL, AC_UNIT); &#125; &#125; U.putOrderedObject(w, QCURRENTJOIN, prevJoin); &#125; return s;&#125; 如果是status&lt;0,表示完成，直接返回 如果是工作线程，尝试把task从top位置弹出，成功则执行task 如果该任务不在top位置,则调用awaitJoin方法： 设置currentJoin表明自己正在等待该任务； 如果发现 w.base == w.top(没任务) 或者 tryRemoveAndExec返回true说明自己所属的队列为空，也说明本线程的任务已经被别的线程偷走，该线程也不会闲着，将会helpStealer帮助帮助自己执行任务的线程执行任务(互惠互利,你来我往) 如果tryCompensate为 true,则阻塞本线程，等待任务执行结束的唤醒 如果不是工作线程在join，则阻塞直到任务执行完毕。 7.4.2.1. tryRemoveAndExec1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * If present, removes from queue and executes the given task, * or any other cancelled task. Used only by awaitJoin. * * @return true if queue empty and task not known to be done */final boolean tryRemoveAndExec(ForkJoinTask&lt;?&gt; task) &#123; ForkJoinTask&lt;?&gt;[] a; int m, s, b, n; if ((a = array) != null &amp;&amp; (m = a.length - 1) &gt;= 0 &amp;&amp; task != null) &#123; while ((n = (s = top) - (b = base)) &gt; 0) &#123; for (ForkJoinTask&lt;?&gt; t;;) &#123; // traverse from s to b long j = ((--s &amp; m) &lt;&lt; ASHIFT) + ABASE; if ((t = (ForkJoinTask&lt;?&gt;)U.getObject(a, j)) == null) return s + 1 == top; // shorter than expected else if (t == task) &#123; boolean removed = false; if (s + 1 == top) &#123; // pop if (U.compareAndSwapObject(a, j, task, null)) &#123; U.putOrderedInt(this, QTOP, s); removed = true; &#125; &#125; else if (base == b) // replace with proxy removed = U.compareAndSwapObject( a, j, task, new EmptyTask()); if (removed) task.doExec(); break; &#125; else if (t.status &lt; 0 &amp;&amp; s + 1 == top) &#123; if (U.compareAndSwapObject(a, j, t, null)) U.putOrderedInt(this, QTOP, s); break; // was cancelled &#125; if (--n == 0) return false; &#125; if (task.status &lt; 0) return false; &#125; &#125; return true;&#125; 如果刚好在top位置，pop出来执行。 如果在队列中间,则使用EmptyTask来占位,将任务取出来执行。 如果执行的任务还没结束。则返回false，外部不进行helpStealer。 7.4.2.2. helpStealer 遍历WorkQueue[]的奇数下标，WorkQueue的currentSteal如果是自己在找的任务，说明这个队列A是小偷 如果A有任务，则从队尾(base)取出执行 如果A没有任务，则根据A的owner线程正在join的任务,在拓扑找到相关的队列B去偷取任务执行。（代码好鸡儿复杂） 123456do &#123; U.putOrderedObject(w, QCURRENTSTEAL, t); t.doExec(); // clear local tasks too&#125; while (task.status &gt;= 0 &amp;&amp; // 小于0表示任务结束 w.top != top &amp;&amp; // top位置相同表示没fork新的子任务到自己queue上 (t = w.pop()) != null); // top位置不同，把子任务pop出来。 帮忙执行任务完成后，如果发现自己的队列有任务了(w.base != w.top)，在不再帮助执行任务了。 否则在等待自己的join的那个任务结束之前，可以不断的偷取任务执行。 7.4.2.3. tryCompensate如果自己等待的任务被偷走执行还没结束,自己的队列还有任务，我们需要做一些补偿 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * Tries to decrement active count (sometimes implicitly) and * possibly release or create a compensating worker in preparation * for blocking. Returns false (retryable by caller), on * contention, detected staleness, instability, or termination. * * @param w caller */private boolean tryCompensate(WorkQueue w) &#123; boolean canBlock; WorkQueue[] ws; long c; int m, pc, sp; if (w == null || w.qlock &lt; 0 || // caller terminating (ws = workQueues) == null || (m = ws.length - 1) &lt;= 0 || (pc = config &amp; SMASK) == 0) // parallelism disabled canBlock = false; else if ((sp = (int)(c = ctl)) != 0) // release idle worker canBlock = tryRelease(c, ws[sp &amp; m], 0L); else &#123; int ac = (int)(c &gt;&gt; AC_SHIFT) + pc; int tc = (short)(c &gt;&gt; TC_SHIFT) + pc; int nbusy = 0; // validate saturation for (int i = 0; i &lt;= m; ++i) &#123; // two passes of odd indices WorkQueue v; if ((v = ws[((i &lt;&lt; 1) | 1) &amp; m]) != null) &#123; if ((v.scanState &amp; SCANNING) != 0) break; ++nbusy; &#125; &#125; if (nbusy != (tc &lt;&lt; 1) || ctl != c) canBlock = false; // unstable or stale else if (tc &gt;= pc &amp;&amp; ac &gt; 1 &amp;&amp; w.isEmpty()) &#123; long nc = ((AC_MASK &amp; (c - AC_UNIT)) | (~AC_MASK &amp; c)); // uncompensated canBlock = U.compareAndSwapLong(this, CTL, c, nc); &#125; else if (tc &gt;= MAX_CAP || (this == common &amp;&amp; tc &gt;= pc + commonMaxSpares)) throw new RejectedExecutionException( \"Thread limit exceeded replacing blocked worker\"); else &#123; // similar to tryAddWorker boolean add = false; int rs; // CAS within lock long nc = ((AC_MASK &amp; c) | (TC_MASK &amp; (c + TC_UNIT))); if (((rs = lockRunState()) &amp; STOP) == 0) add = U.compareAndSwapLong(this, CTL, c, nc); unlockRunState(rs, rs &amp; ~RSLOCK); canBlock = add &amp;&amp; createWorker(); // throws on exception &#125; &#125; return canBlock;&#125; 如果 ((sp = (int)(c = ctl)) != 0) 说明还有 idle worker则可以选择唤醒线程替代自己,挂起自己等待任务来唤醒自己。 如果没有idle worker 则额外创建一个新的工作线程替代自己,挂起自己等待任务来唤醒自己。 8. 后记很多没细看，了解一下思路就没了 = =","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}],"author":"土川"},{"title":"[Java基础]ScheduledThreadPoolExecutor","slug":"Java基础-ScheduledThreadPoolExecutor","date":"2018-09-02T02:56:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"967765342.html","link":"","permalink":"https://htchz.cc/967765342.html","excerpt":"提到定时任务，就会想到Quartz，事实上Quartz起到了调度的作用，真正的执行者还是JDK的ScheduledThreadPoolExecutor","text":"提到定时任务，就会想到Quartz，事实上Quartz起到了调度的作用，真正的执行者还是JDK的ScheduledThreadPoolExecutor Java提供的Time类可以周期性地或者延期执行任务，但是有时我们需要并行执行同样的任务，这个时候如果创建多个Time对象会给系统带来负担，解决办法是将定时任务放到线程池中执行。 Timer的任务挂了会让其他不想干的任务挂掉的。 ScheduledThreadPoolExecutor类实现了ScheduledExecutorService接口，继承了ThreadPoolExecutor，主要是利用延迟队列的特性来实现延迟执行。 1. ScheduledExecutorService12345678910111213141516171819public interface ScheduledExecutorService extends ExecutorService &#123; public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit); public &lt;V&gt; ScheduledFuture&lt;V&gt; schedule(Callable&lt;V&gt; callable, long delay, TimeUnit unit); public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit); public ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit);&#125; schedule方法需要提供一个延迟的时间，可以传入Runnable或者Callable，不同于ThreadPoolExecutor的execute(Runnable command)返回void，schedule(Runnable command,...)返回的是一个Future：ScheduledFuture。 scheduleAtFixedRate：周期性执行任务。 scheduleWithFixedDelay：以给定的延迟时间执行任务，一个任务执行完，等待delay时间再执行下一个 2. ScheduledThreadPoolExecutor事实上，ScheduledThreadPoolExecutor的构造方法都是如下调用了super(…) 1234567891011121314151617181920212223public ScheduledThreadPoolExecutor(int corePoolSize) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue());&#125;public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory);&#125;public ScheduledThreadPoolExecutor(int corePoolSize, RejectedExecutionHandler handler) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), handler);&#125;public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory, handler);&#125; 可以看到不能定制BlockingQueue，只能用内置的DelayedWorkQueue 3. ScheduledFutureTask上一篇说到submit(Runnabel task)会将任务封装，这里同样是是封装，而且不论是Callable还是Runnable。 12345678910111213141516171819private class ScheduledFutureTask&lt;V&gt; extends FutureTask&lt;V&gt; implements RunnableScheduledFuture&lt;V&gt; &#123; // 任务序号 private final long sequenceNumber; // 任务执行的时间 private long time; // 0：不重复 // 正数，固定周期，即scheduleAtFixedRate // 负数，固定延迟，即scheduleWithFixedDelay private final long period; /** The actual task to be re-enqueued by reExecutePeriodic */ RunnableScheduledFuture&lt;V&gt; outerTask = this; // 这里看出任务队列的数据结构依旧是个堆，这个表示在任务队列的数组下标 int heapIndex; 构造方法 1234567891011121314151617181920212223242526272829/** * Creates a one-shot action with given nanoTime-based trigger time. */ScheduledFutureTask(Runnable r, V result, long ns) &#123; super(r, result); this.time = ns; this.period = 0; this.sequenceNumber = sequencer.getAndIncrement();&#125;/** * Creates a periodic action with given nano time and period. */ScheduledFutureTask(Runnable r, V result, long ns, long period) &#123; super(r, result); this.time = ns; this.period = period; this.sequenceNumber = sequencer.getAndIncrement();&#125;/** * Creates a one-shot action with given nanoTime-based trigger time. */ScheduledFutureTask(Callable&lt;V&gt; callable, long ns) &#123; super(callable); this.time = ns; this.period = 0; this.sequenceNumber = sequencer.getAndIncrement();&#125; 由于任务队列是个堆，入队的时候需要比较大小，看compareTo方法 12345678910111213141516171819public int compareTo(Delayed other) &#123; if (other == this) // compare zero if same object return 0; if (other instanceof ScheduledFutureTask) &#123; ScheduledFutureTask&lt;?&gt; x = (ScheduledFutureTask&lt;?&gt;)other; long diff = time - x.time; if (diff &lt; 0) return -1; else if (diff &gt; 0) return 1; // 如果执行时间相同，则按入队顺序 else if (sequenceNumber &lt; x.sequenceNumber) return -1; else return 1; &#125; long diff = getDelay(NANOSECONDS) - other.getDelay(NANOSECONDS); return (diff &lt; 0) ? -1 : (diff &gt; 0) ? 1 : 0; &#125; 4. 任务队列任务队列使用的是WorkDelayQueue，和PriorityBlockingQueue的实现差不多，不过元素的大小比较只能用上一节内置的compareTo(Delayed other)方法。 除此之外，每次添加元素完成之后会在ScheduledFutureTask设置heapIndex 1234private void setIndex(RunnableScheduledFuture&lt;?&gt; f, int idx) &#123; if (f instanceof ScheduledFutureTask) ((ScheduledFutureTask)f).heapIndex = idx;&#125; 由于任务按已经按执行时间排好序，那么队首任务肯定是最迫切需要执行的任务。 ScheduledThreadPoolExecutor的延迟执行实际上是通过DelayWorkQueue的阻塞获取来实现的，这部分代码和前面DelayQueue的实现一毛一样，不作说明 123456789101112131415161718192021222324252627282930313233public RunnableScheduledFuture&lt;?&gt; take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; for (;;) &#123; RunnableScheduledFuture&lt;?&gt; first = queue[0]; if (first == null) available.await(); else &#123; long delay = first.getDelay(NANOSECONDS); if (delay &lt;= 0) return finishPoll(first); first = null; // don't retain ref while waiting if (leader != null) available.await(); else &#123; Thread thisThread = Thread.currentThread(); leader = thisThread; try &#123; available.awaitNanos(delay); &#125; finally &#123; if (leader == thisThread) leader = null; &#125; &#125; &#125; &#125; &#125; finally &#123; if (leader == null &amp;&amp; queue[0] != null) available.signal(); lock.unlock(); &#125;&#125; 5. 提交任务submit()方法依旧是提供的，不过是以延迟时间为0的方式调用schedule方法。 123public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; return schedule(task, 0, NANOSECONDS);&#125; 看schedule方法。 12345678910111213141516171819202122232425262728293031/** * @throws RejectedExecutionException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; */public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit) &#123; if (command == null || unit == null) throw new NullPointerException(); RunnableScheduledFuture&lt;?&gt; t = decorateTask(command, new ScheduledFutureTask&lt;Void&gt;(command, null, triggerTime(delay, unit))); delayedExecute(t); return t;&#125;/** * @throws RejectedExecutionException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; */public &lt;V&gt; ScheduledFuture&lt;V&gt; schedule(Callable&lt;V&gt; callable, long delay, TimeUnit unit) &#123; if (callable == null || unit == null) throw new NullPointerException(); RunnableScheduledFuture&lt;V&gt; t = decorateTask(callable, new ScheduledFutureTask&lt;V&gt;(callable, triggerTime(delay, unit))); delayedExecute(t); return t;&#125; 两种实现大同小异，对于Runnable任务，实际上new ScheduledFutureTask&lt;Void&gt;(command, null,triggerTime(delay, unit)));封装成了一个返回null的Callable任务 12345678910111213ScheduledFutureTask(Runnable r, V result, long ns) &#123; // 父类构造 super(r, result); this.time = ns; this.period = 0; this.sequenceNumber = sequencer.getAndIncrement();&#125;// 上面的super构造函数public FutureTask(Runnable runnable, V result) &#123; this.callable = Executors.callable(runnable, result); this.state = NEW; // ensure visibility of callable&#125; 接下来看看delayedExecute(t)会根据执行时间添加进有序任务队列 12345678910111213141516171819202122private void delayedExecute(RunnableScheduledFuture&lt;?&gt; task) &#123; if (isShutdown()) reject(task); else &#123; super.getQueue().add(task); if (isShutdown() &amp;&amp; !canRunInCurrentRunState(task.isPeriodic()) &amp;&amp; remove(task)) task.cancel(false); else // 好像ScheduledThreadPoolExecutor其他地方没有addWorker的代码，这里addWorker部分 ensurePrestart(); &#125;&#125;void ensurePrestart() &#123; int wc = workerCountOf(ctl.get()); if (wc &lt; corePoolSize) addWorker(null, true); else if (wc == 0) addWorker(null, false);&#125; 6. 任务运行123456789101112131415161718public boolean isPeriodic() &#123; return period != 0;&#125;public void run() &#123; // 是否周期性 boolean periodic = isPeriodic(); if (!canRunInCurrentRunState(periodic)) // 取消任务,唤醒所有`get()`调用，任务移出队列 cancel(false); else if (!periodic) ScheduledFutureTask.super.run(); // else if (ScheduledFutureTask.super.runAndReset()) &#123; setNextRunTime(); reExecutePeriodic(outerTask); &#125;&#125; 主流程分为三步： 判断当前task是否可以执行，如果不能执行，调用cancel方法取消task执行，否则，跳转到步骤2； 判断当前task是否周期性任务，是则调用父类普通执行该task，否则跳转到步骤3； 重置状态，计算任务下次执行时间，重新把任务添加到工作队列中，让该任务可重复执行 1234567891011boolean canRunInCurrentRunState(boolean periodic) &#123; // 下面两个长长的策略是可以通过set来修改的 return isRunningOrShutdown(periodic ? continueExistingPeriodicTasksAfterShutdown : executeExistingDelayedTasksAfterShutdown);&#125;final boolean isRunningOrShutdown(boolean shutdownOK) &#123; int rs = runStateOf(ctl.get()); return rs == RUNNING || (rs == SHUTDOWN &amp;&amp; shutdownOK);&#125; 上一篇没有说到runAndReset(),我们看一下代码 123456789101112131415161718192021222324252627282930protected boolean runAndReset() &#123; if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return false; boolean ran = false; int s = state; try &#123; Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; s == NEW) &#123; try &#123; c.call(); // don't set result ran = true; &#125; catch (Throwable ex) &#123; setException(ex); &#125; // 没有调用setResult(...) &#125; &#125; finally &#123; // runner must be non-null until state is settled to // prevent concurrent calls to run() runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); &#125; return ran &amp;&amp; s == NEW;&#125; run()方法是有setResult(…)的调用，更新FutureTask的state，runAndReset()没有调用，则正常完成的情况下是s == NEW。 还有一点，ran==false的情况下runAndReset()是返回失败的，所以出异常的话周期任务是不会继续执行的。 接下来我们专注于这一部分任务重复执行 1234else if (ScheduledFutureTask.super.runAndReset()) &#123; setNextRunTime(); reExecutePeriodic(outerTask); &#125; 1234567891011121314private void setNextRunTime() &#123; long p = period; // 大于0是fixRate if (p &gt; 0) time += p; // 小于0是fixDelay else time = triggerTime(-p);&#125;long triggerTime(long delay) &#123; return now() + ((delay &lt; (Long.MAX_VALUE &gt;&gt; 1)) ? delay : overflowFree(delay));&#125; 123456789void reExecutePeriodic(RunnableScheduledFuture&lt;?&gt; task) &#123; if (canRunInCurrentRunState(true)) &#123; super.getQueue().add(task); if (!canRunInCurrentRunState(true) &amp;&amp; remove(task)) task.cancel(false); else ensurePrestart(); &#125;&#125; 7. 任务的串行现在有个问题，如果我的线程执行需要2s，而运行周期是是1s，线程数量设置5。那么第二次任务的执行时间是第一个任务开始后1s执行，还是等待第一个任务执行完再执行？ 看了上面的run()的实现后，可以看到reExecutePeriodic(...)是在第一次跑完之后，才执行，任务才重新加入队列中，所以上面的场景是：第二次任务需要等待第一次任务执行完，无论有多少空闲线程都无法保证任务1s周期运行。 8. 写在最后Java好像常用的多线程编程工具都看完了，感觉用到大量的cas+自旋+挂起/唤醒+加锁/解锁。感觉为了做到线程安全Java付出性能代价挺大的。这方面是不是Go就稳的多了呢🧐Go的官方有定时任务包cron，暂时也不清楚是怎么实现的。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}],"author":"土川"},{"title":"[Java基础]ThreadPoolExecutor","slug":"Java基础-ThreadPoolExecutor","date":"2018-08-31T04:00:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"1860367337.html","link":"","permalink":"https://htchz.cc/1860367337.html","excerpt":"前面已经铺垫好，BOSS登场","text":"前面已经铺垫好，BOSS登场 1. 线程池总览1.1. 线程池的工作流程线程池的执行过程，图源，java的线程池是没有调度器的。 1.2. java线程池的继承体系java线程池相对前面几篇容易看得多，因为用了一堆现成的东西🙄 Executor接口：Executor接口中定义了一个execute方法，用来提交线程的执行。 ExecutorService：Executor接口的子接口，用来管理线程的执行，比如关闭线程池(shutdown)等。 ThreadPoolExecutor：大部分线程池的实现，通过不同的传入参数实现不同特性的线程池。 ScheduledExecutorService：延迟或周期性线程池接口，定义了延迟和周期执行接口 ScheduledThreadPoolExecutor：延迟或周期性线程池实现。 Executors：Java提供的一个专门用于创建线程池的工厂类，ExecutorService的初始化可以使用Executors类的静态方法。 shutdown只是将线程池的状态设置为SHUTWDOWN状态，正在执行的任务会继续执行下去，没有被执行的则中断。而shutdownNow则是将线程池的状态设置为STOP，正在执行的任务则被停止，没被执行任务的则返回。 2. ThreadPoolExecutor线程池的有许多初始化方式，最终落到这个构造函数: 123456789101112131415161718192021222324public ThreadPoolExecutor(int corePoolSize, // 核心线程数 int maximumPoolSize, // 最大线程数 long keepAliveTime, // 多余线程的活跃时间 TimeUnit unit, // 活跃时间单位 BlockingQueue&lt;Runnable&gt; workQueue, // 任务队列 ThreadFactory threadFactory, // 线程工厂 RejectedExecutionHandler handler) &#123; // 任务队列满了的执行策略 if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; 下面还有一个属性allowCoreThreadTimeOut，通过allowCoreThreadTimeOut(boolean)设置，表示核心工作线程是否要超时销毁，反正我是没设置过 - - 123456789public void allowCoreThreadTimeOut(boolean value) &#123; if (value &amp;&amp; keepAliveTime &lt;= 0) throw new IllegalArgumentException(\"Core threads must have nonzero keep alive times\"); if (value != allowCoreThreadTimeOut) &#123; allowCoreThreadTimeOut = value; if (value) interruptIdleWorkers(); &#125;&#125; 可以通过Executors类实例化不同的线程池： Executors.newCachedThreadPool Executors.newFixedThreadPool Executors.newWorkStealingPool Executors.newSingleThreadExecutor Executors.newScheduledThreadPool 2.1. ThreadPoolExecutor的重要属性 corePoolSize：线程的核心数量 maximumPoolSize：当任务队列满的时候，提交新任务会创建新线程，这个值即最大线程数量，&gt;=核心线程数量 keepAliveTime：超过核心数量时，线程的最大空闲时间/ threadFactory：创建线程的工厂类，默认是默认为Executors.DefaultThreadFactory，定义了线程的名字 handler：满任务队列满线程数的情况下的拒绝策略，默认为AbortPolicy,抛一个运行时异常 ctl：ctl 是一个 AtomicInteger 类型, 它的 低29位 用于存放当前的线程数, 因此一个线程池在理论上最大的线程数是 536870911; 高 3 位是用于表示当前线程池的状态, 其中高三位的值和状态对应如下: 1234567891011// COUNT_BITS = 32 - 3// 可以接受新的任务，也可以处理阻塞队列里的任务private static final int RUNNING = -1 &lt;&lt; COUNT_BITS;// 不接受新的任务，但是可以处理阻塞队列里的任务private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;// 不接受新的任务，不处理阻塞队列里的任务，中断正在处理的任务private static final int STOP = 1 &lt;&lt; COUNT_BITS;// 过渡状态，也就是说所有的任务都执行完了，当前线程池已经没有有效的线程，这个时候线程池的状态将会TIDYING，并且将要调用terminated方法private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;// 终止状态。terminated方法调用完成以后的状态private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; 这些状态是按着大小排序的，线程的代码许多地方将状态进行大小比较，得出线程池的终止的程度。 其他属性，有些上面已经介绍了,主要有个独占锁mainLcok,终止条件变量termination,工作线程封装workers 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051 public class ThreadPoolExecutor extends AbstractExecutorService &#123; // 这个是一个复用字段, 它复用地表示了当前线程池的状态, 当前线程数信息. private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); // 用于存放提交到线程池中, 但是还未执行的那些任务. private final BlockingQueue&lt;Runnable&gt; workQueue; // 线程池内部锁, 对线程池内部操作加锁, 防止竞态条件 // 对 workers 字段的操作前, 需要获取到这个锁. private final ReentrantLock mainLock = new ReentrantLock(); // 一个 Set 结构, 包含了当前线程池中的所有工作线程. private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); // 条件变量, 用于支持 awaitTermination 操作 private final Condition termination = mainLock.newCondition(); // 记录线程池中曾经到达过的最大的线程数. // 这个字段在获取 mainLock 锁的前提下才能操作. private int largestPoolSize; // 记录已经完成的任务数. 仅仅当工作线程结束时才更新此字段. // 这个字段在获取 mainLock 锁的前提下才能操作. private long completedTaskCount; // 线程工厂. 当需要一个新的线程时, 这里生成. private volatile ThreadFactory threadFactory; // 任务提交失败后的处理 handler private volatile RejectedExecutionHandler handler; // 空闲线程的等待任务时间, 以纳秒为单位. // 当当前线程池中的线程数大于 corePoolSize 时, // 或者 allowCoreThreadTimeOut 为真时, 线程才有 idle 等待超时时间, // 如果超时则此线程会停止.; // 反之线程会一直等待新任务到来. private volatile long keepAliveTime; // 默认为 false. // 当为 false 时, keepAliveTime 不起作用, 线程池中的 core 线程会一直存活, // 即使这些线程是 idle 状态. // 当为 true 时, core 线程使用 keepAliveTime 作为 idle 超时 // 时间来等待新的任务. private volatile boolean allowCoreThreadTimeOut; // 核心线程数. private volatile int corePoolSize; // 最大线程数. private volatile int maximumPoolSize;&#125; 2.2. 提交任务这个方法就是提交任务的主流程了，分为三步 线程数小于corePoolSize，尝试添加Worker并提交任务到任务到worker,true表示核心线程 任务入队成功，二次校验线程池运行状态，是否需要拒绝任务或者增加worker 增加工作线程，false表示超核心数量的线程 12345678910111213141516171819202122232425public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); // step 1 // workerCountOf(c)取低29位 if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; // step 2 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); // 如果不在运行状态且任务未被消费，remove(command)==true，则拒绝任务 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; // step 3 else if (!addWorker(command, false)) reject(command);&#125; 看addWorker(command, true)前，看Worker类，是对线程的封装,实现了Runnable，继承了AQS，所有有锁的能力。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263 private final class Worker extends AbstractQueuedSynchronizer implements Runnable &#123; private static final long serialVersionUID = 6138294804551838833L; // 线程引用 final Thread thread; // 创建线程时带的任务 Runnable firstTask; /** Per-thread task counter */ volatile long completedTasks;// 构造方法 Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); &#125; /** Delegates main run loop to outer runWorker */ public void run() &#123; runWorker(this); &#125; // Lock methods // // The value 0 represents the unlocked state. // The value 1 represents the locked state.// 非0表示该工作线程被占有 protected boolean isHeldExclusively() &#123; return getState() != 0; &#125; protected boolean tryAcquire(int unused) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; protected boolean tryRelease(int unused) &#123; setExclusiveOwnerThread(null); setState(0); return true; &#125; public void lock() &#123; acquire(1); &#125; public boolean tryLock() &#123; return tryAcquire(1); &#125; public void unlock() &#123; release(1); &#125; public boolean isLocked() &#123; return isHeldExclusively(); &#125; void interruptIfStarted() &#123; Thread t; if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; &#125; &#125; &#125; 2.3. 运行任务可以看到newThread(this)方法是传入自身，我们看他的run()方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public void run() &#123; runWorker(this);&#125;final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); // 取出第一个任务 Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; 这里就是线程不断拿任务的原理，通过一个while实现 while (task != null || (task = getTask()) != null) &#123; w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt // 一些中断的判断，lock()调用了AQS的acquire()方法，中断是不会释放锁的 if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; // 好吧，默认实现这里是空的，如果要自己定义线程池可以 beforeExecute(wt, task); Throwable thrown = null; try &#123; // 跑task啦 task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; // 依旧空实现 afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125; 没任务可以拿的时候，工作线程就会跳出while从而终止了，所以没任务的时候想保持线程不被销毁，就得在getTask()阻塞，具体后面小节会讲。 当任务拿完的时候，线程会执行processWorkerExit(w, completedAbruptly) 123456789101112131415161718192021222324252627282930private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; // 非正常结束（抛异常了），那么要减去线程数量补救一下 if (completedAbruptly) // If abrupt, then workerCount wasn't adjusted decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; completedTaskCount += w.completedTasks; workers.remove(w); &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate(); // 清除线程后的检查 int c = ctl.get(); if (runStateLessThan(c, STOP)) &#123; if (!completedAbruptly) &#123; int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; if (workerCountOf(c) &gt;= min) return; // replacement not needed &#125; // 如果是意外中断，且核心工作线程不够，要补回worker addWorker(null, false); &#125;&#125; 这个方法一开始会判断是否正常终止，非正常终止会执行decrementWorkerCount()来减少工作线程数量。 那正常终止呢怎么减数量呢，runWorker没写，这一步骤也放到getTask()里去执行了 工作线程结束后，看是否需要终止线程池，tryTerminate() 123456789101112131415161718192021222324252627282930313233 final void tryTerminate() &#123; for (;;) &#123; int c = ctl.get(); // 如果在运行，或者已经在终止中（TIDYING），或者刚发起终止指令（SHUTDOWN）但是任务队列还没完（isEmpty），那么不需要执行终止线程池。 if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty())) return; if (workerCountOf(c) != 0) &#123; // Eligible to terminate // 线程池SHUTFDOWN，任务对列已空，中断所有工作线程 interruptIdleWorkers(ONLY_ONE); return; &#125; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // cas设置终止中 if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) &#123; try &#123; terminated(); &#125; finally &#123; ctl.set(ctlOf(TERMINATED, 0)); termination.signalAll(); &#125; return; &#125; &#125; finally &#123; mainLock.unlock(); &#125; // cas失败，继续下一轮吧 &#125;&#125; tryTerminate()返回之后，主流程检查线程池的状态，看需要不需要补回销毁的工作线程。 以上是工作线程的运行过程。 2.4. 添加工作线程下面是添加addWorker的部分 retry:是标签(Label)语法，可以执行多层循环的break和continue 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); // 获取线程池运行状态 int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; // 通过控制数量来防止并发 if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl // 如果运行状态不一致了，重新执行外层的运行状态校验 if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); // rs &lt; SHUTDOWN 即 rs = RUNNING if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); // 更新最大记录 if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; // 如果成功创建并添加到工作线程集合里，线程开始跑 t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; // 善后工作 if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125; 返回工作线程是否启动，否的情况下，外部调用会执行拒绝策略，默认抛异常。 2.5. 工作线程的 idle 超时处理在运行任务的小节，有个getTask()方法，如果拿不到任务，那工作线程就得结束了，所以我们看看getTask()的策略是什么。 工作线程的 idle 超出处理在底层依赖于 BlockingQueue 带超时的 poll 方法, 即工作线程会不断地从 workQueue 这个 BlockingQueue 中获取任务, 如果 allowCoreThreadTimeOut 字段为 true, 或者当前的工作线程数大于 corePoolSize, 那么线程的 idle 超时机制就生效了, 此时工作线程会以带超时的 poll 方式从 workQueue 中获取任务. 当超时了还没有获取到任务, 那么我们就知道此线程一个到达 idle 超时时间, 因此终止此工作线程. 12345678910111213141516171819202122232425262728293031323334353637private Runnable getTask() &#123; boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // Are workers subject to culling? boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); // 阻塞 if (r != null) return r; timedOut = true; &#125; catch (InterruptedException retry) &#123; timedOut = false; &#125; &#125;&#125; 2.6. Future Future 可以拿到线程池任务的运行结果，是对任务的封装， 任务必需是Callable类型的任务123456789public interface Callable&lt;V&gt; &#123; /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception;&#125; 123456789101112131415public interface Future&lt;V&gt; &#123; // mayInterruptIfRunning 任务在worker跑的时候是否能被取消 boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); // 阻塞直到拿到运行结果 V get() throws InterruptedException, ExecutionException; // 带超时的get(0 V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; ThreadPoolExecutor通过父类AbstractExecutorService的submit(Runnable task)方法， 123456public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask;&#125; 123456public FutureTask(Callable&lt;V&gt; callable) &#123; if (callable == null) throw new NullPointerException(); this.callable = callable; this.state = NEW; // ensure visibility of callable&#125; 可以看到Future的原理是用一个FutureTask(我们这篇就只看这个类)类对任务进行封装，下面是 FutureTask的几个状态和一些属性，从字面上可以看出各个状态代表的意思，这几个状态和线程池的状态一样是大小不是随便定的 12345678910111213141516171819202122/** * Possible state transitions: * NEW -&gt; COMPLETING -&gt; NORMAL * NEW -&gt; COMPLETING -&gt; EXCEPTIONAL * NEW -&gt; CANCELLED * NEW -&gt; INTERRUPTING -&gt; INTERRUPTED */ private volatile int state; private static final int NEW = 0; private static final int COMPLETING = 1; private static final int NORMAL = 2; private static final int EXCEPTIONAL = 3; private static final int CANCELLED = 4; private static final int INTERRUPTING = 5; private static final int INTERRUPTED = 6; // 运行这个run的线程，即线程池的工作线程 private volatile Thread runner; // 调用了get()的等待线程，是个链表 private volatile WaitNode waiters; 2.6.1. 运行任务当线程池的工作线程的运行任务的run()的的时候，FutureTask就会调用任务的call()，并将存储运行结果。 我们看FutureTask的run()方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public void run() &#123; // 没有人终止任务，state依旧是NEW，则cas设置工作线程，失败则直接结束 if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return; try &#123; Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; state == NEW) &#123; V result; boolean ran; try &#123; result = c.call(); ran = true; &#125; catch (Throwable ex) &#123; result = null; ran = false; // 异常完成的处理方式 setException(ex); &#125; if (ran) // 正常完成，更新状态，唤醒所有等待的线程 set(result); &#125; &#125; finally &#123; // runner must be non-null until state is settled to // prevent concurrent calls to run() runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts int s = state; // 如果任务被取消，调用Thread.yield();直到善后工作做完，状态变成INTERRUPTED if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); &#125;&#125;// protected void set(V v) &#123; if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123; outcome = v; UNSAFE.putOrderedInt(this, stateOffset, NORMAL); // final state // 更新状态，唤醒所有等待的线程 finishCompletion(); &#125;&#125; 2.6.2. 任务完成任务完成的方法，只有四种：正常、异常、取消、中断工作线程，每种分别调用set(result),setException(ex),cancel(boolean)，其中取消和中断都是调用cancel(boolean)，通过参数控制，这几种方法都会调用finishCompletion(),逐一唤醒挂起的线程（比如上面set(V v)的调用） 1234567891011121314151617181920212223242526private void finishCompletion() &#123; // assert state &gt; COMPLETING; for (WaitNode q; (q = waiters) != null;) &#123; // 将整个waiters链表引用置为null，方便gc if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) &#123; // 一一唤醒 for (;;) &#123; Thread t = q.thread; if (t != null) &#123; q.thread = null; LockSupport.unpark(t); &#125; WaitNode next = q.next; if (next == null) break; q.next = null; // unlink to help gc q = next; &#125; break; &#125; &#125; // 预留给子类的空函数 done(); callable = null; // to reduce footprint&#125; 2.6.3. 获取结果挺容易理解的代码，接下来看get() 1234567public V get() throws InterruptedException, ExecutionException &#123; int s = state; if (s &lt;= COMPLETING) // 0L是无超时时间 s = awaitDone(false, 0L); return report(s);&#125; 如果get()调用的时候s &lt;= COMPLETING,即未终止或者未完成，则调用awaitDone(false, 0L)， 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374// 链表，因为get()可以被多个线程调用，所以维护一个链表来存储这些线程。任务完成的时候（无论意外还是正常）会调用`finishCompletion()`唤醒所有还在挂起的线程// 这是一个新节点插在头部的链表static final class WaitNode &#123; volatile Thread thread; volatile WaitNode next; WaitNode() &#123; thread = Thread.currentThread(); &#125;&#125;// 将线程从列表private void removeWaiter(WaitNode node) &#123; // node == null 什么都不做 if (node != null) &#123; node.thread = null; retry: for (;;) &#123; // restart on removeWaiter race for (WaitNode pred = null, q = waiters, s; q != null; q = s) &#123; s = q.next; if (q.thread != null) pred = q; else if (pred != null) &#123; pred.next = s; if (pred.thread == null) // check for race continue retry; &#125; else if (!UNSAFE.compareAndSwapObject(this, waitersOffset, q, s)) continue retry; &#125; break; &#125; &#125;&#125;private int awaitDone(boolean timed, long nanos) throws InterruptedException &#123; final long deadline = timed ? System.nanoTime() + nanos : 0L; WaitNode q = null; boolean queued = false; for (;;) &#123; // 如果线程被中断 if (Thread.interrupted()) &#123; removeWaiter(q); throw new InterruptedException(); &#125; int s = state; if (s &gt; COMPLETING) &#123; if (q != null) q.thread = null; return s; &#125; else if (s == COMPLETING) // cannot time out yet Thread.yield(); else if (q == null) q = new WaitNode(); else if (!queued) // 很花哨地把新地阻塞线程节点放到链表头 queued = UNSAFE.compareAndSwapObject(this, waitersOffset, q.next = waiters, q); // 设置了超时的挂起方式 else if (timed) &#123; nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) &#123; removeWaiter(q); return state; &#125; // 定时挂起 LockSupport.parkNanos(this, nanos); &#125; else // 无限挂起，直到完成唤醒 LockSupport.park(this); &#125;&#125;","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}],"author":"土川"},{"title":"[Java基础]BlockingQueue","slug":"Java基础-BlockingQueue","date":"2018-08-28T12:54:00.000Z","updated":"2019-08-21T06:45:32.901Z","comments":true,"path":"3516892559.html","link":"","permalink":"https://htchz.cc/3516892559.html","excerpt":"java的BlockingQueue解读","text":"java的BlockingQueue解读 Java的BlockingQueue有以下 ArrayBlockingQueue LinkedBlockingQueue SynchronousQueue PriorityBlockingQueue DelayQueue 对于 BlockingQueue，我们的关注点应该在 put(e) 和 take() 这两个方法，因为这两个方法是带阻塞的。 1. ArrayBlockingQueue1234567891011121314151617181920212223242526/** The queued items */final Object[] items;/** items index for next take, poll, peek or remove */int takeIndex;/** items index for next put, offer, or add */int putIndex;/** Number of elements in the queue */int count;/* * Concurrency control uses the classic two-condition algorithm * found in any textbook. *//** Main lock guarding all access */// 只有一个锁final ReentrantLock lock;/** Condition for waiting takes */private final Condition notEmpty;/** Condition for waiting puts */private final Condition notFull; 上一节讲过实现，先略过。 注意： 这是一个循环数组，putIndex、takeIndex在等于items.length的时候会重置为0 用的悲观锁，take()和put()不能并行执行。 2. LinkedBlockingQueue12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * Linked list node class */static class Node&lt;E&gt; &#123; E item; /** * One of: * - the real successor Node * - this Node, meaning the successor is head.next * - null, meaning there is no successor (this is the last node) */ Node&lt;E&gt; next; Node(E x) &#123; item = x; &#125;&#125;/** The capacity bound, or Integer.MAX_VALUE if none */private final int capacity;/** Current number of elements */private final AtomicInteger count = new AtomicInteger();/** * Head of linked list. * Invariant: head.item == null */transient Node&lt;E&gt; head;/** * Tail of linked list. * Invariant: last.next == null */private transient Node&lt;E&gt; last;/** Lock held by take, poll, etc */private final ReentrantLock takeLock = new ReentrantLock();/** Wait queue for waiting takes */private final Condition notEmpty = takeLock.newCondition();/** Lock held by put, offer, etc */private final ReentrantLock putLock = new ReentrantLock();/** Wait queue for waiting puts */private final Condition notFull = putLock.newCondition(); 可以有界可以无界（无界其实容量为Integer.MAX_VALUE），依旧略过。 注意： 用了分离的两个独占锁，put()和take()可并行执行 想不通为什么ArrayBlockingQueue不使用分离的锁，这里说是因为Queue接口继承了Collection接口，所以循环数组迭代在双锁下迭代比较复杂 = = 2.1. ArrayBlockingQueue和LinkedBlockingQueue对比 ArrayBlockingQueue占用内存小，但是不能并行生产消费，需要确定好队列容量 LinkedBlockingQueue占用内存大，但是可以并行生产消费，可以不指定队列容量 3. SynchronousQueue这个同步队列，当一个线程往队列中写入一个元素时，写入操作不会立即返回，需要等待另一个线程来将这个元素拿走；同理，当一个读线程做读操作的时候，同样需要一个相匹配的写线程的写操作。这里的 Synchronous 指的就是读线程和写线程需要同步，一个读线程匹配一个写线程。 这让我想到go不带缓冲的channel也有这种特点 SynchronousQueue不提供任何空间来存储元素（它存在一个node元素里），peek()返回的是null，和其他并发容器一样不允许插入null。 1234567// 指定公平模式还是非公平模式public SynchronousQueue(boolean fair) &#123; transferer = fair ? new TransferQueue() : new TransferStack();&#125;abstract static class Transferer &#123; abstract Object transfer(Object e, boolean timed, long nanos);&#125; 这里面需要说明一下的是，这个方法会根据参数e来区分调用方法的是一个生产者线程还是一个消费者线程，如果e为null，则说明这是一个消费者线程，比如一个take操作，如果e不为null，那么就是一个生产者线程，这个数据就是这个线程需要交付的数据，比如一个put操作。SynchronousQueue有两个版本的Transferer实现，一种为公平交易类型，一种为非公平交易类型，公平交易类型的实现类为TransferQueue，它使用队列来作为交易媒介，请求交易的线程总是先尝试跟队列头部（或者尾部）的线程进行交易，如果失败再将请求的线程添加到队列尾部，而非公平类型的实现类为TransferStack，它使用一个stack来作为交易媒介，请求交易的线程总是试图与栈顶线程进行交易，失败则添加到栈顶。所以SynchronousQueue就是使用队列和栈两种数据结构来模拟公平交易和非公平交易的。下面分别对两种交易类型进行分析。 看put()和take() 12345678910111213141516// 写入值public void put(E o) throws InterruptedException &#123; if (o == null) throw new NullPointerException(); if (transferer.transfer(o, false, 0) == null) &#123; // 1 Thread.interrupted(); throw new InterruptedException(); &#125;&#125;// 读取值并移除public E take() throws InterruptedException &#123; Object e = transferer.transfer(null, false, 0); // 2 if (e != null) return (E)e; Thread.interrupted(); throw new InterruptedException();&#125; 3.1. 公平模式可以看到用的是同一个方法，根据null或非空object来判断出队或者入队。 我们看看他的等待队列的实现方式，这里是等待队列的数据结构，还带有一些CAS方法 12345678910111213/** Node class for TransferQueue. */static final class QNode &#123; volatile QNode next; // 单链表 volatile Object item; // CAS'ed to or from null volatile Thread waiter; // 挂起、唤起线程 final boolean isData; QNode(Object item, boolean isData) &#123; this.item = item; this.isData = isData; &#125; ... &#125; 关于这个item，这是一个用来匹配的关键字，称作match 当tryCancel(e)，被调用时，它被cas成节点本身 当消费者进入transfer出队时，被出队的节点的item被cas成null 当生产者进入transfer入队时，被入队的节点的item被cas成E（生产元素） 通常原来的cas前的值会被保存起来，返回到方法调用上层以供判断当前处于什么情况。 接下来看transfer方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495 E transfer(E e, boolean timed, long nanos) &#123; /* Basic algorithm is to loop trying to take either of * two actions: * * 1. If queue apparently empty or holding same-mode nodes, * try to add node to queue of waiters, wait to be * fulfilled (or cancelled) and return matching item. * * 2. If queue apparently contains waiting items, and this * call is of complementary mode, try to fulfill by CAS'ing * item field of waiting node and dequeuing it, and then * returning matching item. * * In each case, along the way, check for and try to help * advance head and tail on behalf of other stalled/slow * threads. * * The loop starts off with a null check guarding against * seeing uninitialized head or tail values. This never * happens in current SynchronousQueue, but could if * callers held non-volatile/final ref to the * transferer. The check is here anyway because it places * null checks at top of loop, which is usually faster * than having them implicitly interspersed. */// 索引要插入的节点 QNode s = null; // constructed/reused as needed // 是否写入 boolean isData = (e != null); for (;;) &#123; QNode t = tail; QNode h = head; if (t == null || h == null) // saw uninitialized value continue; // spin // 空或者已有node和新的node模式一致，则插入 if (h == t || t.isData == isData) &#123; QNode tn = t.next; // 脏读，已经不是队尾 if (t != tail) continue; // 队尾的next指针已经并发被设置，提前将新元素置为队尾，继续自旋 if (tn != null) &#123; advanceTail(t, tn); continue; &#125; // 超时 if (timed &amp;&amp; nanos &lt;= 0) return null; // 初始新来的小老弟 if (s == null) s = new QNode(e, isData); // cas将新来的小老弟放到队尾next指针 if (!t.casNext(null, s)) continue; // 提前将队尾置为小老弟 advanceTail(t, s); // 阻塞至有人匹配，返回匹配的节点 Object x = awaitFulfill(s, e, timed, nanos); // wait was cancelled if (x == s) &#123; clean(t, s); return null; &#125; if (!s.isOffList()) &#123; // not already unlinked advanceHead(t, s); // unlink if head if (x != null) // and forget fields s.item = s; s.waiter = null; &#125; return (x != null) ? (E)x : e; // 下面的看英文注释好了 &#125; else &#123; // complementary-mode QNode m = h.next; // node to fulfill if (t != tail || m == null || h != head)x continue; // inconsistent read Object x = m.item; if (isData == (x != null) || // m already fulfilled x == m || // m cancelled // 这一步是会执行的 !m.casItem(x, e)) &#123; // lost CAS advanceHead(h, m); // dequeue and retry continue; &#125; advanceHead(h, m); // successfully fulfilled LockSupport.unpark(m.waiter); return (x != null) ? (E)x : e; &#125; &#125; &#125; 123456789101112// 提前置为队尾void advanceTail(QNode t, QNode nt) &#123; if (tail == t) UNSAFE.compareAndSwapObject(this, tailOffset, t, nt);&#125;//void advanceHead(QNode h, QNode nh) &#123; if (h == head &amp;&amp; UNSAFE.compareAndSwapObject(this, headOffset, h, nh)) h.next = h; // forget old next&#125; 根据注释，下面来说明一下整个方法的运行流程： 如果队列为空，或者请求交易的节点和队列中的节点具有相同的交易类型，那么就将该请求交易的节点添加到队列尾部等待交易，直到被匹配或者被取消 如果队列中包含了等待的节点，并且请求的节点和等待的节点是互补的，那么进行匹配并且进行交易 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * The number of times to spin before blocking in timed waits. * The value is empirically derived -- it works well across a * variety of processors and OSes. Empirically, the best value * seems not to vary with number of CPUs (beyond 2) so is just * a constant. */static final int maxTimedSpins = (NCPUS &lt; 2) ? 0 : 32;/** * The number of times to spin before blocking in untimed waits. * This is greater than timed value because untimed waits spin * faster since they don't need to check times on each spin. */static final int maxUntimedSpins = maxTimedSpins * 16; /** * Spins/blocks until node s is fulfilled. * 自旋或者阻塞直到有其他线程匹配 * * @param s the waiting node * @param e the comparison value for checking match * @param timed true if timed wait * @param nanos timeout value * @return matched item, or s if cancelled */ Object awaitFulfill(QNode s, E e, boolean timed, long nanos) &#123; /* Same idea as TransferStack.awaitFulfill */ final long deadline = timed ? System.nanoTime() + nanos : 0L; Thread w = Thread.currentThread(); // 头节点的next指针才要自旋 int spins = ((head.next == s) ? (timed ? maxTimedSpins : maxUntimedSpins) : 0); for (;;) &#123; if (w.isInterrupted()) s.tryCancel(e); Object x = s.item; // 方法的唯一出口 // 在tryCancel(e)取消的时候s.item可能变成QNode类型，从而下一步退出方法，返回被cas的结果，可以用来判断是否取消 // 在匹配的时候，s.item会按场景cas成null或者是E（生成元素），从而下一步退出方法，返回被cas的结果 if (x != e) return x; if (timed) &#123; nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) &#123; s.tryCancel(e); continue; &#125; &#125; // 日常自减 if (spins &gt; 0) --spins; else if (s.waiter == null) s.waiter = w; // 如果自旋次数完毕，又没超时那就挂起吧 else if (!timed) LockSupport.park(this); // 只有&gt; 1ms 才要挂起线程，不然还是自旋，这在Condition篇有提到 else if (nanos &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanos); &#125; &#125; 这里看下取消交易的代码 123456/** * Tries to cancel by CAS'ing ref to this as item. */void tryCancel(Object cmp) &#123; UNSAFE.compareAndSwapObject(this, itemOffset, cmp, this);&#125; 可以看到，取消交易就是将match指向自己，而在awaitFulfill方法中返回的就是match，那么awaitFulfill方法返回之后做一下判断，如果和自己相等，那么就是被取消交易了，那么就需要调用方法clean来清理一下，下面是clean方法的细节： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * Gets rid of cancelled node s with original predecessor pred. */void clean(QNode pred, QNode s) &#123; s.waiter = null; // forget thread /* * At any given time, exactly one node on list cannot be * deleted -- the last inserted node. To accommodate this, * if we cannot delete s, we save its predecessor as * \"cleanMe\", deleting the previously saved version * first. At least one of node s or the node previously * saved can always be deleted, so this always terminates. */ while (pred.next == s) &#123; // Return early if already unlinked QNode h = head; QNode hn = h.next; // Absorb cancelled first node as head if (hn != null &amp;&amp; hn.isCancelled()) &#123; advanceHead(h, hn); continue; &#125; QNode t = tail; // Ensure consistent read for tail if (t == h) return; QNode tn = t.next; if (t != tail) continue; if (tn != null) &#123; advanceTail(t, tn); continue; &#125; if (s != t) &#123; // If not tail, try to unsplice QNode sn = s.next; if (sn == s || pred.casNext(s, sn)) return; &#125; QNode dp = cleanMe; if (dp != null) &#123; // Try unlinking previous cancelled node QNode d = dp.next; QNode dn; if (d == null || // d is gone or d == dp || // d is off list or !d.isCancelled() || // d not cancelled or (d != t &amp;&amp; // d not tail and (dn = d.next) != null &amp;&amp; // has successor dn != d &amp;&amp; // that is on list dp.casNext(d, dn))) // d unspliced casCleanMe(dp, null); if (dp == pred) return; // s is already saved node &#125; else if (casCleanMe(null, pred)) return; // Postpone cleaning s &#125;&#125; 可以发现这个方法较为复杂，现在要提到一个成员变量：cleanMe，这个变量保存的是一个被取消交易但是没有被移除队列的节点，这个节点总是最后被添加到队列的。 3.2. 非公平模式非公平模式的更难一些，暂不说明。 4. PriorityBlockingQueue带排序的 BlockingQueue 实现，其并发控制采用的是 ReentrantLock，队列为无界队列（ArrayBlockingQueue 是有界队列，LinkedBlockingQueue 也可以通过在构造函数中传入 capacity 指定队列最大的容量，但是 PriorityBlockingQueue 只能指定初始的队列大小，后面插入元素的时候，如果空间不够的话会自动扩容）。 简单地说，它就是 PriorityQueue 的线程安全版本。不可以插入 null 值，同时，插入队列的对象必须是可比较大小的（comparable），否则报 ClassCastException 异常。它的插入操作 put 方法不会 block，因为它是无界队列（take 方法在队列为空的时候会阻塞）。 12345678910111213141516171819202122232425// 构造方法中，如果不指定大小的话，默认大小为 11private static final int DEFAULT_INITIAL_CAPACITY = 11;// 数组的最大容量private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;// 存放数据的数组private transient Object[] queue;// 队列当前大小private transient int size;// 大小比较器，如果按照自然序排序，那么此属性可设置为 nullprivate transient Comparator&lt;? super E&gt; comparator;// 并发控制所用的锁，所有的 public 且涉及到线程安全的方法，都必须先获取到这个锁private final ReentrantLock lock;// 非空conditionprivate final Condition notEmpty;// 这个也是用于锁，用于数组扩容的时候，需要先获取到这个锁，才能进行扩容操作，使用 CAS 操作private transient volatile int allocationSpinLock;// 用于序列化和反序列化的时候用，对于 PriorityBlockingQueue 我们应该比较少使用到序列化private PriorityQueue q; 看初始化代码, 比较器默认为空 1234567891011121314151617181920212223// DEFAULT_INITIAL_CAPACITY = 11public PriorityBlockingQueue() &#123; this(DEFAULT_INITIAL_CAPACITY, null);&#125;public PriorityBlockingQueue(int initialCapacity) &#123; this(initialCapacity, null);&#125;public PriorityBlockingQueue(int initialCapacity, Comparator&lt;? super E&gt; comparator) &#123; if (initialCapacity &lt; 1) throw new IllegalArgumentException(); this.lock = new ReentrantLock(); this.notEmpty = lock.newCondition(); this.comparator = comparator; this.queue = new Object[initialCapacity];&#125;// 初始化填充指定集合public PriorityBlockingQueue(Collection&lt;? extends E&gt; c)&#123; ...&#125; 扩容机制 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * Tries to grow array to accommodate at least one more element * (but normally expand by about 50%), giving up (allowing retry) * on contention (which we expect to be rare). Call only while * holding lock. * * @param array the heap array * @param oldCap the length of the array */private void tryGrow(Object[] array, int oldCap) &#123; // 先释放锁，扩容后再获取锁 lock.unlock(); // must release and then re-acquire main lock Object[] newArray = null; if (allocationSpinLock == 0 &amp;&amp; // cas获取扩容锁 UNSAFE.compareAndSwapInt(this, allocationSpinLockOffset, 0, 1)) &#123; try &#123; // 以64为为界限，不同的增长策略，64以下+2 int newCap = oldCap + ((oldCap &lt; 64) ? (oldCap + 2) : // grow faster if small (oldCap &gt;&gt; 1)); if (newCap - MAX_ARRAY_SIZE &gt; 0) &#123; // possible overflow int minCap = oldCap + 1; if (minCap &lt; 0 || minCap &gt; MAX_ARRAY_SIZE) throw new OutOfMemoryError(); newCap = MAX_ARRAY_SIZE; &#125; if (newCap &gt; oldCap &amp;&amp; queue == array) newArray = new Object[newCap]; &#125; finally &#123; // 解锁 allocationSpinLock = 0; &#125; &#125; // 没获取扩容锁 if (newArray == null) // back off if another thread is allocating Thread.yield(); // 上锁复制 lock.lock(); if (newArray != null &amp;&amp; queue == array) &#123; queue = newArray; System.arraycopy(array, 0, newArray, 0, oldCap); &#125;&#125; 老李把数组扩容和复制分为两步，扩容交给扩容锁，复制交给拍他🔒，这样扩容的时候原数组可以继续被访问，增加吞吐量。 4.1. put(e)123456789101112131415161718192021222324252627282930313233343536373839404142// 不用阻塞，因为无界（大爱无疆） public void put(E e) &#123; offer(e); // never need to block &#125; public boolean offer(E e) &#123; if (e == null) throw new NullPointerException(); final ReentrantLock lock = this.lock; lock.lock(); int n, cap; Object[] array; while ((n = size) &gt;= (cap = (array = queue).length)) tryGrow(array, cap); try &#123; Comparator&lt;? super E&gt; cmp = comparator; if (cmp == null) siftUpComparable(n, e, array); else siftUpUsingComparator(n, e, array, cmp); size = n + 1; notEmpty.signal(); &#125; finally &#123; lock.unlock(); &#125; return true; &#125; // 二叉堆的插入，使用插入元素默认的比较方法 private static &lt;T&gt; void siftUpComparable(int k, T x, Object[] array) &#123; Comparable&lt;? super T&gt; key = (Comparable&lt;? super T&gt;) x; while (k &gt; 0) &#123; // 二叉堆中 a[k] 节点的父节点位置 int parent = (k - 1) &gt;&gt;&gt; 1; Object e = array[parent]; if (key.compareTo((T) e) &gt;= 0) break; array[k] = e; k = parent; &#125; array[k] = key; &#125; 继续盗图 = = 4.2. take()123456789101112public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); E result; try &#123; while ( (result = dequeue()) == null) notEmpty.await(); &#125; finally &#123; lock.unlock(); &#125; return result;&#125; 上锁出队，看出队方法 123456789101112131415161718private E dequeue() &#123; int n = size - 1; if (n &lt; 0) return null; else &#123; Object[] array = queue; E result = (E) array[0]; E x = (E) array[n]; array[n] = null; Comparator&lt;? super E&gt; cmp = comparator; if (cmp == null) siftDownComparable(0, x, array, n); else siftDownUsingComparator(0, x, array, n, cmp); size = n; return result; &#125;&#125; 出队比较容易，因为二叉堆的第一个元素就是最小元素 12345678910111213141516171819202122232425262728293031private static &lt;T&gt; void siftDownComparable(int k, T x, Object[] array, int n) &#123; if (n &gt; 0) &#123; Comparable&lt;? super T&gt; key = (Comparable&lt;? super T&gt;)x; // 这里得到的 half 肯定是非叶节点 // a[n] 是最后一个元素，其父节点是 a[(n-1)/2]。所以 n &gt;&gt;&gt; 1 代表的节点肯定不是叶子节点 // 下面，我们结合图来一行行分析，这样比较直观简单 // 此时 k 为 0, x 为 17，n 为 9 int half = n &gt;&gt;&gt; 1; // 得到 half = 4 while (k &lt; half) &#123; // 先取左子节点 int child = (k &lt;&lt; 1) + 1; // 得到 child = 1 Object c = array[child]; // c = 12 int right = child + 1; // right = 2 // 如果右子节点存在，而且比左子节点小 // 此时 array[right] = 20，所以条件不满足 if (right &lt; n &amp;&amp; ((Comparable&lt;? super T&gt;) c).compareTo((T) array[right]) &gt; 0) c = array[child = right]; // key = 17, c = 12，所以条件不满足 if (key.compareTo((T) c) &lt;= 0) break; // 把 12 填充到根节点 array[k] = c; // k 赋值后为 1 k = child; // 一轮过后，我们发现，12 左边的子树和刚刚的差不多，都是缺少根节点，接下来处理就简单了 &#125; array[k] = key; &#125;&#125; 记住二叉堆是一棵完全二叉树，那么根节点 10 拿掉后，最后面的元素 17 必须找到合适的地方放置。首先，17 和 10 不能直接交换，那么先将根节点 10 的左右子节点中较小的节点往上滑，即 12 往上滑，然后原来 12 留下了一个空节点，然后再把这个空节点的较小的子节点往上滑，即 13 往上滑，最后，留出了位子，17 补上即可。 调整图 5. DelayQueue这是个依赖于PriorityQueue延迟队列，上节说到PriorityBlcokingQueue是PriorityQueue的线程安全版本。DelayQueue的元素需要实现Delayed接口，Delayed接口又继承了Comparable,需要实现的方法有两个，一个用于获取当前剩余时间，一个比较大小，因为PriorityQueue是优先级队列。 12345678910111213141516171819202122private final transient ReentrantLock lock = new ReentrantLock();private final PriorityQueue&lt;E&gt; q = new PriorityQueue&lt;E&gt;();/** * Thread designated to wait for the element at the head of * the queue. This variant of the Leader-Follower pattern * (http://www.cs.wustl.edu/~schmidt/POSA/POSA2/) serves to * minimize unnecessary timed waiting. When a thread becomes * the leader, it waits only for the next delay to elapse, but * other threads await indefinitely. The leader thread must * signal some other thread before returning from take() or * poll(...), unless some other thread becomes leader in the * interim. Whenever the head of the queue is replaced with * an element with an earlier expiration time, the leader * field is invalidated by being reset to null, and some * waiting thread, but not necessarily the current leader, is * signalled. So waiting threads must be prepared to acquire * and lose leadership while waiting. */private Thread leader = null;private final Condition available = lock.newCondition(); 5.1. put(e)由于使用的是无界优先级队列，所以put也是调用offer 12345678910111213141516171819public void put(E e) &#123; offer(e);&#125;// q 即 PriorityQueuepublic boolean offer(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; q.offer(e); if (q.peek() == e) &#123; leader = null; available.signal(); &#125; return true; &#125; finally &#123; lock.unlock(); &#125;&#125; 5.2. take()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * Retrieves and removes the head of this queue, waiting if necessary * until an element with an expired delay is available on this queue. * * @return the head of this queue * @throws InterruptedException &#123;@inheritDoc&#125; */public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; for (;;) &#123; // 查询首元素 E first = q.peek(); if (first == null) // condition组素 available.await(); else &#123; long delay = first.getDelay(NANOSECONDS); if (delay &lt;= 0) // 午时已到，元素出队 return q.poll(); first = null; // don't retain ref while waiting if (leader != null) // condition阻塞 available.await(); else &#123; Thread thisThread = Thread.currentThread(); // 占用队列 leader = thisThread; try &#123; // 等待delay时间，然后进行下一波自旋 available.awaitNanos(delay); &#125; finally &#123; if (leader == thisThread) leader = null; &#125; &#125; &#125; &#125; &#125; finally &#123; // 没人占用队列了 if (leader == null &amp;&amp; q.peek() != null) available.signal(); lock.unlock(); &#125;&#125; 6. 参考解读 Java 并发队列 BlockingQueue","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}],"author":"土川"},{"title":"[Java基础]AQS与共享锁","slug":"Java基础-AQS与共享锁","date":"2018-08-27T13:58:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"4255302597.html","link":"","permalink":"https://htchz.cc/4255302597.html","excerpt":"占个坑、不拉💩","text":"占个坑、不拉💩","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}],"author":"土川"},{"title":"[Java基础]AQS与Condition","slug":"Java基础-Condition","date":"2018-08-27T03:43:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"2912753191.html","link":"","permalink":"https://htchz.cc/2912753191.html","excerpt":"这是依赖于ReentrantLock的一个类","text":"这是依赖于ReentrantLock的一个类 Condition基于ReentrantLock，这里有 Doug Lea 举的🌰。 1234567891011121314151617181920212223242526272829303132333435363738394041424344import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;class BoundedBuffer &#123; final Lock lock = new ReentrantLock(); // condition 依赖于 lock 来产生 final Condition notFull = lock.newCondition(); final Condition notEmpty = lock.newCondition(); final Object[] items = new Object[100]; int putptr, takeptr, count; // 生产 public void put(Object x) throws InterruptedException &#123; lock.lock(); try &#123; while (count == items.length) notFull.await(); // 队列已满，等待，直到 not full 才能继续生产 items[putptr] = x; if (++putptr == items.length) putptr = 0; ++count; notEmpty.signal(); // 生产成功，队列已经 not empty 了，发个通知出去 &#125; finally &#123; lock.unlock(); &#125; &#125; // 消费 public Object take() throws InterruptedException &#123; lock.lock(); try &#123; while (count == 0) notEmpty.await(); // 队列为空，等待，直到队列 not empty，才能继续消费 Object x = items[takeptr]; if (++takeptr == items.length) takeptr = 0; --count; notFull.signal(); // 被我消费掉一个，队列 not full 了，发个通知出去 return x; &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; 这个其实就是ArrayBlockingQueue的原理。 获取一个Condition实例要通过ReentrantLock实例 123public Condition newCondition() &#123; return sync.newCondition();&#125; 123final ConditionObject newCondition() &#123; return new ConditionObject();&#125; 12345678public class ConditionObject implements Condition, java.io.Serializable &#123; private static final long serialVersionUID = 1173984872572414699L; /** First node of condition queue. */ private transient Node firstWaiter; /** Last node of condition queue. */ private transient Node lastWaiter; ...&#125; 实际上利用Node的nextWaiter属性，condition维护了一个单向链表 1234567891011/** * Link to next node waiting on condition, or the special * value SHARED. Because condition queues are accessed only * when holding in exclusive mode, we just need a simple * linked queue to hold nodes while they are waiting on * conditions. They are then transferred to the queue to * re-acquire. And because conditions can only be exclusive, * we save a field by using special value to indicate shared * mode. */Node nextWaiter; 偷来一张图，我们把上一节的队列称为阻塞队列，把condition的队列叫做条件队列。 当condition调用await()的时候就把当前线程封装为一个Node放到lastWaiter，并且挂起当前线程。 当condition调用signal()的时候就把firstWaiter放到阻塞队列。 1. 线程挂起1234567891011121314151617181920212223242526// 首先，这个方法是可被中断的，不可被中断的是另一个方法 awaitUninterruptibly()// 这个方法会阻塞，直到调用 signal 方法（指 signal() 和 signalAll()，下同），或被中断public final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); // 添加到 condition 的条件队列中 Node node = addConditionWaiter(); // 释放锁，返回值是释放锁之前的 state 值 int savedState = fullyRelease(node); int interruptMode = 0; // 这里退出循环有两种情况，之后再仔细分析 // 1. isOnSyncQueue(node) 返回 true，即当前 node 已经转移到阻塞队列了 // 2. checkInterruptWhileWaiting(node) != 0 会到 break，然后退出循环，代表的是线程中断 while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; // 被唤醒后，将进入阻塞队列，等待获取锁 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode);&#125; 看addConditionWaiter()，把当前线程加入条件队列 12345678910111213141516171819/** * Adds a new waiter to wait queue. * @return its new wait node */private Node addConditionWaiter() &#123; Node t = lastWaiter; // If lastWaiter is cancelled, clean out. if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); t = lastWaiter; &#125; Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node;&#125; 为什么没有线程安全问题？因为Condition需要和ReentrantLock.lock()一起使用，不一起使用会怎么样呢？就不安全了 取消节点的代码如下： 123456789101112131415161718192021// 等待队列是一个单向链表，遍历链表将已经取消等待的节点清除出去private void unlinkCancelledWaiters() &#123; Node t = firstWaiter; Node trail = null; while (t != null) &#123; Node next = t.nextWaiter; // 如果节点的状态不是 Node.CONDITION 的话，这个节点就是被取消的 if (t.waitStatus != Node.CONDITION) &#123; t.nextWaiter = null; if (trail == null) firstWaiter = next; else trail.nextWaiter = next; if (next == null) lastWaiter = trail; &#125; else trail = t; t = next; &#125;&#125; 加入条件队列之后，就完全释放独占锁，让出锁。 123456789101112131415161718192021// 首先，我们要先观察到返回值 savedState 代表 release 之前的 state 值// 对于最简单的操作：先 lock.lock()，然后 condition1.await()。// 那么 state 经过这个方法由 1 变为 0，锁释放，此方法返回 1// 相应的，如果 lock 重入了 n 次，savedState == n// 如果这个方法失败，会将节点设置为\"取消\"状态，并抛出异常 IllegalMonitorStateExceptionfinal int fullyRelease(Node node) &#123; boolean failed = true; try &#123; int savedState = getState(); // 这里使用了当前的 state 作为 release 的参数，也就是完全释放掉锁，将 state 置为 0 if (release(savedState)) &#123; failed = false; return savedState; &#125; else &#123; throw new IllegalMonitorStateException(); &#125; &#125; finally &#123; if (failed) node.waitStatus = Node.CANCELLED; &#125;&#125; 释放掉锁之后，判断是否当前节点是否在阻塞队列里面，如果不在，挂起，自旋直到进入阻塞队列。 12345678int interruptMode = 0;while (!isOnSyncQueue(node)) &#123; // 线程挂起 LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break;&#125; isOnSyncQueue(Node node)用于判断节点是否已经转移到阻塞队列 1234567891011final boolean isOnSyncQueue(Node node) &#123; // 移动过去的时候，node 的 waitStatus 会置为 0，这个之后在说 signal 方法的时候会说到 // node.prev == null，那么肯定没有进入阻塞队列，node.prev != null, 不一定进入阻塞队列，因为上篇的AQS讲到Node入队首先设置的是 node.prev 指向 tail， // 然后是 CAS 操作将自己设置为新的 tail，可是这次的 CAS 是可能失败的。 if (node.waitStatus == Node.CONDITION || node.prev == null) return false; if (node.next != null) // If has successor, it must be on queue return true; // return findNodeFromTail(node); &#125; 1234567891011// 从同步队列(阻塞队列)的队尾往前遍历，如果找到，返回 trueprivate boolean findNodeFromTail(Node node) &#123; Node t = tail; for (;;) &#123; if (t == node) return true; if (t == null) return false; t = t.prev; &#125;&#125; 2. 线程唤醒12345678910// 唤醒等待了最久的线程// 其实就是，将这个线程对应的 node 从条件队列转移到阻塞队列public final void signal() &#123; // 调用 signal 方法的线程必须持有当前的独占锁 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first);&#125; 1234567891011121314// 从条件队列队头往后遍历，找出第一个需要转移的 node// 因为前面我们说过，有些线程会取消排队，但是还在队列中private void doSignal(Node first) &#123; do &#123; // 将 firstWaiter 指向 first 节点后面的第一个 // 如果将队头移除后，后面没有节点在等待了，那么需要将 lastWaiter 置为 null if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; // 因为 first 马上要被移到阻塞队列了，和条件队列的链接关系在这里断掉 first.nextWaiter = null; &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null); // 这里 while 循环，如果 first 转移不成功，那么选择 first 后面的第一个节点进行转移，依此类推&#125; 转移节点的代码，并且唤醒阻塞线程 12345678910111213141516171819202122// 将节点从条件队列转移到阻塞队列// true 代表成功转移// false 代表在 signal 之前，节点已经取消了final boolean transferForSignal(Node node) &#123; // CAS 如果失败，说明此 node 的 waitStatus 已不是 Node.CONDITION，说明节点已经取消， // 既然已经取消，也就不需要转移了，方法返回，转移后面一个节点 // 否则，将 waitStatus 置为 0 if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; // enq(node): 自旋进入阻塞队列的队尾 // 注意，这里的返回值 p 是 node 在阻塞队列的前驱节点 Node p = enq(node); int ws = p.waitStatus; // ws &gt; 0 说明 node 在阻塞队列中的前驱节点取消了等待锁，直接唤醒 node 对应的线程。唤醒之后会怎么样，后面再解释 // 如果 ws &lt;= 0, 那么 compareAndSetWaitStatus 将会被调用，上篇介绍的时候说过，节点入队后，需要把前驱节点的状态设为 Node.SIGNAL(-1) if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) // 如果前驱节点取消或者 CAS 失败，会进到这里唤醒线程，之后的操作看下一节 LockSupport.unpark(node.thread); return true;&#125; 正常情况下，ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL) 这句中，如果ws &lt;= 0，那么一般 compareAndSetWaitStatus(p, ws, Node.SIGNAL) 会返回 true，所以一般也不会进去 if 语句块中唤醒 node 对应的线程。然后这个方法返回 true，也就意味着 signal 方法结束了，节点进入了阻塞队列。 假设发生了阻塞队列中的前驱节点取消等待，或者 CAS 失败，只要唤醒线程，让其进到下一步即可 没有唤醒的话，因为已经加入阻塞队列，等待前驱节点去唤醒。 3. 唤醒后的操作上一步 signal 之后，我们的线程由条件队列转移到了阻塞队列，之后就准备获取锁了。只要重新获取到锁了以后，继续往下执行。 等线程从挂起中恢复过来，继续往下看 12345678int interruptMode = 0;while (!isOnSyncQueue(node)) &#123; // 线程挂起 LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break;&#125; 3.1. 关于interruptMode REINTERRUPT： 代表 await 返回的时候，需要重新设置中断状态 THROW_IE： 代表 await 返回的时候，需要抛出InterruptedException 异常 0 ：说明在 await 期间，没有发生中断 有三种情况可以让LockSupport.park(this);返回： 常规路径。signal -&gt; 转移节点到阻塞队列 -&gt; 等待前驱节点唤醒 线程中断。在 park 的时候，另外一个线程对这个线程进行了中断 signal()的时候，转移以后的前驱节点取消了，或者对前驱节点的CAS操作失败了 假唤醒。这个也是存在的，和 Object.wait() 类似，都有这个问题 线程唤醒后第一步是调用 checkInterruptWhileWaiting(node) 这个方法，此方法用于判断是否在线程挂起期间发生了中断，如果发生了中断，是 signal 调用之前中断的，还是 signal 之后发生的中断。 12345678// 1. 如果在 signal 之前已经中断，返回 THROW_IE// 2. 如果是 signal 之后中断，返回 REINTERRUPT// 3. 没有发生中断，返回 0private int checkInterruptWhileWaiting(Node node) &#123; return Thread.interrupted() ? (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) : 0;&#125; 判断signal之前还是之后中断的方法： 1234567891011121314151617181920// 只有线程处于中断状态，才会调用此方法// 如果需要的话，将这个已经取消等待的节点转移到阻塞队列// 返回 true：如果此线程在 signal 之前被取消，final boolean transferAfterCancelledWait(Node node) &#123; // 用 CAS 将节点状态设置为 0 // 如果这步 CAS 成功，说明是 signal 方法之前发生的中断，因为如果 signal 先发生的话，signal 中会将 waitStatus 设置为 0 if (compareAndSetWaitStatus(node, Node.CONDITION, 0)) &#123; // 将节点放入阻塞队列 // 这里我们看到，即使中断了，依然会转移到阻塞队列 enq(node); return true; &#125; // 到这里是因为 CAS 失败，肯定是因为 signal 方法已经将 waitStatus 设置为了 0 // signal 方法会将节点转移到阻塞队列，但是可能还没完成，这边自旋等待其完成 // 当然，这种事情还是比较少的吧：signal 调用之后，没完成转移之前，发生了中断 while (!isOnSyncQueue(node)) Thread.yield(); return false;&#125; 上面的代码就是讨论线程中断后怎么让程序恢复正常。 signal之前中断，执行enq(node)，确保进入阻塞队列。 signal之后中断，没转移完成（判断waitStatus==0),让出cpu，自旋直至enq(node)执行完成。 接着获取独占锁，看接下来的代码 12if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; 由于 while 出来后，我们确定节点已经进入了阻塞队列，准备获取锁。 这里的 acquireQueued(node, savedState) 的第一个参数 node 之前已经经过 enq(node) 进入了队列，参数 savedState 是之前释放锁前的 state，这个方法返回的时候，代表当前线程获取了锁，而且 state == savedState了, 原来重入了几次，现在还是算几次。 注意，前面我们说过，不管有没有发生中断，都会进入到阻塞队列，而 acquireQueued(node, savedState) 的返回值就是代表线程是否被中断。如果返回 true，说明被中断了，而且 interruptMode != THROW_IE，说明在 signal 之前就发生中断了，这里将 interruptMode 设置为 REINTERRUPT，用于待会重新中断。 继续 1234 if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters();if (interruptMode != 0) reportInterruptAfterWait(interruptMode); node.nextWaiter != null依旧是对中断的善后，前面signal 的时候会将节点转移到阻塞队列，有一步是 node.nextWaiter = null，将断开节点和条件队列的联系。 可是，在判断发生中断的情况下，是 signal 之前还是之后发生的？ 这部分的时候，我也介绍了，如果 signal 之前就中断了，也需要将节点进行转移到阻塞队列，这部分转移的时候，是没有设置 node.nextWaiter = null 的。 之前我们说过，如果有节点取消，也会调用 unlinkCancelledWaiters 这个方法，就是这里了。 接下来是进入reportInterruptAfterWait代码块： 1234567891011121314/** * Throws InterruptedException, reinterrupts current thread, or * does nothing, depending on mode. */ private void reportInterruptAfterWait(int interruptMode) throws InterruptedException &#123; // THROW_IE 跑出异常 if (interruptMode == THROW_IE) throw new InterruptedException(); // 重新中断，自我了断 else if (interruptMode == REINTERRUPT) selfInterrupt(); // 0不处理 &#125; 4. 其他await4.1. 超时await超时的await都差不多， 123456public final long awaitNanos(long nanosTimeout) throws InterruptedExceptionpublic final boolean awaitUntil(Date deadline) throws InterruptedExceptionpublic final boolean await(long time, TimeUnit unit) throws InterruptedException 看第一个方法 12345678910111213141516171819202122232425262728293031public final long awaitNanos(long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); final long deadline = System.nanoTime() + nanosTimeout; int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; // 超时啦 if (nanosTimeout &lt;= 0L) &#123; transferAfterCancelledWait(node); break; &#125; // spinForTimeoutThreshold = 1000（1ms），当超时时间大于1ms才挂起，否则继续自旋 if (nanosTimeout &gt;= spinForTimeoutThreshold) // 指定时间的挂起 LockSupport.parkNanos(this, nanosTimeout); // 醒来检查是否signal发生中断 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; nanosTimeout = deadline - System.nanoTime(); &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); return deadline - System.nanoTime();&#125; 超时的思路还是很简单的，不带超时参数的 await 是 park，然后等待别人唤醒。而现在就是调用 parkNanos 方法来休眠指定的时间，醒来后判断是否 signal 调用了，调用了就是没有超时，否则就是超时了。超时的话，自己来进行转移到阻塞队列（checkInterruptWhileWaiting方法），然后acquireQueued抢锁。 5. 不抛中断异常的await123456789101112public final void awaitUninterruptibly() &#123; Node node = addConditionWaiter(); int savedState = fullyRelease(node); boolean interrupted = false; while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if (Thread.interrupted()) interrupted = true; &#125; if (acquireQueued(node, savedState) || interrupted) selfInterrupt();&#125; 醒来后检查中断，把中断吞了,使用时确保别人不会来中断他。 6. ReentrantLock的中断锁这篇讲了很多中断的处理，那么回头看ReentrantLock的lock()方法，它里面实际上默认是吞了中断的，想通过中断线程来取消一个锁的获取是不可以的 123456789101112131415161718192021final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 可以看到interrupted = true;之后又开始自旋了，打了个标志之后还是像没事人一样获取🔒。 这时候请看lockInterruptibly()方法： 123public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1);&#125; 1234567public final void acquireInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg);&#125; 如果线程中断，开始疯狂抛异常 123456789101112131415161718192021222324252627/** * Acquires in exclusive interruptible mode. * @param arg the acquire argument */private void doAcquireInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) // 疯狂抛异常 throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 这里抛异常的话，failed是true的，终于有机会进入cancelAcquire(node)了， 12345678910111213141516171819202122232425262728293031323334353637383940414243private void cancelAcquire(Node node) &#123; // Ignore if node doesn't exist if (node == null) return; node.thread = null; // Skip cancelled predecessors Node pred = node.prev; while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; // predNext is the apparent node to unsplice. CASes below will // fail if not, in which case, we lost race vs another cancel // or signal, so no further action is necessary. Node predNext = pred.next; // Can use unconditional write instead of CAS here. // After this atomic step, other Nodes can skip past us. // Before, we are free of interference from other threads. node.waitStatus = Node.CANCELLED; // If we are the tail, remove ourselves. if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123; compareAndSetNext(pred, predNext, null); &#125; else &#123; // If successor needs signal, try to set pred's next-link // so it will get one. Otherwise wake it up to propagate. int ws; if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) &#123; Node next = node.next; if (next != null &amp;&amp; next.waitStatus &lt;= 0) compareAndSetNext(pred, predNext, next); &#125; else &#123; unparkSuccessor(node); &#125; node.next = node; // help GC &#125;&#125; 这里会把node.waitStatus = Node.CANCELLED;，如果是头节点，则唤醒挂起的下一个节点，否则cas将前驱节点的next指向当前节点的next，把自己从阻塞队列清除。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}],"author":"土川"},{"title":"[Java基础]AQS与ReentrantLock","slug":"Java基础-AQS与Lock","date":"2018-08-22T15:54:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"2430429572.html","link":"","permalink":"https://htchz.cc/2430429572.html","excerpt":"AQS是一个抽象类，是java许多Lock实现必不可少的一个数据结构。","text":"AQS是一个抽象类，是java许多Lock实现必不可少的一个数据结构。 AQS，人称AbstractQueuedSynchronizer，它的子类有如下： 有ReentrantLock内部类FairSync、NonfairSync即公平锁与非公平锁等。他有一个volatile int state属性，表明锁的占有情况： 1234/** * The synchronization state. */private volatile int state; 这里先剧透一下，AQS是个队列，那么队头线程理应拿到锁，这是公平锁的情况。而非公平锁的情况下，锁在刚释放的时候（state==0），队头线程可能被新来的插队，新来的插队失败，才乖乖地排到队尾，所以非公平锁并不是就没有队列的概念。 我们结合ReentrantLock来看AQS在Lock里的使用例子。 1. 加锁看ReentrantLock的构造方法如下： 123456789101112131415161718 /** * Creates an instance of &#123;@code ReentrantLock&#125;. * This is equivalent to using &#123;@code ReentrantLock(false)&#125;. */ public ReentrantLock() &#123; sync = new NonfairSync(); &#125; /** * Creates an instance of &#123;@code ReentrantLock&#125; with the * given fairness policy. * * @param fair &#123;@code true&#125; if this lock should use a fair ordering policy */ public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync(); &#125;` 很明显，ReentrantLock能构造公平或者不公平的锁，默认是非公平的。我们先看非公平锁的实现。 123456789101112131415161718192021/** * Sync object for non-fair locks */static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = 7316153563782823691L; /** * Performs lock. Try immediate barge, backing up to normal * acquire on failure. */ final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125;&#125; 这个类继承了Sync，也是AQS的子类。lock()方法先通过CAS尝试将状态从0修改为1。若直接修改成功，前提条件自然是锁的状态为0，则直接将线程的OWNER修改为当前线程，这是一种理想情况，如果并发粒度设置适当也是一种乐观情况。若上一个动作未成功，则会间接调用了acquire(1)来继续操作，这个acquire(int)方法就是在AbstractQueuedSynchronizer当中了。 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 首先看tryAcquire(arg)这里的调用（当然传入的参数是1）,这个方法又交给子类实现了，最终是落到Sync里 123456789101112131415161718final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false;&#125; 判断锁是否被占有：首先获取这个锁的状态，如果状态为0，则尝试设置状态为传入的参数（这里就是1），若设置成功就代表自己获取到了锁，返回true了。状态为0设置1的动作在外部就有做过一次，内部再一次做只是提升概率，而且这样的操作相对锁来讲不占开销。 判断能否重入：如果状态不是0，则判定当前线程是否为排它锁的Owner，如果是Owner则尝试将状态增加acquires（也就是增加1），如果这个状态值越界，则会抛出异常提示，若没有越界，将状态设置进去后返回true（实现了类似于偏向的功能，可重入，但是无需进一步征用）。 如果状态不是0，且自身不是owner，则返回false，获取锁失败 回到AQS的acquire方法，判定中是通过if(!tryAcquire())作为第1个条件的，如果返回获取失败的话，继续acquireQueued(addWaiter(Node.EXCLUSIVE), arg))代码，先看第一个 1234567891011121314151617181920/** * Creates and enqueues node for current thread and given mode. * * @param mode Node.EXCLUSIVE for exclusive, Node.SHARED for shared * @return the new node */private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125; 这里的参数使用了Node.EXCLUSIVE,即排他的意思。Node的结构如下： 1234567891011121314151617181920212223242526272829303132333435363738static final class Node &#123; /** Marker to indicate a node is waiting in shared mode */ // 标识节点当前在共享模式下 static final Node SHARED = new Node(); /** Marker to indicate a node is waiting in exclusive mode */ // 标识节点当前在独占模式下 static final Node EXCLUSIVE = null; // ======== 下面的几个int常量是给waitStatus用的 =========== /** waitStatus value to indicate thread has cancelled */ // 代码此线程取消了争抢这个锁 static final int CANCELLED = 1; /** waitStatus value to indicate successor's thread needs unparking */ // 官方的描述是，其表示当前node的后继节点对应的线程需要被唤醒 static final int SIGNAL = -1; /** waitStatus value to indicate thread is waiting on condition */ // 本文不分析condition，所以略过吧，下一篇文章会介绍这个 static final int CONDITION = -2; /** * waitStatus value to indicate the next acquireShared should * unconditionally propagate */ // 同样的不分析，略过吧 static final int PROPAGATE = -3; // ===================================================== // 取值为上面的1、-1、-2、-3，或者0(以后会讲到) // 这么理解，暂时只需要知道如果这个值 大于0 代表此线程取消了等待， // 也许就是说半天抢不到锁，不抢了，ReentrantLock是可以指定timeouot的。。。 volatile int waitStatus; // 前驱节点的引用 volatile Node prev; // 后继节点的引用 volatile Node next; // 这个就是线程本尊 volatile Thread thread;&#125; 很明显，AQS是个链表结构，还是双向的。Node初始化，保存了当前线程，并赋值给nextWaiter属性。 1234Node(Thread thread, Node mode) &#123; // Used by addWaiter this.nextWaiter = mode; this.thread = thread;&#125; 而最初，tail肯定是null的，直接看enq(node)方法： 1234567891011121314151617181920/** * Inserts node into queue, initializing if necessary. See picture above. * @param node the node to insert * @return node's predecessor */private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 一个死循环，这段代码利用cas插入node，如果cas失败，进入下一次循环继续尝试。最终返回的是Node的前驱节点(addWaiter没有用到这个返回值)，第一个插入的，会初始化一个空（实例化但没有信息）的头节点再append操作。回到addWaiter，可以发现如果tail==null，接下来执行的代码块和enq（node）的部分代码是一样的，总之，addWaiter会初始化一个保存初始化线程的node，加入AQS，并返回。返回的Node和arg=1传入acquireQueued方法， 123456789101112131415161718192021222324252627282930/** * Acquires in exclusive uninterruptible mode for thread already in * queue. Used by condition wait methods as well as acquire. * * @param node the node * @param arg the acquire argument * @return &#123;@code true&#125; if interrupted while waiting */final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; // 这里判断前驱节点是不是head，而不是判断当前节点，因为队头是已经占有锁的/或者是空节点（请看enq方法），所以只要队列老二就可以开始tryAcquire了 final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed)// 没有正确退出，将本节点取消 cancelAcquire(node); &#125;&#125; 这里又是一个死循环，addWaiter是插入的node节点，那么这里如果前驱节点为head的话，说明线程来到了队头，继续执行tryRequire方法，tryAcquire(arg)这个方法我们前面介绍过，成立的条件为：锁的状态为0，且通过CAS尝试设置状态成功或线程的持有者本身是当前线程才会返回true，我们现在来详细拆分这部分代码。 如果这个条件成功后，发生的几个动作包含： 首先调用setHead(Node)的操作，这个操作内部会将传入的node节点作为AQS的head所指向的节点。线程属性设置为空（因为现在已经获取到锁，不再需要记录下这个节点所对应的线程了），再将这个节点的perv引用赋值为null。 进一步将的前一个节点的next引用赋值为null。 在进行了这样的修改后，队列就可以让执行完的节点释放掉内存区域，而不是无限制增长队列，也就真正形成FIFO了。 12345678910111213141516171819202122232425262728private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ // 如果前面的节点是0（因为前面都没出现过waitStatus的赋值，所以只能是默认值0），0是初始状态，那么就把它置为**等待唤醒**状态，如果下次抢占锁失败，前驱节点就会是-1，从而返回true，挂起线程。 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 如果获取不到锁 判断shouldParkAfterFailedAcquire(p , node)，这个方法内部会判定前一个节点的状态是否为：“Node.SIGNAL”，若是则返回true，若不是都会返回false，不过会再做一些操作：判定节点的状态是否大于0，若大于0则认为被“CANCELLED”掉了（大于0的表示CANCELLED的状态），因此会从前一个节点开始逐步循环找到一个没有被“CANCELLED”节点，然后与这个节点的next、prev的引用相互指向（即删除掉取消的队列元素）；如果前一个节点的状态不是大于0的，则通过CAS尝试将状态修改为“Node.SIGNAL”，自然的如果下一轮循环的时候，如果没拿到锁就会返回true。 如果这个方法返回了true，则会执行：“parkAndCheckInterrupt()”方法，它是通过LockSupport.park(this)将当前线程挂起到WATING状态，它需要等待一个中断、unpark方法来唤醒它，通过这样一种FIFO的机制的等待，来实现了Lock的操作。 这里有个节点状态的对应关系 节点类型 值 说明 CANCELLED 1 线程取消 SIGNAL -1 等待唤醒 CONDITION -2 ReenrantLock没用到 PROPAGATE -3 ReenrantLock没用到 简单地说，队列中的线程获取不到锁又检测到前面有人，那就要挂起，直到有人唤醒，这个唤醒靠前面的人来唤醒。 这里再看下非公平锁和公平锁的有什么区别：直接上截图这是非公平锁 这是公平锁 可以看出，非公平锁无论是在第一次尝试lock，还是到有机会tryAcquire时，上来就compareAndSetState(0,1)，完全不理会自己是不是真正的队头，而公平锁要客气地进行hasQueuedPredecessors()判断自己是不是真正的队头。 1.1. 公平锁和非公平锁的对比 公平锁保证各个线程可以拿到锁，但是这样大部分线程会经历一个挂起、唤醒的耗性能过程。非公平锁尽量减少这个耗性能的过程，但是不能保证业务的顺序。 如果线程占有锁处理业务的时间远大于挂起、唤醒的时间耗费，那么使用公平锁可以增强可控性。 2. 解锁解锁就没分公平与不公平了，主要任务就是消除锁占有标识，唤醒挂起的线程。 接下来简单看看unlock()解除锁的方式，如果获取到了锁不释放，那自然就成了死锁，所以必须要释放，来看看它内部是如何释放的。同样从排它锁（ReentrantLock）中的unlock()方法开始： 123public void unlock() &#123; sync.release(1);&#125; 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; tryRelease(arg)进入到Sync的方法 123456789101112protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 这些是重入逻辑，如果state==0那么清空锁的占有者。 state减的数量是根据参数的，而不是一下子清空，所以调用多少次lock(),应该调用相对应次数的unlock() 虽然锁状态清空了，这时被队头挂起的线程还需要unparkSuccessor(h)唤醒，参数是一个头节点。先判空和判断头节点的状态是否非0（几个重要的状态都不是0，0的节点要么是空，要么是被消除锁了）。 1234567891011121314151617181920212223242526private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; unparkSuccessor(h)内部首先会发生的动作是获取head节点的next节点，如果获取到的节点不为空，则直接通过“LockSupport.unpark()”方法来释放对应的被挂起的线程(否则从后往前遍历，拿到最前的等待唤醒的线程节点，虽然我不知道这个否则怎进来 = =，待研究)，这样一来将会有一个节点唤醒后继续循环进一步尝试tryAcquire()方法来获取锁，但是也未必能完全获取到哦，因为此时也可能有一些外部的请求正好与之征用(非公平锁)，而且还奇迹般的成功了，那这个线程的运气就有点悲剧了，不过通常乐观认为不会每一次都那么悲剧。 3. 写在最后有些地方还没弄懂，不过对AQS的结构，ReentrantLock是怎么利用AQS来做锁的有了一个大致的认识。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}],"author":"土川"},{"title":"[Java基础]CAS与Atomic","slug":"Java基础-java的CAS","date":"2018-08-22T15:10:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"1213316024.html","link":"","permalink":"https://htchz.cc/1213316024.html","excerpt":"java.util.concurrent.atomic 这个包提供了一系列的原子变量操作方法。","text":"java.util.concurrent.atomic 这个包提供了一系列的原子变量操作方法。 1. Atomic看看这个包下的类 这个包可以简单分为4类 分别对Boolean、Integer、Long进行操作，提供能进行原子计算的类，jdk8以后还提供了LongAdder、LongAccumulator等进行性能更好、更强大的计算，理论上可以用LongAdder代替AtomicInteger，具体在此博客中也有介绍LongAdder的实现原理。 对引用（Reference）的操作，由于多线程的对同一个Atomic的类型修改，无法避免ABA的问题，所以提供此类型的操作。 数组（Array）操作，针对数组的每个元素读写是线程安全的。 Updater：对普通的变量进行原子性管理，而不用改变原来变量的定义。 2. CAScas即compare and set，在AtomicInteger里有这么一个方法： 123public final boolean compareAndSet(int expect, int update)&#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update);&#125; 具体调用了public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);这个原生方法，需要传入对象本身、值在内存中的地址偏移、原值、改变后的值，即通过一组对比、修改的原子操作，在写入前读取原值，然后写入时如果值和原值不一致，就会更新失败，否则更新成功。 3. cas自旋unsafe类有这么一个方法，也是AtomicInteger自增的实现： 12345678public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125; 如果while()里一直返回的cas结果为false，那么程序就继续尝试cas操作，这就是cas自旋","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}],"author":"土川"},{"title":"[Java基础]synchronized关键字","slug":"Java基础-synchronized关键字","date":"2018-08-22T07:42:00.000Z","updated":"2019-07-20T03:59:13.000Z","comments":true,"path":"589479039.html","link":"","permalink":"https://htchz.cc/589479039.html","excerpt":"来讲讲属于jvm级别的锁","text":"来讲讲属于jvm级别的锁 1. 简介这是java同步的最简单的方法（有了这个并不是代码就保证线程安全了） 同步普通方法，锁的是当前对象。 同步静态方法，锁的是当前 Class 对象。 同步块，锁的是 (){} 中的()括起来的对象。 在JVM中monitorenter和monitorexit字节码依赖于底层的操作系统的Mutex Lock来实现的，但是由于使用Mutex Lock需要将当前线程挂起并从用户态切换到内核态来执行，这种切换的代价是非常昂贵的；然而在现实中的大部分情况下，同步方法是运行在单线程环境（无锁竞争环境）如果每次都调用Mutex Lock那么将严重的影响程序的性能。在jdk1.6中对锁的实现引入了大量的优化，如锁粗化（Lock Coarsening）、锁消除（Lock Elimination）、轻量级锁（Lightweight Locking）、偏向锁（Biased Locking）、适应性自旋（Adaptive Spinning）等技术来减少锁操作的开销。 先看看加了这个关键字的代码会发生什么 12345678910111213141516package com.htc.learning.main;public class Sync &#123; public static void main(String[] args) &#123; Sync sync = new Sync(); synchronized (sync) &#123; System.out.println(\"go die\"); &#125; print(); &#125; public static synchronized void print() &#123; System.out.println(\"print oh that's good\"); &#125;&#125; 运行javap -c Sync 123456789101112131415161718192021222324252627282930313233343536373839404142434445$ javap -c Sync警告: 二进制文件Sync包含com.htc.learning.main.SyncCompiled from &quot;Sync.java&quot;public class com.htc.learning.main.Sync &#123; public com.htc.learning.main.Sync(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return public static void main(java.lang.String[]); Code: 0: new #2 // class com/htc/learning/main/Sync 3: dup 4: invokespecial #3 // Method &quot;&lt;init&gt;&quot;:()V 7: astore_1 8: aload_1 9: dup 10: astore_2 11: monitorenter 12: getstatic #4 // Field java/lang/System.out:Ljava/io/PrintStream; 15: ldc #5 // String go die 17: invokevirtual #6 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 20: aload_2 21: monitorexit 22: goto 30 25: astore_3 26: aload_2 27: monitorexit 28: aload_3 29: athrow 30: invokestatic #7 // Method print:()V 33: return Exception table: from to target type 12 22 25 any 25 28 25 any public static synchronized void print(); Code: 0: getstatic #4 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #8 // String print oh that&apos;s good 5: invokevirtual #6 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return&#125; 看20行和27行，在同步块的入口和出口分别有 monitorenter,monitorexit指令。 JVM 是通过进入、退出对象监视器( Monitor ，即下文的monitor record)来实现对方法、同步块的同步的。 具体实现是在编译之后在同步方法调用前加入一个 monitor.enter 指令，在退出方法和异常处插入 monitor.exit 的指令。 其本质就是对一个对象监视器( Monitor )进行获取，而这个获取过程具有排他性从而达到了同一时刻只能一个线程访问的目的。 而对于没有获取到锁的线程将会阻塞到方法入口处，直到获取锁的线程 monitor.exit 之后才能尝试继续获取锁。 这个关键字可以形成三种锁：偏向锁、轻量级锁、重量锁，三种锁依次升级，不能降级，直到解锁。 接下来会涉及到jvm中对象的markword（对象头），关于对象头看对象的组成 2. monitor recordMonitor Record是线程的数据结构，每一个线程都有一个可用monitor record列表，同时还有一个全局的可用列表；那么这些monitor record有什么用呢？每一个被锁住的对象都会和一个monitor record关联（对象头中的LockWord指向monitor record的起始地址，由于这个地址是8byte对齐的所以LockWord的最低三位可以用来作为状态位），同时monitor record中有一个Owner字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。如下所示：Monitor Record的内部结构 属性 说明 Owner 初始时为NULL表示当前没有任何线程拥有该monitor record，当线程成功拥有该锁后保存线程唯一标识，当锁被释放时又设置为NULL EntryQ 关联一个系统互斥锁（semaphore），阻塞所有试图锁住monitor record失败的线程 RcThis 表示blocked或waiting在该monitor record上的所有线程的个数 Nest 用来实现重入锁的计数 HashCode 保存从对象头拷贝过来的HashCode值（可能还包含GC age） Candidate 用来避免不必要的阻塞或等待线程唤醒，因为每一次只有一个线程能够成功拥有锁，如果每次前一个释放锁的线程唤醒所有正在阻塞或等待的线程，会引起不必要的上下文切换（从阻塞到就绪然后因为竞争锁失败又被阻塞）从而导致性能严重下降。Candidate只有两种可能的值0表示没有需要唤醒的线程1表示要唤醒一个继任线程来竞争锁 下文的lockrecord字段指的就是ptr to lock record 3. 偏向锁Biased Lockmarkword的标志位（bittag）为01，称为biasable。 3.1. 偏向锁的获取过程 初始时对象处于biasable状态 当一个线程试图锁住一个处于biasable&amp; unbiased状态的对象时，通过一个CAS将自己的ThreadID放置到Mark Word中相应的位置，如果CAS操作成功进入第（3）步否则进入（4）步 当进入到这一步时代表当前没有锁竞争，Object继续保持biasable状态，但是这时ThreadID字段被设置成了偏向锁所有者的ID，然后进入到第（6）步 当前线程执行CAS获取偏向锁失败（这一步是偏向锁的关键），表示在该锁对象上存在竞争并且这个时候另外一个线程获得偏向锁所有权。当到达全局安全点（safepoint，gc时也会用到这个时间点）时获得偏向锁的线程被挂起，并从偏向锁所有者的私有Monitor Record列表中获取一个空闲的记录，并将Object设置为LightWeight Lock状态并且Mark Word中的LockRecord指向刚才持有偏向锁线程的Monitor record，最后被阻塞在安全点的线程被释放，进入到轻量级锁的执行路径中，同时被撤销偏向锁的线程继续往下执行同步代码。 当一个线程试图锁住一个处于biasable &amp; biased并且ThreadID不等于自己的ID时，这时由于存在锁竞争必须进入到第（4）步来撤销偏向锁。 运行同步代码块 3.2. 偏向锁的解锁偏向锁解锁过程很简单，只需要测试下是否Object上的偏向锁模式是否还存在，如果存在则解锁成功不需要任何其他额外的操作。 由偏向锁转向轻量级锁是耗性能的，尤其再线程竞争激烈的时候，所以关闭偏向锁的话可以在高并发提高性能。-XX:-UseBiasedLocking 4. 轻量级锁一个线程能够通过两种方式锁住一个对象：1、通过膨胀一个处于无锁状态（状态位001）的对象获得该对象的锁；2、对象已经处于膨胀状态（状态位00）但LockWord指向的monitor record的Owner字段为NULL，则可以直接通过CAS原子指令尝试将Owner设置为自己的标识来获得锁。 4.1. 获取锁（monitorenter） 当对象处于无锁状态时（RecordWord值为HashCode，状态位为001），线程首先从自己的可用moniter record列表中取得一个空闲的moniter record，初始Nest和Owner值分别被预先设置为1和该线程自己的标识，一旦monitor record准备好然后我们通过CAS原子指令安装该monitor record的起始地址到对象头的LockWord字段来膨胀该对象，如果存在其他线程竞争锁的情况而调用CAS失败，则只需要简单的回到monitorenter重新开始获取锁的过程即可。 对象已经被膨胀同时Owner中保存的线程标识为获取锁的线程自己，这就是重入（reentrant）锁的情况，只需要简单的将Nest加1即可。不需要任何原子操作，效率非常高。 对象已膨胀但Owner的值为NULL，当一个锁上存在阻塞或等待的线程同时锁的前一个拥有者刚释放锁时会出现这种状态，此时多个线程通过CAS原子指令在多线程竞争状态下试图将Owner设置为自己的标识来获得锁，竞争失败的线程在则会进入到第四种情况（4）的执行路径。 对象处于膨胀状态同时Owner不为NULL(被锁住)，在调用操作系统的重量级的互斥锁之前先自旋一定的次数，当达到一定的次数时如果仍然没有成功获得锁，则开始准备进入阻塞状态（进入重量级锁，将ptr to heavy monitor的值标志为monitor record的起始地址），首先将rcThis的值原子性的加1，由于在加1的过程中可能会被其他线程破坏Object和monitor record之间的关联，所以在原子性加1后需要再进行一次比较以确保LockWord的值没有被改变，当发现被改变后则要重新进行monitorenter过程。同时再一次观察Owner是否为NULL，如果是则调用CAS参与竞争锁，锁竞争失败则进入到阻塞状态。 4.2. 释放锁（monitorexit） 首先检查该对象是否处于膨胀状态并且该线程是这个锁的拥有者，如果发现不对则抛出异常； 检查Nest字段是否大于1，如果大于1则简单的将Nest减1并继续拥有锁，如果等于1，则进入到第（3）步； 检查RcThis是否大于0，设置Owner为NULL然后唤醒一个正在阻塞或等待的线程再一次试图获取锁，如果等于0则进入到第（4）步 缩小（deflate）一个对象，通过将对象的LockWord置换回原来的HashCode值来解除和monitor record之间的关联来释放锁，同时将monitor record放回到线程是有的可用monitor record列表。 5. 重量级锁即操作系统的Mutex Lock锁。所有cas失败的线程不会再重试，挂起并等待唤醒。 这里有一篇外文文献：https://www.usenix.org/legacy/event/jvm01/full_papers/dice/dice.pdf","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}],"author":"土川"},{"title":"[Go基础]goroutine的一个精彩用法","slug":"Go基础-goroutine的一个精彩用法","date":"2018-07-22T13:03:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"3042075373.html","link":"","permalink":"https://htchz.cc/3042075373.html","excerpt":"这是一个利用goroutine输出素数的一个算法，找个时间写个java版的实现…","text":"这是一个利用goroutine输出素数的一个算法，找个时间写个java版的实现… 1. goroutine实现算法的核心是，利用合数必定是素数的乘积的性质。用一个协程作为生成器（generate）开始生成“2、3、4.。。”的自然数，利用通道将自然数流入（filter的in、out参数传递）素数过滤器（filter）中，这样生成器生成的自然数如果能从第一个素数流经所有已经生成的filter，那么他是素数，并生成一个新的素数过滤器。第一版 12345678910111213141516171819202122232425262728293031323334353637// Copyright 2009 The Go Authors. All rights reserved.// Use of this source code is governed by a BSD-style// license that can be found in the LICENSE file.package mainpackage mainimport \"fmt\"// Send the sequence 2, 3, 4, ... to channel 'ch'.func generate(ch chan int) &#123; for i := 2; ; i++ &#123; ch &lt;- i // Send 'i' to channel 'ch'. &#125;&#125;// Copy the values from channel 'in' to channel 'out',// removing those divisible by 'prime'.func filter(in, out chan int, prime int) &#123; for &#123; i := &lt;-in // Receive value of new variable 'i' from 'in'. if i%prime != 0 &#123; out &lt;- i // Send 'i' to channel 'out'. &#125; &#125;&#125;// The prime sieve: Daisy-chain filter processes together.func main() &#123; ch := make(chan int) // Create a new channel. go generate(ch) // Start generate() as a goroutine. for &#123; prime := &lt;-ch fmt.Print(prime, \" \") ch1 := make(chan int) go filter(ch, ch1, prime) ch = ch1 &#125;&#125; 第二版 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// Copyright 2009 The Go Authors. All rights reserved.// Use of this source code is governed by a BSD-style// license that can be found in the LICENSE file.package mainimport ( \"fmt\")// Send the sequence 2, 3, 4, ... to returned channelfunc generate() chan int &#123; ch := make(chan int) go func() &#123; for i := 2; ; i++ &#123; ch &lt;- i &#125; &#125;() return ch&#125;// Filter out input values divisible by 'prime', send rest to returned channelfunc filter(in chan int, prime int) chan int &#123; out := make(chan int) go func() &#123; for &#123; if i := &lt;-in; i%prime != 0 &#123; out &lt;- i &#125; &#125; &#125;() return out&#125;func sieve() chan int &#123; out := make(chan int) go func() &#123; ch := generate() for &#123; prime := &lt;-ch ch = filter(ch, prime) out &lt;- prime &#125; &#125;() return out&#125;func main() &#123; primes := sieve() for &#123; fmt.Println(&lt;-primes) &#125;&#125;","categories":[{"name":"Golang基础","slug":"Golang基础","permalink":"https://htchz.cc/categories/Golang基础/"}],"tags":[{"name":"goroutine","slug":"goroutine","permalink":"https://htchz.cc/tags/goroutine/"}],"author":"土川"},{"title":"[Go基础]Go defer的那些坑","slug":"Go基础-Go-defer的那些坑","date":"2018-06-24T17:07:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"3084756888.html","link":"","permalink":"https://htchz.cc/3084756888.html","excerpt":"Go defer的那些坑不得不踩一下才爽","text":"Go defer的那些坑不得不踩一下才爽 1. 闭包函数不会执行1234567891011121314151617181920package mainimport \"fmt\"func main() &#123; db := &amp;database&#123;&#125; defer db.connect() fmt.Println(\"query db...\")&#125;type database struct&#123;&#125;func (db *database) connect() (disconnect func()) &#123; fmt.Println(\"connect\") return func() &#123; fmt.Println(\"disconnect\") &#125;&#125; 你猜输出结果，是这样的： query db... connectdisconnect并没有被打印出来，connect在defer里执行完后保存执行域，返回的disconnect函数并没有被执行，要想执行，得使用这种方式 1234567func main() &#123; db := &amp;database&#123;&#125; defer db.connect()() fmt.Println(\"query db...\")&#125; 题外话，我也不懂这种即连接又关闭的目的是什么，只是做个defer执行闭包的演示 2. 在执行块中使用 deferdefer是在函数执行完运行，而不是代码块执行完运行。 3. 想要在函数执行完后对结果值进行嘿嘿嘿先看java的一段代码 123456789101112131415161718192021222324public class LambdaTest &#123; public static void main(String[] args) &#123; System.out.println(finalIntTest()); System.out.println(finalStringTest()); &#125; private static int finalIntTest()&#123; int i = 0; try &#123; return i; &#125; finally &#123; i++; &#125; &#125; private static String finalStringTest()&#123; String a = \"hi \"; try &#123; return a; &#125;finally &#123; a += \"en\"; &#125; &#125;&#125; java想在函数返回前对返回结果进行修改，可以用finally直接修改，输出是这样的 0 hi 虽然finally块对i自增、对字符串修改，但是丝毫不影响返回结果。 这是因为return操作不是原子性的。返回值是作为临时变量进行暂存，然后finally执行完后在返回临时变量 基本数据类型都属于值类型，没有引用，finally里面进行的操作不会对临时变量造成影响。至于String呢，虽然不是基本数据类型，但是他是final类型，每次操作返回的都是新引用，所以finally依旧不能修改返回结果。 明白这点后，可能对go的defer坑有些理解，上一些代码。 123456func f() (result int) &#123; defer func() &#123; result++ &#125;() return 0&#125; 这个函数返回的是1，go的返回值声明特性使得defer语句里可以持有返回值result。 1234567func f() (r int) &#123; t := 5 defer func() &#123; t = t + 5 &#125;() return t&#125; 这个函数返回的是5，因为return时将t当时的值放入r中，defer中的操作只是对t进行运算 123456func f() (r int) &#123; defer func(r int) &#123; r = r + 5 &#125;(r) return 1&#125; 这个函数返回的是1，因为匿名函数体中的r是局部变量，所以不会影响返回值r。 在golang中只有三种引用类型它们分别是切片slice、字典map、管道channel，其它的全部是值类型。所以defer里的函数拿到这些类型的引用的时候，是无论如何可以修改返回值的。","categories":[{"name":"Golang基础","slug":"Golang基础","permalink":"https://htchz.cc/categories/Golang基础/"}],"tags":[{"name":"坑","slug":"坑","permalink":"https://htchz.cc/tags/坑/"}],"author":"土川"},{"title":"[Json]secure json","slug":"Json-secure-json","date":"2018-06-08T05:31:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"235536411.html","link":"","permalink":"https://htchz.cc/235536411.html","excerpt":"安全的Json..","text":"安全的Json.. 学习go的后端框架gin的时候，官方文档提到了这种代码来返回安全的json 12345678910111213141516func main() &#123; r := gin.Default() // You can also use your own secure json prefix // r.SecureJsonPrefix(&quot;)]&#125;&apos;,\\n&quot;) r.GET(&quot;/someJSON&quot;, func(c *gin.Context) &#123; names := []string&#123;&quot;lena&quot;, &quot;austin&quot;, &quot;foo&quot;&#125; // Will output : while(1);[&quot;lena&quot;,&quot;austin&quot;,&quot;foo&quot;] c.SecureJSON(http.StatusOK, names) &#125;) // Listen and serve on 0.0.0.0:8080 r.Run(&quot;:8080&quot;)&#125; 在不设置前缀的情况下，默认在返回的json加上while(1);stackoverflow查阅一下，说是为了防止json hijacking（json劫持） 关于这方面的资料不是很多，中文的更少了。目前这些漏洞大都修复了。 假设有一个http://www.safe.com/contacts的接口， 返回的内容如下 12345678910[ &#123; &quot;id&quot;: 1, &quot;name&quot;: &quot;Riven&quot; &#125;, &#123; &quot;id&quot;: 2, &quot;name&quot;: &quot;Miss Fortune&quot; &#125;] 由于浏览器的同源策略，使得和安全网站的域名、端口、协议不同的页面是不能直接发起上面请求的，这样恶意网站http://www.evil.com/index.html并不能直接请求安全接口。以下情况是没有同源策略限制的： 页面中的链接。很常见的就是导航页面中的链接。 跨域资源获取，当然，浏览器限制了Javascript不能读写加载的内容。这种允许的跨域请求有:src属性(服务器可以拒绝)、&lt;iframe&gt;（服务器可以拒绝） json劫持是通过&lt;script&gt;来进行的。 首先，恶意者在http://www.evil.com/index.html的写入一行 &lt;script src=&quot;http://www.safe.com/contacts&quot;&gt;&lt;/script&gt;由于这种接口一般利用cookie来保证登录状态，所以恶意者把这个钓鱼网站以邮件的形式发到受害者的邮箱， 受害者懵逼点开网站之后，&lt;script&gt;标签就跑起来了，一个Get请求带上还没过期的cookie信息，返回了json数组。 重点来了，虽然浏览器不允许对资源的操作加载的内容，可是&lt;script&gt;是会运行加载到的东西的(这也是jsonp的运行机制),而json数组文本是可以被js引擎运行的，所以浏览器会构造一个Array，但是并没有赋值给谁。 于是恶意者就从构造函数开始动手，如这篇文章，重写Array的构造函数，或者重写Objects.prototype.__defineSetter__来进行原型函数的替换，从而加入自己的恶意代码，如把数据发送到自己的服务器去。 如果http://www.safe.com/contacts接口返回的是对象而不是数组呢，比如该接口返回{&quot;id&quot;: 2, &quot;name&quot;: &quot;batman&quot;}，那么js引擎就会报错，无法运行这个文本。 或者，在json数组前加上一些垃圾串、死循环代码，再用自己的json解析器解析出正确的json数组。比如在Gmail网页版里，就有这样的带有垃圾串的json数组返回。 在es5之后，这些漏洞都不能被利用了，但是如果我们要接别人这种返回带前缀json的api怎么办呢，这位老哥说JQuery用一个过滤器处理（只针对//, while(true);, for(;;);） 123456789101112131415161718192021$.ajaxSetup(&#123; dataFilter: function(data, type) &#123; var prefixes = [&apos;//&apos;, &apos;while(true);&apos;, &apos;for(;;);&apos;], i, l,, pos; if (type != &apos;json&apos; &amp;&amp; type != &apos;jsonp&apos;) &#123; return data; &#125; for (i = 0, l = prefixes.length; i &lt; l; i++) &#123; pos = data.indexOf(prefixes[i]); if (pos === 0) &#123; return data.substring(prefixes[i].length); &#125; &#125; return data; &#125;&#125;);","categories":[],"tags":[{"name":"Json","slug":"Json","permalink":"https://htchz.cc/tags/Json/"}],"author":"土川"},{"title":"[Java基础]找到Java进程中哪个线程占用了大量CPU处理时间","slug":"Java基础-找到-Java-进程中哪个线程占用了大量-CPU-处理时间","date":"2018-06-05T07:32:00.000Z","updated":"2020-03-27T03:12:02.253Z","comments":true,"path":"947951116.html","link":"","permalink":"https://htchz.cc/947951116.html","excerpt":"在Linux环境下找到最大线程占用","text":"在Linux环境下找到最大线程占用 原文传送门 本文的目的是在 Java进程中确定哪个线程正在占用CPU的时间。 当您的系统 CPU 负载居高不下时，这是一种有用的故障排除技术。 下面是详细步骤： 1.首先确定进程的 ID ，可以使用 jps -v 或者 top 命令直接查看 2.查看该进程中哪个线程占用大量 CPU，执行 top -H -p [PID] 结果如下： H参数表示显示线程比top高级点的还可以用htop命令，需要自行安装 可以发现编号为 350xx 的共有 9 个线程占用了 100% 的 CPU，好，接下来咱们随便取一个线程 ID ，假设我们想看编号为 35053 这个线程。 首先将 35053 转成 16 进制是 88ED （可以用开源中国在线工具转换） 3.接下来我们将进程中的所有线程输出到一个文件中，执行：jstack [PID] &gt; jstack.txt 4.在进程中查找对应的线程 ID，执行：cat jstack.txt | grep -i 88ED 结果是： &quot;HTTP Request From : /xxxx/blog/323432(120.27.143.239)&quot; #266 daemon prio=5 os_prio=0 tid=0x00007fcda4146800 nid=0x88e runnable [0x00007fcd54178000]由此可以看出在请求 /xxxx/blog/323432 链接的时候，服务器的处理线程占用了 100% 的 CPU。 找到问题后，接下来去解决就好了！","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"运维","slug":"运维","permalink":"https://htchz.cc/tags/运维/"}],"author":"土川"},{"title":"[正则表达式]replaceAll不为人知的故事","slug":"Java基础-replaceAll不为人知的故事","date":"2018-05-09T07:37:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"2850894714.html","link":"","permalink":"https://htchz.cc/2850894714.html","excerpt":"String.replaceAll和String.replace的区别是，String.replaceAll使用的匹配模式是正则表达式。但是第二参数replacement不是简单的字符串，里面有点特殊的东西。","text":"String.replaceAll和String.replace的区别是，String.replaceAll使用的匹配模式是正则表达式。但是第二参数replacement不是简单的字符串，里面有点特殊的东西。 1. \\的问题已知String str = &quot;a\\\\bc&quot;,请问利用String.replaceAll把str输出为a\\\\bc到控制台怎么做？答案是：System.out.println(str.replaceAll(&quot;\\\\\\\\&quot;, &quot;\\\\\\\\\\\\\\\\&quot;))我们知道一个反斜杠用java正则来表示需要这么写&quot;\\\\\\\\&quot;，所以我一开始这么写str.replaceAll(&quot;\\\\\\\\&quot;, &quot;\\\\\\\\&quot;,结果输出的却是： a\\bc少了一杠，于是我不明白，replacement用&quot;\\\\\\\\&quot;表示两个斜杠有错？ 2. $与\\在String.replaceAll的注释是这样的， Note that backslashes ({@code }) and dollar signs ({@code $}) in the replacement string may cause the results to be different than if it were being treated as a literal replacement string; 接下来他让我详情请看Matcher类注释，而在java.util.regex.Matcher#replaceAll里是这么注释的 Dollar signs may be treated as references to captured subsequences as described above, and backslashes are used to escape literal characters in the replacement string. $在replacement里可以用来表达pattern里的子序列，比如你真的会用java replaceAll函数吗？里举例的 System.out.println(&quot;abac&quot;.replaceAll(&quot;a(\\\\w)&quot;, &quot;$1$1&quot;)); //bbcc System.out.println(&quot;abac&quot;.replaceFirst(&quot;a(\\\\w)&quot;, &quot;$1$1&quot;)); //bbac所以在replacement里，我们要表达$怎么办？用\\来转义，于是代码里就这么写&quot;\\\\$&quot;接着在replacement里，我们要表达特殊的\\怎么办，需要用\\来转义\\，于是代码里就这么写\\\\\\\\。 而在replacement里，其他的转义该怎么写还是怎么写，比如&quot;System.out.println(&quot;abcd&quot;.replaceAll(&quot;a&quot;, &quot;\\t&quot;));&quot;,”a”就被替换成制表符了 按我的理解是存在两种转义，和正则处理一样，当你写&quot;\\\\&quot;的时候，Java第一次转义后在内存里就是\\，replacement检测到反斜杠，会将后面的字符表示为纯文本，所以写System.out.println(s.replaceAll(&quot;a&quot;, &quot;\\\\&quot;));是会报异常的，因为&quot;\\\\&quot;存在第二次转义，而第二次转义的时候后面没跟字符串，所以报异常。idea在写正则的时候，&quot;\\\\&quot;是会提示错误的，但是String.replaceAll里replacement写&quot;\\\\&quot;只有在运行时才检测得到。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"正则","slug":"正则","permalink":"https://htchz.cc/tags/正则/"}],"author":"土川"},{"title":"[Time]一个关于获取系统时间的优化","slug":"Time-一个关于获取系统时间的优化","date":"2018-04-27T18:10:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"3428339883.html","link":"","permalink":"https://htchz.cc/3428339883.html","excerpt":"这是在某个插件里看到的代码[滑稽]","text":"这是在某个插件里看到的代码[滑稽] 查了一下说是把System.currentTimeMillis()放到一个定时任务里可以提高性能，其实写个main测了一下感觉要很大的量级才有效果 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import java.util.concurrent.BrokenBarrierException;import java.util.concurrent.CyclicBarrier;import java.util.concurrent.TimeUnit;/** * 毫秒级系统时间, 显式调用System.currentTimeMillis()据说费性能 * */public class TimeUtil implements Runnable &#123; private static volatile long currentTimeMillis; static &#123; currentTimeMillis = System.currentTimeMillis(); // fetch system time for init Thread deamon = new Thread(new TimeUtil()); deamon.setDaemon(true); deamon.setName(\"time tick thread\"); deamon.start(); &#125; public void run() &#123; while(true)&#123; currentTimeMillis = System.currentTimeMillis(); try &#123; TimeUnit.MILLISECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; //unreachable &#125; &#125; &#125; public static long currentTimeMillis()&#123; return currentTimeMillis; &#125; public static void main(String[] args) &#123; int loop = 100000000; long start = System.currentTimeMillis(); CyclicBarrier barrier = new CyclicBarrier(2, () -&gt; System.out.println(\"begin\")); Thread thread1 = new Thread(() -&gt; &#123; try &#123; System.out.println(\"t1 start\"); barrier.await(); for (int i = 0; i &lt; loop; i++) &#123; System.currentTimeMillis(); &#125; System.out.println(\"t1:\" + (System.currentTimeMillis() - start) +\"ms\"); &#125; catch (InterruptedException | BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125;); Thread thread2 = new Thread(() -&gt; &#123; try &#123; System.out.println(\"t2 start\"); barrier.await(); for (int i = 0; i &lt; loop; i++) &#123; TimeUtil.currentTimeMillis(); &#125; System.out.println(\"t2:\" + (System.currentTimeMillis() - start) +\"ms\"); &#125; catch (InterruptedException | BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125;); thread2.start(); thread1.start(); &#125;&#125; 输出 t2 start t1 start begin t2:50ms t1:1135ms","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[],"author":"土川"},{"title":"[Cron]linux定时任务的坑","slug":"Cron-linux定时任务的坑","date":"2018-04-17T18:23:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"3058313917.html","link":"","permalink":"https://htchz.cc/3058313917.html","excerpt":"写了个脚本定时执行，有天发现命令没有正确找到我配在PATH的环境变量。","text":"写了个脚本定时执行，有天发现命令没有正确找到我配在PATH的环境变量。 用了gdrive来备份博客，日志看到 /root/gdrive-bak-blog.sh: line 2: gdrive: command not found百度一波发现cron读取环境变量有点搓，有两个解决方案 crontab里的命令先执行source 0 8 * * * source /etc/profile &amp;&amp; /root/gdrive-bak-blog.sh &gt; /root/blog-bak.out 2&gt;&amp;1 脚本里执行加载环境变量 #!/bin/sh source /etc/profile ...附上备份脚本 #! /bin/bash oldFileId=`gdrive list | grep &apos;hzblog.bak.tar.gz&apos; | awk &apos;{print $1}&apos;` if [ -z $oldFileId ] then echo &quot;no backup for hzblog.bak.tar.gz&quot; else gdrive delete $oldFileId echo &quot;hzblog.bak.tar.gz[id:$oldFileId] deleted&quot; fi rm -f /root/hzblog.bak.tar.gz tar -czPf hzblog.bak.tar.gz /root/hzblog parentId=`gdrive list | grep &apos;hzblog&apos; | awk &apos;{print $1}&apos;` gdrive upload -p $parentId /root/hzblog.bak.tar.gz echo &quot;hzblog.bak.tar.gz uploaded&quot;","categories":[{"name":"Linux","slug":"Linux","permalink":"https://htchz.cc/categories/Linux/"}],"tags":[],"author":"土川"},{"title":"[JDK8]Stream toMap遇到的坑","slug":"JDK8-Stream-toMap遇到的坑","date":"2018-04-17T03:19:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"2688045267.html","link":"","permalink":"https://htchz.cc/2688045267.html","excerpt":"略懂略懂。","text":"略懂略懂。 1. key重复写了这么一句代码 Map&lt;Long, Integer&gt; map = module.getStocks().stream().collect(Collectors.toMap(SkuStockDTO::getSkuId, SkuStockDTO::getSkuStock));当SkuStockDTO::getSkuId拿到相同id时会报java.lang.IllegalStateException: Duplicate key xxx其实java8已经给我们提供了解决的方式: 方法的第三个参数体现的第三个参数是一个merge策略 2. value为nullvalue为null的时候是会报空指针，java.util.stream.Collectors#toMap其实最终都是调用一个方法 12345678910111213141516171819202122232425262728293031 * @param &lt;T&gt; the type of the input elements * @param &lt;K&gt; the output type of the key mapping function * @param &lt;U&gt; the output type of the value mapping function * @param &lt;M&gt; the type of the resulting &#123;@code Map&#125; * @param keyMapper a mapping function to produce keys * @param valueMapper a mapping function to produce values * @param mergeFunction a merge function, used to resolve collisions between * values associated with the same key, as supplied * to &#123;@link Map#merge(Object, Object, BiFunction)&#125; * @param mapSupplier a function which returns a new, empty &#123;@code Map&#125; into * which the results will be inserted * @return a &#123;@code Collector&#125; which collects elements into a &#123;@code Map&#125; * whose keys are the result of applying a key mapping function to the input * elements, and whose values are the result of applying a value mapping * function to all input elements equal to the key and combining them * using the merge function * * @see #toMap(Function, Function) * @see #toMap(Function, Function, BinaryOperator) * @see #toConcurrentMap(Function, Function, BinaryOperator, Supplier) */public static &lt;T, K, U, M extends Map&lt;K, U&gt;&gt;Collector&lt;T, ?, M&gt; toMap(Function&lt;? super T, ? extends K&gt; keyMapper, Function&lt;? super T, ? extends U&gt; valueMapper, BinaryOperator&lt;U&gt; mergeFunction, Supplier&lt;M&gt; mapSupplier) &#123; BiConsumer&lt;M, T&gt; accumulator = (map, element) -&gt; map.merge(keyMapper.apply(element), valueMapper.apply(element), mergeFunction); return new CollectorImpl&lt;&gt;(mapSupplier, accumulator, mapMerger(mergeFunction), CH_ID);&#125; 可以看到始终都会调用Map.merge，而这个方法有如下代码 1Objects.requireNonNull(value); 解决方法是不用java.util.stream.Collectors#toMap，改用下面的姿势 12Map&lt;Integer, Boolean&gt; collect = list.stream() .collect(HashMap::new, (m,v)-&gt;m.put(v.getId(), v.getAnswer()), HashMap::putAll);","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"jdk8","slug":"jdk8","permalink":"https://htchz.cc/tags/jdk8/"}],"author":"土川"},{"title":"[JVM]G1","slug":"JVM-G1","date":"2018-04-02T09:23:00.000Z","updated":"2020-06-04T03:51:48.841Z","comments":true,"path":"2687941502.html","link":"","permalink":"https://htchz.cc/2687941502.html","excerpt":"不得不说G1有点难理解","text":"不得不说G1有点难理解 G1（Garbage First或者垃圾优先收集器）是CMS的下一代垃圾收集器，设计初衷是为了尽量缩短处理超大堆（大于4GB）时产生的停顿。相对于CMS的优势而言是内存碎片的产生率大大降低。 G1的老年代由于分Region的原因，可以对垃圾多的优先收集，垃圾少的先不处理，这样gc的时间就可控。而新生代在回收时会处理全部Region。 1. RegionG1将整个堆分为多个Region，一个Region可以代表Eden、Survivor、Old、Humongous； 其中带有Humongous的Region存储的是巨大对象(独占)，Humongous对象大小大于等于Region一半的对象，可能占有连续几个Region。这种独占的缺点是会造成空间浪费，所以region大小是一个调优点。 分区的大小可以通过-XX:G1HeapRegionSize调整，为1～32m且是2的幂。 2. TLABThread Local Allocation Buffer，从名字可以知道这是个线程私有的东西，Eden region有一部分会划分给用户线程，线程给新对象分配内存时，直接在自己TLAB分配；如果新对象超过TLAB的范围，需要对其他region进行加锁分配，或者新对象是Humongous，专门划分region存放。 3. PLABPromotion Thread Local Buffer，和TLAB类似，gc线程私有，eden region对象晋升到survivor region时优先分配在线程私有的region上 4. Collection Set(CSet)这是一个集合，记录了可被回收的Region，在gc时使用。G1利用Region分块的特性，对每一块Region做价值评估，构建一个可预测的时间停顿模型，如果Region值得回收，就会被放入CSet。新生代的Region都会被放入CSet 5. Remembered RSet(RSet)在[JVM]CMS里说过，使用了card table机制来维护老年代到新生代的引用关系。G1没用card table卡表来维护这些关系，而是在card table的基础上引入了RSet，每个Region都有一个RSet，RSet是一个hashtable，用来记录谁引用了我，是一种point-into设计，而card table是记录我引用了谁，是一种point-out设计。 引入RSet之后，对Region单独回收的时候就可以判断当前Region里的对象有没有被其他对象引用， card一般是512字节，所以Region与card是一对多的关系。前面说RSet是一个hash table，假如RegionA在索引为8848的card上有对象引用了RegionB，那么B的RSet应该有这样的键值对：key为RegionA的起始地址，value是个集合，card8848的索引是元素之一。 这样，RSet负责记录了老年代到新生代的引用，老年代到老年代的引用。进行YGC的时候，扫描Young Region的RSet，就可以知道老年代对新生代的引用；进行Mixed GC时只需要扫描Old Region的RSet就知道老年代到老年代的引用. RSet的更新也是使用write barrier来实现。 注意⚠️如果一个新生代对象引用了老年代对象，老年代对应的的RSet是不会更新的，这是因为老年代gc时新生代region都会扫描。 6. Snapshot-At-The-Beginning(SATB)SATB是个算法，目标是为了减少重标记时间，使用bitmap作为快照SATB将Region标上了5个指针，bottom、previous TAMS、next TAMS、top和end，top是Region最后一个对象的地址，bottom和end是Region的其始末，TAMS是top-at-mark-start，就是top指针的记录，也就是说previous TAMS、next TAMS是前后两次发生并发标记时top的位置（这里说的有点乱） 下面是G1论文的举例，ABC、DEF是两个周期 如果可回收的价值不大，一个Region可能会经历多个标记周期直到有回收的价值。 NextBitmap是这个标记周期的快照，PrevBitmap是上一个周期的快照。 bitmap是全局的。 大概过程是这样的，假设现在是第N轮，N=1 A，初始标记，stw，top赋值给NextTAMS，清空NextBitmap，将GCROOT可直接到达的对象入栈。 A和B之间有个并发标记，完了B的NextBitmap就是标记的结果，在并发标记过程中，分配的新对象会隐式标记，即视为存活对象。 B，重标记，stw，将satb_mark_queue里的对象进行可达性分析，并在NextBitmap标记 C，清理，将NextBitmap赋值给PrevBitmap，清空NextBitmap，NextTAMS和PrevTAMS交换位置 D，第N+1轮初始标记。。。 E，第N+1轮重标记，可以看到PrevBitmap是有值的，是上一轮的快照（注意，不是说这一轮这个区间的标记就照抄PrevBitmap，NextBitmap和PrevBitmap没有关系） F，第N+1轮清理。。。 总结：(1): [bottom, prevTAMS): 这部分里的对象存活信息可以通过prevBitmap来得知(2): [prevTAMS, nextTAMS): 这部分里的对象在第n-1轮concurrent marking是隐式存活的(3): [nextTAMS, top): 这部分里的对象在第n轮concurrent marking是隐式存活的 (话说为什么要两个bitmap找不到资料，我猜是因为标记没完成也可以gc，标记没完成的情况下只能用prevBitmap快照) 在[JVM]JVM中三色标记法中提到，三色标记法要解决漏标问题，CMS是打破了条件一，G1就是打破条件二。 在标记过程中，如果白色对象从灰色对象删除，删除时会执行pre_write_barrier，将白对象标记为灰色，放入一个线程私有的satb_mark_queue，如果队列已满，该队列会被送去一个全局队列，然后为该线程分配一个新队列。 1234567891011121314151617181920212223// This notes that we don&apos;t need to access any BarrierSet data// structures, so this can be called from a static context.template &lt;class T&gt; static void write_ref_field_pre_static(T* field, oop newVal) &#123; T heap_oop = oopDesc::load_heap_oop(field); if (!oopDesc::is_null(heap_oop)) &#123; enqueue(oopDesc::decode_heap_oop(heap_oop)); &#125;&#125;void G1SATBCardTableModRefBS::enqueue(oop pre_val) &#123; // Nulls should have been already filtered. assert(pre_val-&gt;is_oop(true), &quot;Error&quot;); if (!JavaThread::satb_mark_queue_set().is_active()) return; Thread* thr = Thread::current(); if (thr-&gt;is_Java_thread()) &#123; JavaThread* jt = (JavaThread*)thr; jt-&gt;satb_mark_queue().enqueue(pre_val); &#125; else &#123; MutexLockerEx x(Shared_SATB_Q_lock, Mutex::_no_safepoint_check_flag); JavaThread::satb_mark_queue_set().shared_satb_queue()-&gt;enqueue(pre_val); &#125;&#125; 7. write barrier上面说了RSet和SATB都是用write_barrier来实现，那么对象赋值时的伪代码如下： 12345void oop_field_store(oop* field, oop new_value) &#123; pre_write_barrier(field); // pre-write barrier: for maintaining SATB invariant *field = new_value; // the actual store post_write_barrier(field, new_value); // post-write barrier: for tracking cross-region reference &#125; 为了减少write_barrier的性能影响，这些都是批量处理的(SATB是将oldValue入队satb_mark_queue，RSet是入队dirty_card_queue)。 8. GC模式8.1. YoungGC(YGC)当Eden区满了之后，需要STW，进行新生代的垃圾收集。从GCROOT开始标记，并且跳过老年代，同时扫描新生代Region的RSet，对于存活的对象，移动到survivor，和CMS差不多。 8.2. MixedGC8.2.1. global concurrent marking指全局并发标记。可以通过命令-XX:InitiatingHeapOccupancyPercent来调整，默认45，一旦达到这个阈值就回触发一次并发收集周期。 全局并发标记其实就是应用SATB算法的过程，包括多个阶段： 初始标记（initial-mark）：STW，但是，通常这个工作是由YGC来承担的，也就是让下一次YGC工作久一点，这会增加CPU开销。这个阶段是为Region设置previous TAMS、next TAMS，所有在next TAMS之上的对象在这个并发周期内会被识别为隐式存活对象。使用bitmap来标记对象，不使用对象头的mark word。GC Root直接可达的对象会被压入mark stack; 并发标记（concurrent-mark）：可以通过-XX:ConcGCThreads设置线程数量，默认是-XX:ParallelGCThreads的四分之一。这个阶段会弹出mark stack的对象标记，并对其字段进行压栈，记录在bitmap；重复至栈空 重标记（remarking）：STW，将线程私有和全局的satb_mark_queue里的对象进行分析标记。 清理（cleanup）：不是垃圾回收，这个阶段主要识别空分区、RSet梳理、卸载class、回收Humongous，对老年代Region进行活度排序。 8.2.2. 与cms的比较这个过程有点像CMS的执行过程。总体上看，区别是重标记这个阶段，CMS需要从根集重新扫（见CMS），而STAB算法的写屏障是在对象删除时都要标记对象，避免漏标记。所以在remark阶段只需要扫描队列对象就可以了。 8.2.3. 拷贝存活对象（evacuation）STW，对标记为垃圾的对象进行清理。一次全局并发标记完成后，就开始回收了。 Young GC：选定所有新生代里的Region。通过控制新生代的region个数来控制young GC的开销。 Mixed GC：选定所有新生代里的Region，外加根据global concurrent marking统计得出收集收益高的若干老年代Region。在用户指定的开销目标范围内尽可能选择收益高的老年代Region。两代Region一起清理，这也就是为什么叫Mixed GC了。 对于存活下来的对象，转移到新分区上，这样相对于CMS，减少了内存碎片。 8.3. 可能的GC过程（from RednaxelaFX） 一个假想的混合的STW时间线： 启动程序-&gt; young GC-&gt; young GC-&gt; young GC-&gt; young GC + initial marking(… concurrent marking …)-&gt; young GC (… concurrent marking …)(… concurrent marking …)-&gt; young GC (… concurrent marking …)-&gt; final marking-&gt; cleanup-&gt; mixed GC-&gt; mixed GC-&gt; mixed GC…-&gt; mixed GC-&gt; young GC + initial marking(… concurrent marking …)… 9. 参考 Java Hotspot G1 GC的一些关键技术 G1垃圾收集器详解 https://hllvm-group.iteye.com/group/topic/44381 G1论文原文 面试官问我G1回收器怎么知道你是什么时候的垃圾？","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"GC","slug":"GC","permalink":"https://htchz.cc/tags/GC/"},{"name":"JVM","slug":"JVM","permalink":"https://htchz.cc/tags/JVM/"}],"author":"土川"},{"title":"[JVM]CMS","slug":"JVM-CMS","date":"2018-04-02T00:20:00.000Z","updated":"2020-04-02T10:29:26.793Z","comments":true,"path":"4242301031.html","link":"","permalink":"https://htchz.cc/4242301031.html","excerpt":"","text":"1. 什么是CMSConcurrent Mark Sweep。看名字就知道，CMS是一款并发、使用标记-清除算法的gc。CMS是针对老年代进行回收的GC。 2. CMS有什么用CMS以获取最小停顿时间为目的。在一些对响应时间有很高要求的应用或网站中，用户程序不能有长时间的停顿，CMS 可以用于此场景。 3. 执行流程(6个阶段) 初始标记(STW) 并发标记 预清理 可中断预清理 重标记(STW) 并发清理 重置 3.1. 初始标记 需要stw，暂停用户线程 标记GC ROOT直接关联到的对象 虽然CMS是针对老年代进行回收的GC，但为了完成GCROOT TRACING, 仍要扫描新生代 3.2. 并发标记 继续运行用户线程，标记活动和用户线程并发进行 由初始标记出发，所有可到达的对象都在本阶段中标记，使用三色标记法标记。 3.3. 预清理 由于重标记会导致stw，所以这个阶段目的为了尽可能减少stw时间 此阶段扫描。（1）老年代中card为dirty的对象；（2）幸存区(from和to)中引用的老年代对象。因此，这个阶段也需要扫描新生代+老年代。 3.3.1. cardCMS将老年代分为多个card，又使用一个card table索引card，有点像内存分页机制。 一个card一般是512字节。 当白色对象的引用被黑色对象时，会触发一道写屏障（write barrier）。写屏障会将黑色对象所在的card对应的card table索引处，标记为dirty card，将dirty card入队，将同时把白色对象标记为灰色。 所以预清理和重标记的可达性分析会将dirty card纳入。 另外，新生代的对象如果被老年代引用，如果每次Young GC都要扫描老年代是不现实的，所以Young GC也会扫描dirty card对应的对象进行分析。card table有个8位属性可以表明card的类型。 “屏障”老让我想到lol的“屏障”，“屏障”是保护的，一直以为“写屏障”是“写保护”之类的东西。其实就是一个写拦截器。 3.3.2. incremental updatecms的写屏障发生在堆内引用赋新值的时候，比如下面这段代码， 12345678public static void main(String[] args) &#123; Animal p = new Dog(); p.child = new Dog(); p.child.bark(); Animal q = p.child; p.child = null; q.bark();&#125; 在第4行cms开始标记，p.child是白色对象，在p.child被标记前，将p.child赋值给q，由于赋值局部变量表没有写屏障，所以这个p.child不会被记录下来，而p.child的引用又在第6行解除（如果是SATB是会记录的），然后假设此时并发标记完成。这样remark阶段就需要重新扫一遍根，否则就会漏掉这个白色对象。 与之相对的，G1的STABremark不用重新扫描根集，因为G1比较狠，只要是对象被删除就记录下来。 3.4. 可中断的预清理（abortable preclean）这个过程其实就是不停循环执行预清理。开启条件是： Eden的使用空间大于CMSScheduleRemarkEdenSizeThreshold，这个参数的默认值是2M； Eden的使用率小于CMSScheduleRemarkEdenPenetration，这个参数的默认值是50%。 退出的条件是 循环的次数超过了CMSMaxAbortablePrecleanLoops，这个参数如果没有设置就不会作为条件； 循环总时间超过了CMSMaxAbortablePrecleanLoops，这个参数默认值5000ms。 Eden的使用率大于等于CMSScheduleRemarkEdenPenetration。 这个就很奇妙了，大部分文章都是说可中断的预清理是为了缩短重标记的时间，但是我有另一个疑惑，为什么这个过程要Eden使用率小于50%开始，超过50%结束，我猜50%是个两次Young GC的中间，在这个时间退出abortable preclean进入remark阶段，就可以防止remark的STW和Young GC的STW连续，从而造成比较大的停顿。 另外，可以开启CMSScavengeBeforeRemark，在remark之前进行一次强制的Young GC。 3.5. 重标记（remark） 重标记需要STW（Stop The World） 暂停所有用户线程，从新生代、GCROOT进行可达性分析，标记活着的对象。 多线程操作 已标记过的不会再处理 重新扫描？那前面的工作是白给？其实不是，已标记过的不会再处理，所以重新扫描会遇到很多标记完成的对象。 3.6. 并发清理并发清理。用户线程被重新激活，同时清理那些无效的对象。 3.7. 重置CMS清除内部状态，为下次回收做准备。 4. 存在的问题 费cpu，gc线程和用户线程并发 card解决了漏标的问题，但解决不了误标，误标的即浮动垃圾，需要下一轮GC才能清楚。 由于垃圾回收阶段用户线程仍在执行，必需预留出内存空间给用户线程使用。因此不能像其他回收器那样，等到老年代满了再进行GC。有个CMSInitiatingOccupancyFraction设置一个百分比，表明达到这个值就进行垃圾回收，见《JVM-MinorGC与FullGC》的concurrent mode failure关键字 上面并发造成的，接下来是‘标记-清除’算法造成的，这个算法造成空间碎片，虚拟机还提供了另外一个参数CMSFullGCsBeforeCompaction，用于设置执行多少次不压缩的Full GC后，跟着来一次带压缩的（默认为0，每次进入Full GC时都进行碎片整理）。 5. 参考 关于“Concurrent Abortable Preclean”的疑问 CMS垃圾收集器详解 – 阿杜的世界","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"GC","slug":"GC","permalink":"https://htchz.cc/tags/GC/"},{"name":"JVM","slug":"JVM","permalink":"https://htchz.cc/tags/JVM/"}]},{"title":"[JVM]MinorGC与FullGC","slug":"JVM-MinorGC与FullGC","date":"2018-04-02T00:11:00.000Z","updated":"2020-03-17T14:37:38.140Z","comments":true,"path":"527051980.html","link":"","permalink":"https://htchz.cc/527051980.html","excerpt":"","text":"1. Minor GC？Full GC？ minor gc指的是在年轻代的gc full gc指的是整个堆的清理，包括年轻代和老年代(老年代的gc一般叫major gc) 2. 什么时候会触发Minor GC我们拿CMS来举例子。 Eden区域满了，或者新创建的对象大小 &gt; Eden所剩空间 CMS设置了CMSScavengeBeforeRemark参数，这样在CMS的Remark之前会先做一次Minor GC来清理新生代，加速之后的Remark的速度。这样整体的stop-the world时间反而短 Full GC的时候会先触发Minor GC 3. 什么时候触发Full GC Minor GC后对象晋升老年代，由于担保机制(看《[JVM]GC那些事(四)对象的分配回收策略》)，两种情况触发Full GC，一种晋升平均大小 &gt; 老年代剩余空间（基于历史平均水平），另一种存活对象 &gt; 老年代剩余空间（基于下一次可能要晋升的最大水平），两种情况都属于promotion failure 发生concurrent mode failure会引起Full GC，这种情况下会使用Serial Old收集器，是单线程的，对GC的影响很大。大对象(由PretenureSizeThreshold控制新生代直接晋升老年代的对象size阀值)不能进入到老年代，只有stop the world来暂停用户线程，执行GC清理。可以通过设置CMSInitiatingOccupancyFraction预留合适的CMS执行时剩余的空间 （jdk8 已完全移除永久代，将此类信息放入本地内存）Perm永久代空间不足会触发Full GC，可以让CMS清理永久代的空间。设置CMSClassUnloadingEnabled即可 System.gc()引起的Full GC，可以设置DisableExplicitGC来禁止调用System.gc引发Full GC concurrent mode failure，即启动不了并发清理，因为内存不足导致并发情况下，还没来得及清理内存就爆了，所以要退化为串行的垃圾收集 promotion failure，即担保机制失败 4. 什么时候OOM OOM不是内存达到100%才报的 当花在GC的时间超过了GCTimeLimit，这个值默认是98% 当GC后的容量小于GCHeapFreeLimit，这个值默认是2% 5. 什么是空间不够 剩余空间不够不是说整体的空间不够分配某个对象，而是说连续的空间不够分配给某个对象。所以一旦内存碎片大多就可能发生剩余空间不够的问题，所以CMS这种收集器，需要在标记-清除几次之后进行压缩，进行优化。CMSFullGCsBeforeCompaction可以设置进行几次清除之后进行压缩 6. 其他的一些tip JMI默认会一个小时调用一次System.gc()清理缓存，所以可以DisableExplicitGC，也可以设置sun.rmi.dgc.client.gcInterval和sun.rmi.dgc.server.gcInterval参数来规定JMI清理的时间 一旦对象进入了老年代，那么只有触发CMS(只针对CMS而言)或者Full GC的时候才能被清除。 CMS不等于Full GC，很多人会认为CMS肯定会引发Minor GC。CMS是针对老年代的GC策略，原则上它不会去清理新生代，只有设置CMSScavengeBeforeRemark优化时，或者是concurrent mode failure的时候才会去做Minor GC。 对于性能调优来说，应该理解对于给定的硬件，给定的算法(垃圾收集器)，单个/多个线程单位时间内能够回收的空间是接近一个常量的。如果想要缩短GC的时候，就要考虑是否要相应调小空间 CMS收集器会了减少stop the world的时间，让GC线程和业务线程并发，这样也就相对拉长了CMS收集器单次GC的时间 尽可能地让对象停留在新生代，因为新生代采用了复制算法，相对收回得更快，而且Minor GC的次数肯定比Full GC多，那么对象在新生代被清除的更能性会更高。而对象一旦进入到老年代，那么只有Full GC时才会回收，对象在整个系统停留的时间就会很长，很可能创建的它的线程早就死了，而它还活着 为了尽可能让对象停留在新生代，就要注意设置Survivor区域的大小，因为它直接和对象是否进入老年代相关。之前就遇到过这种情况，明明新生代还有很大的空间，但是每次Minor GC后总是有对象进入到了老年代。后来发现由于Survivor太小，导致Tenuring Threshold为1，意思是年龄为1的对象大小超过了Survivor / 2(可通过TargetSurvivorRatio来调节，默认是50，即1/2)，年龄只要超过1的对象这时候就要直接进入老年代了。而进入老年代，对象就只有在Full GC的时候才会被清除。而如果调大了Survivor空间，让对象对象尽量接近Max Tenuring Threshold时才进入到老年代，这时候会大大减少老年代的对象大小，并且让对象在新生代停留时间变长，提高了它们被快速清理出系统的概率。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"GC","slug":"GC","permalink":"https://htchz.cc/tags/GC/"},{"name":"JVM","slug":"JVM","permalink":"https://htchz.cc/tags/JVM/"}],"author":"土川"},{"title":"[JVM]垃圾收集器","slug":"JVM-垃圾收集器","date":"2018-04-01T23:52:00.000Z","updated":"2020-03-17T14:54:15.191Z","comments":true,"path":"1597842502.html","link":"","permalink":"https://htchz.cc/1597842502.html","excerpt":"","text":"列一下从古到今主流的垃圾收集器 1. Serial收集器——最基本、发展历史最悠久的代收集器Serial收集器是一个单线程的收集器，而且进行垃圾回收时，必须停掉所有其他线程优点：简单高效，单线程可以获得最高的收集效率 Client端下的虚拟机是个很好的新生代收集器 2. ParNew 收集器——Serial的多线程版本除了使用多条线程进行垃圾收集之外，其余行为包括Serial收集器可用的所有控制参数、收集算法、stop the world、对象分配规则、回收策略等都与Serial收集器一样 Server模式下的的首选新生代收集器，可以和CMS配合工作 效果不一定超过Serial，但随着CPU数量的增加，他对于GC是系统资源的有效利用还是很有好处的。 3. Parallel Scavenge收集器Parallel Scavenge是一个新生代收集器，也使用复制算法，并行的多线程收集器。Parallel Scavenge的目标是达到一个可控制的吞吐量 吞吐量 = 运行用户代码时间 / （运行用户代码时间 + 垃圾收集时间） 虚拟机总共运行了100分钟，其中垃圾手机花掉1分钟，吞吐量就99% Parallel Scavenge用了两个参数用于精确控制吞吐量，分别是控制最大垃圾收集停顿时间（-XX:MaxGCPauseMillis）和直接设置吞吐量大小（GCTimeRatio）的参数 MaxGCPauseMillis参数允许的值是一个大于0的毫秒数，收集器尽可能地保证内存回收花费时间不超过设定值。 若参数太小，GC停顿时间是以牺牲吞吐量和新生代空间来换取。把新生代调小，收集速度变快，但GC会更频繁，吞吐量就下降了。 GCTimeRatio是一个[0,100]的整数，也就是垃圾收集时间占总时间的比率，相当于吞吐量的倒数。 如果把参数设置为19， 则允许的最大GC时间就占总时间的5%5（即1/（1+19 ）） 由于和吞吐量关系密切，Parallel Scavenge也被称为“吞吐量优先”收集器 Parallel Scavenge还有一个参数 -XX:+UseAdaptiveSizePolicy,这是个开关参数，当开关打开后，就不需要手工指定：新生代的大小（-Xmn）、Eden与Survivor的比例（-XX:SurvivorRatio）、晋升老年代对象大小（-XX:PretenureSizeThreshold）等细节参数了。虚拟机会根据当前系统情况收集性能监控信息，动态调整这些参数以达到最合适的停顿时间或吞吐量，这叫GC自适应的调节策略（GC Ergonomics） 如果用户对收集器运作不了解，可以将优化任务交给虚拟机，只要设置好基本参数（如最大堆），然后使用控制最大垃圾收集停顿时间（-XX:MaxGCPauseMillis）和直接设置吞吐量大小（GCTimeRatio）给虚拟机设定一个优化目标 自适应调节策略也是Parallel Scavenge和ParNew的重要区别 4. Serial Old收集器Serial Old是Serial的老年代版本，主要也是给Client模式下的虚拟机使用。如果在Server 模式下，还有两大用途： 一种是在jdk1.5及以前版本中与Parallel Scavenge收集器搭配使用 一种是作为CMS的后备预案，在并发收集发生Concurrent Mode Failure时使用 5. Parallel Old 收集器Parallel Old 是Parallel Scavenge的老年代版本，jdk1.6之后才提供，解决在server端Serial Old性能上的拖累，若使用Serial Old + Parallel Scavenge，这种组合的吞吐量不一定有 ParNew + CMS的组合给力 注重吞吐量和CPU资源敏感的场合，都可以优先考虑 Parallel Old + Parallel Scavengede 组合 6. CMS 收集器CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器，在网站设计中此收集器就符合需求。 运作过程： 初始标记 并发标记 重新标记 并发清除 其中初始标记和重新标记这两个步骤仍然需要“Stop The World”，初始标记只是标记GC Roots能直接关联的对象，速度很快并发标记进行GC Roots Tracing 的过程，而重新标记阶段是为了修正并发标记期间产生变动的标记，停顿&gt;初始标记，&lt;&lt;并发标记 缺点： 并发阶段，不会导致用户线程停顿，但会占用CPU 资源导致应用变慢，总吞吐量降低。为了应付这种情况，虚拟机提供了一种“增量式并发收集器”的CMS变种，就是在并发标记、清理的时候让GC线程、用户线程交替运行，尽量减少GC线程独占资源的时间，这样整个GC收集时间会变长，但对程序的影响就会变小一些。（事实证明，效果一般，不推荐使用） CMS无法处理浮动垃圾（Floating Garbage），可能出现Concurrent Mode Failure失败导致另一次Full GC的产生 基于“标记-清除”，产生过多碎片。设计者设置了一个参数（默认值为0），用于设置执行多少次不压缩的Full GC 之后来一次压缩的！ 7. G1收集器——最前沿的成果之一 G1收集器已在JDK 1.7 u4版本正式投入使用。 与其他GC收集器相比，特点： 并行与并发：充分利用多核环境，通过并发的方式在GC过程中让java程序继续运行，缩短Stop-The-World的时间 分代收集： 空间整合：不会产生空间碎片 可预测的停顿：相对于CMS的另一大优势，建立可预测的模型，使用者明确指定在一个M秒时间段内GC时间不能超过N秒 在使用G1收集器的时候，java堆内存就和其他收集器有很大的差别。它将内存分为大小相等的独立区域，虽有老年代和新生代，但新老不隔离，都是Region的一部分集合建立可预测的停顿时间模型：不用再堆中全区域收集。 G1收集器估计所有region的价值大小，建立一个优先列表，大的先收集，所以叫“Garbage-First” 除去维护Remembered Set 的操作，G1收集器的运作大致可以分为 初始标记 并发标记 最终标记 筛选回收","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"GC","slug":"GC","permalink":"https://htchz.cc/tags/GC/"},{"name":"JVM","slug":"JVM","permalink":"https://htchz.cc/tags/JVM/"}],"author":"土川"},{"title":"[JVM]对象的分配回收策略","slug":"JVM-对象的分配回收策略","date":"2018-03-29T08:10:00.000Z","updated":"2020-03-17T06:21:13.111Z","comments":true,"path":"476673891.html","link":"","permalink":"https://htchz.cc/476673891.html","excerpt":"一个对象被new出来分配在哪呢。一个对象的分配，往大方向上讲，就是在堆分配","text":"一个对象被new出来分配在哪呢。一个对象的分配，往大方向上讲，就是在堆分配 内存分配规则不是固定的，取决于虚拟机参数、GC组合类型 1. 对象优先在Eden分配大多数情况下对象再新生代Eden区中分配，当没有足够的空间时，虚拟机将发起一次Minor GC。 2. 大对象直接进入老年代所谓的大对象就是指需要连续空间的java对象，最典型的是数组和字符串。（应避免短命大对象） 3. 长期存活的对象将进入老年代每个对象有对象年龄（Age）计数器。每次在minor GC后仍存在且能被survivor区容纳的话，年龄就+1（初始为0），达到一个阈值（默认15），就晋升到老年代中 4. 动态对象年龄判定 并不是必须达到年龄才可以晋升老年代 如果在Survivor空间中，相同年龄所有对象大小总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代。 5. 空间分配担保Minor GC之前，如果老年代最大可用的连续空间大于新生代所有对象总空间，则GC安全。否则，检查是否允许担保失败（HandlePromotionFailure的值）。如果允许，则继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小。如果大于，则尝试Minor GC。如果小于或者不允许，则改为Full GC jdk 6u24 之后，HandlePromotionFailure已经不影响分配担保策略了。如果老年代最大可用的连续空间大于新生代所有对象总空间，或者大于历次晋升到老年代对象的平均大小，则进行Minor GC，否则Full GC。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"GC","slug":"GC","permalink":"https://htchz.cc/tags/GC/"},{"name":"JVM","slug":"JVM","permalink":"https://htchz.cc/tags/JVM/"}],"author":"土川"},{"title":"[JVM]HotSpot算法的实现","slug":"JVM-HotSpot算法的实现","date":"2018-03-29T07:59:00.000Z","updated":"2020-03-17T06:21:41.100Z","comments":true,"path":"1666990746.html","link":"","permalink":"https://htchz.cc/1666990746.html","excerpt":"什么时机适合进行GC","text":"什么时机适合进行GC HotSpot虚拟机实现这些算法的时候，必须对算法的执行效率有严格的考量，才能保证虚拟机的高效执行。 1. 枚举根节点从GC Roots 节点找引用链这个操作，仅方法区就有有几百兆，若逐个检查，必定消耗很多时间而且，在检查的时候必须 stop the world 停顿一下， 即保证操作的原子性，不能在分析的时候引用链还在变化 HotSpot的实现是使用一组OopMap的数据结构来达到这个目的的。在类加载完成的时候，HotSpot就把对象内什么偏移量上的什么类型的数据计算出来。在JIT编译中，也会在特定的位置记录下栈和寄存器。这样GC在扫描的时候就可以通过记录中的指令直接得到引用的位置信息。 2. 安全点（Safe Point）前面提到，OopMap是在特定的位置记录了指令信息，这些位置称为安全点。只有到达安全点的时候，才能进行GC。安全点不能选择太少以至于让GC等待时间太长，不又能过于频繁以至于增大运行时负荷。 安全点的选定是以程序“是否具有让程序长时间执行的特征”为标准进行选定的（之所以不以指令流的长度为标准，因为指令执行时间很短），长时间执行的最明显特征就是指令序列复用，如方法调用，循环跳转，异常跳转等 GC发生时如何让所有线程都跑到最近的安全点停顿，有两种方式：抢先式中断（Preemptive Suspension）和主动式中断（Voluntary Suspension） 抢先式中断：GC时中断所有线程，若某线程中断的地方不是安全点，恢复线程，跑到安全点。现在几乎没人用 主动式中断：GC需要中断时，不对线程直接操作，设置一个标志（与安全点重合，如把安全点的指令的内存页设置为不可读，线程会异常中断并挂起），线程执行时自动轮询这个标志，然后线程运行到中断标志的时候会自动中断并挂起 3. 安全区域（Safe Region）若程序”不执行“（即没有分配CPU时间，典型的例子是线程处于“Sleep”“Blocked”状态），这时程序不能继续运行到中断标志挂起，这时需要安全区域来解决。 当线程执行到安全区域时，标识自己进入了安全区域。若发生GC，就不用管标识为安全区域的线程。线程若要离开安全区域，必须检查系统是否完成了根节点枚举（或者整个GC过程）。如果完成了，就继续线程。否则，等待直到收到可以离开安全区域的信号为止。","categories":[],"tags":[{"name":"GC","slug":"GC","permalink":"https://htchz.cc/tags/GC/"},{"name":"JVM","slug":"JVM","permalink":"https://htchz.cc/tags/JVM/"}],"author":"土川"},{"title":"[JVM]垃圾回收算法简介","slug":"JVM-垃圾回收算法简介","date":"2018-03-27T03:08:00.000Z","updated":"2020-03-17T14:54:21.322Z","comments":true,"path":"2456754784.html","link":"","permalink":"https://htchz.cc/2456754784.html","excerpt":"识别出了垃圾以后怎么清除呢。","text":"识别出了垃圾以后怎么清除呢。 下面的几种垃圾回收算法在不同的空间都有不同应用。 1. 标记-清除算法（Mark-Sweep）标记出所有要回收的对象，然后统一回收。不足： 效率低下 空间碎片太多（导致分配大对象没有连续空间，不得不触发另一次垃圾收集动作） 2. 复制算法基于前面的算法，把内存按容量分为两部分，第一次使用其中一部分，在gc完成后将存活对象复制到另一部分内存，清除第一部分的内存。 但是按照把内存划分为两半，可用内存就缩小为一半，代价真他妈高 于是现代的商业虚拟机都是采用这种方式，但不是1：1分配内存而是分为一块较大的Eden和两块较小的Survivor(一般来说是8：1：1)。当回收时，将Eden和Survivor中的存活对象一次性地复制到另外一块Survivor空间上，清理掉原来的Eden和Survivor中的空间 2.1. 为什么要有两块Survivor假设有survivor1和survivor2，那么eden和survivor1进行minor gc后一般survivor1会有内存碎片，这时候把存活对象放进空的survivor2，清空survivor1，就能解决内存碎片化问题。 2.2. 为什么不设多点survivor两块够了。。 如果空间不足，则使用分配担保机制来申请内存 3. 标记-整理算法复制收集算法在对象存活率较高时就要进行较多的复制操作，效率变低。标记-整理算法在标记之后，将存活对象都往一端移动，最后直接清理端边界以外的内存。 4. 分代收集算法将内存分为“新生代”“老年代”，新生代使用复制算法。老年代是用标记-清除算法、标记-整理算法。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"GC","slug":"GC","permalink":"https://htchz.cc/tags/GC/"},{"name":"JVM","slug":"JVM","permalink":"https://htchz.cc/tags/JVM/"}],"author":"土川"},{"title":"[JVM]判断对象已死（含GC ROOT）","slug":"JVM-判断对象已死","date":"2018-03-26T18:17:00.000Z","updated":"2020-06-04T10:09:31.123Z","comments":true,"path":"2872318404.html","link":"","permalink":"https://htchz.cc/2872318404.html","excerpt":"","text":"看过《深入java虚拟机》，里面对GC的讲解看完有个大概了解。于是自己总结一下。 怎么判断一个对象已死，是GC的第一步。 1. 引用计数法引用计数法就是当对象的引用为0时，才进行GC。事实上这是不可行的。看下面的示例。 对象a和b都有一个instance字段，如果执行a.instance = b;b.instance = a;a = null;b = null; 上面的两个对象相互引用着，引用数都为1，但是a和b指的对象都不能再被访问，理论上在内存中是垃圾，但两个对象无法被gc回收。 2. 可达性分析算法我们一般通过可达性分析算法来确认对象的存活。 通过一系列的成为GC Roots的引用作为起始点，从这些节点开始向下搜索，搜索走过的路径称为引用链（Reference Chain） 当一个对象到GC Roots没有任何引用链相连时，证明此对象不可用 在java中可以作为GC Roots的包括下面几种 虚拟机栈中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法中JNI引用的对象 被加载的类 Java中什么样的对象才能作为gc root，gc roots有哪些呢？ 3. 再谈引用java引用在jdk1.2之后进行了扩充，分为强引用（Strong Reference）、软引用（Soft Reference）、弱引用（Weak Reference）、虚引用（Phantom Reference） 强引用最普遍，GC不会回收被引用的对象 软引用用来描述还有用但非必需的对象，要发生OOM时进行清理 弱引用用来描述非必需的，只能生存到下次GC收集之前。如果没有强引用引用着这个弱引用对象，就可以在GC回收掉。 虚引用也称为幽灵引用和幻影引用。为一个对象设置虚引用的唯一目的：在这个对象被收集器回收时收到一个系统通知 4. 生存还是死亡一个对象进行可达性分析算法后如不可达，也只是进入缓刑。真正宣告一个对象死亡，要经历两次标记： 没有和GC Roots相连接，没有则第一次标记 被第一次标记过的对象进行筛选，若未重写finalize()方法或对象被执行过一次finalize()，则没必要执行finalize()方法，死刑 若对象有必要执行finalize()方法，则对象会被放在一个F-Queue中，并稍后有虚拟机创建的一个低优先级的线程去触发方法。 对象可以在finalize()方法中自救，比如把自己this赋值给某个变量 尽量别使用这个运行代价高昂的方法finalize() 5. 回收方法区此处回收两部分内容： 废弃常量和无用的类 回收废弃常量和回收java堆中的对象很相似：假如一个字符串“abc”被放进常量池，但系统没有一个string对象是“abc”的，那么内存回收时，“abc”会被清理 判断一个类是否是无用的类条件比较苛刻，需满足下面三个： 该类所有实例被回收 加载该类的ClassLoader已经被回收 对应的java.lang.Class 对象没有在任何地方被引用，无法通过反射访问该方法 满足以上三个才“可以”（不是必然）被回收。虚拟机提供了一些参数进行回收 在大量使用反射的框架、动态代理的框架、jsp等频繁自定义ClassLoader的场景都需要具备类卸载功能","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"GC","slug":"GC","permalink":"https://htchz.cc/tags/GC/"},{"name":"JVM","slug":"JVM","permalink":"https://htchz.cc/tags/JVM/"}],"author":"土川"},{"title":"[建站]Linode开启Google BBR的正确方法","slug":"建站-Linode开启Google-BBR的正确方法","date":"2018-03-26T15:55:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"1807419896.html","link":"","permalink":"https://htchz.cc/1807419896.html","excerpt":"在linode一直开启不了bbr加速，在一个老哥的博客看到这个传送门","text":"在linode一直开启不了bbr加速，在一个老哥的博客看到这个传送门 简单来说，Linode服务器的内核是要在配置页面修改才能正确引导的，而且4.9.0以上的liux内核都编译了tcp_bbr加速模块，所以不用自己配置了。 还有一点，lsmod找不到tcp_bbr，博主说有一种说法是，Linode自带的内核都是把模块都编译一块的，所以lsmod里看不到正常，lsmod是看额外加载的模块的。 Linode冲5刀送20刀，快去啊，不过填个人信息得填优惠码和另一个忘了什么鬼码，否则没有20刀。","categories":[{"name":"建站","slug":"建站","permalink":"https://htchz.cc/categories/建站/"}],"tags":[{"name":"bbr","slug":"bbr","permalink":"https://htchz.cc/tags/bbr/"}],"author":"土川"},{"title":"[Mysql]查询条件的类型强转","slug":"Mysql-查询条件的类型强转","date":"2018-03-23T08:44:00.000Z","updated":"2020-04-25T16:11:44.442Z","comments":true,"path":"3095735483.html","link":"","permalink":"https://htchz.cc/3095735483.html","excerpt":"网上看到的类型强转的引起了慢查询，自己建表试了一下果真如此。","text":"网上看到的类型强转的引起了慢查询，自己建表试了一下果真如此。 1. 建表CREATE TABLE `users` ( `userID` int(11) NOT NULL AUTO_INCREMENT, `username` varchar(20) NOT NULL, `password` varchar(20) NOT NULL, `age` int(4) DEFAULT NULL, PRIMARY KEY (`userID`), KEY `password` (`password`), KEY `age` (`age`) USING BTREE ) ENGINE=InnoDB AUTO_INCREMENT=100003 DEFAULT CHARSET=utf8;插入了10w条数据 2. 执行explain这是第一种：这是第二种： 两条语句的差别是对于字符索引，查询条件加不加引号的区别 从上面可以很明显的看到由于password是varchar，在where条件中不加’’，会引发全索引查询(type=index比type=all还是快的)，加了就可以用到索引（type=ref），这扫描的行数可是天差地别，对于服务器的压力和响应时间自然也是天差地别的。 我们看第三种： 我们看第四种 对于整型，加了引号与否影响不大，只是差别在Extra栏 rows有5w是因为10w行的age都是1。。。，如果改为离散的值，rows会下降很多。 以下是5.5官方手册的说明： If both arguments in a comparison operation are strings, they are compared as strings.两个参数都是字符串，会按照字符串来比较，不做类型转换。If both arguments are integers, they are compared as integers.两个参数都是整数，按照整数来比较，不做类型转换。Hexadecimal values are treated as binary strings if not compared to a number.十六进制的值和非数字做比较时，会被当做二进制串。If one of the arguments is a TIMESTAMP or DATETIME column and the other argument is a constant, the constant is converted to a timestamp before the comparison is performed. This is done to be more ODBC-friendly. Note that this is not done for the arguments to IN()! To be safe, always use complete datetime, date, or time strings when doing comparisons. For example, to achieve best results when using BETWEEN with date or time values, use CAST() to explicitly convert the values to the desired data type.有一个参数是 TIMESTAMP 或 DATETIME，并且另外一个参数是常量，常量会被转换为 timestampIf one of the arguments is a decimal value, comparison depends on the other argument. The arguments are compared as decimal values if the other argument is a decimal or integer value, or as floating-point values if the other argument is a floating-point value.有一个参数是 decimal 类型，如果另外一个参数是 decimal 或者整数，会将整数转换为 decimal 后进行比较，如果另外一个参数是浮点数，则会把 decimal 转换为浮点数进行比较In all other cases, the arguments are compared as floating-point (real) numbers.所有其他情况下，两个参数都会被转换为浮点数再进行比较 根据以上的说明，当where条件之后的值的类型和表结构不一致的时候，MySQL会做隐式的类型转换，都将其转换为浮点数在比较。 mysql&gt; SELECT CAST(&apos; 1&apos; AS SIGNED)=1; +-------------------------+ | CAST(&apos; 1&apos; AS SIGNED)=1 | +-------------------------+ | 1 | +-------------------------+ 1 row in set (0.00 sec) mysql&gt; SELECT CAST(&apos; 1a&apos; AS SIGNED)=1; +--------------------------+ | CAST(&apos; 1a&apos; AS SIGNED)=1 | +--------------------------+ | 1 | +--------------------------+ 1 row in set, 1 warning (0.00 sec) mysql&gt; SELECT CAST(&apos;1&apos; AS SIGNED)=1; +-----------------------+ | CAST(&apos;1&apos; AS SIGNED)=1 | +-----------------------+ | 1 | +-----------------------+ 1 row in set (0.00 sec) 比如where string = 1，需要将索引中的字符串转换成浮点数，但是由于’1’,’ 1’,’1a’都会比转化成1,故MySQL无法直接使用索引只能进行全表扫描，故造成了慢查询的产生。 同时需要注意一点，由于都会转换成浮点数进行比较，而浮点数只有53bit，故当超过最大值的时候，比较会出现问题。 由于索引建立在int的基础上，而将纯数字的字符串可以百分百转换成数字，故可以使用到索引，虽然也会进行一定的转换，消耗一定的资源，但是最终仍然使用了索引，不会产生慢查询。 mysql&gt; select CAST( &apos;30&apos; as SIGNED) = 30; +----------------------------+ | CAST( &apos;30&apos; as SIGNED) = 30 | +----------------------------+ | 1 | +----------------------------+ 1 row in set (0.00 sec)","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://htchz.cc/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://htchz.cc/tags/Mysql/"}],"author":"土川"},{"title":"[JVM]Java对象的组成、大小计算","slug":"JVM-对象的组成","date":"2018-03-22T14:23:00.000Z","updated":"2020-03-17T14:53:31.731Z","comments":true,"path":"2006878642.html","link":"","permalink":"https://htchz.cc/2006878642.html","excerpt":"基于Hotspot，我们给自己一个对象 :(","text":"基于Hotspot，我们给自己一个对象 :( 1. Java对象模型Hotspot主要是用C++写的，所以它定义的Java对象表示模型也是基于C++实现的。 Java对象的表示模型叫做“OOP-Klass”二分模型，包括两部分: OOP，即Ordinary Object Point，普通对象指针，说白了就是表示对象除了元数数据之外的信息。 Klass，即Java类的C++对等体，用来描述Java类，包含了元数据和方法信息 一个Java对象就包括两部分，数据和方法，分别对应到OOP和Klass。 JVM运行时加载一个Class时，会在JVM内部创建一个instanceKlass对象，表示这个类的运行时元数据。创建一个这个Class的Java对象时，会在JVM内部相应的创建一个instanceOop来表示这个Java对象。熟悉JVM的同学可以明白，instanceKlass对象放在了方法区，instanceOop放在了堆，instanceOop的引用放在了JVM栈。 JVM是基于栈来运行的，当一个线程调用一个对象的方法时，会在它的JVM栈的栈顶创建一个栈帧（Frame）的数据结构，这个数据结构是用来保存方法的局部变量，操作数栈，动态连接和方法返回值的。通过参数传递的值和在方法中new出来的对象的引用都保持在局部变量表里面。 Java的方法调用是值传递，不是引用传递，原因就在这里，传递进来的参数相当于在局部变量表里面拷贝了一份，实际计算时，操作数栈操作的是局部变量变量里面的值，而不是外部的变量。 在堆中创建的Java对象实际只包含数据信息，它主要包含三（四）部分： 对象头，也叫Markword 元数据指针，可以理解为类对象指针，指向方法区的instanceKlass实例。如果是32位的，默认开启对象指针压缩，4个字节 实例数据 (如果是数组对象的话，还多了一个部分，就是数组长度)，4个字节 另外还有Padding(内存对齐)，按照8的倍数对齐 对象头代表的意义是可变的，通过标志位决定。主要存储对象运行时记录信息，如hashcode, GC分代年龄，锁状态标志，偏向线程ID，偏向时间戳等。对象头的长度和JVM的字长一致，比如32位JVM的对象头是32位，64位JVM的对象头是64位。下面是对于64位jvm的markword的说明 偏向锁标识位 锁标识位 锁状态 存储内容 0 01 未锁定 hashcode(31),年龄(4) 1 01 偏向锁 线程ID(54),时间戳(2),年龄(4) 无 00 轻量级锁 栈中锁记录的指针(64) 无 10 重量级锁 monitor的指针(64) 无 11 GC标记 空，不需要记录信息 所谓的给一个对象加锁，其实就是设置了对象头标志位。当其他线程看到这个对象的状态是加锁状态后，就等待释放锁。关于锁我们另开一篇。 在方法区的instanceKlass对象相当于Class加载后创建的运行时对象，它包含了运行时常量池，字段，方法等元数据，当调用一个对象的方法时，如上面的图所示，实际定位到了方法区的instanceKlass对象的方法元数据。 2. 使用HSDB调试 HSDB是一款内置与SA的GUI调试工具，集成了各种JVM监控工具，可以用来深入分析JVM内部状态。这玩意在windows的jdk7才自带，mac和linux吓得jdk6就有了。 首先我们运行一个程序，并打上断点。 1234567891011121314151617181920public class Person &#123; private String name; private int age; private boolean sex; public void sayHi()&#123; System.out.println(&quot;Say hi from ITer_ZC&quot;); &#125; public static void main(String[] args)&#123; Person p = new Person(); p.sayHi(); try &#123; Thread.sleep(500000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 上面断点用sleep代替。好像还可以用jdb工具断点，没研究 - - 启动程序，运行jps命令，查看当前java进程id， 1234C:\\Users\\zack.huang&gt;jps75248276 Jps4552 Person 由4552 Person得知4552是上面java程序的id，接着运行下面的命令， java -cp sa-jdi.jar sun.jvm.hotspot.HSDB sa-jdi.jar在%JAVA_HOME%\\lib目录下，不过我的JAVA_HOME路径好像因为带了空格老启动不了，直接把jar复制到桌面了启动。 界面一片白。 输入pid之后，显示可以看到Personde的地址 在inspector里面查看0x00000007c0060028，我们可以看到instanceKlass的字段，方法，运行时常量池，父类，兄弟类等元数据信息 在Object Histogram里面找到Person对象 查看Person Oop的运行时实例 _mark就是对象头，接着是实例数据信息。HSDB没有显示类对象指针 3. 计算对象的大小程序计算方法 通过java.lang.instrument.Instrumentation的getObjectSize(obj)直接获取对象的大小 通过sun.misc.Unsafe对象的objectFieldOffset(field)等方法结合反射来计算对象的大小 3.1. java.lang.instrument.Instrumentation.getObjectSize()的方式讲讲java.lang.instrument.Instrumentation.getObjectSize()的方式，这种方法得到的是Shallow Size，即遇到引用时，只计算引用的长度，不计算所引用的对象的实际大小。如果要计算所引用对象的实际大小，可以通过递归的方式去计算。 java.lang.instrument.Instrumentation的实例必须通过指定javaagent的方式才能获得，具体的步骤如下： 定义一个类，提供一个premain方法: public static void premain(String agentArgs, Instrumentation instP) 创建META-INF/MANIFEST.MF文件，内容是指定PreMain的类是哪个： Premain-Class: sizeof.ObjectShallowSize 把这个类打成jar，然后用java -javaagent XXXX.jar XXX.main的方式执行 下面先定义一个类来获得java.lang.instrument.Instrumentation的实例,并提供了一个static的sizeOf方法对外提供Instrumentation的能力 123456789101112131415package sizeof; import java.lang.instrument.Instrumentation; public class ObjectShallowSize &#123; private static Instrumentation inst; public static void premain(String agentArgs, Instrumentation instP)&#123; inst = instP; &#125; public static long sizeOf(Object obj)&#123; return inst.getObjectSize(obj); &#125; &#125; 定义META-INF/MANIFEST.MF文件 Premain-Class: sizeof.ObjectShallowSize 打成jar包 cd 编译后的类和META-INF文件夹所在目录 jar cvfm java-agent-sizeof.jar META-INF/MANIFEST.MF . 准备好了这个jar之后，我们可以写测试类来测试Instrumentation的getObjectSize方法了。在这之前我们先来看对象在内存中是按照什么顺序排列的，字段的定义按如下顺序 123456789private static class ObjectA &#123; // 注释是对应类型占的字节空间 String str; // 4 int i1; // 4 byte b1; // 1 byte b2; // 1 int i2; // 4 ObjectB obj; //4 byte b3; // 1 &#125; 按照我们之前说的方法来计算一下这个对象所占大小，注意按8对齐： 8(_mark) + 4(元数据指针) + 4(str) + 4(i1) + 1(b1) + 1(b2) + 2(padding) + 4(i2) + 4(obj) + 1(b3) + 7(padding) = 40 ?但事实上是这样的吗？ 我们来用Instrumentation的getObjectSize来计算一下先: 1234567891011121314151617181920212223package test; import sizeof.ObjectShallowSize; public class SizeofWithInstrumetation &#123; private static class ObjectA &#123; String str; // 4 int i1; // 4 byte b1; // 1 byte b2; // 1 int i2; // 4 ObjectB obj; //4 byte b3; // 1 &#125; private static class ObjectB &#123; &#125; public static void main(String[] args)&#123; System.out.println(ObjectShallowSize.sizeOf(new ObjectA())); &#125; &#125; 得到的结果是32！不是会按8对齐吗，b3之前的数据加起来已经是32了，多了1个b3，为33，应该对齐到40才对。事实上，HotSpot创建的对象的字段会先按照给定顺序排列一下,默认的顺序如下，从长到短排列，引用排最后: long/double --&gt; int/float --&gt; short/char --&gt; byte/boolean --&gt; Reference这个顺序可以使用JVM参数: -XX:FieldsAllocationSylte=0(默认是1)来改变。我们使用sun.misc.Unsafe对象的objectFieldOffset方法来验证一下: 1234Field[] fields = ObjectA.class.getDeclaredFields(); for(Field f: fields)&#123; System.out.println(f.getName() + \" offset: \" +unsafe.objectFieldOffset(f)); &#125; 可以看到确实是按照从长到短，引用排最后的方式在内存中排列的。按照这种方法我们来重新计算下ObjectA创建的对象的长度: 8(_mark) + 4(元数据指针) + 4(i1) + + 4(i2) + 1(b1) + 1(b2) + 1(b3) + 1(padding) + 4(str) + 4(obj) = 32这种计算方法和程序计算方法一样 unsafe的方式就不讲了，这篇主要想说怎么计算一个对象占用的内存大小，可以点击原博查看unsafe","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://htchz.cc/tags/JVM/"},{"name":"OOP","slug":"OOP","permalink":"https://htchz.cc/tags/OOP/"}],"author":"土川"},{"title":"[分布式]哈希一致性","slug":"分布式-哈希一致性","date":"2018-03-22T10:08:00.000Z","updated":"2019-08-18T11:29:43.108Z","comments":true,"path":"3621931521.html","link":"","permalink":"https://htchz.cc/3621931521.html","excerpt":"哈希一致性在很多地方都有出现，Redis、MC、Hadoop里都有它的身影。","text":"哈希一致性在很多地方都有出现，Redis、MC、Hadoop里都有它的身影。 一致性哈希算法在1997年由麻省理工学院提出的一种分布式哈希（DHT）实现算法，设计目标是为了解决因特网中的热点(Hot spot)问题，初衷和CARP十分类似。一致性哈希修正了CARP使用的简 单哈希算法带来的问题，使得分布式哈希（DHT）可以在P2P环境中真正得到应用。 一致性hash算法提出了在动态变化的Cache环境中，判定哈希算法好坏的四个条件: 平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。 单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。 在Jdk8的HashMap的扩容就保证了元素的单调性。 分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。 负载(Load)：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。 在分布式集群中，对机器的添加删除，或者机器故障后自动脱离集群这些操作是分布式集群管理最基本的功能。如果采用常用的hash(object)%N算法，那么在有机器添加或者删除后，很多原有的数据就无法找到了，这样严重的违反了单调性原则。接下来主要讲解一下一致性哈希算法是如何设计的： 1. 哈希环按照常用的hash算法来将对应的key哈希到一个具有2^32次方个桶的空间中，即0~(2^32)-1的数字空间中。现在我们可以将这些数字头尾相连，想象成一个闭合的环形。如下图 2. 哈希映射2.1. 将对象映射现在我们将object1、object2、object3、object4四个对象通过特定的Hash函数计算出对应的key值，然后散列到Hash环上。如下图 Hash(object1) = key1； Hash(object2) = key2； Hash(object3) = key3； Hash(object4) = key4； 2.2. 将机器映射在采用一致性哈希算法的分布式集群中将新的机器加入，其原理是通过使用与对象存储一样的Hash算法将机器也映射到环中（一般情况下对机器的hash计算是采用机器的IP或者机器唯一的别名作为输入值），然后以顺时针的方向计算，将所有对象存储到离自己最近的机器中。假设现在有NODE1，NODE2，NODE3三台机器，通过Hash算法得到对应的KEY值，映射到环中，其示意图如下： Hash(NODE1) = KEY1; Hash(NODE2) = KEY2; Hash(NODE3) = KEY3; 通过上图可以看出对象与机器处于同一哈希空间中，这样按顺时针转动object1存储到了NODE1中，object3存储到了NODE2中，object2、object4存储到了NODE3中。在这样的部署环境中，hash环是不会变更的，因此，通过算出对象的hash值就能快速的定位到对应的机器中，这样就能找到对象真正的存储位置了。 3. 机器的删除与添加普通hash求余算法最为不妥的地方就是在有机器的添加或者删除之后会照成大量的对象存储位置失效，这样就大大的不满足单调性了。下面来分析一下一致性哈希算法是如何处理的。 部分缓存失效是不可避免的。 3.1. 节点(机器)的删除以上面的分布为例，如果NODE2出现故障被删除了，那么按照顺时针迁移的方法，object3将会被迁移到NODE3中，这样仅仅是object3的映射位置发生了变化，其它的对象没有任何的改动。如下图： 3.2. 节点（机器）的添加如果往集群中添加一个新的节点NODE4，通过对应的哈希算法得到KEY4，并映射到环中，如下图： 4. 平衡性根据上面的图解分析，一致性哈希算法满足了单调性和负载均衡的特性以及一般hash算法的分散性，但这还并不能当做其被广泛应用的原由，因为还缺少了平衡性。下面将分析一致性哈希算法是如何满足平衡性的。hash算法是不保证平衡的，如上面只部署了NODE1和NODE3的情况（NODE2被删除的图），object1存储到了NODE1中，而object2、object3、object4都存储到了NODE3中，这样就照成了非常不平衡的状态。在一致性哈希算法中，为了尽可能的满足平衡性，其引入了虚拟节点。 “虚拟节点”（ virtual node ）是实际节点（机器）在 hash 空间的复制品（ replica ），一实际个节点（机器）对应了若干个“虚拟节点”，这个对应个数也成为“复制个数”，“虚拟节点”在 hash 空间中以hash值排列。 以上面只部署了NODE1和NODE3的情况（NODE2被删除的图）为例，之前的对象在机器上的分布很不均衡，现在我们以2个副本（复制个数）为例，这样整个hash环中就存在了4个虚拟节点，最后对象映射的关系图如下： 根据上图可知对象的映射关系：object1-&gt;NODE1-1，object2-&gt;NODE1-2，object3-&gt;NODE3-2，object4-&gt;NODE3-1。通过虚拟节点的引入，对象的分布就比较均衡了。那么在实际操作中，正真的对象查询是如何工作的呢？对象从hash到虚拟节点到实际节点的转换如下图： “虚拟节点”的hash计算可以采用对应节点的IP地址加数字后缀的方式。例如假设NODE1的IP地址为192.168.1.100。引入“虚拟节点”前，计算 cache A 的 hash 值： Hash(“192.168.1.100”);引入“虚拟节点”后，计算“虚拟节”点NODE1-1和NODE1-2的hash值： Hash(“192.168.1.100#1”); // NODE1-1 Hash(“192.168.1.100#2”); // NODE1-2 一句话就是，通过虚拟节点的方式，让元素在机器上分布均匀","categories":[{"name":"分布式","slug":"分布式","permalink":"https://htchz.cc/categories/分布式/"}],"tags":[{"name":"一致性算法","slug":"一致性算法","permalink":"https://htchz.cc/tags/一致性算法/"}],"author":"土川"},{"title":"[碧油鸡]使用HttpClient3的坑","slug":"碧油鸡-使用HttpClient3的坑","date":"2018-03-22T09:57:00.000Z","updated":"2020-01-12T06:32:50.243Z","comments":true,"path":"589437945.html","link":"","permalink":"https://htchz.cc/589437945.html","excerpt":"特么登录状态老是丢失。。。","text":"特么登录状态老是丢失。。。 1. 场景使用阿里开源配置中心的diamond-sdk时需要登录配置中心才有权限进行操作。diamond-sdk是使用HttpClient3来进行信息传输的，于是在进行配置的操作之前客户端会先模拟登录获得session。然而在接下来的操作却一直报”未登录”之类的提示。 debug大法后发现Cookie对象好像id一直在变，返回的jsessionid也没保存。一波探索发现HttpClient3需要手动设置cookie策略。 2. 解决方法HttpClient3 默认的cookie策略是每次新建一个Cookie对象，复用Cookie的话，要进行如下设置。 client.getParams().setCookiePolicy(CookiePolicy.BROWSER_COMPATIBILITY)(完)","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"BUG","slug":"BUG","permalink":"https://htchz.cc/tags/BUG/"}],"author":"土川"},{"title":"[Spring]Spring之循环依赖","slug":"Spring-Spring之循环依赖","date":"2018-03-19T17:57:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"3244702836.html","link":"","permalink":"https://htchz.cc/3244702836.html","excerpt":"面试面过这个问题，整理一下。所谓循环依赖就是多个Bean之间依赖关系形成一个闭环，例如A-&gt;B-&gt;C-&gt;…-&gt;A 这种情况，当然，最简单的循环依赖就是2个Bean之间互相依赖：A-&gt;B（A依赖B), B-&gt;A(B依赖A) 。在Spring中，如果A-&gt;B,那么在创建A的过程中会去创建B,在创建B（或B的依赖)的过程中又发现B-&gt;A，这个时候就出现了循环依赖的现象。","text":"面试面过这个问题，整理一下。所谓循环依赖就是多个Bean之间依赖关系形成一个闭环，例如A-&gt;B-&gt;C-&gt;…-&gt;A 这种情况，当然，最简单的循环依赖就是2个Bean之间互相依赖：A-&gt;B（A依赖B), B-&gt;A(B依赖A) 。在Spring中，如果A-&gt;B,那么在创建A的过程中会去创建B,在创建B（或B的依赖)的过程中又发现B-&gt;A，这个时候就出现了循环依赖的现象。 1. 不是循环调用循环依赖就是循环引用，就是两个或多个Bean相互之间的持有对方，比如CircleA引用CircleB，CircleB引用CircleC，CircleC引用CircleA，则它们最终反映为一个环。此处不是循环调用，循环调用是方法之间的环调用，如下图： 而循环调用是无法解决的，除非有终结条件，否则就是死循环，最终导致内存溢出错误。 Spring容器循环依赖包括构造器循环依赖和setter循环依赖，那Spring容器如何检测和解决循环依赖呢？ 2. Spring可以解决的循环依赖spring中的循环依赖只有当 Bean是单例 通过属性注入的情况 这两个条件满足的情况下是没问题的。但是如果是通过构造器依赖，或者不是单例模式的情况下循环依赖就会抛出异常BeanCurrentlyInCreationException。下面从代码层面上解析一下为什么。 至于为什么要有prototype类型的bean，我想典型的应用场景就是struts的Action（有点像springmvc的Controller）实例。struts的request参数是绑定在Action对象的成员变量上的，如果Action的bean是单例的就会造成线程不安全。 3. Prototype循环依赖抛异常123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129protected &lt;T&gt; T doGetBean( final String name, final Class&lt;T&gt; requiredType, final Object[] args, boolean typeCheckOnly) throws BeansException &#123; final String beanName = transformedBeanName(name); Object bean; // Eagerly check singleton cache for manually registered singletons. Object sharedInstance = getSingleton(beanName); if (sharedInstance != null &amp;&amp; args == null) &#123; ...// 日志代码 bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); &#125; else &#123; // 请看这里，抛异常 // Fail if we're already creating this bean instance: // We're assumably within a circular reference. if (isPrototypeCurrentlyInCreation(beanName)) &#123; throw new BeanCurrentlyInCreationException(beanName); &#125; // Check if bean definition exists in this factory. BeanFactory parentBeanFactory = getParentBeanFactory(); if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) &#123; // Not found -&gt; check parent. String nameToLookup = originalBeanName(name); if (args != null) &#123; // Delegation to parent with explicit args. return (T) parentBeanFactory.getBean(nameToLookup, args); &#125; else &#123; // No args -&gt; delegate to standard getBean method. return parentBeanFactory.getBean(nameToLookup, requiredType); &#125; &#125; if (!typeCheckOnly) &#123; markBeanAsCreated(beanName); &#125; try &#123; final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); checkMergedBeanDefinition(mbd, beanName, args); // Guarantee initialization of beans that the current bean depends on. String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) &#123; for (String dep : dependsOn) &#123; if (isDependent(beanName, dep)) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Circular depends-on relationship between '\" + beanName + \"' and '\" + dep + \"'\"); &#125; registerDependentBean(dep, beanName); getBean(dep); &#125; &#125; // Create bean instance. if (mbd.isSingleton()) &#123; sharedInstance = getSingleton(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; try &#123; return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; // Explicitly remove instance from singleton cache: It might have been put there // eagerly by the creation process, to allow for circular reference resolution. // Also remove any beans that received a temporary reference to the bean. destroySingleton(beanName); throw ex; &#125; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; else if (mbd.isPrototype()) &#123; // It's a prototype -&gt; create a new instance. Object prototypeInstance = null; try &#123; beforePrototypeCreation(beanName); prototypeInstance = createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); &#125; else &#123; String scopeName = mbd.getScope(); final Scope scope = this.scopes.get(scopeName); if (scope == null) &#123; throw new IllegalStateException(\"No Scope registered for scope name '\" + scopeName + \"'\"); &#125; try &#123; Object scopedInstance = scope.get(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; beforePrototypeCreation(beanName); try &#123; return createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; &#125; &#125;); bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &#125; catch (IllegalStateException ex) &#123; throw new BeanCreationException(beanName, \"Scope '\" + scopeName + \"' is not active for the current thread; consider \" + \"defining a scoped proxy for this bean if you intend to refer to it from a singleton\", ex); &#125; &#125; &#125; catch (BeansException ex) &#123; cleanupAfterBeanCreationFailure(beanName); throw ex; &#125; &#125; ...// type校验 return (T) bean;&#125; 可以看出，该流程中就考虑了Prototype的循环依赖的问题，只要在创建Prototype的Bean中出现循环依赖那么就抛出异常。但是在singleton的情况下，则通过另外的方式来解决。 4. Singleton的循环依赖之构造注入上面的代码有这么一段Singleton的处理 12345678910111213141516171819// Create bean instance.if (mbd.isSingleton()) &#123; sharedInstance = getSingleton(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; try &#123; return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; // Explicitly remove instance from singleton cache: It might have been put there // eagerly by the creation process, to allow for circular reference resolution. // Also remove any beans that received a temporary reference to the bean. destroySingleton(beanName); throw ex; &#125; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd);&#125; 这个getSingleton涉及到了ObjectFactory这个接口类，这个接口的功能和FactoryBean类似，但是主要是用来解决循环依赖的。在初始化过程决定返回的Singleton对象。关于单例的对象的创建，又要介绍一下DefaultSingletonBeanRegistry这个类，这个类主要用来帮助创建单例模式，其中主要的属性： 12345678910111213141516/** 缓存创建的单例对象: bean名字 --&gt; bean对象 */private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;String, Object&gt;(256);/** 缓存单例的factory,就是ObjectFactory这个东西，: bean name --&gt; ObjectFactory */private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;String, ObjectFactory&lt;?&gt;&gt;(16);/** 也是缓存创建的单例对象，功能和singletonObjects不一样，在bean构造成功之后，属性初始化之前会把对象放入到这里，主要是用于解决属性注入的循环引用: bean name --&gt; bean instance */private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;String, Object&gt;(16);/** 记录在创建单例对象中循环依赖的问题，还记得Prototype中又记录创建过程中依赖的map吗？在Prototype中只要出现了循环依赖就抛出异常，而在单例中会尝试解决 */private final Set&lt;String&gt; singletonsCurrentlyInCreation = Collections.newSetFromMap(new ConcurrentHashMap&lt;String, Boolean&gt;(16)); 现在看getSingleton(beanName, new ObjectFactory&lt;Object&gt;()的实现 1234567891011121314151617181920212223242526272829303132333435363738394041public Object getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; Assert.notNull(beanName, \"'beanName' must not be null\"); synchronized (this.singletonObjects) &#123; Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) &#123; if (this.singletonsCurrentlyInDestruction) &#123; throw new BeanCreationNotAllowedException(beanName, \"Singleton bean creation not allowed while singletons of this factory are in destruction \" + \"(Do not request a bean from a BeanFactory in a destroy method implementation!)\"); &#125; //日志代码 ... //把当前beanName加入到singletonsCurrentlyInCreation中 beforeSingletonCreation(beanName); boolean newSingleton = false; boolean recordSuppressedExceptions = (this.suppressedExceptions == null); if (recordSuppressedExceptions) &#123; this.suppressedExceptions = new LinkedHashSet&lt;Exception&gt;(); &#125; try &#123; singletonObject = singletonFactory.getObject(); newSingleton = true; &#125; catch(...)&#123; ... &#125; //从singletonsCurrentlyInCreation中删除beanName finally &#123; if (recordSuppressedExceptions) &#123; this.suppressedExceptions = null; &#125; afterSingletonCreation(beanName); &#125; if (newSingleton) &#123; addSingleton(beanName, singletonObject); &#125; &#125; return (singletonObject != NULL_OBJECT ? singletonObject : null); &#125;&#125; 这段逻辑是不是和Prototype中解决循环类似,这里其实就是调用了ObjectFactory的getObject()获取对象，回过头去看前面代码，ObjectFactory的getObject()方法实际调用的是createBean(beanName, mbd, args)。说到createBean(beanName, mbd, args)又不得不说AbstractAutowireCapableBeanFactory这个类，主要功能就是完成依赖注入的Bean的创建，这个类的createBean方法代码如下,注意注解说明： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657@Overrideprotected Object createBean(String beanName, RootBeanDefinition mbd, Object[] args) throws BeanCreationException &#123; ... Object beanInstance = doCreateBean(beanName, mbdToUse, args); ...&#125;protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final Object[] args) throws BeanCreationException &#123; // 实例化bean BeanWrapper instanceWrapper = null; if (mbd.isSingleton()) &#123; instanceWrapper = this.factoryBeanInstanceCache.remove(beanName); &#125; if (instanceWrapper == null) &#123; //如果没实例化则创建新的BeanWrapper //如果是通过构造器注入，这里是一个关键点 /* 因为在A初始化的时候发现构造函数依赖B，就会去实例化B， 然后B也会运行到这段逻辑，构造函数中发现依赖A， 这个时候就会抛出循环依赖的异常 */ instanceWrapper = createBeanInstance(beanName, mbd, args); &#125; //如果当前是单例，并且allowCircularReferences为true(默认就是true，除非我们不希望Spring帮我们解决) boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) &#123; /* ！！！这里很重要，把构造成功，但属性还没注入的 的bean加到singletonFactory中，这样再解决A的依赖 过程中如果依赖A，就把这个半成品返回回去。 */ addSingletonFactory(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; return getEarlyBeanReference(beanName, mbd, bean); &#125; &#125;); &#125; Object exposedObject = bean; try &#123; //自动注入属性 populateBean(beanName, mbd, instanceWrapper); if (exposedObject != null) &#123; exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; &#125; ... return exposedObject;&#125; 5. 总结 AbstractBeanFactory,这个类中包含了Bean创建的主要流程，在doGetBean这个方法中包含了对Prototype循环依赖处理。逻辑很简单，出现了循环依赖则直接抛出异常 DefaultSingletonBeanRegister 用于管理Singleton的对象的创建，以及解决循环依赖的问题,其中解决循环依赖的关键属性就是了earlySingletonObjects，他会在构造Singleton对象过程中暂时缓存构造成功，但属性还未注入的对象，这样就可以解决循环依赖的问题。 AbstractAutowireCapableBeanFactory,自动注入的相关逻辑，包自动注入的对象的创建、初始化和注入。但如果在调用构造函数中发现了循环依赖，则抛出异常 ObjectFactory,这个接口功能和FactoryBean类似，但是为了解决循环依赖，他决定了在获取的getSingleton()是一个完成品还是一个半成品。 6. 构造函数和属性注入依赖的循环看下面的场景 123456789101112131415@Componentpublic class BeanA &#123; private BeanB beanB; @Autowired public BeanA(BeanB beanB) &#123; this.beanB = beanB; &#125;&#125;@Componentpublic class BeanB &#123; @Autowired private BeanA beanA;&#125; 这种情况会不会报依赖异常？写个demo，报下面的错误信息。 *************************** APPLICATION FAILED TO START *************************** Description: The dependencies of some of the beans in the application context form a cycle: ┌─────┐ | beanA defined in file [C:\\Users\\zack.huang\\IdeaProjects\\xunhuanbean\\target\\classes\\com\\htc\\testbean\\xunhuanbean\\BeanA.class] ↑ ↓ | beanB (field private com.htc.testbean.xunhuanbean.BeanA com.htc.testbean.xunhuanbean.BeanB.beanC) └─────┘按照类名的字典排序，BeanA是会比BeanB先被扫描到的，那么先构造BeanA，BeanA明显构造需要BeanB依赖，初始化BeanB，BeanA没构造完成无法注入，于是GG。 如果BeanA改名为BeanC，就可以解决问题，不过这种谁先谁后是不可靠的，勿写这种代码。","categories":[{"name":"Spring","slug":"Spring","permalink":"https://htchz.cc/categories/Spring/"}],"tags":[{"name":"Bean","slug":"Bean","permalink":"https://htchz.cc/tags/Bean/"},{"name":"IOC","slug":"IOC","permalink":"https://htchz.cc/tags/IOC/"}],"author":"土川"},{"title":"[碧油鸡]浅谈0xFF","slug":"碧油鸡-浅谈0xFF","date":"2018-03-16T07:47:00.000Z","updated":"2020-06-06T17:52:05.928Z","comments":true,"path":"2016889271.html","link":"","permalink":"https://htchz.cc/2016889271.html","excerpt":"这是一个无符号数引发的bug","text":"这是一个无符号数引发的bug 1. 场景项目中使用了Redis的BitMap数据结构，关于它的用法就不赘述了。 笔者用BitMap来作为ip地址的黑名单模型，使用ip的hashcode作为offset，再合适不过。 但是ip是一个32位的无符号数，而java是没有无符号数的，这就导致有些ip的hashcode是一个负数。 java的做法是通过掩码的操作来进行有符号数到无符号数的转换。 2. 解决方法hashCode() &amp; 0x00000000FFFFFFFFL 通过这行代码把int转为long，而且数值是无符号int的值 java也有BitMap位图模型——java.util.BitSet,而且java的BitSet的api只能使用大于0的int作为offset，而redis是可以用long作为offset的。(redis的bitset大小限制是512MB，即2^32bit) 3. 二进制那些事 在java.io.FilterOutputStream.DataOutputStream：与机器无关地写入各种类型的数据以及String对象的二进制形式，从高位开始写。这样一来，任何机器上任何DataInputStream都能够读取它们。所有方法都以“write”开头，例如writeByte()，writeFloat()等。java.io.FilterOutputStream.PrintStream最初的目的是为了以可视化格式打印所有的基本数据类型以及String对象。这和DataOutputStream不同，它目的是将数据元素置入“流”中，使DataInputStream能够可移植地重构它们。 如何把一串字符串写成二进制？ 字符串的本质是char的序列，也就是char []。因此，遍历写入每一个char，就完成了写一个字符串的功能。 char写成二进制？英语字母有ASCII码，可以把每个字符转换成对应的数字，那么汉字日语呢泰国语呢？这个问题前人早就已经解决。世界上的绝大部分字符都有一张类似于ASCII码表的字符和编码间的映射，那就是Unicode码表。 Unicode 字符编码标准是固定长度的字符编码方案，它包含了世界上几乎所有现用语言的字符。有关 Unicode 的信息可在最新版本的 The Unicode Standard 一书中找到，并可从 Unicode 协会 Web 站点（www.unicode.org）中找到。 Unicode 根据要编码的数据类型使用两种编码格式：8 位和 16 位。缺省编码格式是 16 位，即每个字符是 16 位（两个字节）宽，并且通常显示为 U+hhhh，其中 hhhh 是字符的十六进制代码点。虽然生成的 65000 多个代码元素足以用于 编码世界上主要语言的大多数字符，但 Unicode 标准还提供了一种扩展机制，允许编码一百多万个字符。扩展机制使用一对高位和低位代用字符来对扩展字符或补充字符进行编码。第一个（或高位）代用字符具有 U+D800 和 U+DBFF 之间的代码值，而第二个（或低位）代用字符具有 U+DC00 和 U+DFFF 之间的代码值。 unicode码可以用2个字节表示世界上的绝大部分字符。 一个char是0-65535间的数字，一个String就是一串长长长的数字。 所以DataOutputStream.writeChars(str)的源码是这样的： 123456789101112131415161718192021/** * Writes a string to the underlying output stream as a sequence of * characters. Each character is written to the data output stream as * if by the &lt;code&gt;writeChar&lt;/code&gt; method. If no exception is * thrown, the counter &lt;code&gt;written&lt;/code&gt; is incremented by twice * the length of &lt;code&gt;s&lt;/code&gt;. * * @param s a &lt;code&gt;String&lt;/code&gt; value to be written. * @exception IOException if an I/O error occurs. * @see java.io.DataOutputStream#writeChar(int) * @see java.io.FilterOutputStream#out */public final void writeChars(String s) throws IOException &#123; int len = s.length(); for (int i = 0 ; i &lt; len ; i++) &#123; int v = s.charAt(i); out.write((v &gt;&gt;&gt; 8) &amp; 0xFF); // `out.wirte(int)` 是一个抽象方法，一次传入一个int，而`out.wirte(int)`的实现总是把他强转成byte。 out.write((v &gt;&gt;&gt; 0) &amp; 0xFF); &#125; incCount(len * 2);&#125; 那么回到标题，(v &gt;&gt;&gt; 8) &amp; 0xFF、(v &gt;&gt;&gt; 0) &amp; 0xFF是干嘛的？ 0（零）xFF是16进制的255，也就是二进制的 1111 1111&amp; AND 按位与操作，同时为1时才是1，否则为0.————位移运算计算机中存的都是数的补码，所以位移运算都是对补码而言的————&lt;&lt; 左移 右补0&gt;&gt; 有符号右移 左补符号位，即：如果符号位是1 就左补1，如果符号位是0 就左补0&gt;&gt;&gt; 无符号右移 ，顾名思义，统一左补0 位移操作是不会改变原来的数的，就像String的操作都是返回一个新的String int v = s.charAt(i)得到的v是一个char强转的int，这个int的有效信息其实是低16位（int是32位，char是16位）的两个byte的信息。 那么怎么获得这两个byte并一一入参呢？ 这里可以把&amp;0XFF看成一把剪刀，看下面的操作。 1000,0000,0000,0011 这是一个short（为什么不用char？）的二进制 0000,0000,1000,0000 这是&quot;&gt;&gt;&gt;8&quot;的结果 然后再 &amp;0XFF，得到 1000,0000 （准确的说是 0000 0000 1000 0000）这就是第一个byte(从高位开始)。 接着 1000,0000,0000,0011 short的二进制原码 1000,0000,0000,0011 &gt;&gt;&gt;0还是源码本身不变然后再 &amp;0XFF，得到 0000,0011（准确的说是 0000 0000 0000 0011）所以 &amp;0xFF 就像计算机中的一把剪刀，用来截取一个byte。同理，&amp;0x0F呢？得到4bits有效值。 4. &amp;0xFF和上面的bug什么关系？既然实际上Redis的java客户端Jedis的位图api是这样的 public void setbit(byte[] key, long offset, boolean value)offset是一个long值，那么传入一个int类型的hashcode必然会强转。如果一个ip是128.xxx.xxx.xxx，那么二进制是10000000 xxxxxxxx xxxxxxxx xxxxxxxx，hashcode就是一个负数，一个负的int转成long之后，对于计算机为了保持补码数值不变，高位得自动补1，所以得到 11111111 11111111 11111111 11111111 10000000 xxxxxxxx xxxxxxxx xxxxxxxx可我们想得到的期望数是 00000000 00000000 00000000 00000000 10000000 xxxxxxxx xxxxxxxx xxxxxxxx这时候我们就要一把剪刀&amp; 0x00000000FFFFFFFFL来剪一下，得到我们的期望数。 5. 题外话既然我们的DataOutputstrem是要write一个byte，为什么要用int入参引来一把剪刀的麻烦，其实是java没有无符号数的麻烦。 这其实和read()对应，read()是返回0-255的数据，和 -1 代表文件末尾，所以没有无符号数的java只能用read返回int。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"BUG","slug":"BUG","permalink":"https://htchz.cc/tags/BUG/"},{"name":"位运算","slug":"位运算","permalink":"https://htchz.cc/tags/位运算/"}],"author":"土川"},{"title":"[Java基础]HashMap的扩容机制及jdk8优化——resize()","slug":"Java基础-HashMap的扩容机制——resize","date":"2018-03-16T03:19:00.000Z","updated":"2019-08-21T06:55:50.534Z","comments":true,"path":"92838208.html","link":"","permalink":"https://htchz.cc/92838208.html","excerpt":"我们来讲讲jdk8的HashMap扩容机制。虽然《Java集合(八)HashMap》贴过代码了","text":"我们来讲讲jdk8的HashMap扩容机制。虽然《Java集合(八)HashMap》贴过代码了 1. 什么时候扩容当向容器添加元素的时候，会判断当前容器的元素个数，如果大于等于阈值——即当前数组的长度乘以加载因子的值的时候，就要自动扩容啦。 2. 扩容(resize)数组是不能扩容的，所以扩容方法自然是使用一个新的更大容量的数组代替已有的容量小的数组 分析下resize的源码，鉴于JDK1.8融入了红黑树，较复杂，为了便于理解我们仍然使用JDK1.7的代码，好理解一些，本质上区别不大，具体区别后文再说。 12345678910111213void resize(int newCapacity) &#123; //传入新的容量 Entry[] oldTable = table; //引用扩容前的Entry数组 int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; //扩容前的数组大小如果已经达到最大(2^30)了 threshold = Integer.MAX_VALUE; //修改阈值为int的最大值(2^31-1)，这样以后就不会扩容了 return; &#125; Entry[] newTable = new Entry[newCapacity]; //初始化一个新的Entry数组 transfer(newTable); //！！将数据转移到新的Entry数组里 table = newTable; //HashMap的table属性引用新的Entry数组 threshold = (int) (newCapacity * loadFactor);//修改阈值 &#125; 这里就是使用一个容量更大的数组来代替已有的容量小的数组，transfer()方法将原有Entry数组的元素拷贝到新的Entry数组里。 1234567891011121314151617void transfer(Entry[] newTable) &#123; Entry[] src = table; //src引用了旧的Entry数组 int newCapacity = newTable.length; for (int j = 0; j &lt; src.length; j++) &#123; //遍历旧的Entry数组 Entry&lt;K, V&gt; e = src[j]; //取得旧Entry数组的每个元素 if (e != null) &#123; src[j] = null;//释放旧Entry数组的对象引用（for循环后，旧的Entry数组不再引用任何对象） do &#123; Entry&lt;K, V&gt; next = e.next; // 保存要处理的entry的next对象 int i = indexFor(e.hash, newCapacity); //重新计算entry在数组中的位置 e.next = newTable[i]; //这个操作将把处理的entry插到新数组i位置的entry链头部，然后结果就是最终链表倒置可以看下图 newTable[i] = e; //将entry放在新数组i位置上 e = next; //访问下一个Entry链上的元素 &#125; while (e != null); &#125; &#125; &#125; 123static int indexFor(int h, int length) &#123; return h &amp; (length - 1); // 这是取模运算，看那篇《[JDK8]HashMap的tableSizeFor()》中有提到&#125; 假设了我们的hash算法就是简单的用key mod 一下表的大小（也就是数组的长度）。 其中的哈希桶数组table的size=2，现在有key = 3、7、5，put顺序依次为 5、7、3。在mod 2以后都冲突在table[1]这里了。这里假设负载因子 loadFactor=1，即当键值对的实际大小size 大于 table的实际大小时进行扩容。接下来的三个步骤是哈希桶数组 resize成4，然后所有的Node重新rehash的过程。 jdk1.7扩容例图 经过观测可以发现，我们使用的是2次幂的扩展(指长度扩为原来2倍，power of two)，所以， 经过rehash之后，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。所以，jdk7的对于处理后还在原位置的元素的操作，冗余的操作，于是jdk8有了以下优化。 12345678910/** * Initializes or doubles table size. If null, allocates in * accord with initial capacity target held in field threshold. * Otherwise, because we are using power-of-two expansion, the * elements from each bin must either stay at same index, or move * with a power of two offset in the new table. * * @return the table */ final Node&lt;K,V&gt;[] resize() &#123; 看下图可以明白这句话的意思，n为table的长度，图（a）表示扩容前的key1和key2两种key确定索引位置的示例，图（b）表示扩容后key1和key2两种key确定索引位置的示例，其中hash1是key1对应的哈希与高位运算结果。 元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化： 因此，我们在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”，可以看看下图为16扩充为32的resize示意图： 这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。这一块就是JDK1.8新增的优化点。有一点注意区别，JDK1.7中rehash的时候，旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置，但是从上图可以看出，JDK1.8不会倒置。有兴趣的同学可以研究下JDK1.8的resize源码，写的很赞，如下: 下面是他的实现: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182/** * Initializes or doubles table size. If null, allocates in * accord with initial capacity target held in field threshold. * Otherwise, because we are using power-of-two expansion, the * elements from each bin must either stay at same index, or move * with a power of two offset in the new table. * * @return the table */final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125;","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"jdk8","slug":"jdk8","permalink":"https://htchz.cc/tags/jdk8/"},{"name":"Java集合","slug":"Java集合","permalink":"https://htchz.cc/tags/Java集合/"}],"author":"土川"},{"title":"[集合扩容]HashMap的tableSizeFor()","slug":"JDK8-HashMap的tableSizeFor","date":"2018-03-15T08:51:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"2353864749.html","link":"","permalink":"https://htchz.cc/2353864749.html","excerpt":"jdk8的HashMap源码阅读的时候，发现一个tableSizeFor()方法是一串位运算，这个方法第一次出现是在HashMap指定容量的构造函数里出现","text":"jdk8的HashMap源码阅读的时候，发现一个tableSizeFor()方法是一串位运算，这个方法第一次出现是在HashMap指定容量的构造函数里出现 1. 代码1234567891011 // Returns a power of two size for the given target capacity. // 这是方法的注释 // 大致意思就是找到大于等于指定容量(capacity)参数的2的幂 static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; &#125; 2. 目的这段代码的目的注如注释所说：找到一个数，满足下面的条件 它是2的幂(有助于提高性能)， 它大于或者等于capacity 满足上面两个条件的数中最小(也就是最接近capacity) 3. 个人瞎掰对一个数A，怎么找一个数B 满足上面条件呢 下面的方法不是代码对应的实现 把数转为二进制，找到A的最高位，那么数B就是数A最高位左移一位其余为0的数。举个例子。 比如要找给定的数7，满足条件的数明显是8。 8的2进制： 0000 1000 7的2进制： 0000 0111从7得到8： 我们把7的最高位第三位左移一位，得到0000 1110 其余清零，得到0000 1000，就是目标的8 但是这样有个问题，如果一个数刚好是2的幂，比如2对应的0000 0010，那么经过左移、清零操作，得到0000 0100，也就是4，明显比满足条件的数大了一倍（给定2满足条件的数还是2） 这样还得判断一个数是不是2的幂，烦不？ 4. 代码的实现代码的逻辑是介样的： 我们先不看int n = cap - 1 直接说他的位移操作。通过位移操作，从最高位是1的位置开始，往低位置全部置为1(这个方法是通过或操作|和无符号右移&gt;&gt;&gt;来实现的，拿草稿纸按照代码写一下就清楚逻辑了)，然后+1。 从7得到8： 我们把7的最高位往低位置1，得到0000 0111 接着+1，得到0000 1000 这样还是没解决“一个数刚好是2的幂”的问题，于是有了那一行int n = cap - 1，这个减一操作可以完美避免“判断一个数是不是2的幂”。 如果一个数不是2的幂，减一操作后，最终会被置1操作补偿回来。 如果一个数是2的幂，减一操作后，可以把这个数缩小一倍，最后置1、+1操作会把数还原。 （完） ** 其实还没完，为什么这么执着于把容量改成2的幂？** 其实HashMap在根据hashcode取数组下标的时候，代码是这样的 123static int indexFor(int h, int length) &#123; return h &amp; (length - 1); &#125; 这个h &amp; (length - 1)这是一个取模操作 取模算法中的除法运算效率很低，在HashMap中通过h&amp;（n-1）替代取模，得到所在数组位置，效率会高很多。（前提是保证数组的容量是2的整数倍） （完）","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"Java集合","slug":"Java集合","permalink":"https://htchz.cc/tags/Java集合/"}],"author":"土川"},{"title":"[Java基础]Integer与int","slug":"Java基础-Integer与int","date":"2018-03-13T02:27:00.000Z","updated":"2019-08-18T11:26:12.743Z","comments":true,"path":"1834665960.html","link":"","permalink":"https://htchz.cc/1834665960.html","excerpt":"贴代码:","text":"贴代码: 1234567891011121314151617181920public static void main(String[] args) &#123; int i = 128; Integer i2 = 128; Integer i3 = new Integer(128); //Integer会自动拆箱为int，所以为true System.out.println(i == i2); System.out.println(i == i3); System.out.println(&quot;**************&quot;); Integer i5 = 127;//java在编译的时候,被翻译成-&gt; Integer i5 = Integer.valueOf(127); Integer i6 = 127; System.out.println(i5 == i6);//true /*Integer i5 = 128; Integer i6 = 128; System.out.println(i5 == i6);//false*/ Integer ii5 = new Integer(127); System.out.println(i5 == ii5); //false Integer i7 = new Integer(128); Integer i8 = new Integer(123); System.out.println(i7 == i8); //false&#125; 11 行为true，16行为false，是因为： java在编译Integer i5 = 127的时候,被翻译成-&gt; Integer i5 = Integer.valueOf(127);所以关键就是看valueOf()函数了。只要看看valueOf()函数的源码就会明白了。JDK源码的valueOf函数式这样的： 123456public static Integer valueOf(int i) &#123; assert IntegerCache.high &gt;= 127; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);&#125; 1. 总结 无论如何，Integer与new Integer不会相等。不会经历拆箱过程，i3的引用指向堆，而i4指向专门存放他的内存（常量池），他们的内存地址不一样，所以为false 两个都是非new出来的Integer，如果数在-128到127之间，则是true,否则为false（Integer的缓存）java在编译Integer i2 = 128的时候,被翻译成-&gt; Integer i2 = Integer.valueOf(128);而valueOf()函数会对-128到127之间的数进行缓存 两个都是new出来的,都为false int和integer(无论new否)比，都为true，因为会把Integer自动拆箱为int再去比","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://htchz.cc/tags/JVM/"}],"author":"土川"},{"title":"[Java基础]LongAdder","slug":"Java基础-LongAdder","date":"2018-03-13T02:07:00.000Z","updated":"2019-08-21T06:40:10.205Z","comments":true,"path":"973885938.html","link":"","permalink":"https://htchz.cc/973885938.html","excerpt":"","text":"1. 前言LongAdder是jdk8新增的用于并发环境的计数器，目的是为了在高并发情况下，代替AtomicLong/AtomicInt，成为一个用于高并发情况下的高效的通用计数器。高并发下计数，一般最先想到的应该是AtomicLong/AtomicInt，AtmoicXXX使用硬件级别的指令 CAS 来更新计数器的值，这样可以避免加锁，机器直接支持的指令，效率也很高。但是AtomicXXX中的 CAS 操作在出现线程竞争时，失败的线程会白白地循环一次，在并发很大的情况下，因为每次CAS都只有一个线程能成功，竞争失败的线程会非常多。失败次数越多，循环次数就越多，很多线程的CAS操作越来越接近 自旋锁（spin lock）。计数操作本来是一个很简单的操作，实际需要耗费的cpu时间应该是越少越好，AtomicXXX在高并发计数时，大量的cpu时间都浪费会在自旋上了，这很浪费，也降低了实际的计数效率。 12345678910// jdk1.8的AtomicLong的实现代码，这段代码在sun.misc.Unsafe中 // 当线程竞争很激烈时，while判断条件中的CAS会连续多次返回false，这样就会造成无用的循环，循环中读取volatile变量的开销本来就是比较高的 // 因为这样，在高并发时，AtomicXXX并不是那么理想的计数方式 public final long getAndAddLong(Object o, long offset, long delta) &#123; long v; do &#123; v = getLongVolatile(o, offset); &#125; while (!compareAndSwapLong(o, offset, v, v + delta)); return v; &#125; 现在，在处理高并发计数时，应该优先使用LongAdder，而不是继续使用AtomicLong。当然，线程竞争很低的情况下进行计数，使用Atomic还是更简单更直接，并且效率稍微高一些。其他情况，比如序号生成，这种情况下需要准确的数值，全局唯一的AtomicLong才是正确的选择，此时不应该使用LongAdder。 下面简要分析下LongAdder的源码，有了ConcurrentHashMap（LongAdder比较像1.6和1.7的，可以看下1.7的）的基础，这个类的源码看起来也不复杂。 2. 类的关系 公共父类Striped64是实现中的核心，它实现一些核心操作，处理64位数据，很容易就能转化为其他基本类型，是个通用的类。二元算术运算累积，指的是你可以给它提供一个二元算术方式，这个类按照你提供的方式进行算术计算，并保存计算结果。二元运算中第一个操作数是累积器中某个计数单元当前的值，另外一个值是外部提供的。举几个例子：假设每次操作都需要把原来的数值加上某个值，那么二元运算为 (x, y) -&gt; x+y，这样累积器每次都会加上你提供的数字y，这跟LongAdder的功能基本上是一样的；假设每次操作都需要把原来的数值变为它的某个倍数，那么可以指定二元运算为 (x, y) -&gt; xy，累积器每次都会乘以你提供的数字y，y=2时就是通常所说的每次都翻一倍；假设每次操作都需要把原来的数值变成它的5倍，再加上3，再除以2，再减去4，再乘以你给定的数，最后还要加上6，那么二元运算为 (x, y) -&gt; ((x5+3)/2 - 4)y +6，累积器每次累积操作都会按照你说的做；……LongAccumulator是标准的实现类，LongAdder是特化的实现类，它的功能等价于LongAccumulator((x, y) -&gt; x+y, 0L)。它们的区别很简单，前者可以进行任何二元算术操作，后者只能进行加减两种算术操作。Double版本是Long版本的简单改装，相对Long版本，主要的变化就是用Double.longBitsToDouble 和Double.doubleToRawLongBits对底层的8字节数据进行long &lt;—&gt; double转换，存储的时候使用long型，计算的时候转化为double型。这是因为CAS是sun.misc.Unsafe中提供的操作，只对int、long、对象类型（引用或者指针）提供了这种操作，其他类型都需要转化为这三种类型才能进行CAS操作。这里的long型也可以认为是8字节的原始类型，因为把它视为long类型是无意义的。java中没有C语言中的 void 无类型（或者叫原始类型），只能用最接近的long类型来代替。 四个实现类的区别就上面这两句话，这里只讲LongAdder一个类。 3. 核心实现Striped64四个类的核心实现都在Striped64中，这个类使用分段的思想，来尽量平摊并发压力。类似1.7及以前版本的ConcurrentHashMap.Segment，Striped64中使用了一个叫Cell的类，是一个普通的二元算术累积单元，线程也是通过hash取模操作映射到一个Cell上进行累积。为了加快取模运算效率，也把Cell数组的大小设置为2^n，同时大量使用Unsafe提供的底层操作。基本的实现桶1.7的ConcurrentHashMap非常像，而且更简单。 3.1. 累积单元Cell看到这里我想了一个看似简单的问题：既然Cell这么简单，只有一个long型变量，为什么不直接用long value？首先声明下，Unsafe提供的操作很强大，也能对数组的元素进行volatile读写，同时数组计算某个元素的offset偏移量本身就很简单，因此volatile、cas这种站不住脚。这个问题是因为：（用对象封装，保证对象的引用改变时，能保证改变的value不会丢失） 1234567891011121314151617181920212223// 很简单的一个类，这个类可以看成是一个简化的AtomicLong // 通过cas操作来更新value的值 // @sun.misc.Contended是一个高端的注解，代表使用缓存行填来避免伪共享，可以自己网上搜下，这个我就不细说了 @sun.misc.Contended static final class Cell &#123; volatile long value; Cell(long x) &#123; value = x; &#125; final boolean cas(long cmp, long val) &#123; return UNSAFE.compareAndSwapLong(this, valueOffset, cmp, val); &#125; // Unsafe mechanics Unsafe相关的初始化 private static final sun.misc.Unsafe UNSAFE; private static final long valueOffset; static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; ak = Cell.class; valueOffset = UNSAFE.objectFieldOffset (ak.getDeclaredField(\"value\")); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125; &#125; 3.2. Striped64主体代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159abstract class Striped64 extends Number &#123; @sun.misc.Contended static final class Cell &#123; ... &#125; /** Number of CPUS, to place bound on table size */ static final int NCPU = Runtime.getRuntime().availableProcessors(); // cell数组，长度一样要是2^n，可以类比为jdk1.7的ConcurrentHashMap中的segments数组 transient volatile Cell[] cells; // 累积器的基本值，在两种情况下会使用： // 1、没有遇到并发的情况，直接使用base，速度更快； // 2、多线程并发初始化table数组时，必须要保证table数组只被初始化一次，因此只有一个线程能够竞争成功，这种情况下竞争失败的线程会尝试在base上进行一次累积操作 transient volatile long base; // 自旋标识，在对cells进行初始化，或者后续扩容时，需要通过CAS操作把此标识设置为1（busy，忙标识，相当于加锁），取消busy时可以直接使用cellsBusy = 0，相当于释放锁 transient volatile int cellsBusy; Striped64() &#123; &#125; // 使用CAS更新base的值 final boolean casBase(long cmp, long val) &#123; return UNSAFE.compareAndSwapLong(this, BASE, cmp, val); &#125; // 使用CAS将cells自旋标识更新为1 // 更新为0时可以不用CAS，直接使用cellsBusy就行 final boolean casCellsBusy() &#123; return UNSAFE.compareAndSwapInt(this, CELLSBUSY, 0, 1); &#125; // 下面这两个方法是ThreadLocalRandom中的方法，不过因为包访问关系，这里又重新写一遍 // probe翻译过来是探测/探测器/探针这些，不好理解，它是ThreadLocalRandom里面的一个属性， // 不过并不影响对Striped64的理解，这里可以把它理解为线程本身的hash值 static final int getProbe() &#123; return UNSAFE.getInt(Thread.currentThread(), PROBE); &#125; // 相当于rehash，重新算一遍线程的hash值 static final int advanceProbe(int probe) &#123; probe ^= probe &lt;&lt; 13; // xorshift probe ^= probe &gt;&gt;&gt; 17; probe ^= probe &lt;&lt; 5; UNSAFE.putInt(Thread.currentThread(), PROBE, probe); return probe; &#125; /** * 核心方法的实现，此方法建议在外部进行一次CAS操作（cell != null时尝试CAS更新base值，cells != null时，CAS更新hash值取模后对应的cell.value） * @param x the value 前面我说的二元运算中的第二个操作数，也就是外部提供的那个操作数 * @param fn the update function, or null for add (this convention avoids the need for an extra field or function in LongAdder). * 外部提供的二元算术操作，实例持有并且只能有一个，生命周期内保持不变，null代表LongAdder这种特殊但是最常用的情况，可以减少一次方法调用 * @param wasUncontended false if CAS failed before call 如果为false，表明调用者预先调用的一次CAS操作都失败了 */ final void longAccumulate(long x, LongBinaryOperator fn, boolean wasUncontended) &#123; int h; // 这个if相当于给线程生成一个非0的hash值 if ((h = getProbe()) == 0) &#123; ThreadLocalRandom.current(); // force initialization h = getProbe(); wasUncontended = true; &#125; boolean collide = false; // True if last slot nonempty 如果hash取模映射得到的Cell单元不是null，则为true，此值也可以看作是扩容意向，感觉这个更好理解 for (;;) &#123; Cell[] as; Cell a; int n; long v; if ((as = cells) != null &amp;&amp; (n = as.length) &gt; 0) &#123; // cells已经被初始化了 if ((a = as[(n - 1) &amp; h]) == null) &#123; // hash取模映射得到的Cell单元还为null（为null表示还没有被使用） if (cellsBusy == 0) &#123; // Try to attach new Cell 如果没有线程正在执行扩容 Cell r = new Cell(x); // Optimistically create 先创建新的累积单元 if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123; // 尝试加锁 boolean created = false; try &#123; // Recheck under lock 在有锁的情况下再检测一遍之前的判断 Cell[] rs; int m, j; if ((rs = cells) != null &amp;&amp; (m = rs.length) &gt; 0 &amp;&amp; rs[j = (m - 1) &amp; h] == null) &#123; // 考虑别的线程可能执行了扩容，这里重新赋值重新判断 rs[j] = r; // 对没有使用的Cell单元进行累积操作（第一次赋值相当于是累积上一个操作数，求和时再和base执行一次运算就得到实际的结果） created = true; &#125; &#125; finally &#123; cellsBusy = 0; 清空自旋标识，释放锁 &#125; if (created) // 如果原本为null的Cell单元是由自己进行第一次累积操作，那么任务已经完成了，所以可以退出循环 break; continue; // Slot is now non-empty 不是自己进行第一次累积操作，重头再来 &#125; &#125; collide = false; // 执行这一句是因为cells被加锁了，不能往下继续执行第一次的赋值操作（第一次累积），所以还不能考虑扩容 &#125; else if (!wasUncontended) // CAS already known to fail 前面一次CAS更新a.value（进行一次累积）的尝试已经失败了，说明已经发生了线程竞争 wasUncontended = true; // Continue after rehash 情况失败标识，后面去重新算一遍线程的hash值 else if (a.cas(v = a.value, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) // 尝试CAS更新a.value（进行一次累积） ------ 标记为分支A break; // 成功了就完成了累积任务，退出循环 else if (n &gt;= NCPU || cells != as) // cell数组已经是最大的了，或者中途发生了扩容操作。因为NCPU不一定是2^n，所以这里用 &gt;= collide = false; // At max size or stale 长度n是递增的，执行到了这个分支，说明n &gt;= NCPU会永远为true，下面两个else if就永远不会被执行了，也就永远不会再进行扩容 // CPU能够并行的CAS操作的最大数量是它的核心数（CAS在x86中对应的指令是cmpxchg，多核需要通过锁缓存来保证整体原子性），当n &gt;= NCPU时，再出现几个线程映射到同一个Cell导致CAS竞争的情况，那就真不关扩容的事了，完全是hash值的锅了 else if (!collide) // 映射到的Cell单元不是null，并且尝试对它进行累积时，CAS竞争失败了，这时候把扩容意向设置为true // 下一次循环如果还是跟这一次一样，说明竞争很严重，那么就真正扩容 collide = true; // 把扩容意向设置为true，只有这里才会给collide赋值为true，也只有执行了这一句，才可能执行后面一个else if进行扩容 else if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123; // 最后再考虑扩容，能到这一步说明竞争很激烈，尝试加锁进行扩容 ------ 标记为分支B try &#123; if (cells == as) &#123; // Expand table unless stale 检查下是否被别的线程扩容了（CAS更新锁标识，处理不了ABA问题，这里再检查一遍） Cell[] rs = new Cell[n &lt;&lt; 1]; // 执行2倍扩容 for (int i = 0; i &lt; n; ++i) rs[i] = as[i]; cells = rs; &#125; &#125; finally &#123; cellsBusy = 0; // 释放锁 &#125; collide = false; // 扩容意向为false continue; // Retry with expanded table 扩容后重头再来 &#125; h = advanceProbe(h); // 重新给线程生成一个hash值，降低hash冲突，减少映射到同一个Cell导致CAS竞争的情况 &#125; else if (cellsBusy == 0 &amp;&amp; cells == as &amp;&amp; casCellsBusy()) &#123; // cells没有被加锁，并且它没有被初始化，那么就尝试对它进行加锁，加锁成功进入这个else if boolean init = false; try &#123; // Initialize table if (cells == as) &#123; // CAS避免不了ABA问题，这里再检测一次，如果还是null，或者空数组，那么就执行初始化 Cell[] rs = new Cell[2]; // 初始化时只创建两个单元 rs[h &amp; 1] = new Cell(x); // 对其中一个单元进行累积操作，另一个不管，继续为null cells = rs; init = true; &#125; &#125; finally &#123; cellsBusy = 0; // 清空自旋标识，释放锁 &#125; if (init) // 如果某个原本为null的Cell单元是由自己进行第一次累积操作，那么任务已经完成了，所以可以退出循环 break; &#125; else if (casBase(v = base, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) // cells正在进行初始化时，尝试直接在base上进行累加操作 break; // Fall back on using base 直接在base上进行累积操作成功了，任务完成，可以退出循环了 &#125; &#125; // double的不讲，更long的逻辑基本上是一样的 final void doubleAccumulate(double x, DoubleBinaryOperator fn, boolean wasUncontended); // Unsafe mechanics Unsafe初始化 private static final sun.misc.Unsafe UNSAFE; private static final long BASE; private static final long CELLSBUSY; private static final long PROBE; static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; sk = Striped64.class; BASE = UNSAFE.objectFieldOffset (sk.getDeclaredField(\"base\")); CELLSBUSY = UNSAFE.objectFieldOffset (sk.getDeclaredField(\"cellsBusy\")); Class&lt;?&gt; tk = Thread.class; PROBE = UNSAFE.objectFieldOffset (tk.getDeclaredField(\"threadLocalRandomProbe\")); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125; &#125; 4. LongAdder看完了Striped64的讲解，这部分就很简单了，只是一些简单的封装。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182public class LongAdder extends Striped64 implements Serializable &#123; // 构造方法，什么也不做，直接使用默认值，base = 0, cells = null public LongAdder() &#123; &#125; // add方法，根据父类的longAccumulate方法的要求，这里要进行一次CAS操作 // （虽然这里有两个CAS，但是第一个CAS成功了就不会执行第二个，要执行第二个，第一个就被“短路”了不会被执行） // 在线程竞争不激烈时，这样做更快 public void add(long x) &#123; Cell[] as; long b, v; int m; Cell a; //首先判断cells是否还没被初始化，并且尝试对value值进行cas操作 if ((as = cells) != null || !casBase(b = base, b + x)) &#123; boolean uncontended = true; //此处有多个判断条件，依次是 //1.cell[]数组还未初始化 //2.cell[]数组虽然初始化了但是数组长度为0 //3.该线程所对应的cell为null，其中要注意的是，当n为2的n次幂时，（(n - 1) &amp; h）等效于h%n //4.尝试对该线程对应的cell单元进行cas更新（加上x) if (as == null || (m = as.length - 1) &lt; 0 || (a = as[getProbe() &amp; m]) == null || !(uncontended = a.cas(v = a.value, v + x))) // 表示第一次cas成功情况 longAccumulate(x, null, uncontended); &#125; &#125; public void increment() &#123; add(1L); &#125; public void decrement() &#123; add(-1L); &#125; // 返回累加的和，也就是“当前时刻”的计数值 // 此返回值可能不是绝对准确的，因为调用这个方法时还有其他线程可能正在进行计数累加， // 方法的返回时刻和调用时刻不是同一个点，在有并发的情况下，这个值只是近似准确的计数值 // 高并发时，除非全局加锁，否则得不到程序运行中某个时刻绝对准确的值，但是全局加锁在高并发情况下是下下策 // 在很多的并发场景中，计数操作并不是核心，这种情况下允许计数器的值出现一点偏差，此时可以使用LongAdder // 在必须依赖准确计数值的场景中，应该自己处理而不是使用通用的类 public long sum() &#123; Cell[] as = cells; Cell a; long sum = base; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum; &#125; // 重置计数器，只应该在明确没有并发的情况下调用，可以用来避免重新new一个LongAdder public void reset() &#123; Cell[] as = cells; Cell a; base = 0L; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) a.value = 0L; &#125; &#125; &#125; // 相当于sum()后再调用reset() public long sumThenReset() &#123; Cell[] as = cells; Cell a; long sum = base; base = 0L; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) &#123; sum += a.value; a.value = 0L; &#125; &#125; &#125; return sum; &#125; // 其他的不说了 &#125; 5. 后记这个类是jdk1.8新增的类，目的是为了提供一个通用的，更高效的用于并发场景的计数器。可以网上搜下一些关于LongAdder的性能测试，有很多现成的，我自己就不写了。jdk1.8的ConcurrentHashMap中，没有再使用Segment，使用了一个简单的仿造LongAdder实现的计数器，这样能够保证计数效率不低于使用Segment的效率。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}],"author":"土川"},{"title":"[Java基础]BitSet","slug":"Java基础-BitSet","date":"2018-03-13T02:02:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"4146306917.html","link":"","permalink":"https://htchz.cc/4146306917.html","excerpt":"","text":"1. BitSet类大小可动态改变, 取值为true或false的位集合。用于表示一组布尔标志。 此类实现了一个按需增长的位向量。位 set 的每个组件都有一个 boolean 值。用非负的整数将 BitSet 的位编入索引。可以对每个编入索引的位进行测试、设置或者清除。通过逻辑与、逻辑或和逻辑异或操作，可以使用一个 BitSet 修改另一个 BitSet 的内容。默认情况下，set 中所有位的初始值都是 false。每个位 set 都有一个当前大小，也就是该位 set 当前所用空间的位数。注意，这个大小与位 set 的实现有关，所以它可能随实现的不同而更改。位 set 的长度与位 set 的逻辑长度有关，并且是与实现无关而定义的。除非另行说明，否则将 null 参数传递给 BitSet 中的任何方法都将导致 NullPointerException。 在没有外部同步的情况下，多个线程操作一个 BitSet 是不安全的。 2. 构造函数:BitSet() or BitSet(int nbits) 3. 一些方法12345678910111213141516public void set(int pos): 位置pos的字位设置为true。 public void set(int bitIndex, boolean value) 将指定索引处的位设置为指定的值。 public void clear(int pos): 位置pos的字位设置为false。public void clear() : 将此 BitSet 中的所有位设置为 false。 public int cardinality() 返回此 BitSet 中设置为 true 的位数。 public boolean get(int pos): 返回位置是pos的字位值。 public void and(BitSet other): other同该字位集进行与操作，结果作为该字位集的新值。 public void or(BitSet other): other同该字位集进行或操作，结果作为该字位集的新值。 public void xor(BitSet other): other同该字位集进行异或操作，结果作为该字位集的新值。public void andNot(BitSet set) 清除此 BitSet 中所有的位,set - 用来屏蔽此 BitSet 的 BitSetpublic int size(): 返回此 BitSet 表示位值时实际使用空间的位数。public int length() 返回此 BitSet 的“逻辑大小”：BitSet 中最高设置位的索引加 1。 public int hashCode(): 返回该集合Hash 码， 这个码同集合中的字位值有关。 public boolean equals(Object other): 如果other中的字位同集合中的字位相同，返回true。 public Object clone() 克隆此 BitSet，生成一个与之相等的新 BitSet。 public String toString() 返回此位 set 的字符串表示形式。 4. 解释Java.util.BitSet可以按位存储。计算机中一个字节（byte）占8位（bit），我们java中数据至少按字节存储的，比如一个int占4个字节。如果遇到大的数据量，这样必然会需要很大存储空间和内存。如何减少数据占用存储空间和内存可以用算法解决。java.util.BitSet就提供了这样的算法。比如有一堆数字，需要存储，source=[3,5,6,9]用int就需要4*4个字节。java.util.BitSet可以存true/false。如果用java.util.BitSet，则会少很多，其原理是： 先找出数据中最大值maxvalue=9 声明一个BitSet bs,它的size是maxvalue+1=10 遍历数据source，bs[source[i]]设置成true. 最后的值是：(0为false;1为true) bs [0,0,0,1,0,1,1,0,0,1] 这样一个本来要int型需要占4字节共32位的数字现在只用了1位！比例32:1 ,这样就省下了很大空间。 默认的构造函数声明一个64位的BitSet，值都是false。如果你要用的位超过了默认size,它会再申请64位，而不是报错。 123456789101112131415/** * @param args */ public static void main(String[] args) &#123; BitSet bm=new BitSet(); System.out.println(bm.isEmpty()+\"--\"+bm.size()); // true--64 bm.set(0); System.out.println(bm.isEmpty()+\"--\"+bm.size()); // false--64 bm.set(1); System.out.println(bm.isEmpty()+\"--\"+bm.size()); // false--64 System.out.println(bm.get(65)); // false System.out.println(bm.isEmpty()+\"--\"+bm.size()); // false--64 bm.set(65); System.out.println(bm.isEmpty()+\"--\"+bm.size()); // false--128 &#125; 申请的位都是以64为倍数的，就是说你申请不超过一个64的就按64算，超过一个不超过2个的就按128算。 12345678910111213public static void main(String[] args) &#123; BitSet bm1=new BitSet(7); System.out.println(bm1.isEmpty()+&quot;--&quot;+bm1.size()); // true-64 BitSet bm2=new BitSet(63); System.out.println(bm2.isEmpty()+&quot;--&quot;+bm2.size()); // true-64 BitSet bm3=new BitSet(65); System.out.println(bm3.isEmpty()+&quot;--&quot;+bm3.size()); // true-128 BitSet bm4=new BitSet(111); System.out.println(bm4.isEmpty()+&quot;--&quot;+bm4.size()); // true-128&#125; 来看一个小代码: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package com; import java.util.BitSet; public class MainTestFive &#123; /** * @param args */ public static void main(String[] args) &#123; int[] shu=&#123;2,42,5,6,6,18,33,15,25,31,28,37&#125;; BitSet bm1=new BitSet(MainTestFive.getMaxValue(shu)); System.out.println(&quot;bm1.size()--&quot;+bm1.size()); MainTestFive.putValueIntoBitSet(shu, bm1); printBitSet(bm1); &#125; //初始全部为false，这个你可以不用，因为默认都是false public static void initBitSet(BitSet bs)&#123; for(int i=0;i&lt;bs.size();i++)&#123; bs.set(i, false); &#125; &#125; //打印 public static void printBitSet(BitSet bs)&#123; StringBuffer buf=new StringBuffer(); buf.append(&quot;[\\n&quot;); for(int i=0;i&lt;bs.size();i++)&#123; if(i&lt;bs.size()-1)&#123; buf.append(MainTestFive.getBitTo10(bs.get(i))+&quot;,&quot;); &#125;else&#123; buf.append(MainTestFive.getBitTo10(bs.get(i))); &#125; if((i+1)%8==0&amp;&amp;i!=0)&#123; buf.append(&quot;\\n&quot;); &#125; &#125; buf.append(&quot;]&quot;); System.out.println(buf.toString()); &#125; //找出数据集合最大值 public static int getMaxValue(int[] zu)&#123; int temp=0; temp=zu[0]; for(int i=0;i&lt;zu.length;i++)&#123; if(temp&lt;zu[i])&#123; temp=zu[i]; &#125; &#125; System.out.println(&quot;maxvalue:&quot;+temp); return temp; &#125; //放值 public static void putValueIntoBitSet(int[] shu,BitSet bs)&#123; for(int i=0;i&lt;shu.length;i++)&#123; bs.set(shu[i], true); &#125; &#125; //true,false换成1,0为了好看 public static String getBitTo10(boolean flag)&#123; String a=&quot;&quot;; if(flag==true)&#123; return &quot;1&quot;; &#125;else&#123; return &quot;0&quot;; &#125; &#125; &#125; 输出: maxvalue:42 bm1.size()--64 0,0,1,0,0,1,1,0, 0,0,0,0,0,0,0,1, 0,0,1,0,0,0,0,0, 0,1,0,0,1,0,0,1, 0,1,0,0,0,1,0,0, 0,0,1,0,0,0,0,0, 0,0,0,0,0,0,0,0, 0,0,0,0,0,0,0,0这样便完成了存值和取值。注意它会对重复的数字过滤，就是说，一个数字出现过超过2次的它都记成1.出现的次数这个信息就丢了。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"位图","slug":"位图","permalink":"https://htchz.cc/tags/位图/"}],"author":"土川"},{"title":"[多线程]一个线程饥饿死锁的例子","slug":"多线程-一个线程饥饿死锁的例子","date":"2018-03-10T12:44:00.000Z","updated":"2019-08-21T06:47:46.115Z","comments":true,"path":"45692816.html","link":"","permalink":"https://htchz.cc/45692816.html","excerpt":"简单地说，就是循环阻塞，互相抢占资源。","text":"简单地说，就是循环阻塞，互相抢占资源。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.htc.test;import java.util.concurrent.*;/** * Created by Zack.Huang on 2017/8/24. */public class ThreadDeadlock &#123; ExecutorService exec = Executors.newSingleThreadScheduledExecutor();// ExecutorService exec = Executors.newCachedThreadPool(); //如果添加给线程池中添加足够多的线程，就可以让所有任务都执行，避免饥饿死锁。 /** * 模拟页面加载的例子 * * 产生死锁分析： * RenderPageTask任务中有2个子任务分别是“加载页眉”和“加载页脚”。当提交RenderPageTask任务时，实际上是向线程池中添加了3个任务， * 但是由于线程池是单一线程池，同时只会执行一个任务，2个子任务就会在阻塞在线程池中。而RenderPageTask任务由于得不到返回，也会 * 一直堵塞，不会释放线程资源让子线程执行。这样就导致了线程饥饿死锁。 * * 在一个Callable任务中，要返回2个子任务 * @author hadoop * */ class RenderPageTask implements Callable&lt;String&gt; &#123; @Override public String call() throws Exception &#123; Future&lt;String&gt; header,footer; header = exec.submit(() -&gt; &#123; System.out.println(\"加载页眉\"); Thread.sleep(2*1000); return \"页眉\"; &#125;); footer = exec.submit(() -&gt; &#123; System.out.println(\"加载页脚\"); Thread.sleep(3*1000); return \"页脚\"; &#125;); System.out.println(\"渲染页面主体\"); return header.get() + footer.get();//return \"you bad bad\"; 这里改为这样就可以不阻塞 &#125; &#125; public static void main(String[] args) throws InterruptedException, ExecutionException &#123; ThreadDeadlock td = new ThreadDeadlock(); Future&lt;String&gt; futre = td.exec.submit(td.new RenderPageTask()); String result = futre.get(); System.out.println(\"执行结果为：\" + result); &#125;&#125;","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}],"author":"土川"},{"title":"[老司机]BT协议学习笔记","slug":"网络-BT协议学习笔记","date":"2018-03-10T08:01:00.000Z","updated":"2019-12-03T01:02:43.251Z","comments":true,"path":"2501905798.html","link":"","permalink":"https://htchz.cc/2501905798.html","excerpt":"","text":"1. 编码 B encode在说明网络流程之前，先简单介绍下B encode，因为在BitTorrent协议中的数据几乎都是用B encode进行编码的。它是一种作用类似于XML和JSON的数据组织格式，可以表达字符串、整数两种基本类型，列表、字典两种数据结构，它的语法规则十分简单。 字节串按如下方式编码： &lt;以十进制ASCII编码的串长度&gt;：&lt;串数据&gt;例：“4:spam”表示字节串“spam” 整数按如下方式编码： i&lt;以十进制ASCII编码的整数&gt;e例：“i3e”表示整数“3” 列表按如下方式编码： l&lt;内容&gt;e开始的“l”与结尾的“e”分别是开始和结束分隔符。lists可以包含任何B编码的类型，包括整数、串、dictionaries和其他的lists。例：l4:spam4:eggse 表示含有两个串的lists:[“spam”、“eggs”] 字典按如下方式编码： d&lt;内容&gt;e开始的“d”与结尾的“e”分别是开始和结束分隔符。注意键（key）必须被B编码为串。值可以是任何B编码的类型，包括整数、串、lists和其他的dictionaries。键（key）必须是串，并且以排序的顺序出现（以原始串排列，而不是以字母数字顺序）。例1：d3:cow3:moo4:spam4:eggse 表示dictionary { “cow” =&gt; “moo”, “spam” =&gt; “eggs” } 2. 元信息文件 .torrent作为发布者，首先需要有一个域名，一台作为Tracker的服务器，一台发布.torrent文件的服务器，一台保存资源的服务器，当然这些可以共用一台服务器。使用BitTorrent工具选择“海贼王712集.mkv”文件，指定Tracker服务器的URL，会生成一个.torrent文件。 .torrent文件使用B encode表示，整个是一个字典数据结构，它有多个key值，包括一些是可选的，这里介绍最关键的几个键值对。 info：存储资源文件的元信息 piece length pieces name/path announce：描述tracker服务器的URL info键对应的值又是一个字典结构，BT协议将一个文件分成若干片，便于客户端从各个主机下载各个片。其中的piece length键值对表示一个片的长度，通畅情况下是2的n次方，根据文件大小有所权衡，通长越大的文件piece length越大以减少piece的数量，降低数量一方面降低了.torrent保存piece信息的大小，一方面也减少了下载需要对片做的确认操作，加快下载速度。目前通常是256kB,512kB或者1MB。 pieces则是每个piece的正确性验证信息，每一片均对应一个唯一的SHA1散列值，该键对应的值是所有的20字节SHA1散列值连接而成的字符串。 name/path比较笼统的说，就是具体文件的信息。因为BitTorrent协议允许将数个文件和文件夹作为一个BitTorrent下载进行发布，因此下载方可以根据需要勾选某一些下载文件。注意，这里将数个文件也砍成一个数据流，因此一个piece如果在文件边界上，可能包含不同文件的信息。 announce保存的是tracker服务器的URL，也就是客户端拿到.torrent文件首先要访问的服务器，在一些扩展协议中，announce可以保存多个tracker服务器作为备选。 生成好.torrent文件之后，发布者需要先作为下载者一样根据.torrent文件进行下载，这样就会连接到tracker服务器。由于发布者已经有了完整的资源文件，tracker服务器会得知这是一个完全下载完成的用户，会把发布者的信息保存在tracker服务器中，这之间的协议在后面讲客户端和tracker服务器的通信协议的时候再说。 发布者还要做的最后一件事就是将.torrent文件放在服务器上，可以通过HTTP或者FTP协议供用户下载这个.torrent文件。相比于直接将整个资源文件提供给用户下载，只传输一个.torrent文件大大降低了服务器的负荷。 这样，发布者的任务就完成了，只需要在资源传播开前保证资源服务器，也就是保存了“海贼王712集.mkv”文件的服务器在开启状态，能够持续上传直到资源传播开来。 3. 客户端和Tracker服务器现在我是一个动漫爱好者，我发现了漫游上有新的“海贼王712集.mkv”的BT资源，我需要怎样才能下载到这个视频呢？ 首先，可以通过HTTP或者FTP协议直接从服务器上得到.torrent文件。然后使用BitTorrent软件客户端打开.torrent文件，软件会根据.torrent的name/path元信息告诉我这个.torrent文件可以下载到一个.mkv文件，一个字幕文件，在这个阶段我可以进行一些勾选，选择下载某些而不是全部的资源。 资源选择确定后，BitTorrent软件客户端就开始了下载。客户端的第一步任务根据.torrent上的URL使用HTTP GET请求，这个请求包含了很多参数，这里只介绍从客户端发送到Tracker的请求最关键的几个参数。 info_hash peer_id ip port info_hash是元信息.torrent文件中info键所对应的值的SHA1散列，可以被Tracker服务器用来索引唯一的对应资源。 peer_id是20byte的串，没有任何要求，被Tracker服务器用于记录客户端的名字。 ip可以从HTTP GET请求中直接获取，放在参数中可以解决使用代理进行HTTP GET的情况，Tracker服务器可以记录客户端的IP地址。 port客户端监听的端口号，用于接收response。一般情况下为BitTorrent协议保留的端口号是6881-6889，Tracker服务器会记录下端口号用于通知其他客户端。 在Tracker服务器收到客户端的HTTP GET请求后，会返回B encode形式的text/plain文本，同样是一个字典数据结构，其中最关键的一个键值对是peers，它的值是个字典列表结构，列表中的每一项都是如下的字典结构。 peers peer_id ip port 这些信息在每个客户端连接Tracker服务器的时候都发送过，并且被Tracker服务器保存了下来。新来的客户端自然要获取到这些下载中或者已下载完的客户端的ip，port等信息，有了这些信息，客户端就不需要像FTP或者HTTP协议一样持续找服务器获取资源，可以从这些其他客户端上请求获取资源。 4. peer to peerpeer to peer，简称P2P，就是从其他的下载用户那里获取数据，也就是BitTorrent下载的核心特点。客户端从Tracker服务器获取到若干其他下载者(peer)的ip和port信息，会进行请求并维持跟每一个peer的连接状态。一个客户端和每一个peer的状态主要有下列状态信息： choked：远程客户端拒绝响应任何本客户端的请求。 interested：远程客户端对本客户端的数据感兴趣，当本客户端unchoked远程客户端后，远程客户端会请求数据。 所以应该有4个参数，分别表示本客户端对远程客户端是否chock，是否interested，远程客户端对本客户端是否chock，是否interested。当一个客户端对一个远程peer感兴趣并且那个远程peer没有choke这个客户端，那么这个客户端就可以从远程peer下载块(block)。当一个客户端没有choke一个peer，并且那个peer对这个客户端这个感兴趣时，这个客户端就会上传块(block)。 第一次通信会先发送握手报文，告诉远程客户端本客户端的一些信息，包括info_hash和peer_id。接下来的所有报文有如下几种类型： keep-alive：告诉远程客户端这个通信还在维持，否则超过2分钟没有任何报文远程客户端会将通信关闭 choke unchoke interested not interested bitfield：告诉对方我已经有的piece have：告诉对方某个piece已经成功下载并且通过hash校验 request：请求某个块(block) index: 整数，指定从零开始的piece索引 begin: 整数，指定piece中从零开始的字节偏移 length: 整数，指定请求的长度 piece：返回请求的块(block)的数据，是真正的资源信息 index: 整数，指定从零开始的piece索引 begin: 整数，指定piece中从零开始的字节偏移 block: 数据块经过这些报文在本地客户端和若干个远程客户端之间的来回传递，就能够获取到资源文件。 经过前面的简单描述，可以看到这种P2P信息传递的有诸多可以进行挖掘和优化的地方。比如每次tracker服务器返回多少个peer，多了无用并且增加网络负荷，少了又不够。客户端同时和多少个peer保持通信最好。客户端应该优先请求哪些piece，如何请求连续的piece能够提高缓存的使用率。为什么下载接近完成最后的一些数据总是非常慢。这些都是值得优化和研究的地方。","categories":[{"name":"网络","slug":"网络","permalink":"https://htchz.cc/categories/网络/"}],"tags":[{"name":"BT","slug":"BT","permalink":"https://htchz.cc/tags/BT/"}],"author":"土川"},{"title":"[Nginx]Nginx location 匹配原则","slug":"Nginx-location-匹配原则","date":"2018-03-10T07:16:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"3180078468.html","link":"","permalink":"https://htchz.cc/3180078468.html","excerpt":"","text":"Location block 的基本语法形式是：location [=|~|~*|^~|@] pattern { ... } [=|~|~*|^~|@]被称作 location modifier ，这会定义 Nginx 如何去匹配其后的 pattern ，以及该 pattern 的最基本的属性（简单字符串或正则表达式） 1. location modifier详解 1、= 123456server &#123; server_name htchz.com; location = /abcd &#123; […] &#125;&#125; 匹配情况： http://website.com/abcd # 正好完全匹配 http://website.com/ABCD # 如果运行 Nginx server 的系统本身对大小写不敏感，比如 Windows ，那么也匹配 http://website.com/abcd?param1m2 # 忽略查询串参数（query string arguments），这里就是 /abcd 后面的 ?param1m2 http://website.com/abcd/ # 不匹配，因为末尾存在反斜杠（trailing slash），Nginx 不认为这种情况是完全匹配 http://website.com/abcde # 不匹配，因为不是完全匹配 2、(None) 不写 location modifier ，Nginx 仍然能去匹配 pattern 。这种情况下，匹配那些以指定的 patern 开头的 URI，注意这里的 URI 只能是普通字符串，不能使用正则表达式。 123456server &#123; server_name website.com; location /abcd &#123; […] &#125;&#125; 匹配情况： http://website.com/abcd # 正好完全匹配 http://website.com/ABCD # 如果运行 Nginx server 的系统本身对大小写不敏感，比如 Windows ，那么也匹配 http://website.com/abcd?param1m2 # 忽略查询串参数（query string arguments），这里就是 /abcd 后面的 ?param1m2 http://website.com/abcd/ # 末尾存在反斜杠（trailing slash）也属于匹配范围内 http://website.com/abcde # 仍然匹配，因为 URI 是以 pattern 开头的 3、~ 123456server &#123; server_name website.com; location ~ ^/abcd$ &#123; […] &#125;&#125; 匹配情况： http://website.com/abcd # 完全匹配 http://website.com/ABCD # 不匹配，~ 对大小写是敏感的 http://website.com/abcd?param1m2 # 忽略查询串参数（query string arguments），这里就是 /abcd 后面的 ?param1m2 http://website.com/abcd/ # 不匹配，因为末尾存在反斜杠（trailing slash），并不匹配正则表达式 ^/abcd$ http://website.com/abcde # 不匹配正则表达式 ^/abcd$ 对于一些对大小写不敏感的系统，比如 Windows ，~ 和 ~* 都是不起作用的，这主要是操作系统的原因。 4、~* 与 ~ 类似，但这个 location modifier 不区分大小写，pattern 须是正则表达式 123456server &#123; server_name website.com; location ~* ^/abcd$ &#123; […] &#125;&#125; http://website.com/abcd # 完全匹配 http://website.com/ABCD # 匹配，这就是它不区分大小写的特性 http://website.com/abcd?param1m2 # 忽略查询串参数（query string arguments），这里就是 /abcd 后面的 ?param1m2 http://website.com/abcd/ # 不匹配，因为末尾存在反斜杠（trailing slash），并不匹配正则表达式 ^/abcd$ http://website.com/abcde # 不匹配正则表达式 ^/abcd$ 5、^~ 匹配情况类似 2. (None) 的情况，以指定匹配模式开头的 URI 被匹配，不同的是，一旦匹配成功，那么 Nginx 就停止去寻找其他的 Location 块进行匹配了（与 Location 匹配顺序有关） 6、@ 用于定义一个 Location 块，且该块不能被外部 Client 所访问，只能被 Nginx 内部配置指令所访问，比如 try_files or error_page 2. 搜索顺序以及生效优先级因为可以定义多个 Location 块，每个 Location 块可以有各自的 pattern 。因此就需要明白（不管是 Nginx 还是你），当 Nginx 收到一个请求时，它是如何去匹配 URI 并找到合适的 Location 的。 要注意的是，写在配置文件中每个 Server 块中的 Location 块的次序是不重要的，Nginx 会按 location modifier 的优先级来依次用 URI 去匹配 pattern ，顺序如下： 1. = 2. (None) 如果 pattern 完全匹配 URI（不是只匹配 URI 的头部） 3. ^~ 4. ~ 或 ~* 5. (None) pattern 匹配 URI 的头部3. 实际使用建议所以实际使用中，个人觉得至少有三个匹配规则定义，如下：直接匹配网站根，通过域名访问网站首页比较频繁，使用这个会加速处理，官网如是说。这里是直接转发给后端应用服务器了，也可以是一个静态首页 第一个必选规则 123location = / &#123; proxy_pass http://tomcat:8080/index&#125; 第二个必选规则是处理静态文件请求，这是nginx作为http服务器的强项,有两种配置模式，目录匹配或后缀匹配,任选其一或搭配使用 123location ^~ /static/ &#123; root /webroot/static/;&#125; 123location ~* \\.(gif|jpg|jpeg|png|css|js|ico)$ &#123; root /webroot/res/;&#125; 第三个规则就是通用规则，用来转发动态请求到后端应用服务器，非静态文件请求就默认是动态请求，自己根据实际把握 123location / &#123; proxy_pass http://tomcat:8080/&#125;","categories":[{"name":"服务器","slug":"服务器","permalink":"https://htchz.cc/categories/服务器/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://htchz.cc/tags/Nginx/"}],"author":"土川"},{"title":"[Spring]Spring加载参数那些事","slug":"Spring加载参数那些事","date":"2018-03-10T07:06:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"298553133.html","link":"","permalink":"https://htchz.cc/298553133.html","excerpt":"","text":"1. 通过&lt;context:property-placeholder location=”classpath:conn.properties” &gt;1234567 &lt;context:property-placeholder location=\"classpath:conn.properties\"/&gt;&lt;bean id=\"dataSource\" class=\"$&#123;dataSource&#125;\"&gt; &lt;!-- 这些配置Spring在启动时会去conn.properties中找 --&gt; &lt;property name=\"driverClass\" value=\"$&#123;driverClass&#125;\" /&gt; &lt;property name=\"jdbcUrl\" value=\"$&#123;jdbcUrl&#125;\" /&gt; &lt;property name=\"user\" value=\"$&#123;user&#125;\" /&gt; &lt;property name=\"password\" value=\"$&#123;password&#125;\" /&gt; &lt;/bean&gt; 2. 通过@Value注解@Value注解有两种Configurer可以使用，一种是PropertiesFactoryBean，另一种是PropertyPlaceholderConfigurer，后者注重于模板${} 123456789&lt;!-- 第二种方式是使用注解的方式注入，主要用在java代码中使用注解注入properties文件中相应的value值 --&gt; &lt;bean id=\"prop\" class=\"org.springframework.beans.factory.config.PropertyPlaceholderConfigurer\"&gt; &lt;!-- 或者使用&lt;bean id=\"prop\" class=\"org.springframework.beans.factory.config.PropertiesFactoryBean\"&gt; --&gt; &lt;property name=\"locations\"&gt;&lt;!-- 这里是PropertiesFactoryBean类，它也有个locations属性，也是接收一个数组，跟上面一样 &lt;array&gt; &lt;value&gt;classpath:public.properties&lt;/value&gt; &lt;/array&gt; &lt;/property&gt; &lt;/bean&gt; 然后在bean里使用@Value(“#{beanId[property_name]}”)(PropertiesFactoryBean)或者@Value(“${xxxxx}”)(PropertyPlaceholderConfigurer)即可，如public.properties里有 username=htc 那么在bean里使用@Value(“${username}”) String username 注入在方法参数 注意要有set方法才能被注入进来，注解写在set方法上即可。在setFilePath方法中通过控制台打印filePath是为了在启动tomcat的时候，观察控制台有没有输出来，如果有，说明Spring在启动时，已经将filePath给加载好了，我们看一下控制台的启动信息：3. 重要：第三种@ConfigurationProperties 123456@Bean(value = \"dataSource\", destroyMethod = \"close\", initMethod = \"init\")@Primary@ConfigurationProperties(prefix = \"druid\")public DataSource getDataSource(@Value(\"$&#123;jdbcUrl&#125;\") String jdbcUrl,@Value(\"$&#123;user&#125;\") String user,@Value(\"$&#123;password&#125;\") String password)&#123; return DataSourceBuilder.create().username(user).password(password).type(DruidDataSource.class).url(jdbcUrl).build();&#125; 这里使用了@ConfigurationProperties在使得在处理bean的时候可以自动根据fieldname注入值然而使用上面的配置是不会注入的，因为读不到！上面的配置是用PropertyPlaceholderConfigurer这个类来存储配置文件，而@ConfigurationProperties是使用这个类 org.springframework.context.support.PropertySourcesPlaceholderConfigurer所以要配置的话得这么配置 1234567&lt;bean id=\"resourcePropertyConfigurer\" class=\"org.springframework.context.support.PropertySourcesPlaceholderConfigurer\"&gt; &lt;property name=\"locations\"&gt; &lt;list&gt; &lt;value&gt;classpath*:druid.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt; 实际上PropertySourcesPlaceholderConfigurer是springframework后来出的，相当于PropertyPlaceholderConfigurer的升级版 druid.properties里的内容类似于 druid.initialSize=10 druid.minIdle=1 ...如上，spring还可以自动根据前缀装配，根据属性名模糊匹配。 spring使用了模糊匹配，对于一个属性可以生成几十个变种，如有个属性叫”serverPort”，可以有“serverPort“、“server-port“、“serverport“等很多变种，是一种松懈的匹配，然后对于生成的几十种变种遍历，逐一和properties匹配，匹配到第一个就返回 以上就是Spring加载properties配置文件的几种方式。实际上，上面基于xml方式中的PropertyPlaceholderConfigurer类和这里基于注解方式的PropertiesFactoryBean类都是继承PropertiesLoaderSupport，都是用来加载properties配置文件的。 在spring配置文件中，对于bean的配置有这样一个配置：&lt;property name=”ignoreUnresolvablePlaceholders” value=”true” /&gt;这个主要是为了解决抛出cannot be resolved的异常。","categories":[{"name":"Spring","slug":"Spring","permalink":"https://htchz.cc/categories/Spring/"}],"tags":[{"name":"properties","slug":"properties","permalink":"https://htchz.cc/tags/properties/"}],"author":"土川"},{"title":"[qps]HystrixRollingNumber,可作为一个qps计数器","slug":"HystrixRollingNumber-可作为一个qps计数器","date":"2018-03-10T06:53:00.000Z","updated":"2019-06-24T07:32:04.000Z","comments":true,"path":"10902277.html","link":"","permalink":"https://htchz.cc/10902277.html","excerpt":"","text":"Hystrix是Netflix开源的一款容错系统，能帮助使用者码出具备强大的容错能力和鲁棒性的程序。 1. 前言考虑到一种需求场景，我们需要统计系统qps、每秒平均错误率等。qps表示每秒的请求数目，能想到的最简单的方法就是统计一定时间内的请求总数然后除以总统计时间，所以计数是其中最核心的部分。通常我们的额系统是工作在多线程的环境下，所以计数我们可以考虑使用AtomicInteger/AtomicLong系列，AtomXXX中没有使用锁，使用的是循环+CAS，在多线程的条件下可以在一定程度上减少锁带来的性能损失。但是在竞争特别激烈的情况，会大量出现cas不成功的情况带来性能上的开销。为了更进一步分散线程写的压力，JDK8中引入了LongAdder，LongAdder会分成多个桶，将每个线程绑定到固定的桶空间中进行读写，计数可以对所有的桶中的值求总数。前面提到求qps最简单的方法就是统计一定时间内的请求总数然后除以总统计时间，这样的方法虽然简单但是对有一定的问题，比如说统计出的qps跳跃性会比较大，不够平滑等。在本文中将介绍HystrixRollingNumber，这是Hystrix的一个工具类，这个数据结构在统计qps等类似的求和统计的场景下非常有用。 要我自己写的话。。要么粒度太大，不够平滑，要么粒度小了，一堆锁竞争。 2. 基本原理如前所说，HystrixRollingNumber中利用了LongAdder，也借鉴了LongAdder分段的思想。HystrixRollingNumber基本思想就是分段统计，比如说要统计qps，即1秒内的请求总数。如下图所示，我们可以将1s的时间分成10段，每段100ms。在第一个100ms内，写入第一个段中进行计数，在第二个100ms内，写入第二个段中进行计数，这样如果要统计当前时间的qps，我们总是可以通过统计当前时间前1s（共10段）的计数总和值。让我们来看看HystrixRollingNumber中具体是怎么做的。 3. BucketHystrixRollingNumber中对Bucket的描述是“Counters for a given ‘bucket’ of time”，即“给定时间桶内的计数器”，也即是我们上面所说的“段”。Bucket中有三个重要的属性值 final long windowStart; final LongAdder[] adderForCounterType; final LongMaxUpdater[] updaterForCounterType;windowStart记录了该Bucket所属的时间段的开始时间，adderForCounterType是一个LongAdder数组，每个元素代表了一种事件类型的计数值。updaterForCounterType同理。adderForCounterType数组的长度等于事件类型的个数，具体的事件类型可以参考HystrixRollingNumberEvent枚举类。相关的方法介绍如下(以下代码去掉了LongMaxUpdater相关，LongMaxUpdater用来统计最大值，和LongAdder类似可类比)： long get(HystrixRollingNumberEvent type):获取事件对应的LongAdder的总和 LongAdder getAdder(HystrixRollingNumberEvent type):获取事件对应的LongAdder对象 4. ListStateHystrixRollingNumber中对ListState的描述是“Immutable object that is atomically set every time the state of the BucketCircularArray changes，This handles the compound operations”，即“ListState是个不可变类，每次BucketCircularArray状态改变的时候，会新建一个并且会原子地设置到BucketCircularArray中，它用来处理复合操作”。ListState中比较重要的的属性值介绍如下： private final AtomicReferenceArray data:官方的说明是“this is an AtomicReferenceArray and not a normal Array because we’re copying the reference between ListState objects and multiple threads could maintain references across these compound operations so I want the visibility/concurrency guarantees”，意思是说“ListState持有Bucket数组对象，但是这个数组不是普通的数组而是AtomicReferenceArray，这是因为我们会在ListState对象之间拷贝reference，多个线程之间会通过复合操作持有引用，我们想要保证可见性/并发性”（AtomicXXX是原子操作） private final int size;（持有的Bucket数组大小，可以增加，但是最大值是numBuckets） private final int tail;（数组的尾部地址） private final int head;（数组的头部地址）ListState中有几个比较重要的方法 public Bucket tail():返回数组尾部的元素 public ListState clear():清空数组元素 public ListState addBucket(Bucket b):在尾部增加一个BucketListState是个不可变类，遵循者不可变类的原则 Fields为final，在构造方法中全部发布一次copy on write，写方法（addBucket）返回新的ListStateListState算是个助手类，维持了一个Bucket数组，定义了一些围绕着Bucket数组的有用操作，并且自身是个不可变类，天然的线程安全属性。 5. BucketCircularArray从名字上来说是一个环形数组，数组中的每个元素是一个Bucket，事实上大部分操作都是落到了ListState数据结构上BucketCircularArray中比较重要的属性值介绍如下： private final AtomicReference state: 维持了一个ListState的AtomicReference private final int numBuckets:环的大小 其中主要的比较重要的一个方法是：public void addLast(Bucket o) : 12345678910111213141516171819public void addLast(Bucket o) &#123; ListState currentState = state.get(); // create new version of state (what we want it to become) ListState newState = currentState.addBucket(o); //这里返回新的ListState实例 /* * use compareAndSet to set in case multiple threads are attempting (which shouldn&apos;t be the case because since addLast will ONLY be called by a single thread at a time due to protection * provided in &lt;code&gt;getCurrentBucket&lt;/code&gt;) */ if (state.compareAndSet(currentState, newState)) &#123; // we succeeded return; &#125; else &#123; // we failed, someone else was adding or removing // instead of trying again and risking multiple addLast concurrently (which shouldn&apos;t be the case) // we&apos;ll just return and let the other thread &apos;win&apos; and if the timing is off the next call to getCurrentBucket will fix things return; &#125;&#125; 这个方法主要就是为了在ListState的尾部添加一个Bucket，并且将新返回的ListState对象CAS到state中，但是其中有个比较特殊的处理，就是在一次CAS不成功的时候，程序完全忽略这次失败。注释是这么解释的“we failed, someone else was adding or removing instead of trying again and risking multiple addLast concurrently (which shouldn’t be the case) we’ll just return and let the other thread ‘win’ and if the timing is off the next call to getCurrentBucket will fix things”。大概意思就是说如果CAS失败是因为其他线程正在执行adding或者removing操作。我们不重试，而只是返回让其他线程“win”(这只是一个创建桶的操作)，如果时间片流逝了，我们可以通过下次调用getCurrentBucket进行补偿（详细的请看下面对于getCurrentBucket的分析） 6. HystrixRollingNumber官方doc中给其的定义是“A number which can be used to track counters (increment) or set values over time.”，用来统计一段时间内的计数。其中比较重要的的属性值如下： private final Time time: 获取当前时间毫秒值 final int timeInMilliseconds: 统计的时间长度（毫秒单位） final int numberOfBuckets: Bucket的数量（分成多少段进行统计） final int bucketSizeInMillseconds: 每个Bucket所对应的时间片（毫秒单位） final BucketCircularArray buckets: 使用BucketCircularArray帮助维持环形数组桶 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374Bucket getCurrentBucket() &#123; // 获取当前的毫秒时间 long currentTime = time.getCurrentTimeInMillis(); //获取最后一个Bucket（即最新一个Bucket） Bucket currentBucket = buckets.peekLast(); if (currentBucket != null &amp;&amp; currentTime &lt; currentBucket.windowStart + this.bucketSizeInMillseconds) &#123; //如果当前时间是在currentBucket对应的时间窗口内，直接返回currentBucket return currentBucket; &#125; /* if we didn&apos;t find the current bucket above, then we have to create one */ //如果当前时间对应的Bucket不存在，我们需要创建一个 if (newBucketLock.tryLock()) &#123; //尝试获取一次锁 try &#123; if (buckets.peekLast() == null) &#123; // the list is empty so create the first bucket //首次创建 Bucket newBucket = new Bucket(currentTime); buckets.addLast(newBucket); return newBucket; &#125; else &#123; // We go into a loop so that it will create as many buckets as needed to catch up to the current time // as we want the buckets complete even if we don&apos;t have transactions during a period of time. // 将创建一个或者多个Bucket，直到Bucket代表的时间窗口赶上当前时间 for (int i = 0; i &lt; numberOfBuckets; i++) &#123; // we have at least 1 bucket so retrieve it Bucket lastBucket = buckets.peekLast(); if (currentTime &lt; lastBucket.windowStart + this.bucketSizeInMillseconds) &#123; // if we&apos;re within the bucket &apos;window of time&apos; return the current one // NOTE: We do not worry if we are BEFORE the window in a weird case of where thread scheduling causes that to occur, // we&apos;ll just use the latest as long as we&apos;re not AFTER the window return lastBucket; &#125; else if (currentTime - (lastBucket.windowStart + this.bucketSizeInMillseconds) &gt; timeInMilliseconds) &#123; // the time passed is greater than the entire rolling counter so we want to clear it all and start from scratch reset(); // recursively call getCurrentBucket which will create a new bucket and return it return getCurrentBucket(); &#125; else &#123; // we&apos;re past the window so we need to create a new bucket // create a new bucket and add it as the new &apos;last&apos; buckets.addLast(new Bucket(lastBucket.windowStart + this.bucketSizeInMillseconds)); // add the lastBucket values to the cumulativeSum cumulativeSum.addBucket(lastBucket); &#125; &#125; // we have finished the for-loop and created all of the buckets, so return the lastBucket now return buckets.peekLast(); &#125; &#125; finally &#123; //释放锁 newBucketLock.unlock(); &#125; &#125; else &#123; //如果获取不到锁，尝试获取最新一个Bucket currentBucket = buckets.peekLast(); if (currentBucket != null) &#123; //如果不为null，直接返回最新Bucket // we didn&apos;t get the lock so just return the latest bucket while another thread creates the next one return currentBucket; &#125; else &#123; //多个线程同时创建第一个Bucket，尝试等待，递归调用getCurrentBucket // the rare scenario where multiple threads raced to create the very first bucket // wait slightly and then use recursion while the other thread finishes creating a bucket try &#123; Thread.sleep(5); &#125; catch (Exception e) &#123; // ignore &#125; return getCurrentBucket(); &#125; &#125;&#125; 其实HystrixRollingNumber中写了很多有用的注释，解释了为什么要这么做。上述getCurrentBucket主要是为了获取当前时间窗所对应的Bucket，但是为了减少竞争，其中只使用了tryLock()，如果不成功则直接返回最新的一个不为空的Bucket。如果获取了锁则尝试增加Bucket（增加Bucket会一直增加到Bucket对应的时间窗口覆盖当前时间）。这样处理会有个小问题，就是获取的Bucket可能没有覆盖当前时间（原因是 currentTime只获取一次，在for循环的过程中会过时），这是为了减少竞争，提高效率，而且未创建的bucket最终还是会被创建（下一次getCurrentBucket()），这在统计的场景下可以容忍，将计数统计到之前的时间窗口内在计算qps等数值时通常不会有太大影响（numberOfBuckets通常不止一个）。 7. 总结HystrixRollingNumber这个数据结构用于统计qps很有用，通常这种统计需求（限流监控统计qps的场景下）不能影响主要业务，对性能要求比较高，HystrixRollingNumber中采取了很多技巧避免使用锁，避免多个线程竞争，所以HystrixRollingNumber效率会非常高。","categories":[{"name":"微服务","slug":"微服务","permalink":"https://htchz.cc/categories/微服务/"}],"tags":[{"name":"服务限流","slug":"服务限流","permalink":"https://htchz.cc/tags/服务限流/"},{"name":"Hystrix","slug":"Hystrix","permalink":"https://htchz.cc/tags/Hystrix/"}],"author":"土川"},{"title":"[碧油鸡]Hexo-admin的404探索","slug":"碧油鸡-Hexo","date":"2018-03-10T02:58:00.000Z","updated":"2020-06-06T17:53:23.395Z","comments":true,"path":"3915904827.html","link":"","permalink":"https://htchz.cc/3915904827.html","excerpt":"","text":"作为一个不懂js的后端开始了瞎搞。。 hexo-admin在写的时候，一般是把图片放到图床，再获得图片链接加入md，但是笔者习惯了为知笔记直接把图片复制粘贴进md里。不过hexo-admin确实加入了这个直接粘贴图片的功能，把图片复制进md里，有时会出现一个404的问题，一直百度谷歌无果，同事老哥一直叫我用gitbook，但是不找出这个404的谜底实在难受，于是有了下面的记录。 1. First Blood 第一张图如上图，上传成功后出现了404，点击404发生的代码，如下：hexo-admin直接生成html进行html内容的替换。可以看到笔者把图片粘贴之后，hexo-admin做了三个操作： 上传图片，返回![upload successful](/images/pasted-8.png)的字符串给客户端 客户端根据返回的字符串重新渲染 把新的文章内容post到服务器 为什么上传成功还404???这时笔者点开图片的链接 没问题啊，诡异。 2. 第二张图粘贴第二张图片的时候 可以看到第一次获取失败的Nubia Z17获取成功了，证明图片是上传成功，然而林允儿在上传完成后，并没有404 3. 第三张图片粘贴Gakki，又是404 4. 其他现象 上面是在宿舍的操作，在公司操作的时候完全没出现这种404。不过有一个现象是，公司网络ping这台vps的时候有点慢，宿舍网ping这台vps非常快。 新建了另一台vps，同样的环境，也没有404。但是这台vps在洛杉矶，网络时延有点大。 5. 各种小动作于是在404的js打上断点， 运行到这里之后，继续执行所有js，没发生404。 于是乎猜想： 服务器保存图片的接下来，返回了response，肯定还进行了某个操作，但是短时间内这个操作没完成，导致短时间内访问的时候还不能通。 这可以解释上面： 第一次操作是404，第二次却是两张图片都成功请求到。原因是第二次访问时，由于我的Nubia没成功加载，他会去再访问一次，这就导致了林允儿的请求会稍晚一点，而这点时间间隔里，对林允儿的某个操作已经完成，所以第二次操作不存在404，而第三次操作，Gakki又没给某个操作留时间完成，请求结果明显404。 公司访问我的vps比较慢，网络上的时延足够某个操作完成 断点的时延足够某个操作完成 那么上vps看日志，三次操作依次三张图。 hexo server --debug可以输出日志 利用小学找规律题目的尿性，我发觉404发生在这坨Generator操作之前 规律不是3次操作总结的，其实复现了很多次了 网上看到hexo-server会jian视source文件夹的变动，我手动把一张图片加入source/images目录下，他也自动跑出Generator日志。于是我猜想这个Generator不跑完，就不能通过hexo-server访问到图片。 怎么验证，琢磨去改hexo-admin代码，上github，不懂node.js，看到一个api.js的就点进去，惊喜找到这个接口 推荐个看GitHub的神器Octotree，我在chrome商店装的，可以直接看到GitHub的目录。 这个方法拉到最底 12345678910111213141516... var dataURI = req.body.data.slice('data:image/png;base64,'.length) var buf = new Buffer(dataURI, 'base64') hexo.log.d(`saving image to $&#123;outpath&#125;`) fs.writeFile(outpath, buf, function (err) &#123; if (err) &#123; console.log(err) &#125; hexo.source.process().then(function () &#123; res.done(&#123; src: path.join(hexo.config.root + filename), msg: msg &#125;) &#125;); &#125;)... 把服务器发送响应res.done语句延迟50ms执行后，再也没有发生过过404 123456789101112131415161718... var dataURI = req.body.data.slice('data:image/png;base64,'.length) var buf = new Buffer(dataURI, 'base64') hexo.log.d(`saving image to $&#123;outpath&#125;`) fs.writeFile(outpath, buf, function (err) &#123; if (err) &#123; console.log(err) &#125; hexo.source.process().then(function () &#123; setTimeout(function()&#123; // 百度来的延迟执行的方法。。 res.done(&#123; src: path.join(hexo.config.root + filename), msg: msg &#125;) &#125;, 50); &#125;); &#125;)... 为什么是50ms？看日志的时间，100ms左右可以保证Generator操作完成，于是我直接设置50ms，到现在也没再404过。 6. 后记我看hexo-admin也没人提这个issue，估计直接粘贴图片的人不多，毕竟这种方法不能清理md不再引用的图片。我能想到的解决方法就是延迟执行再响应请求了，毕竟这个线程也不清楚Generator什么时候才执行完。。。","categories":[{"name":"建站","slug":"建站","permalink":"https://htchz.cc/categories/建站/"}],"tags":[{"name":"BUG","slug":"BUG","permalink":"https://htchz.cc/tags/BUG/"}],"author":"土川"},{"title":"[建站]Hexo+Nginx+VPS实现HTTPS建站","slug":"建站-Hexo+Nginx+VPS实现HTTPS建站","date":"2018-03-08T10:02:00.000Z","updated":"2019-08-21T06:49:14.951Z","comments":true,"path":"711179553.html","link":"","permalink":"https://htchz.cc/711179553.html","excerpt":"","text":"拿人家hexo来建站，参考hexo建站写的，加上一些自己的东西 系统：centos6，是vultr的一个vps，1000g流量100m带宽可以跑满，最低每个月5美刀，点击就送屠龙宝刀嘿嘿vultr.com使用工具：nginx用来做反向代理和https重定向、certbot来做免费证书申请、GitHub pages 同步博客、hexo做静态资源、hey hexo做博客管理 1. GitHub Pageshexo可以将文件同步到GitHub page上，可以同步后，输入[你的帐户名].github.io 来访问 没有GitHub账号吗，现在你有了 命名格式是:[你的帐户名].github.io，不然不行哦 2. Hexo最好照着官网来，因为这个东西更新有点快,链接已经说明一切装node curl --silent --location https://rpm.nodesource.com/setup_9.x | sudo bash - yum -y install nodejs装git yum -y install git安装完后，正常情况下的hexo命令会加入/usr/bin中， 不正常情况下…我的的命令在/etc/node/lib/node_modules/hexo/bin下且没加入环境变量，找了半天，第二次安装就正常了，可能是第一次没有npm没加-g参数。 这时建个站点，执行hexo init your_blog_name，这里假设你要建立一个叫叫foo的博客，执行hexo init foo | cd foo | npm install, ls可以看到foo目录。 这里foo路径是相对于你执行命令的路径。 进入foo目录，vim打开_config.yml，并滚动到最下面添加如下配置信息（注意最下边有deploy和type字段，覆盖这两个字段或者删除这两个字段然后复制下面的四个字段也行。）： deploy: type: git repo: git@github.com:hz8080/hz8080.github.io.git branch: master 我配了ssh验证，避免密码登陆 foo目录的结构 ├── _config.yml ├── package.json ├── scaffolds ├── source | ├── _drafts | └── _posts └── themesthemes是我们待会主题放的地方 接着在foo目录执行hexo s -p 5000看到输出，输入ip:5000就可以看到你的博客了。 s是server的意思，-p是端口，默认4000。不要把s写成-s，-s可以加，但是s 是启动必须的。 3. 发布 hexo cleanhexo ghexo d hexo clean是清楚缓存hexo g是生成本地发布文件夹hexo d是发布到deploy到 _config.yml设置的目标地址 可以把三条写进bash脚本~ #!/bin/bash hexo clean hexo g hexo d hexo d 遇到not found 问题, 输入npm install hexo-deployer-git --save，再执行hexo d 4. 主题hexo有很多主题，比如我用的是next 5. 给菜单增加标签、类目在站点内，执行hexo new page tags，这时在sources/tags有index.md，vim编辑之， --- title: tags date: 2016-11-11 21:40:58 type: &quot;tags&quot; ---在站点的_config.yml把标签打开 menu: home: / #categories: /categories #about: /about archives: /archives tags: /tags //确保标签页已打开 #schedule: /schedule #commonweal: /404.html 分类同理，在站点内，执行hexo new page categories，这时在sources/categories有index.md，vim编辑之，然后在_config.yml把# 去掉 最后！在主题文件里（themes/next/）的_config.yml的tags和categories记得把注释去掉，菜单栏才会显示标签和分类 123456789menu: home: / || home #about: /about/ || user tags: /tags/ || tags categories: /categories/ || th archives: /archives/ || archive #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat 重新部署，即可生效。 其他换图标、头像什么的可以搞搞 hexo 修改了站点名字、介绍什么的，好像重启才生效，不知道是不是bug 6. 设置‘阅读全文’hexo默认显示全部，设置阅读全文有两种方法， 第一种，在主题的_config.yml的auto_excerpt.enable改为true，length是预览长度 第二种，在文章加入&lt;!--more--&gt;，首页就会预览到&lt;!--more--&gt;的位置 第一种会有...，且预览长度是一样的 7. 域名我从godaddy 买了一个.me后缀的，年费挺便宜的，不过续费就不便宜了，可以试用一波。具体绑定方法自找。 买完后在dns管理把A类名指向自己的服务器ip，配置完毕浏览器打开你的域名:hexo端口试试 8. 博客文章管理 hexo-hey，不推荐，已经停止更新，有莫名其妙的bug hexo-admin ，用法简单粗暴，还能自动保存，用的这个 9. nginx安装安装不赘述，直接从配置动手在/etc/nginx/conf.d/default.conf是一个配置模板，在/etc/nginx/conf.d/下的*.conf都会被nginx读取。我只有一个应用，直接在default.conf动手 123456789101112131415161718192021222324252627282930313233upstream hexo_host&#123; server localhost:4000;&#125;## The default serveserver &#123; server_name htchz.me; # root /usr/share/nginx/html; # Load configuration files for the default server block. # include /etc/nginx/default.d/*.conf; location /admin &#123; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://hexo_host; &#125; // 非后台管理直接走静态文件 location / &#123; root /root/htc/public/; expires 30m; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; 执行nginx -s reload， 重启nginx，输入域名（http默认80端口），验证nginx转发端口是否生效 如果请求资源报403权限不足，可能是/etc/nginx/nginx.conf的user权限不足，改成root就可以 10. certbot申请证书 为什么要博客升级https，其实只是为了装逼。chrome打开的时候地址栏一个绿色的安全|https 看着挺舒服的 终端输入 wget https://dl.eff.org/certbot-auto chmod a+x certbot-auto ./certbot-auto --nginx期间要输入你的邮箱，选择申请证书的域名，选择是否原端口重定向到https（443），选是 然后certbot会自动申请证书、修改你的nginx配置。 下边是80转443的配置。 123456789server &#123; if ($host = htchz.me) &#123; return 301 https://$host$request_uri; &#125; # managed by Certbot listen 80; server_name htchz.me; return 404; # managed by Certbot&#125; 也可以这么写 12345server &#123; listen 80; server_name htchz.me; return 301 https://$server_name$request_uri;&#125; 记得开通你的80、443端口。。。 11. 自动续期certbot申请的证书只有三个月，这里写个定时任务，命令行： crontab -e写入 0 0 * * 0 /root/www/certbot-auto renew这条命令的意思是每周日的0点0分执行/root/www/certbot-auto renew这条命令。执行下面这条命令查看定时任务列表中是否有刚才添加的任务 [root@California_VPS etc]# crontab -l 0 0 * * 0 /root/www/certbot-auto renew12. 后来发现的问题到这里整个博客差不多了。 但还是有问题。没加图片的时候，chrome还是一把小绿锁，知道加了图片之后，小绿锁就没了。打开chrome控制台，看到类似下面warning， Mixed Content: The page at &apos;https://domain.com/w/a?id=074ac65d-70db-422d-a6d6-a534b0f410a4&apos; was loaded over HTTPS, but requested an insecure image &apos;http://img.domain.com/images/2016/5/3/2016/058c5085-21b0-4b1d-bb64-23a119905c84_cf0d97ab-bbdf-4e25-bc5b-868bdfb581df.jpg&apos;. This content should also be served over HTTPS.原来是https站点下，图片依旧是http访问。 12.1. 解决方法这个简单，在服务器返回响应时加响应头，nginx配置如下 server { ... add_header Content-Security-Policy upgrade-insecure-requests; ... }还有一个方法是在html加入meta &lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;upgrade-insecure-requests&quot; /&gt;在hexo这个要去改模板太麻烦 然后重新加载配置文件，顺利解决~ 13. 优化 优化url过长 标题自动编号","categories":[{"name":"建站","slug":"建站","permalink":"https://htchz.cc/categories/建站/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://htchz.cc/tags/Hexo/"},{"name":"Https","slug":"Https","permalink":"https://htchz.cc/tags/Https/"}]}]}