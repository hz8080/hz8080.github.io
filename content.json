{"meta":{"title":"土川的自留地","subtitle":"via fennecs.huang@gmail.com","description":"我是黄土川，是兄弟，就来砍我。","author":"土川","url":"https://htchz.cc","root":"/"},"pages":[{"title":"关于","date":"2019-08-15T14:48:32.946Z","updated":"2019-03-04T07:34:25.000Z","comments":false,"path":"about/index.html","permalink":"https://htchz.cc/about/index.html","excerpt":"","text":"邮箱fennecs.huang@gmail.com。 评论模块需要梯子~"},{"title":"分类","date":"2019-08-15T14:48:32.947Z","updated":"2018-12-17T09:14:15.000Z","comments":false,"path":"categories/index.html","permalink":"https://htchz.cc/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2019-08-15T14:48:33.087Z","updated":"2018-12-17T09:13:02.000Z","comments":false,"path":"tags/index.html","permalink":"https://htchz.cc/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"[TCP]TCP拥塞控制那些事","slug":"TCP-TCP拥塞控制那些事","date":"2019-08-15T02:05:00.000Z","updated":"2019-08-15T06:46:56.000Z","comments":true,"path":"3284953854.html","link":"","permalink":"https://htchz.cc/3284953854.html","excerpt":"","text":"前言看完了《TCP/IP详解 卷一》，对TCP/IP协议簇的认知多了一些。不过这本书没提到TCP分段，就先总结一下TCP窗口有关的慢启动、拥塞避免、快速重传、快速恢复的概念。 TCP滑动窗口窗口有两种，通告窗口(Receiver Window,rwnd)和拥塞窗口(Congestion Window,cwnd)。 通告窗口：通告窗口表明了接收端当前的接受能力。TCP在发送端和接收端都是有缓冲区的，通告窗口声明了当前接收端的缓冲区还能接收的字节大小。这个数值会在TCP报文里携带。 拥塞窗口：拥塞窗口不被TCP报文传输，是发送端基于拥塞避免算法算出来的一个窗口。这个窗口限制了发送方的发送速率避免网络拥塞。 两个窗口共同组成了一个滑动窗口。简单来说，通告窗口是强制限制，拥塞窗口是自发限制。 有一点要注意的是，窗口的单位用字节表示，但是拥塞窗口的调整总是以一个MSS的倍数来调整。 这里用书上的图描述滑动窗口，当一个TCP发送方发送数据的时候就会查看可用窗口能否发送（如果启用了Nagle算法，可用窗口必须大于等于一个MSS，发送方才发送数据） 上面是抓包得到的一个报文，Win=2027是一个通告窗口，表示服务器的缓冲区还能接受2027字节的数据。 拥塞控制上图是一个tcp刚开始传输数据时的速率变化走向。 拥塞避免、慢启动、快速重传、快速恢复这四个词其实并不能单独分开讲。当一个连接的网络情况不好的时候，就会丢包或超时，这时就要降低发送方的发送速率防止恶化，这种就是拥塞控制。 这种机制涉及到cwnd和ssthresh两个指标，ssthresh是一个区分慢启动和拥塞避免的阈值，当拥塞发生时，分两种情况超时：ssthresh = cwnd / 2（最小为2MSS），cwnd = 1MSS，进入慢启动丢包：ssthresh = cwnd / 2（最小为2MSS），cwnd = ssthresh + 3MSS，进入快速重传 慢启动慢启动其实是发送速率重新计算，cwnd 初始值为一个数据报大小，ssthresh初始值为65535，是一个然后在到达阈值之前，每接收到一个新的ACK，cwnd就会增加一个报文段的大小，这样子慢启动其实是以指数增加网络传 拥塞控制上图是一个tcp刚开始传输数据时的速率变化走向。 拥塞避免、慢启动、快速重传、快速恢复这四个词其实并不能单独分开讲。当一个连接的网络情况不好的时候，就会丢包或超时，这时就要降低发送方的发送速率防止恶化，这种就是拥塞控制。 这种机制涉及到cwnd和ssthresh两个指标，ssthresh是一个区分慢启动和拥塞避免的阈值，当拥塞发生时，分两种情况超时：ssthresh = cwnd / 2（最小为2MSS），cwnd = 1MSS，进入慢启动丢包：进入快速重传 慢启动慢启动其实是发送速率重新计算，cwnd 初始值为一个数据报大小，ssthresh初始值为65535，是一个然后在到达阈值之前，每接收到一个新的ACK，cwnd就会增加一个报文段的大小，这样子慢启动其实是以指数增加网速到一个比较平衡的水平。 拥塞避免当cwnd大于等于ssthresh时进入拥塞避免状态，在一个RTT内无论收到多少ACK都只将cwnd增加一个报文大小，从时间上来看网速线性增加。 快速重传和快速恢复快速重传指，当收到重复的3个ACK报文时（duplicate ack），设置ssthresh = cwnd / 2（最小为2MSS），cwnd = ssthresh + 3MSS，然后进入快速恢复阶段。 暂停发送新的报文，重传丢失报文。 接下来每收到重复的ACK时，将cwnd增加一个报文大小。如果cwnd大于未确认报文大小（报文丢失后我们还在发新的报文，未确认报文指丢失报文到最后一个报文之间报文总大小），可以发送新报文。 接下来如果收到新的ACK报文，将cwnd设置为ssthresh，也就是网速降为一半，并进入拥塞避免阶段。 总的来说，网速一直处于一个动态调整的过程，一个连接上cwnd随时间的变化如图所示 还有一点，上面关于cwnd的比较其实还要考虑rwnd的值，如果rwnd&gt;cwnd，应取rwnd去比较，毕竟两者决定了可用窗口大小。 后记TCP拥塞控制其实还有很多改进未去了解。比如当收到重复的3个ACK报文时，其实不一定只丢了一个报文，所以网速可能指数下降，不能达到快速恢复的目的。","categories":[{"name":"网络","slug":"网络","permalink":"https://htchz.cc/categories/网络/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"https://htchz.cc/tags/TCP/"}]},{"title":"[碎碎念]给机器加个监控","slug":"碎碎念-给机器加个监控","date":"2019-07-20T05:49:00.000Z","updated":"2019-07-20T12:50:36.000Z","comments":true,"path":"3663317463.html","link":"","permalink":"https://htchz.cc/3663317463.html","excerpt":"","text":"明明只有一台破机器，却要装成用不起的样子","categories":[{"name":"碎碎念","slug":"碎碎念","permalink":"https://htchz.cc/categories/碎碎念/"}],"tags":[],"author":"土川"},{"title":"[FCM]用FCM做一个跨设备消息同步工具","slug":"FCM-用FCM做一个跨设备消息同步工具","date":"2019-05-18T03:00:00.000Z","updated":"2019-05-20T07:45:55.000Z","comments":true,"path":"2379284348.html","link":"","permalink":"https://htchz.cc/2379284348.html","excerpt":"Fcm真是个好东西，希望你也有。","text":"Fcm真是个好东西，希望你也有。 需求背景作为一个穷人，手持不了iPhone(滑稽)，当同时使用着macOS、windows、安卓三个平台时，我面临着几个问题： 传文件。对于传文件，有许多方案，我偏向于用Feem或者共享文件夹，都是局域网传输，又快又不用经过第三方服务器。 复制文本。iPhone和mac之间有通用剪切板，win10和iPhone、安卓之间有微软小娜。 通知同步。主要是手机通知，上班工作时，听到手机推送的声音想知道时什么东西又懒得去看手机。 短信验证码。电脑上用短信验证码场景并不是很多，不过我们公司的线上服务器登录时需要短信验证码的二次验证，这时候去解锁手机、看验证码、一个一个输入终端。。。妈蛋很烦。 于是找了一堆，AirDroid、Pushbullet等等，在到处讲隐私的今天，我觉得把自己的剪切板、短信、通知就这么发送给人家总是有点不安（不过用fcm也是把数据给号称‘不作恶’口号的谷歌）。偶然看到了剪纸云，是个收费软件，不过看了简介说是用FCM做的，找了下FCM的接入指北，自己做一个同步工具。 整体流程 数据的流向如图，终端把要同步的数据发到自己的应用服务器，应用服务器载把数据发到FCM，交由FCM推送到设备组。 对于每一台设备，当应用与FCM建立起连接后可以得到一个fcm token，这个token就是这台设备这个应用的id了。 至于设备组id，我是用Firebase-Auth的userId作为设备组id的。 程序主要流程是： 客户端启动时获取fcm token，持久化存储（这个fcm token除非把应用删了和我不知道的情况，否则万年不更新一次，当然fcm sdk提供了更新的回调，我们要实现这个方法。） 客户端登录，拉起谷歌的OAuth2.0授权（Chrome插件用的clientId模式），登录成功后获取到firebase-auth的userId，持久化存储 登录成功后把userId和fcm token发送到应用服务器保存，维护双向关系，完成注册。 客户端每次发送同步数据时，带上时间戳、同步类型、fcm token等内容。 客户端接受到fcm推送时，见机行事。 同步数据的数据结构 字段 说明 type 短信、通知、剪切板 time 毫秒时间戳，也作为分片id（其实是偷懒） text 文本内容 head 额外内容，主要是为了存通知的通知标题 fcm_token 设备id mark 分片的标识，8位整数，高位起第一位表示是否分片，第二位表示是否还有分片，余下6位表示分片顺序 服务端服务端用go写的，框架使用gin，数据库用redis。 主要维护两个关系。 设备id到设备组id的关系 设备组id到所有设备id的关系 第一个直接用redis的kv模型，第二个用redis的哈希模型。 当服务器接收到客户端的同步请求时，推送到fcm有两种方式。 使用fcm的设备组管理，fcm设备组管理需要新建设备组，把fcm token添加到设备组，发送同步数据时，带上fcm设备组id，fcm就会把同步数据推送到所有组。对于已经失效的fcm token，fcm设备组管理会自己清理。 自己维护设备组，遍历设备组的设备，一个个带上fcm token推到fcm。如果接收到fcm token无效的响应，就从redis把fcm token的kv关系、哈希关系删除。 使用fcm的设备组管理的好处是只需要维护设备id到设备组id的关系，对于一些无效的fcm token由fcm自己去管理，不足的是目前fcm设备组管理没有提供API获取设备组的设备组列表，而且一发就是发全部，客户端发消息出去，待会又收到自己的消息。此外，fcm设备组管理在go没有sdk。。。 所以我决定自己管理设备组。 这里有一个☝️剪切板的问题，当发送到fcm的payload大于4kb的时候，会返回 400; reason: request contains an invalid argument; code: invalid-argument; details: Request contains an invalid argument.也就是说，我们要控制好数据大小。作为ctrl cv工程师，如果要从mac往windows复制1000行代码怎么办？答案是分片。 正如ip分片和tcp分段为了解决报文的大小限制，我们要在应用层进行分片重组。不过这个由于是应用层的分片要简单的多。 应用服务器接收到同步数据后，如果text文本大于4kb，则进行分片，mark高位第一位置0，否则置1直接推到FCM。 第二步，由于json是个文本协议，我们分片的时候有两种方案，第一种转换为字节分片，第二种转换为rune分片（rune是go的数据类型，可以表示一个utf8字符），一个rune的大小是4个字节，为了防止达到限制，rune分片大小应为1000个rune，不过这样就可能会导致一次payload利用率不高，毕竟1000个汉字是1000个rune，至少占3000字节，1000个字母也是1000个rune，占1000个字节；好处是在客户端可以直接使用。如果使用字节分片，客户端接收到分片后需要转换为字节数组，组合字节数组，再将字节数组转换为字符串，炒鸡麻烦。 接下来在分片mark高位起低6位设置好分片顺序，只要简单的0，1，2..这样就好了（不同于ip分片，ip分片使用的是数据偏移量作为位置索引）。如果是最后一片分片，mark高位起第二位要置1表示没有更多分片。 接下来利用sdk推送到fcm就好了。应用服务器的接入fcm有多种方式，文档真是傻瓜式教程。 客户端客户端写Chrome拓展和android。主要流程是 根据接收到的数据类型处理，（1）通知直接显示，（2）短信显示并且检验有没有验证码，有则将验证码提取放入剪切板，（3）剪切板进行分片判断 如果不是分片，直接放入剪切板，否则进行重组。 重组需要一个全局哈希表，key为时间戳，也是分片id（这里用时间戳是偷懒，毕竟一个人1毫秒内也不能复制两次叭）；value是维护分片的数据结构FragHold，如下 字段 说明 count 整型 length 整型 text 数组 当第一个分片到来时，将分片time作为key，初始化一个FragHold。每次到达一个分片，FragHold.count加1，当最后一个分片到来，FragHold.length可以确定。如果FragHold的count == length，那么分片重组完成，直接对数组一个join操作得到一篇完整的千字文，又可以愉快地ctrl cv了。 此外起一个定时任务，不断将全局哈希表里过期的FragHold剔除，毕竟这个是没有超时重传的，一旦丢了就再复制一次呗。 结语这里要说一下在设备组管理遇到的问题，一开始我也是用fcm的设备组管理，导致发送方会接收到自己发送的消息。这个本来无所谓，根据消息的fcm_token判断一下，如果等于自己的fcm_token，就不处理。但是js客户端是用service worker来处理，当service worker重新唤醒时，因为查询indexedDB和调用fcm接口都要在第二轮事件循环才能拿到自己的fcm_token, 而service worker被唤醒后的第一个事件循环就要处理消息了，所以第一次被唤醒时是不知道自己fcm_token的。 还有一点，fcm js要求你必须对收到的push弹窗，否则他会帮你弹窗，有知道怎么解决的告诉我一下。。。","categories":[{"name":"Firebase","slug":"Firebase","permalink":"https://htchz.cc/categories/Firebase/"}],"tags":[{"name":"数据分片","slug":"数据分片","permalink":"https://htchz.cc/tags/数据分片/"}]},{"title":"[Dubbo]Dubbo SPI 机制","slug":"Dubbo-Dubbo的SPI","date":"2019-03-25T03:44:00.000Z","updated":"2019-03-25T09:16:08.000Z","comments":true,"path":"2436052280.html","link":"","permalink":"https://htchz.cc/2436052280.html","excerpt":"","text":"前言之前一篇[Java基础]Java的SPI机制讲到Java spi的缺陷是在查找所需实现的时候，会实例化无关的实现，那么这篇看看Dubbo是怎么规避这个问题的。 Dubbo spi的特点1234567891011@Documented@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.TYPE&#125;)public @interface SPI &#123; /** * default extension name */ String value() default \"\";&#125; 由于配置文件是以key-value配置的，这里可以为SPI接口指定一个默认实现的key Dubbo spi有以下特点 不需要遍历所有实例化所有实现类 增加了对扩展点IoC和AOP的支持，一个扩展点可以直接setter注入其它扩展点。 Demo接口,需要加上org.apache.dubbo.common.extension.SPI注解 1234@SPIpublic interface Runner &#123; void run(String name);&#125; 两个实现 1234567891011121314151617public class DefaultRunner implements Runner &#123; private Logger log = LoggerFactory.getLogger(getClass()); @Override public void run(String name) &#123; log.info(\"I'm a DefaultRunner\"); &#125;&#125;public class ExcitedRunner implements Runner &#123; private Logger log = LoggerFactory.getLogger(getClass()); @Override public void run(String name) &#123; log.info(\"I'm a ExcitedRunner!\"); &#125;&#125; 在资源目录META-INF/dubbo下创建文件com.htc.learning.api.Runner 内容是一行一行的键值对，value是实现类，我们只要通过key就能直接拿到所需类。 12default=com.htc.learning.api.impl.DefaultRunnerexcited=com.htc.learning.api.impl.ExcitedRunner 测试方法 12345678@Testpublic void dubboSpiTest() &#123; ExtensionLoader&lt;Runner&gt; extensionLoader = ExtensionLoader.getExtensionLoader(Runner.class); Runner defaultRunner = extensionLoader.getExtension(\"default\"); defaultRunner.run(\"htc\"); Runner excitedRunner = extensionLoader.getExtension(\"excited\"); excitedRunner.run(\"htc\");&#125; 输出 2019-03-23 12:20:50.681 INFO --- [ main] com.htc.learning.api.impl.DefaultRunner : I&apos;m a DefaultRunner 2019-03-23 12:20:50.681 INFO --- [ main] com.htc.learning.api.impl.ExcitedRunner : I&apos;m a ExcitedRunner!原理getExtensionLoaderDubbo spi与java spi的ServiceLoader对应的，是ExtensionLoader。不同于ServiceLoader的load方法每次返回都要实例化一个对象，ExtensionLoader每次getExtensionLoader会进行缓存。 1234567891011121314151617181920public static &lt;T&gt; ExtensionLoader&lt;T&gt; getExtensionLoader(Class&lt;T&gt; type) &#123; if (type == null) &#123; throw new IllegalArgumentException(\"Extension type == null\"); &#125; if (!type.isInterface()) &#123; throw new IllegalArgumentException(\"Extension type(\" + type + \") is not interface!\"); &#125; if (!withExtensionAnnotation(type)) &#123; throw new IllegalArgumentException(\"Extension type(\" + type + \") is not extension, because WITHOUT @\" + SPI.class.getSimpleName() + \" Annotation!\"); &#125; ExtensionLoader&lt;T&gt; loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); if (loader == null) &#123; EXTENSION_LOADERS.putIfAbsent(type, new ExtensionLoader&lt;T&gt;(type)); loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); &#125; return loader;&#125; ExtensionLoader构造函数 1234private ExtensionLoader(Class&lt;?&gt; type) &#123; this.type = type; objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension());&#125; 其中objectFactory是一个接口,与IOC相关，该接口根据type和name找到一个bean，这个bean可以是Spring的bean，也可以是一个dubbo spi实现类。 12345678910111213@SPIpublic interface ExtensionFactory &#123; /** * Get extension. * * @param type object type. * @param name object name. * @return object instance. */ &lt;T&gt; T getExtension(Class&lt;T&gt; type, String name);&#125; 可以看出，这是也是一个SPI接口，接下来调用的getExtensionLoader逻辑就是通过他实现的。 getExtension12345678910111213141516171819202122232425262728public T getExtension(String name) &#123; if (name == null || name.length() == 0) throw new IllegalArgumentException(\"Extension name == null\"); if (\"true\".equals(name)) &#123; // 获取默认的拓展实现类 return getDefaultExtension(); &#125; // Holder，顾名思义，用于持有目标对象 Holder&lt;Object&gt; holder = cachedInstances.get(name); if (holder == null) &#123; cachedInstances.putIfAbsent(name, new Holder&lt;Object&gt;()); holder = cachedInstances.get(name); &#125; Object instance = holder.get(); // 双重检查 if (instance == null) &#123; synchronized (holder) &#123; instance = holder.get(); if (instance == null) &#123; // 创建拓展实例 instance = createExtension(name); // 设置实例到 holder 中 holder.set(instance); &#125; &#125; &#125; return (T) instance;&#125; 123456789101112131415161718192021222324252627282930private T createExtension(String name) &#123; // 从配置文件中加载所有的拓展类，可得到“配置项名称”到“配置类”的映射关系表 Class&lt;?&gt; clazz = getExtensionClasses().get(name); if (clazz == null) &#123; throw findException(name); &#125; try &#123; T instance = (T) EXTENSION_INSTANCES.get(clazz); if (instance == null) &#123; // 通过反射创建实例 EXTENSION_INSTANCES.putIfAbsent(clazz, clazz.newInstance()); instance = (T) EXTENSION_INSTANCES.get(clazz); &#125; // 向实例中注入依赖 injectExtension(instance); Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses; if (wrapperClasses != null &amp;&amp; !wrapperClasses.isEmpty()) &#123; // 循环创建 Wrapper 实例 for (Class&lt;?&gt; wrapperClass : wrapperClasses) &#123; // 将当前 instance 作为参数传给 Wrapper 的构造方法，并通过反射创建 Wrapper 实例。 // 然后向 Wrapper 实例中注入依赖，最后将 Wrapper 实例再次赋值给 instance 变量 instance = injectExtension( (T) wrapperClass.getConstructor(type).newInstance(instance)); &#125; &#125; return instance; &#125; catch (Throwable t) &#123; throw new IllegalStateException(\"...\"); &#125;&#125; 这里按逻辑可以拆分成四步 getExtensionClasses()获取接口的所有实现类。这个方法会在很多地方被调用，保证所有类被获取到。由于多次调用缓存也是必须的。 实例化目标类的对象。 IOC注入。注入其他SPI实现。 AOP实现。如果需要，把对象实例包裹在Wrapper中。 getExtensionClasses12345678910111213141516private Map&lt;String, Class&lt;?&gt;&gt; getExtensionClasses() &#123; // 从缓存中获取已加载的拓展类 Map&lt;String, Class&lt;?&gt;&gt; classes = cachedClasses.get(); // 双重检查 if (classes == null) &#123; synchronized (cachedClasses) &#123; classes = cachedClasses.get(); if (classes == null) &#123; // 加载拓展类 classes = loadExtensionClasses(); cachedClasses.set(classes); &#125; &#125; &#125; return classes;&#125; 典型的双重校验，这里的缓存key是实现类的key，值就是实现类了。如果缓存为null，调用loadExtensionClasses初始化缓存。 123456789101112131415161718192021222324252627// synchronized in getExtensionClassesprivate Map&lt;String, Class&lt;?&gt;&gt; loadExtensionClasses() &#123; final SPI defaultAnnotation = type.getAnnotation(SPI.class); if (defaultAnnotation != null) &#123; // 如果设置了默认实现，就缓存以下这个默认实现的key String value = defaultAnnotation.value(); if ((value = value.trim()).length() &gt; 0) &#123; String[] names = NAME_SEPARATOR.split(value); if (names.length &gt; 1) &#123; throw new IllegalStateException(\"more than 1 default extension name on extension \" + type.getName() + \": \" + Arrays.toString(names)); &#125; if (names.length == 1) &#123; cachedDefaultName = names[0]; &#125; &#125; &#125; Map&lt;String, Class&lt;?&gt;&gt; extensionClasses = new HashMap&lt;String, Class&lt;?&gt;&gt;(); loadDirectory(extensionClasses, DUBBO_INTERNAL_DIRECTORY, type.getName()); loadDirectory(extensionClasses, DUBBO_INTERNAL_DIRECTORY, type.getName().replace(\"org.apache\", \"com.alibaba\")); loadDirectory(extensionClasses, DUBBO_DIRECTORY, type.getName()); loadDirectory(extensionClasses, DUBBO_DIRECTORY, type.getName().replace(\"org.apache\", \"com.alibaba\")); loadDirectory(extensionClasses, SERVICES_DIRECTORY, type.getName()); loadDirectory(extensionClasses, SERVICES_DIRECTORY, type.getName().replace(\"org.apache\", \"com.alibaba\")); return extensionClasses;&#125; java spi的配置只能放在一个目录META-INF/services/,dubbo spi的配置可以放在三个目录 12345private static final String SERVICES_DIRECTORY = \"META-INF/services/\";private static final String DUBBO_DIRECTORY = \"META-INF/dubbo/\";private static final String DUBBO_INTERNAL_DIRECTORY = DUBBO_DIRECTORY + \"internal/\"; 这里的依赖我用的是apache-dubbo，相对于alibaba-dubbo三个目录，估计为了兼容，apache-dubbo版本的loadDirectory方法进行了一个包名的替换。 1234567891011121314151617181920212223private void loadDirectory(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, String dir) &#123; // fileName = 文件夹路径 + type 全限定名 String fileName = dir + type.getName(); try &#123; Enumeration&lt;java.net.URL&gt; urls; ClassLoader classLoader = findClassLoader(); // 根据文件名加载所有的同名文件 if (classLoader != null) &#123; urls = classLoader.getResources(fileName); &#125; else &#123; urls = ClassLoader.getSystemResources(fileName); &#125; if (urls != null) &#123; while (urls.hasMoreElements()) &#123; java.net.URL resourceURL = urls.nextElement(); // 加载资源 loadResource(extensionClasses, classLoader, resourceURL); &#125; &#125; &#125; catch (Throwable t) &#123; logger.error(\"...\"); &#125;&#125; 接下来“真·读取配置文件” 123456789101112131415161718192021222324252627282930313233343536373839404142private void loadResource(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, ClassLoader classLoader, java.net.URL resourceURL) &#123; try &#123; BufferedReader reader = new BufferedReader( new InputStreamReader(resourceURL.openStream(), \"utf-8\")); try &#123; String line; // 按行读取配置内容 while ((line = reader.readLine()) != null) &#123; // 定位 # 字符 final int ci = line.indexOf('#'); if (ci &gt;= 0) &#123; // 截取 # 之前的字符串，# 之后的内容为注释，需要忽略 line = line.substring(0, ci); &#125; line = line.trim(); if (line.length() &gt; 0) &#123; try &#123; String name = null; int i = line.indexOf('='); if (i &gt; 0) &#123; // 以等于号 = 为界，截取键与值 name = line.substring(0, i).trim(); line = line.substring(i + 1).trim(); &#125; if (line.length() &gt; 0) &#123; // 加载类，并通过 loadClass 方法对类进行缓存 loadClass(extensionClasses, resourceURL, Class.forName(line, true, classLoader), name); &#125; &#125; catch (Throwable t) &#123; IllegalStateException e = new IllegalStateException(\"Failed to load extension class...\"); &#125; &#125; &#125; &#125; finally &#123; reader.close(); &#125; &#125; catch (Throwable t) &#123; logger.error(\"Exception when load extension class...\"); &#125;&#125; 读完配置文件，下面不单是对类进行加载，而且还对Adaptive、Wrapper类进行缓存。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455private void loadClass(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, java.net.URL resourceURL, Class&lt;?&gt; clazz, String name) throws NoSuchMethodException &#123; if (!type.isAssignableFrom(clazz)) &#123; throw new IllegalStateException(\"Error when load extension class(interface: \" + type + \", class line: \" + clazz.getName() + \"), class \" + clazz.getName() + \"is not subtype of interface.\"); &#125; // 只能有一个自适应实现类 if (clazz.isAnnotationPresent(Adaptive.class)) &#123; if (cachedAdaptiveClass == null) &#123; cachedAdaptiveClass = clazz; &#125; else if (!cachedAdaptiveClass.equals(clazz)) &#123; throw new IllegalStateException(...); &#125; &#125; else if (isWrapperClass(clazz)) &#123; Set&lt;Class&lt;?&gt;&gt; wrappers = cachedWrapperClasses; if (wrappers == null) &#123; cachedWrapperClasses = new ConcurrentHashSet&lt;Class&lt;?&gt;&gt;(); wrappers = cachedWrapperClasses; &#125; wrappers.add(clazz); &#125; else &#123; clazz.getConstructor(); if (name == null || name.length() == 0) &#123; name = findAnnotationName(clazz); if (name.length() == 0) &#123; throw new IllegalStateException(...); &#125; &#125; String[] names = NAME_SEPARATOR.split(name); if (names != null &amp;&amp; names.length &gt; 0) &#123; Activate activate = clazz.getAnnotation(Activate.class); if (activate != null) &#123; cachedActivates.put(names[0], activate); &#125; else &#123; // support com.alibaba.dubbo.common.extension.Activate com.alibaba.dubbo.common.extension.Activate oldActivate = clazz.getAnnotation(com.alibaba.dubbo.common.extension.Activate.class); if (oldActivate != null) &#123; cachedActivates.put(names[0], oldActivate); &#125; &#125; for (String n : names) &#123; if (!cachedNames.containsKey(clazz)) &#123; cachedNames.put(clazz, n); &#125; Class&lt;?&gt; c = extensionClasses.get(n); if (c == null) &#123; extensionClasses.put(n, clazz); // 实现类重复报错 &#125; else if (c != clazz) &#123; throw new IllegalStateException(...); &#125; &#125; &#125; &#125;&#125; 要注意的几点： @Adaptive注解是标明一个SPI实现类是属于自适应类，一个SPI接口只能有一个自适应实现，这从代码逻辑可以看出来，如果!cachedAdaptiveClass.equals(clazz)则报错。具体这个自适应类可以做什么，下面会说。 Wrapper类是AOP类 这里还有一个@Active注解，标明实现类的激活条件，是一种条件机制。 IOC1234567891011121314151617181920212223242526272829303132333435private T injectExtension(T instance) &#123; try &#123; if (objectFactory != null) &#123; for (Method method : instance.getClass().getMethods()) &#123; if (method.getName().startsWith(\"set\") &amp;&amp; method.getParameterTypes().length == 1 &amp;&amp; Modifier.isPublic(method.getModifiers())) &#123; /** * Check &#123;@link DisableInject&#125; to see if we need auto injection for this property */ if (method.getAnnotation(DisableInject.class) != null) &#123; continue; &#125; Class&lt;?&gt; pt = method.getParameterTypes()[0]; if (ReflectUtils.isPrimitives(pt)) &#123; continue; &#125; try &#123; String property = method.getName().length() &gt; 3 ? method.getName().substring(3, 4).toLowerCase() + method.getName().substring(4) : \"\"; Object object = objectFactory.getExtension(pt, property); if (object != null) &#123; method.invoke(instance, object); &#125; &#125; catch (Exception e) &#123; logger.error(\"fail to inject via method \" + method.getName() + \" of interface \" + type.getName() + \": \" + e.getMessage(), e); &#125; &#125; &#125; &#125; &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; return instance;&#125; dubbo的IOC目前只对setter方法支持，如果set的方法参数只有一个，那么就拿参数类型pt和setProperty的property去objectFactory找。objectFactory是ExtensionFactory接口，有两个实现， 上面提到ExtensionLoader构造函数 1234private ExtensionLoader(Class&lt;?&gt; type) &#123; this.type = type; objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension());&#125; 这里的getAdaptiveExtension()是什么？ @AdaptivegetAdaptiveExtension()的实现如下， 1234567891011121314151617181920212223public T getAdaptiveExtension() &#123; Object instance = cachedAdaptiveInstance.get(); if (instance == null) &#123; if (createAdaptiveInstanceError == null) &#123; synchronized (cachedAdaptiveInstance) &#123; instance = cachedAdaptiveInstance.get(); if (instance == null) &#123; try &#123; instance = createAdaptiveExtension(); cachedAdaptiveInstance.set(instance); &#125; catch (Throwable t) &#123; createAdaptiveInstanceError = t; throw new IllegalStateException(...); &#125; &#125; &#125; &#125; else &#123; throw new IllegalStateException(...); &#125; &#125; return (T) instance;&#125; dubbo的Adaptive机制如下 如果一个SPI接口实现类存在自适应实现，那么直接拿这个类； 否则动态创建自适应类(手动拼接代码字符，并转为字节码，加载到jvm中)，由于dubbo是以url为协议的，所以创建的自适应代码是根据url中的内容决定使用那种实现。 下面是alibaba dubbo 的中文注释 12345678910111213141516171819202122232425@Documented@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)public @interface Adaptive &#123; /** * 从&#123;@link URL&#125;的Key名，对应的Value作为要Adapt成的Extension名。 * &lt;p&gt; * 如果&#123;@link URL&#125;这些Key都没有Value，使用 用 缺省的扩展（在接口的&#123;@link SPI&#125;中设定的值）。&lt;br&gt; * 比如，&lt;code&gt;String[] &#123;\"key1\", \"key2\"&#125;&lt;/code&gt;，表示 * &lt;ol&gt; * &lt;li&gt;先在URL上找key1的Value作为要Adapt成的Extension名； * &lt;li&gt;key1没有Value，则使用key2的Value作为要Adapt成的Extension名。 * &lt;li&gt;key2没有Value，使用缺省的扩展。 * &lt;li&gt;如果没有设定缺省扩展，则方法调用会抛出&#123;@link IllegalStateException&#125;。 * &lt;/ol&gt; * &lt;p&gt; * 如果不设置则缺省使用Extension接口类名的点分隔小写字串。&lt;br&gt; * 即对于Extension接口&#123;@code com.alibaba.dubbo.xxx.YyyInvokerWrapper&#125;的缺省值为&lt;code&gt;String[] &#123;\"yyy.invoker.wrapper\"&#125;&lt;/code&gt; * * @see SPI#value() */ String[] value() default &#123;&#125;;&#125; 也就是说，如果@Adaptive上的key从url获取不到，就以@SPI上的默认扩展值作为key去url找，如果@SPI都没默认值，就将接口类名用.分隔，作为接口缺省值（这么奇怪的key吗 =。=） 以下面代码为例， 123456789101112@SPI(\"dubbo\")public interface Protocol &#123; int getDefaultPort(); @Adaptive &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException; @Adaptive &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException; void destroy();&#125; 1Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); 这里会返回一个Protocol$Adaptive类，因为Protocol没有一个自适应实现类，所以dubbo动态生成了一个自适应类，通过debug得 12345678910111213141516171819202122232425262728293031323334353637package org.apache.dubbo.rpc;import org.apache.dubbo.common.extension.ExtensionLoader;public class Protocol$Adaptive implements org.apache.dubbo.rpc.Protocol &#123; public void destroy() &#123; throw new UnsupportedOperationException(\"method public abstract void org.apache.dubbo.rpc.Protocol.destroy() of interface org.apache.dubbo.rpc.Protocol is not adaptive method!\"); &#125; public int getDefaultPort() &#123; throw new UnsupportedOperationException(\"method public abstract int org.apache.dubbo.rpc.Protocol.getDefaultPort() of interface org.apache.dubbo.rpc.Protocol is not adaptive method!\"); &#125; public org.apache.dubbo.rpc.Exporter export(org.apache.dubbo.rpc.Invoker arg0) throws org.apache.dubbo.rpc.RpcException &#123; if (arg0 == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument == null\"); if (arg0.getUrl() == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument getUrl() == null\"); org.apache.dubbo.common.URL url = arg0.getUrl(); // 这里默认使用dubbo String extName = (url.getProtocol() == null ? \"dubbo\" : url.getProtocol()); if (extName == null) throw new IllegalStateException(\"Fail to get extension(org.apache.dubbo.rpc.Protocol) name from url(\" + url.toString() + \") use keys([protocol])\"); org.apache.dubbo.rpc.Protocol extension = (org.apache.dubbo.rpc.Protocol) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.Protocol.class).getExtension(extName); return extension.export(arg0); &#125; public org.apache.dubbo.rpc.Invoker refer(java.lang.Class arg0, org.apache.dubbo.common.URL arg1) throws org.apache.dubbo.rpc.RpcException &#123; if (arg1 == null) throw new IllegalArgumentException(\"url == null\"); org.apache.dubbo.common.URL url = arg1; // 这里默认使用dubbo String extName = (url.getProtocol() == null ? \"dubbo\" : url.getProtocol()); if (extName == null) throw new IllegalStateException(\"Fail to get extension(org.apache.dubbo.rpc.Protocol) name from url(\" + url.toString() + \") use keys([protocol])\"); org.apache.dubbo.rpc.Protocol extension = (org.apache.dubbo.rpc.Protocol) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.Protocol.class).getExtension(extName); return extension.refer(arg0, arg1); &#125;&#125; 这里Protocol$Adaptive代码里，如果接口方法没有设置@Adaptive注解，以抛异常处理。 在生成的方法中，以protocol为key去url里查找这个key的值，如果url里没有设置，就以Protocol接口上的@SPI注解默认值——“dubbo”作为自适应类要找的扩展的name。 创建code代码太长，不贴。 拿ExtensionFactory来说，他有三个实现（有一个废弃的） 一个自适应实现类，以@Adaptive标注 1234567891011121314151617181920212223242526@Adaptivepublic class AdaptiveExtensionFactory implements ExtensionFactory &#123; private final List&lt;ExtensionFactory&gt; factories; public AdaptiveExtensionFactory() &#123; ExtensionLoader&lt;ExtensionFactory&gt; loader = ExtensionLoader.getExtensionLoader(ExtensionFactory.class); List&lt;ExtensionFactory&gt; list = new ArrayList&lt;ExtensionFactory&gt;(); for (String name : loader.getSupportedExtensions()) &#123; list.add(loader.getExtension(name)); &#125; factories = Collections.unmodifiableList(list); &#125; @Override public &lt;T&gt; T getExtension(Class&lt;T&gt; type, String name) &#123; for (ExtensionFactory factory : factories) &#123; T extension = factory.getExtension(type, name); if (extension != null) &#123; return extension; &#125; &#125; return null; &#125;&#125; 一个用于获取dubbo Spi实现类 1234567891011121314public class SpiExtensionFactory implements ExtensionFactory &#123; @Override public &lt;T&gt; T getExtension(Class&lt;T&gt; type, String name) &#123; if (type.isInterface() &amp;&amp; type.isAnnotationPresent(SPI.class)) &#123; ExtensionLoader&lt;T&gt; loader = ExtensionLoader.getExtensionLoader(type); if (!loader.getSupportedExtensions().isEmpty()) &#123; return loader.getAdaptiveExtension(); &#125; &#125; return null; &#125;&#125; 一个是用于获取Spring的bean，代码太长不贴 @Active@Active注解用于实现类上，表示一些激活条件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@Documented@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)public @interface Activate &#123; /** * Activate the current extension when one of the groups matches. The group passed into * &#123;@link ExtensionLoader#getActivateExtension(URL, String, String)&#125; will be used for matching. * * @return group names to match * @see ExtensionLoader#getActivateExtension(URL, String, String) */ String[] group() default &#123;&#125;; /** * Activate the current extension when the specified keys appear in the URL's parameters. * &lt;p&gt; * For example, given &lt;code&gt;@Activate(\"cache, validation\")&lt;/code&gt;, the current extension will be return only when * there's either &lt;code&gt;cache&lt;/code&gt; or &lt;code&gt;validation&lt;/code&gt; key appeared in the URL's parameters. * &lt;/p&gt; * * @return URL parameter keys * @see ExtensionLoader#getActivateExtension(URL, String) * @see ExtensionLoader#getActivateExtension(URL, String, String) */ String[] value() default &#123;&#125;; /** * Relative ordering info, optional * Deprecated since 2.7.0 * * @return extension list which should be put before the current one */ @Deprecated String[] before() default &#123;&#125;; /** * Relative ordering info, optional * Deprecated since 2.7.0 * * @return extension list which should be put after the current one */ @Deprecated String[] after() default &#123;&#125;; /** * Absolute ordering info, optional * * @return absolute ordering info */ int order() default 0;&#125; 同样由于dubbo是面向url的协议，所以这些激活条件需要通过url匹配。 在加载类的时候，有这么几行代码，以扩展名字为key，以扩展上的注解为值进行map缓存。 1234567891011// org.apache.dubbo.common.extension.ExtensionLoader#loadClassActivate activate = clazz.getAnnotation(Activate.class);if (activate != null) &#123; cachedActivates.put(names[0], activate);&#125; else &#123; // support com.alibaba.dubbo.common.extension.Activate com.alibaba.dubbo.common.extension.Activate oldActivate = clazz.getAnnotation(com.alibaba.dubbo.common.extension.Activate.class); if (oldActivate != null) &#123; cachedActivates.put(names[0], oldActivate); &#125;&#125; 获取激活的的扩展可以通过以下方法调用 123456789101112131415161718192021222324252627282930313233public List&lt;T&gt; getActivateExtension(URL url, String key) &#123; return getActivateExtension(url, key, null);&#125;/** * This is equivalent to &lt;pre&gt; * getActivateExtension(url, values, null); * &lt;/pre&gt; * * @param url url * @param values extension point names * @return extension list which are activated * @see #getActivateExtension(com.alibaba.dubbo.common.URL, String[], String) */public List&lt;T&gt; getActivateExtension(URL url, String[] values) &#123; return getActivateExtension(url, values, null);&#125;/** * This is equivalent to &lt;pre&gt; * getActivateExtension(url, url.getParameter(key).split(\",\"), null); * &lt;/pre&gt; * * @param url url * @param key url parameter key which used to get extension point names * @param group group * @return extension list which are activated. * @see #getActivateExtension(com.alibaba.dubbo.common.URL, String[], String) */public List&lt;T&gt; getActivateExtension(URL url, String key, String group) &#123; String value = url.getParameter(key); return getActivateExtension(url, value == null || value.length() == 0 ? null : Constants.COMMA_SPLIT_PATTERN.split(value), group);&#125; 这些方法的具体实现如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * Get activate extensions. * * @param url url * @param values extension point names * @param group group * @return extension list which are activated * @see com.alibaba.dubbo.common.extension.Activate */public List&lt;T&gt; getActivateExtension(URL url, String[] values, String group) &#123; List&lt;T&gt; exts = new ArrayList&lt;T&gt;(); List&lt;String&gt; names = values == null ? new ArrayList&lt;String&gt;(0) : Arrays.asList(values); if (!names.contains(Constants.REMOVE_VALUE_PREFIX + Constants.DEFAULT_KEY)) &#123; getExtensionClasses(); for (Map.Entry&lt;String, Activate&gt; entry : cachedActivates.entrySet()) &#123; String name = entry.getKey(); Activate activate = entry.getValue(); if (isMatchGroup(group, activate.group())) &#123; T ext = getExtension(name); if (!names.contains(name) &amp;&amp; !names.contains(Constants.REMOVE_VALUE_PREFIX + name) &amp;&amp; isActive(activate, url)) &#123; exts.add(ext); &#125; &#125; &#125; // order 值越小越靠前 Collections.sort(exts, ActivateComparator.COMPARATOR); &#125; List&lt;T&gt; usrs = new ArrayList&lt;T&gt;(); for (int i = 0; i &lt; names.size(); i++) &#123; String name = names.get(i); if (!name.startsWith(Constants.REMOVE_VALUE_PREFIX) &amp;&amp; !names.contains(Constants.REMOVE_VALUE_PREFIX + name)) &#123; if (Constants.DEFAULT_KEY.equals(name)) &#123; if (usrs.size() &gt; 0) &#123; exts.addAll(0, usrs); usrs.clear(); &#125; &#125; else &#123; T ext = getExtension(name); usrs.add(ext); &#125; &#125; &#125; if (usrs.size() &gt; 0) &#123; exts.addAll(usrs); &#125; return exts;&#125; 123456789101112131415161718private boolean isActive(String[] keys, URL url) &#123; if (keys.length == 0) &#123; return true; &#125; // 两次for循环 for (String key : keys) &#123; for (Map.Entry&lt;String, String&gt; entry : url.getParameters().entrySet()) &#123; String k = entry.getKey(); String v = entry.getValue(); // 如果key存在且对应的value不为空 if ((k.equals(key) || k.endsWith(\".\" + key)) &amp;&amp; ConfigUtils.isNotEmpty(v)) &#123; return true; &#125; &#125; &#125; return false;&#125; 匹配条件的逻辑是，先匹配组，再匹配键，键只要都存在值，那么即匹配成功。当注解上order值越小，这个实现类的排序越靠前。 关于排序，这里的一个具体例子是Dubbo服务的过滤器往往加上了@Active注解，这时候如果要设置过滤器的处理顺序，就可以通过该注解上的order属性设置。 结束语还差Wrapper机制没看。。关于下面那段话我也没看到具体的例子。 如果扩展点加载失败，连扩展点的名称都拿不到了。比如：JDK标准的ScriptEngine，通过getName();获取脚本类型的名称，但如果RubyScriptEngine因为所依赖的jruby.jar不存在，导致RubyScriptEngine类加载失败，这个失败原因被吃掉了，和ruby对应不起来，当用户执行ruby脚本时，会报不支持ruby，而不是真正失败的原因。 参考 Apache Dubbo SPI","categories":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://htchz.cc/categories/Dubbo/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"https://htchz.cc/tags/OOP/"}]},{"title":"[Java代理]Cglib代理","slug":"Java代理-cglib代理","date":"2019-03-10T06:03:00.000Z","updated":"2019-08-15T16:08:49.216Z","comments":true,"path":"3922793788.html","link":"","permalink":"https://htchz.cc/3922793788.html","excerpt":"","text":"Cglib CGLIB是一个强大的高性能的代码生成包。CGLIB包的底层是通过使用一个小而快的字节码处理框架ASM，来转换字节码并生成新的类。除了CGLIB包，脚本语言例如Groovy和BeanShell，也是使用ASM来生成java的字节码。当然不鼓励直接使用ASM，因为它要求你必须对JVM内部结构包括class文件的格式和指令集都很熟悉。 Demo直接上Demo～ 1234567891011/** * 目标类 */public class RunnerDefault implements Runner &#123; private Logger log = LoggerFactory.getLogger(getClass()); @Override public void run(String name) &#123; log.info(&quot;run: &quot; + name); &#125;&#125; 指定Callback的顺序 123456789public class CglibCallbackFilter implements CallbackFilter &#123; @Override public int accept(Method method) &#123; if (&quot;toString&quot;.equals(method.getName())) &#123; return 1; &#125; return 0; &#125;&#125; 代理逻辑及生成代理的封装 1234567891011121314151617// 拦截所有方法public class CglibProxy implements MethodInterceptor &#123; private Enhancer enhancer = new Enhancer(); @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; objects[0] = &quot;cglib &quot; + objects[0]; return methodProxy.invokeSuper(o, objects); &#125; public Object newProxy(Class klass) &#123; enhancer.setSuperclass(klass); enhancer.setCallbackFilter(new CglibCallbackFilter()); enhancer.setCallbacks(new Callback[]&#123;new CglibProxy(), new CglibStringProxy()&#125;); return enhancer.create(); &#125;&#125; 123456789// 为了拦截toString方法public class CglibStringProxy implements MethodInterceptor &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; logger.info(\"toString hijacked\"); return null; &#125;&#125; 测试类 123456789@Testpublic void testCglib() &#123; // 生成class文件 System.setProperty(DebuggingClassWriter.DEBUG_LOCATION_PROPERTY, \"./\"); CglibProxy cglibProxy = new CglibProxy(); RunnerDefault runner = (RunnerDefault) cglibProxy.newProxy(RunnerDefault.class); runner.run(\"proxy\"); runner.toString();&#125; 输出: 2019-03-07 16:48:44.248 INFO --- [ main] RunnerDefault$$EnhancerByCGLIB$$5b557d48 : run: cglib proxy 2019-03-07 16:48:44.254 INFO --- [ main] com.htc.learning.proxy.CglibStringProxy : toString hijacked 也可以不配置CallbackFilter，只能配一个Callback，Enhancer会把单个的Callback转为数组,并且把CallbackFilter设置为ALL_ZERO，固定返回0 下面是上面test执行过程中生成的文件 NamingPolicy上面的RunnerDefault$$EnhancerByCGLIB$$16487fc是cglib命名而来的，默认实现类是net.sf.cglib.core.DefaultNamingPolicy命名规则如下： 目标ClassName + &quot;$$&quot; + 使用cglib处理的ClassName + &quot;ByCGLIB&quot; + &quot;$$&quot; + key的hashcodeKey和缓存KeyFactory先看KeyFactory，这个类可以生成一个代理类，这个代理类对于给定的参数，每次调用返回的对象的equals、hashcode方法都是返回相同的值。由于cglib的配置项比较多，所以使用这个类用于生成缓存key的。 目标类需要提供一个public Object newInstance(...)的声明，参数数量类型随意。 下面是cglib 12345678910111213141516public class KeySample &#123; private interface MyFactory &#123; public Object newInstance(int a, char[] b, String d); &#125; public static void main(String[] args) &#123; // 源码没有这一行，加上这一行，cglib的debug模式打开，就可以输出生成代理类的class文件了。 System.setProperty(DebuggingClassWriter.DEBUG_LOCATION_PROPERTY, \"./\"); MyFactory f = (MyFactory)KeyFactory.create(MyFactory.class); Object key1 = f.newInstance(20, new char[]&#123; 'a', 'b' &#125;, \"hello\"); Object key2 = f.newInstance(20, new char[]&#123; 'a', 'b' &#125;, \"hello\"); Object key3 = f.newInstance(20, new char[]&#123; 'a', '_' &#125;, \"hello\"); System.out.println(key1.equals(key2));// true System.out.println(key2.equals(key3));// false &#125;&#125; 三次生成的是不同对象。key1和key2是相等的，key2和key3是不等的。追踪代码可以看到KeyFactory重写了代理类的equals、hashcode 123456789101112131415161718192021222324252627282930313233343536// net.sf.cglib.core.KeyFactory.Generator#generateClass...// hash codee = ce.begin_method(Constants.ACC_PUBLIC, HASH_CODE, null);int hc = (constant != 0) ? constant : PRIMES[(int)(Math.abs(seed) % PRIMES.length)];int hm = (multiplier != 0) ? multiplier : PRIMES[(int)(Math.abs(seed * 13) % PRIMES.length)];e.push(hc);for (int i = 0; i &lt; parameterTypes.length; i++) &#123; e.load_this(); e.getfield(getFieldName(i)); EmitUtils.hash_code(e, parameterTypes[i], hm, customizers);&#125;e.return_value();e.end_method();// equalse = ce.begin_method(Constants.ACC_PUBLIC, EQUALS, null);Label fail = e.make_label();e.load_arg(0);e.instance_of_this();e.if_jump(e.EQ, fail);for (int i = 0; i &lt; parameterTypes.length; i++) &#123; e.load_this(); e.getfield(getFieldName(i)); e.load_arg(0); e.checkcast_this(); e.getfield(getFieldName(i)); EmitUtils.not_equals(e, parameterTypes[i], fail, customizers);&#125;e.push(1);e.return_value();e.mark(fail);e.push(0);e.return_value();e.end_method();... 代理缓存所有cglib代理类的缓存都存在于net.sf.cglib.core.AbstractClassGenerator的static变量里， 123private static volatile Map&lt;ClassLoader, ClassLoaderData&gt; CACHE = new WeakHashMap&lt;ClassLoader, ClassLoaderData&gt;();private static final boolean DEFAULT_USE_CACHE = Boolean.parseBoolean(System.getProperty(\"cglib.useCache\", \"true\")); 这个缓存是一个WeakHashMap，key和jdk代理一样，也是以ClassLoader为为key，至于ClassLoaderData是一个关于interfaces的封装，到最底层其实是一个ConcurrentHashMap。看net.sf.cglib.core.AbstractClassGenerator#create的代码 1234567891011121314151617181920212223242526272829protected Object create(Object key) &#123; try &#123; ClassLoader loader = getClassLoader(); Map&lt;ClassLoader, ClassLoaderData&gt; cache = CACHE; ClassLoaderData data = cache.get(loader); // 维护多线程 if (data == null) &#123; synchronized (AbstractClassGenerator.class) &#123; cache = CACHE; data = cache.get(loader); if (data == null) &#123; Map&lt;ClassLoader, ClassLoaderData&gt; newCache = new WeakHashMap&lt;ClassLoader, ClassLoaderData&gt;(cache); data = new ClassLoaderData(loader); newCache.put(loader, data); CACHE = newCache; &#125; &#125; &#125; this.key = key; // 这里发生了二级缓存的put操作 Object obj = data.get(this, getUseCache()); if (obj instanceof Class) &#123; return firstInstance((Class) obj); &#125; return nextInstance(obj); &#125; catch (...) &#123; ... &#125;&#125; 看net.sf.cglib.core.AbstractClassGenerator.ClassLoaderData#get方法 12345678910public Object get(AbstractClassGenerator gen, boolean useCache) &#123; // 不使用缓存直接生成 if (!useCache) &#123; return gen.generate(ClassLoaderData.this); &#125; else &#123; // 底层是去ConcurrentHashMap拿 Object cachedValue = generatedClasses.get(gen); return gen.unwrapCachedValue(cachedValue); &#125;&#125; 前面说到二级缓存其实是ConcurrentHashMap,那么key，value分别是什么？key是AbstractClassGenerator子类决定的，比如KeyFactory使用的是目标类名；至于value又有jdk代理的味道——value值不是固定的，可能是生成的代理类，也可能是一个FutureTask，多个线程下多个FutureTask调用get()只会有一个在执行，避免了重复生成字节码。 1234567891011121314151617181920212223242526272829303132333435363738394041protected V createEntry(final K key, KK cacheKey, Object v) &#123; FutureTask&lt;V&gt; task; boolean creator = false; if (v != null) &#123; // Another thread is already loading an instance task = (FutureTask&lt;V&gt;) v; &#125; else &#123; task = new FutureTask&lt;V&gt;(new Callable&lt;V&gt;() &#123; public V call() throws Exception &#123; return loader.apply(key); &#125; &#125;); Object prevTask = map.putIfAbsent(cacheKey, task); if (prevTask == null) &#123; // creator does the load creator = true; task.run(); &#125; else if (prevTask instanceof FutureTask) &#123; task = (FutureTask&lt;V&gt;) prevTask; &#125; else &#123; return (V) prevTask; &#125; &#125; V result; try &#123; result = task.get(); &#125; catch (InterruptedException e) &#123; throw new IllegalStateException(\"Interrupted while loading cache item\", e); &#125; catch (ExecutionException e) &#123; Throwable cause = e.getCause(); if (cause instanceof RuntimeException) &#123; throw ((RuntimeException) cause); &#125; throw new IllegalStateException(\"Unable to load cache item\", cause); &#125; if (creator) &#123; map.put(cacheKey, result); &#125; return result;&#125; EnhancerEnhancer是CGLib中的一个字节码增强器，一般我们都用这个来进行生成cglib代理类。 123456789101112131415private Class[] interfaces;private CallbackFilter filter;private Callback[] callbacks;// 回调逻辑的类型，包括 MethodInterceptor|NoOp|LazyLoader|Dispatcher|InvocationHandler|FixedValueprivate Type[] callbackTypes;private boolean validateCallbackTypes;// create()是否只生成代理类,而不是返回一个对象,如果只生成代理类，callback不能设置，会报错private boolean classOnly;private Class superclass;private Class[] argumentTypes;private Object[] arguments;// 是否使用工厂类private boolean useFactory = true;private Long serialVersionUID;private boolean interceptDuringConstruction = true; 下面是创建逻辑 123456789101112131415private Object createHelper() &#123; // 这里进行一些配置校验，比如设置了多个Callback但是没有设置filter preValidate(); // 这里KEY_FACTORY是KeyFactory实例 Object key = KEY_FACTORY.newInstance((superclass != null) ? superclass.getName() : null, ReflectUtils.getNames(interfaces), filter == ALL_ZERO ? null : new WeakCacheKey&lt;CallbackFilter&gt;(filter), callbackTypes, useFactory, interceptDuringConstruction, serialVersionUID); this.currentKey = key; Object result = super.create(key); return result;&#125; Object result = super.create(key);又是跳到上面提到过的net.sf.cglib.core.AbstractClassGenerator#create 123456789101112131415161718192021222324252627protected Object create(Object key) &#123; try &#123; ClassLoader loader = getClassLoader(); Map&lt;ClassLoader, ClassLoaderData&gt; cache = CACHE; ClassLoaderData data = cache.get(loader); if (data == null) &#123; synchronized (AbstractClassGenerator.class) &#123; cache = CACHE; data = cache.get(loader); if (data == null) &#123; Map&lt;ClassLoader, ClassLoaderData&gt; newCache = new WeakHashMap&lt;ClassLoader, ClassLoaderData&gt;(cache); data = new ClassLoaderData(loader); newCache.put(loader, data); CACHE = newCache; &#125; &#125; &#125; this.key = key; Object obj = data.get(this, getUseCache()); if (obj instanceof Class) &#123; return firstInstance((Class) obj); &#125; return nextInstance(obj); &#125; catch (...) &#123; ... &#125;&#125; 如上一小节提到，这里面是有缓存的。 代理主流程net.sf.cglib.proxy.Enhancer#generateClass方法负责生成代理，主要是通过CallbackFilter为不同的Method提供不同的Callback 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596public void generateClass(ClassVisitor v) throws Exception &#123; Class sc = (superclass == null) ? Object.class : superclass; if (TypeUtils.isFinal(sc.getModifiers())) throw new IllegalArgumentException(\"Cannot subclass final class \" + sc.getName()); List constructors = new ArrayList(Arrays.asList(sc.getDeclaredConstructors())); filterConstructors(sc, constructors); // Order is very important: must add superclass, then // its superclass chain, then each interface and // its superinterfaces. List actualMethods = new ArrayList(); List interfaceMethods = new ArrayList(); final Set forcePublic = new HashSet(); // 看下面代码 getMethods(sc, interfaces, actualMethods, interfaceMethods, forcePublic); // 这里把actualMethods中，非abstract,非native,非synchronized方法的修饰符全部变成final，将转化后的方法信息MethodInfo列表 记录在methods中 List methods = CollectionUtils.transform(actualMethods, new Transformer() &#123; public Object transform(Object value) &#123; Method method = (Method)value; int modifiers = Constants.ACC_FINAL | (method.getModifiers() &amp; ~Constants.ACC_ABSTRACT &amp; ~Constants.ACC_NATIVE &amp; ~Constants.ACC_SYNCHRONIZED); if (forcePublic.contains(MethodWrapper.create(method))) &#123; modifiers = (modifiers &amp; ~Constants.ACC_PROTECTED) | Constants.ACC_PUBLIC; &#125; return ReflectUtils.getMethodInfo(method, modifiers); &#125; &#125;); ClassEmitter e = new ClassEmitter(v); // 这个currentData不知道是干嘛的 if (currentData == null) &#123; e.begin_class(Constants.V1_2, Constants.ACC_PUBLIC, getClassName(), Type.getType(sc), (useFactory ? TypeUtils.add(TypeUtils.getTypes(interfaces), FACTORY) : TypeUtils.getTypes(interfaces)), Constants.SOURCE_FILE); &#125; else &#123; e.begin_class(Constants.V1_2, Constants.ACC_PUBLIC, getClassName(), null, new Type[]&#123;FACTORY&#125;, Constants.SOURCE_FILE); &#125; List constructorInfo = CollectionUtils.transform(constructors, MethodInfoTransformer.getInstance()); e.declare_field(Constants.ACC_PRIVATE, BOUND_FIELD, Type.BOOLEAN_TYPE, null); e.declare_field(Constants.ACC_PUBLIC | Constants.ACC_STATIC, FACTORY_DATA_FIELD, OBJECT_TYPE, null); if (!interceptDuringConstruction) &#123; e.declare_field(Constants.ACC_PRIVATE, CONSTRUCTED_FIELD, Type.BOOLEAN_TYPE, null); &#125; e.declare_field(Constants.PRIVATE_FINAL_STATIC, THREAD_CALLBACKS_FIELD, THREAD_LOCAL, null); e.declare_field(Constants.PRIVATE_FINAL_STATIC, STATIC_CALLBACKS_FIELD, CALLBACK_ARRAY, null); if (serialVersionUID != null) &#123; e.declare_field(Constants.PRIVATE_FINAL_STATIC, Constants.SUID_FIELD_NAME, Type.LONG_TYPE, serialVersionUID); &#125; // 根据callbackTypes增加属性，名字为CGLIB$CALLBACK_xx(xx是序号) for (int i = 0; i &lt; callbackTypes.length; i++) &#123; e.declare_field(Constants.ACC_PRIVATE, getCallbackField(i), callbackTypes[i], null); &#125; // This is declared private to avoid \"public field\" pollution e.declare_field(Constants.ACC_PRIVATE | Constants.ACC_STATIC, CALLBACK_FILTER_FIELD, OBJECT_TYPE, null); if (currentData == null) &#123; // 为目标方法配置Callback emitMethods(e, methods, actualMethods); emitConstructors(e, constructorInfo); &#125; else &#123; emitDefaultConstructor(e); &#125; emitSetThreadCallbacks(e); emitSetStaticCallbacks(e); emitBindCallbacks(e); if (useFactory || currentData != null) &#123; int[] keys = getCallbackKeys(); emitNewInstanceCallbacks(e); emitNewInstanceCallback(e); emitNewInstanceMultiarg(e, constructorInfo); emitGetCallback(e, keys); emitSetCallback(e, keys); emitGetCallbacks(e); emitSetCallbacks(e); &#125; e.end_class();&#125; 获取要代理的方法123456789101112131415161718192021222324252627private static void getMethods(Class superclass, Class[] interfaces, List methods, List interfaceMethods, Set forcePublic)&#123; // 下面这一坨是把目标类的方法，接口方法的信息（类型是 MethodInfo）都加入到methods列表里 ReflectUtils.addAllMethods(superclass, methods); List target = (interfaceMethods != null) ? interfaceMethods : methods; if (interfaces != null) &#123; for (int i = 0; i &lt; interfaces.length; i++) &#123; if (interfaces[i] != Factory.class) &#123; ReflectUtils.addAllMethods(interfaces[i], target); &#125; &#125; &#125; if (interfaceMethods != null) &#123; if (forcePublic != null) &#123; forcePublic.addAll(MethodWrapper.createSet(interfaceMethods)); &#125; methods.addAll(interfaceMethods); &#125; // 过滤static方法 CollectionUtils.filter(methods, new RejectModifierPredicate(Constants.ACC_STATIC)); // 根据布尔值决定是否过滤protected的方法，过滤private方法 CollectionUtils.filter(methods, new VisibilityPredicate(superclass, true)); // 过滤重复 CollectionUtils.filter(methods, new DuplicatesPredicate(methods)); // 过滤final方法 CollectionUtils.filter(methods, new RejectModifierPredicate(Constants.ACC_FINAL));&#125; 针对demo的RunnerDefault，获取到的最终方法为 为目标方法配置Callback123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144// methods的类型是MethodInfo，主要是改了原方法的modifiers// actualMethods的类型Methodprivate void emitMethods(final ClassEmitter ce, List methods, List actualMethods) &#123; CallbackGenerator[] generators = CallbackInfo.getGenerators(callbackTypes); Map groups = new HashMap(); final Map indexes = new HashMap(); final Map originalModifiers = new HashMap(); final Map positions = CollectionUtils.getIndexMap(methods); final Map declToBridge = new HashMap(); Iterator it1 = methods.iterator(); Iterator it2 = (actualMethods != null) ? actualMethods.iterator() : null; while (it1.hasNext()) &#123; MethodInfo method = (MethodInfo)it1.next(); Method actualMethod = (it2 != null) ? (Method)it2.next() : null; // 获取 index int index = filter.accept(actualMethod); if (index &gt;= callbackTypes.length) &#123; throw new IllegalArgumentException(\"Callback filter returned an index that is too large: \" + index); &#125; originalModifiers.put(method, new Integer((actualMethod != null) ? actualMethod.getModifiers() : method.getModifiers())); // 把index放入map indexes.put(method, new Integer(index)); List group = (List)groups.get(generators[index]); if (group == null) &#123; groups.put(generators[index], group = new ArrayList(methods.size())); &#125; group.add(method); // Optimization: build up a map of Class -&gt; bridge methods in class // so that we can look up all the bridge methods in one pass for a class. if (TypeUtils.isBridge(actualMethod.getModifiers())) &#123; Set bridges = (Set)declToBridge.get(actualMethod.getDeclaringClass()); if (bridges == null) &#123; bridges = new HashSet(); declToBridge.put(actualMethod.getDeclaringClass(), bridges); &#125; bridges.add(method.getSignature()); &#125; &#125; final Map bridgeToTarget = new BridgeMethodResolver(declToBridge, getClassLoader()).resolveAll(); Set seenGen = new HashSet(); CodeEmitter se = ce.getStaticHook(); se.new_instance(THREAD_LOCAL); se.dup(); se.invoke_constructor(THREAD_LOCAL, CSTRUCT_NULL); se.putfield(THREAD_CALLBACKS_FIELD); final Object[] state = new Object[1]; CallbackGenerator.Context context = new CallbackGenerator.Context() &#123; public ClassLoader getClassLoader() &#123; return Enhancer.this.getClassLoader(); &#125; public int getOriginalModifiers(MethodInfo method) &#123; return ((Integer)originalModifiers.get(method)).intValue(); &#125; public int getIndex(MethodInfo method) &#123; return ((Integer)indexes.get(method)).intValue(); &#125; // 根据index获取对应的Callback（从DeclaredField获取） public void emitCallback(CodeEmitter e, int index) &#123; emitCurrentCallback(e, index); &#125; public Signature getImplSignature(MethodInfo method) &#123; return rename(method.getSignature(), ((Integer)positions.get(method)).intValue()); &#125; public void emitLoadArgsAndInvoke(CodeEmitter e, MethodInfo method) &#123; // If this is a bridge and we know the target was called from invokespecial, // then we need to invoke_virtual w/ the bridge target instead of doing // a super, because super may itself be using super, which would bypass // any proxies on the target. Signature bridgeTarget = (Signature)bridgeToTarget.get(method.getSignature()); if (bridgeTarget != null) &#123; // checkcast each argument against the target's argument types for (int i = 0; i &lt; bridgeTarget.getArgumentTypes().length; i++) &#123; e.load_arg(i); Type target = bridgeTarget.getArgumentTypes()[i]; if (!target.equals(method.getSignature().getArgumentTypes()[i])) &#123; e.checkcast(target); &#125; &#125; e.invoke_virtual_this(bridgeTarget); Type retType = method.getSignature().getReturnType(); // Not necessary to cast if the target &amp; bridge have // the same return type. // (This conveniently includes void and primitive types, // which would fail if casted. It's not possible to // covariant from boxed to unbox (or vice versa), so no having // to box/unbox for bridges). // TODO: It also isn't necessary to checkcast if the return is // assignable from the target. (This would happen if a subclass // used covariant returns to narrow the return type within a bridge // method.) if (!retType.equals(bridgeTarget.getReturnType())) &#123; e.checkcast(retType); &#125; &#125; else &#123; e.load_args(); e.super_invoke(method.getSignature()); &#125; &#125; public CodeEmitter beginMethod(ClassEmitter ce, MethodInfo method) &#123; CodeEmitter e = EmitUtils.begin_method(ce, method); if (!interceptDuringConstruction &amp;&amp; !TypeUtils.isAbstract(method.getModifiers())) &#123; Label constructed = e.make_label(); e.load_this(); e.getfield(CONSTRUCTED_FIELD); e.if_jump(e.NE, constructed); e.load_this(); e.load_args(); e.super_invoke(); e.return_value(); e.mark(constructed); &#125; return e; &#125; &#125;; for (int i = 0; i &lt; callbackTypes.length; i++) &#123; CallbackGenerator gen = generators[i]; if (!seenGen.contains(gen)) &#123; seenGen.add(gen); final List fmethods = (List)groups.get(gen); if (fmethods != null) &#123; try &#123; gen.generate(ce, context, fmethods); gen.generateStatic(se, context, fmethods); &#125; catch (RuntimeException x) &#123; throw x; &#125; catch (Exception x) &#123; throw new CodeGenerationException(x); &#125; &#125; &#125; &#125; se.return_value(); se.end_method();&#125; 这里代码没有看的很细，了解了大概。 一个方法只会有一个Callback。 这一节，最后看一下代理出来的类的代码 12345678910111213public final void run(String var1) &#123; MethodInterceptor var10000 = this.CGLIB$CALLBACK_0; if (var10000 == null) &#123; CGLIB$BIND_CALLBACKS(this); var10000 = this.CGLIB$CALLBACK_0; &#125; if (var10000 != null) &#123; var10000.intercept(this, CGLIB$run$0$Method, new Object[]&#123;var1&#125;, CGLIB$run$0$Proxy); &#125; else &#123; super.run(var1); &#125;&#125; 其中 12345// CGLIB$run$0$Method Method CGLIB$run$0$Method = ReflectUtils.findMethods(new String[]&#123;\"run\", \"(Ljava/lang/String;)V\"&#125;, (var1 = Class.forName(\"com.htc.learning.api.impl.RunnerDefault\")).getDeclaredMethods())[0];// CGLIB$run$0$ProxyMethodProxy CGLIB$run$0$Proxy = MethodProxy.create(var1, var0, \"(Ljava/lang/String;)V\", \"run\", \"CGLIB$run$0\"); 所以逻辑是这样的，代理类将调用转发给一个Callback，在Callback里，如果要执行目标类的目标方法，即调用net.sf.cglib.proxy.MethodProxy#invokeSuper 等等，MethodProxy是什么 此外从生成的类里，我们可以看除了Enhancer和KeyFactory的增强类之外，还生成了三个类 第二个是我们的代理类，那么其余两个是干嘛的，FastClass又是什么? MethodProxy与Fastclass为什么要有MethodProxy、Fastclass我们配置代理的时候，并没有传入一个目标类实例，而是传入目标类的class，这时我们要去调用目标方法的时候，如果每次都靠反射，那就没有直接调用一个对象来的快。 没错每次都靠反射说的就是你jdk代理。 MethodProxyMethodProxy表明了一个方法到另一个方法的映射，我们看一下代理类run方法的代码 1234567891011121314public final void run(String var1) &#123; MethodInterceptor var10000 = this.CGLIB$CALLBACK_0; if (var10000 == null) &#123; CGLIB$BIND_CALLBACKS(this); var10000 = this.CGLIB$CALLBACK_0; &#125; if (var10000 != null) &#123; // CGLIB$run$0$Proxy 即是 MethodProxy var10000.intercept(this, CGLIB$run$0$Method, new Object[]&#123;var1&#125;, CGLIB$run$0$Proxy); &#125; else &#123; super.run(var1); &#125;&#125; 其中, 123Class var0 = Class.forName(\"com.htc.learning.api.impl.RunnerDefault$$EnhancerByCGLIB$$5b557d48\"); Class var1 = Class.forName(\"com.htc.learning.api.impl.RunnerDefault\")CGLIB$run$0$Proxy = MethodProxy.create(var1, var0, \"(Ljava/lang/String;)V\", \"run\", \"CGLIB$run$0\"); 再其中，&quot;CGLIB$run$0&quot;是Enhancer代理类里的一个已经生成的方法， 123final void CGLIB$run$0(String var1) &#123; super.run(var1);&#125; MethodProxy的create方法， 1234567public static MethodProxy create(Class c1, Class c2, String desc, String name1, String name2) &#123; MethodProxy proxy = new MethodProxy(); proxy.sig1 = new Signature(name1, desc); proxy.sig2 = new Signature(name2, desc); proxy.createInfo = new MethodProxy.CreateInfo(c1, c2); return proxy;&#125; 这一段就是说c1的方法name1,对应的代理方法是实现类c2的方法name2。再具体一点，RunnerDefault的run方法，对应的就是com.htc.learning.api.impl.RunnerDefault$$EnhancerByCGLIB$$5b557d48的CGLIB$run$0方法，这两个签名没有依赖，MethodProxy利用这两个签名，提供两种不同的目标方法调用， FastClass上面只是创建了一个关联关系，接下来看net.sf.cglib.proxy.MethodProxy#invokeSuper 12345678910111213141516171819202122232425262728293031323334353637383940public Object invokeSuper(Object obj, Object[] args) throws Throwable &#123; try &#123; this.init(); MethodProxy.FastClassInfo fci = this.fastClassInfo; // f2是Enhancer代理类，i2是配置好的可以调用到目标方法的索引，invoke根据索引，使用switch块直接调用方法，而不是利用反射 return fci.f2.invoke(fci.i2, obj, args); &#125; catch (InvocationTargetException var4) &#123; throw var4.getTargetException(); &#125;&#125;private void init() &#123; // 单例模式，防止重复创建 if (this.fastClassInfo == null) &#123; synchronized(this.initLock) &#123; if (this.fastClassInfo == null) &#123; MethodProxy.CreateInfo ci = this.createInfo; MethodProxy.FastClassInfo fci = new MethodProxy.FastClassInfo(); fci.f1 = helper(ci, ci.c1); fci.f2 = helper(ci, ci.c2); fci.i1 = fci.f1.getIndex(this.sig1); fci.i2 = fci.f2.getIndex(this.sig2); this.fastClassInfo = fci; this.createInfo = null; &#125; &#125; &#125;&#125;private static FastClass helper(MethodProxy.CreateInfo ci, Class type) &#123; Generator g = new Generator(); g.setType(type); g.setClassLoader(ci.c2.getClassLoader()); g.setNamingPolicy(ci.namingPolicy); g.setStrategy(ci.strategy); g.setAttemptLoad(ci.attemptLoad); // 进去代码后可以看到使用了缓存，所以不会重复生成FastClass return g.create();&#125; 123456789private static class FastClassInfo &#123; FastClass f1; FastClass f2; int i1; int i2; private FastClassInfo() &#123; &#125;&#125; 这个参数命令实在有点难懂，梳理一下，针对run方法， 参数 说明 c1 RunnerDefault f1 RunnerDefault$$FastClassByCGLIB$$a60a67a3 i1 目标类run的索引 c2 RunnerDefault$$EnhancerByCGLIB$$5b557d48 (Enhancer代理类) f2 RunnerDefault$$EnhancerByCGLIB$$5b557d48$$FastClassByCGLIB$$9f176e41（Enhancer代理类的一个快速查找类） i2 Enhancer代理类调用run的索引 下面是RunnerDefault$$FastClassByCGLIB$$a60a67a3的部分代码(如果是RunnerDefault$$EnhancerByCGLIB$$5b557d48$$FastClassByCGLIB$$9f176e41switch块会更大，因为RunnerDefault$$EnhancerByCGLIB$$5b557d48的方法更多) 1234567891011121314151617181920212223242526public int getIndex(Signature var1) &#123; String var10000 = var1.toString(); switch(var10000.hashCode()) &#123; case -1717138348: if (var10000.equals(\"run(Ljava/lang/String;)V\")) &#123; return 0; &#125; break; case 1826985398: if (var10000.equals(\"equals(Ljava/lang/Object;)Z\")) &#123; return 1; &#125; break; case 1913648695: if (var10000.equals(\"toString()Ljava/lang/String;\")) &#123; return 2; &#125; break; case 1984935277: if (var10000.equals(\"hashCode()I\")) &#123; return 3; &#125; &#125; return -1;&#125; 1234567891011121314151617181920212223// 注意这的var2是Enhancer代理类public Object invoke(int var1, Object var2, Object[] var3) throws InvocationTargetException &#123; RunnerDefault var10000 = (RunnerDefault)var2; int var10001 = var1; try &#123; switch(var10001) &#123; case 0: var10000.run((String)var3[0]); return null; case 1: return new Boolean(var10000.equals(var3[0])); case 2: return var10000.toString(); case 3: return new Integer(var10000.hashCode()); &#125; &#125; catch (Throwable var4) &#123; throw new InvocationTargetException(var4); &#125; throw new IllegalArgumentException(\"Cannot find matching method/constructor\");&#125; StackOverflowError如果我们写Callback的时候，把invokeSuper写成invoke会怎么样，答案是：栈溢出。MethodProxy的invoke方法是这样的， 123456789public Object invoke(Object obj, Object[] args) throws Throwable &#123; try &#123; this.init(); MethodProxy.FastClassInfo fci = this.fastClassInfo; return fci.f1.invoke(fci.i1, obj, args); &#125; catch (...) &#123; ... &#125;&#125; 这里的obj是Enhancer代理类，而f1是RunnerDefault$$FastClassByCGLIB$$a60a67a3，所以又会索引到Enhancer代理类的代理run方法，接着又执行上面的invoke,balabala…陷入死循环。 invoke与invokeSuper那是不是invoke不能被调用了？不是，上面说到MethodProxy利用这两个签名，提供两种不同的目标方法调用，所以，invoke是另一种调用目标方法的姿势。 写Callback的时候， 12345@Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; objects[0] = \"cglib \" + objects[0]; return methodProxy.invokeSuper(o, objects); &#125; 传入的Object o是Enhancer代理类，而我们不能执行methodProxy.invoke(o, objects)陷入死循环，所以我们在Callback需要保存一个目标类实例的引用target，然后methodProxy.invoke(target, objects)。 总结MethodProxy与Fastclass提供了一个 Signature -&gt; index -&gt; invoke的机制。 缺陷如果理解了FastClass，那么很容猜测cglib的性能瓶颈在于，当目标类的方法很多的时候，switch块就是一个很慢的查找，这个查找是有优化空间的。此外，cglib代理的创建时间会比jdk代理的创建更耗时间，不过我觉得这都不是事。 参考 cglib demo以及Enhancer源码解析","categories":[{"name":"Proxy","slug":"Proxy","permalink":"https://htchz.cc/categories/Proxy/"}],"tags":[{"name":"AOP","slug":"AOP","permalink":"https://htchz.cc/tags/AOP/"}]},{"title":"[Java代理]Jdk代理","slug":"Java代理-jdk代理","date":"2019-03-04T16:16:00.000Z","updated":"2019-08-15T16:08:49.215Z","comments":true,"path":"68869360.html","link":"","permalink":"https://htchz.cc/68869360.html","excerpt":"","text":"前言相比静态代理需要手动写代理类，动态代理可以通过抽象代码完成对一定规则的类的代理，生成的代理类直接以字节码的形式存在于内存中。Spring里Aop的实现使用了两种动态代理方案，一种是jdk代理，一种是cglib代理。 jdk代理是从目标类的接口生成实现类，cglib是继承目标类生成子类。 Demo123456/** * 接口 */public interface Runner &#123; void run(String name);&#125; 123456789101112/** * 接口实现类 * created by Huang.Zhen on 2019-02-22 */public class RunnerDefault implements Runner &#123; private Logger log = LoggerFactory.getLogger(getClass()); @Override public void run(String name) &#123; log.info(\"run: \" + name); &#125;&#125; 1234567891011121314151617181920212223242526272829/** * 代理类 * created by Huang Zhen on 2019-02-22 */public class JdkProxyHandler implements InvocationHandler &#123; private Logger log = LoggerFactory.getLogger(getClass()); private Object target; // 保存目标类的引用 public JdkProxyHandler(Object target) &#123; this.target = target; &#125; /** * 对newProxyInstance方法的封装 * @return 代理类 */ public Object getProxy() &#123; // 生成代理类 return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this); &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; args[0] = \"jdk \" + args[0]; return method.invoke(target, args); &#125;&#125; 用下面的代码获取代理类并运行 12345@Testpublic void testJdk() &#123; Runner runner = (Runner) new JdkProxyHandler(new RunnerDefault()).getProxy(); runner.run(\"proxy\");&#125; 输出 2019-03-01 16:02:17.623 INFO --- [ main] com.htc.learning.api.impl.RunnerDefault : run: jdk proxy原理怎么生成代理类class文件直捣Proxy.newProxyInstance方法， 1234/* * Look up or generate the designated proxy class. */Class&lt;?&gt; cl = getProxyClass0(loader, intfs); 进入getProxyClass0，从proxyClassCache字面上理解，jdk代理是有缓存的 1234// If the proxy class defined by the given loader implementing// the given interfaces exists, this will simply return the cached copy;// otherwise, it will create the proxy class via the ProxyClassFactoryreturn proxyClassCache.get(loader, interfaces); 进入get方法。可以看到出现了jdk8级别的代码，说明jdk8里jdk代理又被优化了 1234567891011// create subKey and retrieve the possible Supplier&lt;V&gt; stored by that// subKey from valuesMap// subKeyFactory 其实是 java.lang.reflect.Proxy.ProxyClassFactoryObject subKey = Objects.requireNonNull(subKeyFactory.apply(key, parameter));Supplier&lt;V&gt; supplier = valuesMap.get(subKey);...V value = supplier.get();if (value != null) &#123; return value;&#125;... 进入java.lang.reflect.Proxy.ProxyClassFactory#apply方法 1234567.../* * Generate the specified proxy class. */byte[] proxyClassFile = ProxyGenerator.generateProxyClass( proxyName, interfaces, accessFlags);... 123456789101112131415161718192021222324252627282930public static byte[] generateProxyClass(final String var0, Class&lt;?&gt;[] var1, int var2) &#123; ProxyGenerator var3 = new ProxyGenerator(var0, var1, var2); // 生成字节码的方法，不想看 final byte[] var4 = var3.generateClassFile(); // 这里可以通过命令行参数设置要不要存储生成的class文件 if (saveGeneratedFiles) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; try &#123; int var1 = var0.lastIndexOf(46); Path var2; if (var1 &gt; 0) &#123; Path var3 = Paths.get(var0.substring(0, var1).replace('.', File.separatorChar)); Files.createDirectories(var3); var2 = var3.resolve(var0.substring(var1 + 1, var0.length()) + \".class\"); &#125; else &#123; var2 = Paths.get(var0 + \".class\"); &#125; Files.write(var2, var4, new OpenOption[0]); return null; &#125; catch (IOException var4x) &#123; throw new InternalError(\"I/O exception saving generated file: \" + var4x); &#125; &#125; &#125;); &#125; return var4;&#125; 以往都是说jdk代理比cglib性能差，其实优化到现在都没差多少了，更多的时候是从两者的特性按需求采取不同的。 缓存jdk代理获取Class的时候使用了缓存 1234567891011private static Class&lt;?&gt; getProxyClass0(ClassLoader loader, Class&lt;?&gt;... interfaces) &#123; if (interfaces.length &gt; 65535) &#123; throw new IllegalArgumentException(\"interface limit exceeded\"); &#125; // If the proxy class defined by the given loader implementing // the given interfaces exists, this will simply return the cached copy; // otherwise, it will create the proxy class via the ProxyClassFactory return proxyClassCache.get(loader, interfaces);&#125; proxyClassCache的声明是这样的 12345/** * a cache of proxy classes */ private static final WeakCache&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt; proxyClassCache = new WeakCache&lt;&gt;(new KeyFactory(), new ProxyClassFactory()); 主要的成员变量 123456789101112131415// 引用队列private final ReferenceQueue&lt;K&gt; refQueue = new ReferenceQueue&lt;&gt;();// 缓存本存// the key type is Object for supporting null keyprivate final ConcurrentMap&lt;Object, ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt;&gt; map = new ConcurrentHashMap&lt;&gt;();// 反向索引，用来快速判断一个对象是否存在缓存里private final ConcurrentMap&lt;Supplier&lt;V&gt;, Boolean&gt; reverseMap = new ConcurrentHashMap&lt;&gt;();// 两个二元运算方法// subKeyFactory = new KeyFactory()private final BiFunction&lt;K, P, ?&gt; subKeyFactory;// valueFactory = new ProxyClassFactory()private final BiFunction&lt;K, P, V&gt; valueFactory; 这里里的缓存map的value又是一个ConcurrentMap,说明这个缓存是一个二级缓存。 字段名 说明 一级缓存key 一个CacheKey类型的对象，以ClassLoader作为hash 一级缓存value 一级缓存 字段名 说明 二级缓存key 以interfaces为key 二级缓存value Supplier接口，可能是CacheValue 或者 代理工厂对象 看代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// 在Proxy类的代码中，key是ClassLoader，parameter是interface数组public V get(K key, P parameter) &#123; Objects.requireNonNull(parameter); expungeStaleEntries(); Object cacheKey = CacheKey.valueOf(key, refQueue); // lazily install the 2nd level valuesMap for the particular cacheKey // 初始化二级缓存，用了双重校验，保证所有线程拿到的是同一个实例 ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt; valuesMap = map.get(cacheKey); if (valuesMap == null) &#123; ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt; oldValuesMap = map.putIfAbsent(cacheKey, valuesMap = new ConcurrentHashMap&lt;&gt;()); if (oldValuesMap != null) &#123; valuesMap = oldValuesMap; &#125; &#125; // create subKey and retrieve the possible Supplier&lt;V&gt; stored by that // subKey from valuesMap Object subKey = Objects.requireNonNull(subKeyFactory.apply(key, parameter)); Supplier&lt;V&gt; supplier = valuesMap.get(subKey); Factory factory = null; while (true) &#123; if (supplier != null) &#123; // supplier might be a Factory or a CacheValue&lt;V&gt; instance V value = supplier.get(); if (value != null) &#123; return value; &#125; &#125; // else no supplier in cache // or a supplier that returned null (could be a cleared CacheValue // or a Factory that wasn't successful in installing the CacheValue) // lazily construct a Factory if (factory == null) &#123; factory = new Factory(key, parameter, subKey, valuesMap); &#125; if (supplier == null) &#123; supplier = valuesMap.putIfAbsent(subKey, factory); if (supplier == null) &#123; // successfully installed Factory supplier = factory; &#125; // else retry with winning supplier &#125; else &#123; if (valuesMap.replace(subKey, supplier, factory)) &#123; // successfully replaced // cleared CacheEntry / unsuccessful Factory // with our Factory supplier = factory; &#125; else &#123; // retry with current supplier supplier = valuesMap.get(subKey); &#125; &#125; &#125;&#125; 这里的代码主要是维护Map.put操作多线程下的一些同步，防止重复实例化。虽然map是ConcurrentHashMap,但重复put还是得避免的。 二级缓存Map的value为Supplier类型，第一次访问是 Factory对象，第二次访问就可能是CacheValue，因为Factory存有二级缓存map的引用，会把value从this（Factory本身）替换为CacheValue 其实不太明白这种机制,可能为了提高并发性能？先返回值，再为值构造缓存。 缓存过期机制CacheKey是一个WeakReference，当gc时就会被清理掉引用的对象，这时需要把CacheKey从Map里remove，下面这个方法在WeakCache执行读操作的时候会执行一遍。 123456private void expungeStaleEntries() &#123; CacheKey&lt;K&gt; cacheKey; while ((cacheKey = (CacheKey&lt;K&gt;)refQueue.poll()) != null) &#123; cacheKey.expungeFrom(map, reverseMap); &#125;&#125; CacheValue也是虚引用。 InvocationHandler注入代理类已经生成了，我们写的InvocationHandler还没有注入，所以生成代理类的时候是不包含代理逻辑的。 我们回到Proxy.newProxyInstance方法，这时已经获取到class， 123456789101112...final Constructor&lt;?&gt; cons = cl.getConstructor(constructorParams);final InvocationHandler ih = h;if (!Modifier.isPublic(cl.getModifiers())) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; cons.setAccessible(true); return null; &#125; &#125;);&#125;return cons.newInstance(new Object[]&#123;h&#125;); InvocationHandler是通过构造参数注入的。 代理class文件的内容我们生成基本的class文件只需要给一个自定义类名和一个目标类就可以了。 123456789101112131415@Test public void saveJdkProxyClass() throws IOException &#123; String path = \"./$Proxy0.class\"; byte[] classFile = ProxyGenerator.generateProxyClass(\"$Proxy0\", RunnerDefault.class.getInterfaces()); FileOutputStream out = null; try &#123; out = new FileOutputStream(path); out.write(classFile); out.flush(); &#125; finally &#123; if (out != null) &#123; out.close(); &#125; &#125; &#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374//// Source code recreated from a .class file by IntelliJ IDEA// (powered by Fernflower decompiler)//import com.htc.learning.api.Runner;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.lang.reflect.UndeclaredThrowableException;public final class $Proxy0 extends Proxy implements Runner &#123; private static Method m1; private static Method m2; private static Method m3; private static Method m0; public $Proxy0(InvocationHandler var1) throws &#123; super(var1); &#125; public final boolean equals(Object var1) throws &#123; try &#123; return (Boolean)super.h.invoke(this, m1, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final String toString() throws &#123; try &#123; return (String)super.h.invoke(this, m2, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final void run(String var1) throws &#123; try &#123; super.h.invoke(this, m3, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final int hashCode() throws &#123; try &#123; return (Integer)super.h.invoke(this, m0, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; static &#123; try &#123; m1 = Class.forName(\"java.lang.Object\").getMethod(\"equals\", Class.forName(\"java.lang.Object\")); m2 = Class.forName(\"java.lang.Object\").getMethod(\"toString\"); m3 = Class.forName(\"com.htc.learning.api.Runner\").getMethod(\"run\", Class.forName(\"java.lang.String\")); m0 = Class.forName(\"java.lang.Object\").getMethod(\"hashCode\"); &#125; catch (NoSuchMethodException var2) &#123; throw new NoSuchMethodError(var2.getMessage()); &#125; catch (ClassNotFoundException var3) &#123; throw new NoClassDefFoundError(var3.getMessage()); &#125; &#125;&#125; 那么cglib方案的代理类class文件又要怎么获取呢，下篇再说。 可以看到字节码里每个目标方法都有一个同名的代理方法包着，代理逻辑已经写在InvocationHandler，代理方法直接调用InvocationHandler就可以了。 从代理类获取原始对象的Class在Spring里，bean被代理是很常见的，假如我们要获取目标bean上的注解，这时候我们拿到的如果是代理类，是获取不到的目标bean上的注解的。所以这时我们得从代理类获取原始对象，再获得对应的Class。 我的做法在InvocationHandler实现类里，把目标类对象放入了一个target成员变量，然后当我们拿到代理类后，通过调用java.lang.reflect.Proxy#getInvocationHandler方法，再通过反射即可获取到原始对象target。 Spring的做法Spring有一个AopProxyUtils的工具，其中有个方法可以获取到jdk代理或cglib代理的原始对象。关于这个工具更多使用参考AopProxyUtils详解 12345678910111213141516 // candidate即传入的代理类实例public static Class&lt;?&gt; ultimateTargetClass(Object candidate) &#123; Assert.notNull(candidate, \"Candidate object must not be null\"); Object current = candidate; Class&lt;?&gt; result = null; // Spring的代理类都实现了 TargetClassAware，调用getTargetClass()可获取到目标对象，注意，这里不一定是原始对象，因为可能切面切了很多次，生成了很多层的代理类，这也是为什么需要一个while循环 while (current instanceof TargetClassAware) &#123; result = ((TargetClassAware) current).getTargetClass(); current = getSingletonTarget(current); &#125; if (result == null) &#123; // 如果是cglib代理，则获取对象父类，否则是jdk代理，直接获取对象类型 result = (AopUtils.isCglibProxy(candidate) ? candidate.getClass().getSuperclass() : candidate.getClass()); &#125; return result;&#125; 123456789public static Object getSingletonTarget(Object candidate) &#123; if (candidate instanceof Advised) &#123; TargetSource targetSource = ((Advised) candidate).getTargetSource(); if (targetSource instanceof SingletonTargetSource) &#123; return ((SingletonTargetSource) targetSource).getTarget(); &#125; &#125; return null;&#125; 这里的代码逻辑看起来不难，但是涉及了Spring Aop的接口概念，所以具体调用我也不太懂是干嘛的。 Spring在代理逻辑中拦截了getTargetClass()等切面方法，将这些方法转发给Advised去执行。 缺陷从class文件看，由于代理类继承了Proxy类（其实这个类看起来也只有一个java.lang.reflect.Proxy#getInvocationHandler比较通用的方法，其实我觉得这个InvocationHandler可以通过反射拿到，不懂为什么非要继承这个类，喵？），导致jdk代理不能通过继承目标类来达到代理的目的。 关于SpringSpring有个属性是proxy-target-class，默认值是false，表示默认使用jdk代理，这时使用常常会发生类型转换的错误，因为最终bean的class已经不是最初的bean的类型。在Springboot里，proxy-target-class使用spring.aop.proxy-target-class属性来配置，默认为true，即都使用cglib来代理。如果配置为false，Springboot会对实现接口的bean使用jdk代理，对于没有实现接口的类依旧使用cglib代理。 参考 AopProxyUtils详解","categories":[{"name":"Proxy","slug":"Proxy","permalink":"https://htchz.cc/categories/Proxy/"}],"tags":[{"name":"AOP","slug":"AOP","permalink":"https://htchz.cc/tags/AOP/"}]},{"title":"[NIO]linux的I/O多路复用","slug":"NIO-linux的I-O多路复用","date":"2019-01-30T18:07:00.000Z","updated":"2019-02-01T05:05:56.000Z","comments":true,"path":"3010153098.html","link":"","permalink":"https://htchz.cc/3010153098.html","excerpt":"","text":"前言上篇提到i/o多路复用，是通过单进程监听多个文件描述的状态，达到减少线程阻塞的目的。 内核（kernel）利用文件描述符（file descriptor）来访问文件。 文件描述符是非负整数。 打开现存文件或新建文件时(包括socket被打开)，内核会返回一个文件描述符。 读写文件也需要使用文件描述符来指定待读写的文件。在linux环境下，进入/proc目录可以看到许多代表文件描述符的文件夹。 linux i/o多路复用的系统调用接口有三种，分别是 select,poll,epoll。 接口作为一个学java的，了解一下java底层调用的函数，还是挺有助于理解的。 i/o多路复用原理linux(2.6+)内核的事件wakeup callback机制，是linux i/o多路复用的原理。内核管理一个process的睡眠队列，当socket事件发生的时候，唤醒队列的process，调用callback函数完成通知。总体上会涉及两大逻辑：（1）睡眠等待逻辑；（2）唤醒逻辑。 1.睡眠等待逻辑：涉及select、poll、epoll_wait的阻塞等待逻辑 select、poll、epoll_wait陷入内核，判断监控的socket是否有关心的事件发生了，如果没，则为当前process构建一个wait_entry节点，然后插入到监控socket的sleep_list 进入循环的schedule直到关心的事件发生了 关心的事件发生后，将当前process的wait_entry节点从socket的sleep_list中删除。 2.唤醒逻辑。 socket的事件发生了，然后socket顺序遍历其睡眠队列，依次调用每个wait_entry节点的callback函数 直到完成队列的遍历或遇到某个wait_entry节点是排他的才停止。 一般情况下callback包含两个逻辑：1.wait_entry自定义的私有逻辑；2.唤醒的公共逻辑，主要用于将该wait_entry的process放入CPU的就绪队列，让CPU随后可以调度其执行。 select12345678#include &lt;sys/select.h&gt;#include &lt;sys/time.h&gt;int select(int max_fd, fd_set *readset, fd_set *writeset, fd_set *exceptset, struct timeval *timeout)FD_ZERO(int fd, fd_set* fds) //清空集合FD_SET(int fd, fd_set* fds) //将给定的描述符加入集合FD_ISSET(int fd, fd_set* fds) //将给定的描述符从文件中删除 FD_CLR(int fd, fd_set* fds) //判断指定描述符是否在集合中 select 方法的第一个参数max_fd指待测试的fd（fd即文件描述符，一个socket会有一个文件描述符）个数，它的值是待测试的最大文件描述符加1，文件描述符从0开始到max_fd-1都将被测试。中间三个参数readset、writeset和exceptset指定要让内核测试读、写和异常条件的fd集合，如果不需要测试的可以设置为NULL。 select被调用的时候，被监控的readset(假设对socket的读事件感兴趣)会从用户空间复制到内核空间，然后遍历监听的socket，如果在超时或者有一个或多个socket产生了读事件，那么select唤醒线程，注意这里只是唤醒，并没有返回就绪的fd，接下来线程要再次遍历readset，收集可读事件。 select的问题是： 监听的socket数量有限，为了减少fd拷贝的性能损耗，限定了1024个文件描述符 线程被唤醒的时候，需要再次遍历fd列表。 poll12345678#include &lt;poll.h&gt;int poll(struct pollfd fds[], nfds_t nfds, int timeout);typedef struct pollfd &#123; int fd; // 需要被检测或选择的文件描述符 short events; // 对文件描述符fd上感兴趣的事件 short revents; // 文件描述符fd上当前实际发生的事件*/&#125; pollfd_t; poll换了个数据结构，解决了select其中一个问题：监听的数量有限。但实际上并有解决拷贝的性能损耗和需要再次遍历fd列表获取就绪事件。 epoll1234#include &lt;sys/epoll.h&gt;int epoll_create(int size);int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); epoll不是一个方法，而是由三个函数组成; epoll_create创建了一个epoll的fd，参数size表明内核要监听的描述符数量 epoll_ctl用来对fd集合进行修改，参照select，poll每次调用都是将所有fd集合复制，鉴于fd集合的变化不频繁，其实每次全量复制过去是没必要的。 epoll_wait相当于前两种i/o多路复用调用，该函数等待事件的就绪，成功时返回就绪的事件数目，调用失败时返回 -1，等待超时返回 0，events指针指向了就绪的集合。 epoll通过epoll_ctl来对监控的fds集合来进行增、删、改，那么必须涉及到fd的快速查找问题，于是，一个低时间复杂度的增、删、改、查的数据结构来组织被监控的fds集合是必不可少的了。在linux 2.6.8之前的内核，epoll使用hash来组织fds集合，于是在创建epoll fd的时候，epoll需要初始化hash的大小。于是epoll_create(int size)有一个参数size，以便内核根据size的大小来分配hash的大小。在linux 2.6.8以后的内核中，epoll使用红黑树来组织监控的fds集合，于是epoll_create(int size)的参数size实际上已经没有意义了。 epoll解决了select、poll的主要问题： 没有最大并发连接的限制，能打开的fd上限远大于1024 采用回调的方式，效率提升。只有活跃可用的fd才会调用callback函数，也就是说 epoll 只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，epoll的效率就会远远高于select和poll。 epoll对文件描述符的操作有两种模式：LT(level trigger，水平触发)和ET(Edge trigger，边缘触发)。 LT:这次事件没处理，下次还告诉你。ET:这次事件没处理，下次不告诉你。 java nio在linux环境下，java nio 底层调用是epoll，这里有个博主写了一个基于epoll实现的web服务器，在linux下编译完成后，可以浏览器访问8080端口，观察输出。 另外，java使用的模式是水平触发。传送门 结束语作为linux门外汉，了解的不是很深入。 参考 大话 Select、Poll、Epoll 基于epoll实现简单的web服务器","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"NIO","slug":"NIO","permalink":"https://htchz.cc/tags/NIO/"}],"author":"土川"},{"title":"[NIO]五个I/O模型","slug":"NIO-IO模型","date":"2019-01-27T14:35:00.000Z","updated":"2019-01-31T07:24:21.000Z","comments":true,"path":"2990610001.html","link":"","permalink":"https://htchz.cc/2990610001.html","excerpt":"","text":"前言不先了解一下Linux的IO模型，看java的nio真是一脸懵逼。。 linux的io模型Blocking (I/O阻塞IO模型)刚学java的时候想必学的都是阻塞IO传输，底层调用就是上面的图锁展示的过程，进程调用recvfrom，进入阻塞状态，然后系统将数据从网卡/硬盘读取到内核，由从内核复制到用户态，最终返回给进程，进程继续运行。 这是比较耗时和浪费CPU的做法，需要阻塞数据到达，数据复制 Nonblocking I/O（非阻塞IO模型）底层轮询调用recvfrom，系统会立刻返回读取结果，如果读取不到数据，则开启下一次调用，直到数据返回。 这种模式不用阻塞数据到达，需要阻塞数据复制。但是处于轮询状态的进程又是另一种意义上的阻塞，所以其实效率没有提高多少。 I/O Multiplexing(多路复用)Unix/Linux 环境下的 I/O 复用模型包含三组系统调用，分别是 select、poll 和 epoll，在历史上依次出现。select 有三个文件描述符集（readfds），分别是可读文件描述符集（writefds）、可写文件描述符集和异常文件描述符集（exceptfds）。进程将文件描述符（socket也有文件描述符表示）注册到感兴趣的文件描述符集中， 在这种模式下，select先被调用，进程处于阻塞状态，直至一个或多个事件返回。然后使用recvfrom读取数据。 这种模式需要阻塞数据到达，数据复制。但是BIO由于一次只等待一个数据到达，所以性能上多路复用更优。 Signal-Driven I/O（信号驱动I/O）进程告诉内核，某个socket 的某个事件发生时，向进程发送信号。接收到信号后，对应的函数回去处理事件。 这种模式不用阻塞数据到达，需要阻塞数据复制 想想，如果数据复制完再通知进程，不就不用阻塞了。于是有下面的异步IO的模型出现。 Asynchronous I/O （异步I/O）这就是信号驱动I/O的升级版，完全异步，进程无阻塞。对于大部分平台来说，底层利用的还是非异步模型结合回调函数来实现。 遗憾的是，linux的网络IO中是不存在异步IO的，linux的网络IO处理的第二阶段总是阻塞等待数据copy完成的。真正意义上的网络异步IO是Windows下的IOCP（IO完成端口）模型。 对比 总结 Unix网络编程」中说道，按照POSIX标准中的术语，同步指的是I/O动作会导致用户进程阻塞，异步则刚好相反。按照这种分类，上边5种I/O模型中，只有AIO一种是异步的，其他都是同步的。 但是这些只是相对的，程序往往是多线程运行，拿Java来说，主线程调用select操作是阻塞的，但是数据复制这个阻塞过程放到子线程中，对主线程来说没有影响。这也是为什么java的NIO称为同步非阻塞IO。 参考 IO复用","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"NIO","slug":"NIO","permalink":"https://htchz.cc/tags/NIO/"}],"author":"土川"},{"title":"[Java基础]SimpleDateFormat线程安全的问题","slug":"Java基础-SimpleDateFormat线程安全","date":"2018-12-25T10:19:00.000Z","updated":"2019-08-15T16:08:49.213Z","comments":true,"path":"3683368056.html","link":"","permalink":"https://htchz.cc/3683368056.html","excerpt":"今天把SimpleDateFormat设置为static，老哥说你错了，你真的错了。","text":"今天把SimpleDateFormat设置为static，老哥说你错了，你真的错了。 前言SimpleDateFormat是个线程不安全的类，不可以在多线程里面使用。 代码123456789101112131415private static int num = 4;private static ExecutorService executorService = Executors.newFixedThreadPool(num);private static SimpleDateFormat simpleDateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");public static void main(String[] args) &#123; IntStream.range(0, num).parallel().forEach(a -&gt; executorService.submit(() -&gt; &#123; try &#123; System.out.println(simpleDateFormat.parse(\"2017-12-13 15:17:27\")); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;)); executorService.shutdown();&#125; 这个程序会这么报： 1234567891011121314151617181920212223242526272829303132java.lang.NumberFormatException: multiple points at java.base/jdk.internal.math.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1890) at java.base/jdk.internal.math.FloatingDecimal.parseDouble(FloatingDecimal.java:110) at java.base/java.lang.Double.parseDouble(Double.java:543) at java.base/java.text.DigitList.getDouble(DigitList.java:169) at java.base/java.text.DecimalFormat.parse(DecimalFormat.java:2128) at java.base/java.text.SimpleDateFormat.subParse(SimpleDateFormat.java:2240) at java.base/java.text.SimpleDateFormat.parse(SimpleDateFormat.java:1541) at java.base/java.text.DateFormat.parse(DateFormat.java:393) at com.htc.learning.main.SimpleDateFormatTest.lambda$main$0(SimpleDateFormatTest.java:18) at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) at java.base/java.lang.Thread.run(Thread.java:834)java.lang.NumberFormatException: multiple points at java.base/jdk.internal.math.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1890) at java.base/jdk.internal.math.FloatingDecimal.parseDouble(FloatingDecimal.java:110) at java.base/java.lang.Double.parseDouble(Double.java:543) at java.base/java.text.DigitList.getDouble(DigitList.java:169) at java.base/java.text.DecimalFormat.parse(DecimalFormat.java:2128) at java.base/java.text.SimpleDateFormat.subParse(SimpleDateFormat.java:2240) at java.base/java.text.SimpleDateFormat.parse(SimpleDateFormat.java:1541) at java.base/java.text.DateFormat.parse(DateFormat.java:393) at com.htc.learning.main.SimpleDateFormatTest.lambda$main$0(SimpleDateFormatTest.java:18) at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) at java.base/java.lang.Thread.run(Thread.java:834)Wed Dec 13 15:17:27 CST 2017Tue Dec 13 15:17:27 CST 12 这段代码有时报错，有时能正常输出，但也不是正确输出。 SimpleDateFormat的类图结构可以看到内部维护了一个Calendar类，归根到底就是这个家伙线程不安全。 源码看parse(String)方法， 12345678910111213141516171819202122public Date parse(String text, ParsePosition pos)&#123; // 解析字符串将每步的执行结果放入CalendarBuilder的实例calb中 ... Date parsedDate; try &#123; parsedDate = calb.establish(calendar).getTime(); // If the year value is ambiguous, // then the two-digit year == the default start year if (ambiguousYear[0]) &#123; if (parsedDate.before(defaultCenturyStart)) &#123; parsedDate = calb.addYear(100).establish(calendar).getTime(); &#125; &#125; &#125; // An IllegalArgumentException will be thrown by Calendar.getTime() // if any fields are out of range, e.g., MONTH == 17. catch (IllegalArgumentException e) &#123; ... &#125; return parsedDate;&#125; 看calb.establish(calendar).getTime(),这里传入的是一个成员变量，每个SimpleDateFormat使用一个Calendar实例 12345678Calendar establish(Calendar cal) &#123; ... // reset日期对象cal的属性值 cal.clear(); // 使用calb中中属性设置cal ... // return cal; 由于多个线程使用的是同一个Calendar，就会出现一些奇奇怪怪的错误。 那么format()呢 12345678910111213141516public StringBuffer format(Date date, StringBuffer toAppendTo, FieldPosition pos) &#123; pos.beginIndex = pos.endIndex = 0; return format(date, toAppendTo, pos.getFieldDelegate()); &#125; // Called from Format after creating a FieldDelegate private StringBuffer format(Date date, StringBuffer toAppendTo, FieldDelegate delegate) &#123; // Convert input date to time field list calendar.setTime(date); ... return toAppendTo; &#125; 主要看这里calendar.setTime(date);,同样的原因，calendar被并发操作，最后多个线程会输出同样的值。 解决方案 每个线程一个SimpleDateFormat实例，不过我觉得这样没必要。 使用Apache的FastDateFormat类，这是一个线程安全类 FastDateFormat也是依赖Calendar，不过每次方法调用都会实例化一次，避免多线程操作同一个Calendar。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}]},{"title":"[Java基础]Java的SPI机制","slug":"Java基础-Java的SPI机制","date":"2018-11-29T08:04:00.000Z","updated":"2019-07-18T09:55:56.000Z","comments":true,"path":"754409717.html","link":"","permalink":"https://htchz.cc/754409717.html","excerpt":"","text":"为什么要SPISPI, Service Provider Interface, 简单来说就是调用方提供接口，接入方提供实现。比如一个应用程序调用JDBC的接口，你要是使用mysql，就得提供mysql提供的jdbc实现。这和我们定义接口然后写实现类差不多，只不过实现类是可以在jar/war外提供。 原理java的实现无非是读取文件，按类名加载。 调用方定义接口123public interface Name &#123; String getName();&#125; 第三方实现接口123456public class HtcName implements Name &#123; @Override public String getName() &#123; return \"htc\"; &#125;&#125; 123456public class DefaultName implements Name &#123; @Override public String getName() &#123; return \"default\"; &#125;&#125; 声明第三方实现在CLASSPATH下建META-INF/services,这个路径是java的代码写死的。然后新建一个文件，文件名为接口名。 文件的内容就是声明要加载的实现类。 com.htc.learning.api.impl.DefaultName com.htc.learning.api.impl.HtcName调用方加载实现类使用ServiceLoader类加载实现类，他会搜索CLASSPATH下的所有的”META-INF/services/com.htc.learning.api.Name”文件，获取所有声明一一加载。注意,类的实例化发生在遍历的时候 12345678public class SpiTest &#123; public static void main(String[] args) &#123; ServiceLoader&lt;Name&gt; serviceLoader = ServiceLoader.load(Name.class); for (Name name : serviceLoader) &#123; System.out.println(name.getName()); &#125; &#125;&#125; 源码看看ServiceLoader.load(Name.class)做了什么事。 1234public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) &#123; ClassLoader cl = Thread.currentThread().getContextClassLoader(); return ServiceLoader.load(service, cl);&#125; 这里使用了线程上下文类加载器，因为内置Spi接口都是由Bootstrap类加载器加载，Bootstrap类加载器又加载不了第三方实现类，所以要使用线程上下文类加载器（默认是App类加载器） 进入方法后，获取了ClassLoader,接下来继续进入ServiceLoader.load(service, cl);方法。 12345public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service, ClassLoader loader)&#123; return new ServiceLoader&lt;&gt;(service, loader);&#125; 返回了一个实例，那么查看他的构造方法。 1234567891011public void reload() &#123; providers.clear(); lookupIterator = new LazyIterator(service, loader);&#125;private ServiceLoader`(Class&lt;S&gt; svc, ClassLoader cl) &#123; service = Objects.requireNonNull(svc, \"Service interface cannot be null\"); loader = (cl == null) ? ClassLoader.getSystemClassLoader() : cl; acc = (System.getSecurityManager() != null) ? AccessController.getContext() : null; reload();&#125; 到这里，完全没有任何实例化的代码。 前面说到是实例化发生在遍历的时候，在构造函数里也有实例化一个LazyIterator的类，我们转到ServiceLoader的iterator()方法。 123456789101112131415161718192021222324public Iterator&lt;S&gt; iterator() &#123; return new Iterator&lt;S&gt;() &#123; Iterator&lt;Map.Entry&lt;String,S&gt;&gt; knownProviders = providers.entrySet().iterator(); public boolean hasNext() &#123; if (knownProviders.hasNext()) return true; return lookupIterator.hasNext(); &#125; public S next() &#123; if (knownProviders.hasNext()) return knownProviders.next().getValue(); return lookupIterator.next(); &#125; public void remove() &#123; throw new UnsupportedOperationException(); &#125; &#125;;&#125; 先是hasNext(),有一个knownProviders的变量，它从providers属性获得，这个属性是一个LinkedHashMap&lt;String,S&gt;，起到一个缓存的作用，保证实现类只被加载一次。我们可以不关注缓存，看lookupIterator.hasNext()。lookupIterator在上面lookupIterator = new LazyIterator(service, loader);被赋值了的，下面是LazyIterator的代码 12345678910public boolean hasNext() &#123; if (acc == null) &#123; return hasNextService(); &#125; else &#123; PrivilegedAction&lt;Boolean&gt; action = new PrivilegedAction&lt;Boolean&gt;() &#123; public Boolean run() &#123; return hasNextService(); &#125; &#125;; return AccessController.doPrivileged(action, acc); &#125;&#125; 这里有java SecurityManager的管理，直接看hasNextService()的代码就好了。 123456789101112131415161718192021222324252627private boolean hasNextService() &#123; //nextName在上一次查询提前缓存实现类的名字，做到快速判断 if (nextName != null) &#123; return true; &#125; if (configs == null) &#123; try &#123; // 这里的 PREFIX 就是 \"META-INF/services/\" String fullName = PREFIX + service.getName(); if (loader == null) configs = ClassLoader.getSystemResources(fullName); else configs = loader.getResources(fullName); &#125; catch (IOException x) &#123; fail(service, \"Error locating configuration files\", x); &#125; &#125; while ((pending == null) || !pending.hasNext()) &#123; if (!configs.hasMoreElements()) &#123; return false; &#125; pending = parse(service, configs.nextElement()); &#125; // 提前缓存实现类的名字，下一次查询做到快速判断 nextName = pending.next(); return true;&#125; 接下来看next()操作。 12345public S next() &#123; if (knownProviders.hasNext()) return knownProviders.next().getValue(); return lookupIterator.next();&#125; 转到lookupIterator.next() 12345678910public S next() &#123; if (acc == null) &#123; return nextService(); &#125; else &#123; PrivilegedAction&lt;S&gt; action = new PrivilegedAction&lt;S&gt;() &#123; public S run() &#123; return nextService(); &#125; &#125;; return AccessController.doPrivileged(action, acc); &#125;&#125; 看nextService() 12345678910111213141516171819202122232425262728private S nextService() &#123; // 这里会执行hasNextService()的判断 if (!hasNextService()) throw new NoSuchElementException(); String cn = nextName; nextName = null; Class&lt;?&gt; c = null; try &#123; c = Class.forName(cn, false, loader); &#125; catch (ClassNotFoundException x) &#123; fail(service, \"Provider \" + cn + \" not found\"); &#125; if (!service.isAssignableFrom(c)) &#123; fail(service, \"Provider \" + cn + \" not a subtype\"); &#125; try &#123; S p = service.cast(c.newInstance()); providers.put(cn, p); return p; &#125; catch (Throwable x) &#123; fail(service, \"Provider \" + cn + \" could not be instantiated\", x); &#125; throw new Error(); // This cannot happen&#125; 实际上nextService()没参与遍历，实现类的遍历是交给了hasNextService()并把遍历到的ClassName存放到nextName属性，nextService()只负责把nextName实例化，并且放入缓存中。 缺点java的SPI是有缺点的，这也是dubbo为什么要实现自己的SPI机制。 JDK 标准的 SPI 会一次性实例化扩展点所有实现，如果有扩展实现初始化很耗时，但如果没用上也加载，会很浪费资源。 题外话我们java程序加载数据库驱动的时候，利用的就是java的spi机制。如果我们引入了多个数据库的jdbc驱动jar，那么java怎么知道加载哪一个呢。 我们我的数据库驱动是由java.sql.DriverManager管理的，现在看他的一个getDriver()方法， 123456789101112131415161718192021222324252627@CallerSensitivepublic static Driver getDriver(String url) throws SQLException &#123; ... // who understands the given URL. for (DriverInfo aDriver : registeredDrivers) &#123; // If the caller does not have permission to load the driver then // skip it. if(isDriverAllowed(aDriver.driver, callerClass)) &#123; try &#123; // 就是这一行！ if(aDriver.driver.acceptsURL(url)) &#123; // Success! println(\"getDriver returning \" + aDriver.driver.getClass().getName()); return (aDriver.driver); &#125; &#125; catch(SQLException sqe) &#123; // Drop through and try the next driver. &#125; &#125; else &#123; println(\" skipping: \" + aDriver.driver.getClass().getName()); &#125; &#125; ...&#125; 看if(aDriver.driver.acceptsURL(url))这一行，DriverManager用连接的url对每一个驱动进行尝试，尝试得通就是这个驱动没跑了。。。 结束语无。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"https://htchz.cc/tags/OOP/"}],"author":"土川"},{"title":"[Dubbo]探索dubbo2.6.3版本之前的一个问题","slug":"碧油鸡-探索dubbo2-6-3版本之前的一个问题","date":"2018-10-20T02:55:00.000Z","updated":"2019-03-12T07:01:11.000Z","comments":true,"path":"1632594101.html","link":"","permalink":"https://htchz.cc/1632594101.html","excerpt":"由于dubbo版本较低遇到了一个诡异的问题。","text":"由于dubbo版本较低遇到了一个诡异的问题。 场景dubbo的RpcContext存放了一个attachments属性，用于隐式传递参数，每次发起调用之后会clear清空。 使用了cat监控之后，可以在dubbo服务调用之间传递一个id作为链路跟踪。而这个参数就是在Comsumer发起请求前放入attachments，在Provider接收到请求后从attachments拿出。 测试环境调用某服务会出现这个id时有时无的情况，于是分析日志，发现没有这个id的情况下，dubbo协议走的是hessian协议。原来此服务提供了hessian访问，于是客户端会随机走dubbo或者hessian协议。 为什么hessian协议会丢attachments？这个id是通过实现dubbo的Filter塞进去的，理论上Filter应该是协议无关的。通过debug发现，在发送请求之前的RpcContext.attachments里也的确是有这个id。 探索dubbo协议dubbo的consumer调用抽象为Invoker和Invocation，在Invoker执行invoke方法之前，需要执行负载均衡、重试计数、拦截器调用链，最后执行抽象类AbstractInvoker.invoke方法，继而调用不同协议的doInvoke方法 看看dubbo协议的doInvoke方法， 可以看到请求是由一个HeaderExchangeClient去发起，这里的的channel是一个nettyClient，而request的内容如下：dubbo协议的实现是利用socket长连接，将整个request对象发送过去的,没有丢attachments hessian协议hessian协议下是通过com.caucho.hessian.client.HessianProxy#invoke来发起请求，这个方法签名如下： 1public Object invoke(Object proxy, Method method, Object[] args) 第一个参数不知道是干嘛的，第二个参数和第三个参数分别是调用服务的方法对象和参数。反正这个方法是没地方放attchments这种隐式参数含义的东西。 debug看他的调用栈， 定位到这个com.alibaba.dubbo.rpc.proxy.AbstractProxyInvoker#invoke方法 123456789public Result invoke(Invocation invocation) throws RpcException &#123; try &#123; return new RpcResult(doInvoke(proxy, invocation.getMethodName(), invocation.getParameterTypes(), invocation.getArguments())); &#125; catch (InvocationTargetException e) &#123; return new RpcResult(e.getTargetException()); &#125; catch (Throwable e) &#123; throw new RpcException(\"Failed to invoke remote proxy method \" + invocation.getMethodName() + \" to \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125;&#125; 可以看到，从这里开始 1return new RpcResult(doInvoke(proxy, invocation.getMethodName(), invocation.getParameterTypes(), invocation.getArguments())); 就把invocation里的attachments丢了 解决方法dubbo版本至少升级直2.6.3，这个版本对提供了对hessian协议的attachments支持。 下面是部分代码， 12345678910111213public class DubboHessianURLConnectionFactory extends HessianURLConnectionFactory &#123; @Override public HessianConnection open(URL url) throws IOException &#123; HessianConnection connection = super.open(url); RpcContext context = RpcContext.getContext(); for (String key : context.getAttachments().keySet()) &#123; connection.addHeader(Constants.DEFAULT_EXCHANGER + key, context.getAttachment(key)); &#125; return connection; &#125;&#125; dubbo通过继承hessian库的类，在处理URL的时候把attachments放到header里去了，接收请求时再从header里拿出来。","categories":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://htchz.cc/categories/Dubbo/"}],"tags":[{"name":"碧油鸡","slug":"碧油鸡","permalink":"https://htchz.cc/tags/碧油鸡/"}],"author":"土川"},{"title":"[Java基础]正确使用CompletableFuture","slug":"Java基础-正确使用CompletableFuture","date":"2018-10-12T05:36:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"1193009570.html","link":"","permalink":"https://htchz.cc/1193009570.html","excerpt":"用不好可就搞笑了哦","text":"用不好可就搞笑了哦 前言这个类是jdk8提供的类，在这个类之前的其他Future实现类，存在一些缺点，比如缺少一些任务完成的通知机制。 于是CompletableFuture诞生了，他提供了任务回调的机制，还可以简洁的组合两个任务；更可以聚合n个任务，在任何一个任务完成的全部任务完成后进行某种操作。关于它的特性不多说。 jdk8里的ParallelStream和CompletableFuture的出现让java的异步编程变的更为自然灵活。 线程池那些事jdk1.7老李设计了ForkJoinPool框架，核心就是任务窃取算法。ForkJoinPool有个通用线程池，他的工作线程数在多核环境下默认是Runtime.getRuntime().availableProcessors() - 1,也就“机器cpu的线程数 - 1“（减一可能是最佳实践吧）， 1234public static ForkJoinPool commonPool() &#123; // assert common != null : \"static init error\"; return common;&#125; ParallelStream新任务是只能提交到这个线程池的，而CompletableFuture默认使用这个线程池，但是也支持自己提供线程池。 可以看到runAsync和supplyAsync有重载方法提供Executor。 那么我们什么时候要提供线程池呢，这里看《java8实战》的一段话， 并行——使用流还是CompletableFutures?集合进行并行计算有两种方式:要么将其转化为并行流，利用map这样的操作开展工作，要么枚举出集合中的每一个元素，创建新的线程，在CompletableFuture内对其进行操作。后者提供了更多的灵活性，你可以调整线程池的大小，而这能帮助你确保整体的计算不会因为线程都在等待I/O而发生阻塞。我们对使用这些API的建议如下。 如果你进行的是计算密集型的操作，并且没有I/O，那么推荐使用Stream接口，因为实现简单，同时效率也可能是最高的(如果所有的线程都是计算密集型的，那就没有必要创建比处理器核数更多的线程)。 如果你并行的工作单元还涉及等待I/O的操作(包括网络连接等待)，那么使用CompletableFuture灵活性更好，你可以像前文讨论的那样，依据等待/计算，或者 W/C的比率设定需要使用的线程数。这种情况不使用并行流的另一个原因是，处理流的流水线中如果发生I/O等待，流的延迟特性(流的中间操作会在一起执行)会让我们很难判断到底什么时候触发了等待。 简单地说，ForkJoinPool通用线程池的线程数比较少，不适合用来进行需要I/O等待的任务。如果用CompletableFuture提交一些需要I/O等待的任务，需要提供一个自定义的Executor。 下面用程序演示一下， 12345678910111213141516171819202122232425262728public class CompletableTest &#123; public static void main(String[] args) &#123; ExecutorService service = Executors.newFixedThreadPool(100); Stopwatch stopwatch = Stopwatch.createUnstarted(); stopwatch.start(); // 不提供Executor，Uninterruptibles.sleepUninterruptibly(1, TimeUnit.SECONDS)模拟网络I/O 1秒 CompletableFuture.allOf( IntStream.rangeClosed(1, 100).boxed() .map(a -&gt; CompletableFuture.runAsync(() -&gt; Uninterruptibles.sleepUninterruptibly(1, TimeUnit.SECONDS))) .toArray(CompletableFuture[]::new)) .join(); System.out.println(\"elapsed with ForkJoinPool:\" + stopwatch.stop().elapsed(TimeUnit.MILLISECONDS) + \" ms\"); stopwatch.reset().start(); // 提供Executor CompletableFuture.allOf( IntStream.rangeClosed(1, 100).boxed() .map(a -&gt; CompletableFuture.runAsync(() -&gt; Uninterruptibles.sleepUninterruptibly(1, TimeUnit.SECONDS), service)) .toArray(CompletableFuture[]::new)) .join(); System.out.println(\"elapsed with Executor:\" + stopwatch.stop().elapsed(TimeUnit.MILLISECONDS) + \" ms\"); service.shutdown(); &#125;&#125; elapsed with ForkJoinPool:15100 ms elapsed with Executor:1019 ms我的电脑是8线程，那么ForkJoinPool通用线程池就是 (8 - 1 = 7 )个线程， 可以看到100个任务执行了15秒 ( 约等于 100 / 7)。所以使用CompletableFuture的时候要注意这点。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}],"author":"土川"},{"title":"[服务限流]接口限流","slug":"服务限流-接口限流","date":"2018-09-29T07:51:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"2168043814.html","link":"","permalink":"https://htchz.cc/2168043814.html","excerpt":"尝试一下用lua脚本执行redis命令","text":"尝试一下用lua脚本执行redis命令 前言对于应用内部的服务限流，熔断器Hystrix，作出很好的实践。最近开源的Sentinel也是一个不错的选择。不过对于对外接口限流，好像没有什么框架。常用的限流算法就是：漏桶算法和令牌桶算法。本文将利用redis和lua脚本实现令牌桶算法，同时通过spring来驱动脚本。Guava提供了一个RateLimiter，我们也看一下。 当然还可以用计数器方法，如设定一个计数key，一秒过期，一秒内达到n次就拒绝服务。 两个算法Google了十几个中文博客，每一篇都是一样的，都说两种算法能限制速率，但是漏桶算法不能应对突发流量而令牌桶可以，又没说为什么。在我看来，两种算法的算法不过是“一正一反”，本质是一样的。无奈英语渣看了一下维基百科”LeakyBucket”词条，Overview里提到，文献描述了两种版本的漏桶算法： as a meter（作为计量工具） as a queue（作为调度队列） 第一种版本是令牌桶算法的镜像实现，第二种是第一种的变种。也就是其实都差不多的。 漏桶算法（LeakyBucket） 漏桶算法指一定速率漏水，流量进来的时候是把水加入桶里，当水&gt; 容量的时候拒绝服务（或者其他策略balabala）。 两个重要参数： 漏水速率 桶容量 对于桶满的情况下，对于新的流量有两种处理方式： Traffic Shaping: 暂时拦截住上方水的向下流动，等待桶中的一部分水漏走后，再放行上方水。也就是上面的as a queue。 Traffic Policing: 溢出的上方水直接抛弃，也就是上面的as a meter（作为计量工具） 可以看到这种算法提供一种机制控制接口被访问的速率，平滑突发的流量。 伪代码： 12345678910111213141516171819double rate; // leak rate in calls/sdouble burst; // bucket size in callslong refreshTime; // time for last water refreshdouble water; // water count at refreshTimerefreshWater() &#123; long now = getTimestamp(); //计算两次请求之间流失的水并相减 water = max(0, water- (now - refreshTime)*rate); refreshTime = now;&#125;bool check() &#123; refreshWater(); if (water &lt; burst) &#123; // 水桶还没满,继续加1 water ++; return true; &#125; else &#123; return false; &#125;&#125; 令牌桶算法（TokenBucket） 令牌桶算法是网络流量整形（Traffic Shaping）和速率限制（Rate Limiting）中最常使用的一种算法。典型情况下，令牌桶算法用来控制发送到网络上的数据字节数目，并允许突发数据的发送，用令牌数量代表字节数量。 两个重要参数： 发牌速率 令牌桶容量 对于令牌不足的情况，对流量可以进行三种方式的处理： 丢弃数据包 放入等待队列直至令牌足够 进行标记，过载情况下可以进行丢弃 令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务(或者其他策略balabala)。从原理上看，令牌桶算法和漏桶算法是相反的，一个“进水”，一个是“漏水”。 丢弃数据包的实现看楼下lua脚本 Guava的RateLimiter就是使用了令牌桶算法。 redis实现redis在2.6之后内置了对lua脚本的支持。通过lua脚本我们可以执行一些复杂的逻辑操作，同时保证整个操作过程的原子性。 lua脚本写在客户端，下面是一个lua脚本，应该很容易理解 12345678910111213141516171819202122232425262728293031323334353637383940--token_bucket.lua--keys和argv都是数组--tonumber()方法是转整数--local表示本地变量，速度比全局变量快--..表示拼接字符串local key = KEYS[1];--local limit = tonumber(ARGV[1]);local step = tonumber(ARGV[2]);local interval = tonumber(ARGV[3]);local nowTime = tonumber(ARGV[4]);local lastClearTimeKey = 'lastTimeOf' .. keylocal lastClearTime = redis.call('GET', lastClearTimeKey);local existKey = redis.call('EXISTS', key);if existKey == 1 then local diff = tonumber(nowTime) - tonumber(lastClearTime); local value = tonumber(redis.call('GET', key)); if diff &gt; interval then local maxValue = value + diff / interval * step; if maxValue &gt; step then value = step; else value = maxValue; end redis.call('SET', lastClearTimeKey, nowTime); redis.call('SET', key, math.floor(value)); end if value &lt;= 0 then return 0; else redis.call('DECR', key); endelse redis.call('SET', key, step - 1); redis.call('SET', lastClearTimeKey, nowTime);endreturn 1; 使用spring驱动由于使用的是spring-boot，redis-server在本地，所以只要引入spring-data-redis和jedis,其他配置默认 12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-redis&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt; 设置序列化器 1234567891011@Bean@SuppressWarnings(\"unchecked\")public RedisTemplate redisTemplate(RedisConnectionFactory redisConnectionFactory) &#123; RedisTemplate redisTemplate = new RedisTemplate(); redisTemplate.setConnectionFactory(redisConnectionFactory); // 设置键的序列化器 redisTemplate.setKeySerializer(new StringRedisSerializer()); // 默认Serializer,RedisTemplate在序列化key、反序列化返回值的时候找不到设置的Serializer会使用默认Serializer，而默认的默认Serializer是JdkSerializationRedisSerializer，这个会转成很难看的码可能导致lua执行出错 redisTemplate.setDefaultSerializer( new GenericJackson2JsonRedisSerializer()); return redisTemplate;&#125; 脚本的抽象类是DefaultRedisScript, 使用RedisTemplate调用。keys是List类型，argvs是数组类型，不可以搞混。 123456789101112131415161718public class RedisScriptService &#123; private final static Logger log = LoggerFactory.getLogger(RedisScriptService.class); @Resource private RedisTemplate redisTemplate; public void counterConsume(String key, int limit, int step, int interval) &#123; DefaultRedisScript&lt;Long&gt; consumeRedisScript = new DefaultRedisScript&lt;&gt;(); consumeRedisScript.setResultType(Long.class); consumeRedisScript.setScriptSource(new ResourceScriptSource(new ClassPathResource(\"script/token_bucket.lua\")));//加载lua脚本文件 List&lt;Object&gt; keyList = new LinkedList&lt;&gt;(); keyList.add(key);//通过KEYS[1]取值 for (int i = 0; i &lt; 15; i++) &#123; log.info(\"result:\" + redisTemplate.execute(consumeRedisScript, keyList, new Object[]&#123;limit, step, interval, System.currentTimeMillis()&#125;).toString()); &#125; &#125;&#125; 2018-09-30 16:23:17.066 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:1 2018-09-30 16:23:17.067 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:1 2018-09-30 16:23:17.067 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:1 2018-09-30 16:23:17.068 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:1 2018-09-30 16:23:17.069 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:1 2018-09-30 16:23:17.070 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:1 2018-09-30 16:23:17.071 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:1 2018-09-30 16:23:17.072 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:1 2018-09-30 16:23:17.072 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:1 2018-09-30 16:23:17.073 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:1 2018-09-30 16:23:17.074 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:0 2018-09-30 16:23:17.075 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:0 2018-09-30 16:23:17.076 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:0 2018-09-30 16:23:17.077 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:0 2018-09-30 16:23:17.078 INFO 18660 --- [ main] c.h.learning.service.RedisScriptService : result:0result的1是通过，0是不通过。 键没有设置过期，可以优化。 Guava RateLimiterGuava RateLimiter实现了令牌桶算法。这里有一个中文版的官方文档：Guava官方文档，主要就是声明发牌速率，然后需要判断能否获取令牌，则调用tryAcquire()或tryAcquire(int)方法；需要阻塞直至令牌足够，则调用acquire()或acquire(int)。 qps限制器假设我们要限制每秒处理task或者qps的值，代码： 1234567891011121314public class RateLimiterTest &#123; public static void main(String[] args) &#123; RateLimiter rateLimiter = RateLimiter.create(5); IntStream.range(0, 15).forEach((a) -&gt; &#123; if (a == 5) &#123; SleepUtil.sleep(2000); &#125; System.out.println(rateLimiter.acquire()); if ((a + 1) % 5 == 0) &#123; System.out.println(); &#125; &#125;); &#125;&#125; 0.0// 0令牌，还不用阻塞 0.143213 0.196686 0.198948 0.199056 0.0// 停了2秒，发了5个令牌 0.0 0.0 0.0 0.0 0.0// 0令牌，还不用阻塞 0.199505 0.198738 0.197634 0.196273示例里先实例一个限流器，速率为1秒5次，通过acquire()阻塞获得令牌，总调用15次，并返回等待时间。第5次acquire()完的时候，挂起2秒。 从输出来看，第一次取得令牌是不用等待的。 挂起2秒后，接下来的5次不用阻塞，再接下来的5次除了以第一次发生了阻塞(第一次)，也就是2秒内只发了5个令牌，不会累积。 为什么看起来0令牌的情况下，第一次调用阻塞时间都是0呢？那是因为RateLimiter可以预消费（acquire()实际上是调用acquire(1), 这和调用acquire(1000) 将得到相同的限制效果，如果存在这样的调用的话），但会影响下一次请求的，也就是说，如果一个高开销的任务抵达一个空闲的RateLimiter，它会被马上许可，但是下一个请求会经历额外的限制，从而来偿付高开销任务。 此外需注意：RateLimiter 并不提供公平性的保证，没有先来先得的概念。 这个类其实实现了令牌不足下多种应对策略 require()属于流量整形的实现 tryRequire()属于服务限流的实现 后记除此之外，nginx也有限流模块，一种是限制连接数，一种是使用令牌桶算法，具体效果没实战。","categories":[{"name":"分布式","slug":"分布式","permalink":"https://htchz.cc/categories/分布式/"}],"tags":[{"name":"服务限流","slug":"服务限流","permalink":"https://htchz.cc/tags/服务限流/"}],"author":"土川"},{"title":"[Golang基础]Goroutine调度","slug":"Golang基础-Goroutine调度","date":"2018-09-28T06:48:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"2747343217.html","link":"","permalink":"https://htchz.cc/2747343217.html","excerpt":"摘抄自小米运维","text":"摘抄自小米运维 前言随着服务器硬件迭代升级，配置也越来越高。为充分利用服务器资源，并发编程也变的越来越重要。在开始之前，需要了解一下并发(concurrency)和并行(parallesim)的区别。 并发: 逻辑上具有处理多个同时性任务的能力。 并行: 物理上同一时刻执行多个并发任务。 通常所说的并发编程，也就是说它允许多个任务同时执行，但实际上并不一定在同一时刻被执行。在单核处理器上，通过多线程共享CPU时间片串行执行(并发非并行)。而并行则依赖于多核处理器等物理资源，让多个任务可以实现并行执行(并发且并行)。 多线程或多进程是并行的基本条件，但单线程也可以用协程(coroutine)做到并发。简单将Goroutine归纳为协程并不合适，因为它运行时会创建多个线程来执行并发任务，且任务单元可被调度到其它线程执行。这更像是多线程和协程的结合体，能最大限度提升执行效率，发挥多核处理器能力。 Go编写一个并发编程程序很简单，只需要在函数之前使用一个Go关键字就可以实现并发编程。 12345func main() &#123; go func()&#123; fmt.Println(\"Hello,World!\") &#125;()&#125; Go调度器组成Go语言虽然使用一个 Go 关键字即可实现并发编程，但Goroutine被调度到后端之后，具体的实现比较复杂。先看看调度器有哪几部分组成。 G M P GG是 Go routine的缩写，相当于操作系统中的进程控制块，在这里就是Goroutine的控制结构，是对Goroutine的抽象。其中包括执行的函数指令及参数；G保存的任务对象；线程上下文切换，现场保护和现场恢复需要的寄存器(SP、IP)等信息。 Go不同版本Goroutine默认栈大小不同。 12345678910111213141516171819202122// Go1.11版本默认stack大小为2KB_StackMin = 2048 // 创建一个g对象,然后放到g队列// 等待被执行func newproc1(fn *funcval, argp *uint8, narg int32, callergp *g, callerpc uintptr) &#123; _g_ := getg() _g_.m.locks++ siz := narg siz = (siz + 7) &amp;^ 7 _p_ := _g_.m.p.ptr() newg := gfget(_p_) if newg == nil &#123; // 初始化g stack大小 newg = malg(_StackMin) casgstatus(newg, _Gidle, _Gdead) allgadd(newg) &#125; // 以下省略&#125; MM是一个线程或称为Machine，对应操作系统线程。所有M是有线程栈的。如果不对该线程栈提供内存的话，系统会给该线程栈提供内存(不同操作系统提供的线程栈大小不同)。当指定了线程栈，则M.stack→G.stack，M的PC寄存器指向G提供的函数，然后去执行。 1234567891011121314type m struct &#123; /* 1. 所有调用栈的Goroutine,这是一个比较特殊的Goroutine。 2. 普通的Goroutine栈是在Heap分配的可增长的stack,而g0的stack是M对应的线程栈。 3. 所有调度相关代码,会先切换到该Goroutine的栈再执行。 */ g0 *g curg *g // M当前绑定的结构体G // SP、PC寄存器用于现场保护和现场恢复 vdsoSP uintptr vdsoPC uintptr // 省略…&#125; PP(Processor)是一个抽象的概念，它存在的意义是为了限制并发任务的数量，并不是物理CPU的抽象。所以当P有任务时需要创建或者唤醒一个系统线程来执行它队列里的任务。所以P/M需要进行绑定，构成一个执行单元。 P决定了同时可以并发任务的数量，可通过GOMAXPROCS限制同时执行用户级任务的操作系统线程。可以通过runtime.GOMAXPROCS进行指定。在Go1.5之后GOMAXPROCS被默认设置可用的核数，而之前则默认为1。 1234567891011121314// 自定义设置GOMAXPROCS数量func GOMAXPROCS(n int) int &#123; /* 1. GOMAXPROCS设置可执行的CPU的最大数量,同时返回之前的设置。 2. 如果n &lt; 1,则不更改当前的值。 */ ret := int(gomaxprocs) stopTheWorld(\"GOMAXPROCS\") // startTheWorld启动时,使用newprocs。 newprocs = int32(n) startTheWorld() return ret&#125; 123456789101112131415161718192021222324252627282930313233343536373839// 默认P被绑定到所有CPU核上// P == cpu.coresfunc getproccount() int32 &#123; const maxCPUs = 64 * 1024 var buf [maxCPUs / 8]byte // 获取CPU Core r := sched_getaffinity(0, unsafe.Sizeof(buf), &amp;buf[0]) n := int32(0) for _, v := range buf[:r] &#123; for v != 0 &#123; n += int32(v &amp; 1) v &gt;&gt;= 1 &#125; &#125; if n == 0 &#123; n = 1 &#125; return n&#125;// 一个进程默认被绑定在所有CPU核上,返回所有CPU core。// 获取进程的CPU亲和性掩码系统调用// rax 204 ; 系统调用码// system_call sys_sched_getaffinity; 系统调用名称// rid pid ; 进程号// rsi unsigned int len // rdx unsigned long *user_mask_ptrsys_linux_amd64.s:TEXT runtime·sched_getaffinity(SB),NOSPLIT,$0 MOVQ pid+0(FP), DI MOVQ len+8(FP), SI MOVQ buf+16(FP), DX MOVL $SYS_sched_getaffinity, AX SYSCALL MOVL AX, ret+24(FP) RET 调度过程首先创建一个G对象，G对象保存到P本地队列或者是全局队列。P此时去唤醒一个M。P继续执行它的执行序。M寻找是否有空闲的P，如果有则将该G对象移动到它本身。接下来M执行一个调度循环(调用G对象-&gt;执行-&gt;清理线程→继续找新的Goroutine执行)。 M执行过程中，随时会发生上下文切换。当发生上线文切换时，需要对执行现场进行保护，以便下次被调度执行时进行现场恢复。Go调度器M的栈保存在G对象上，只需要将M所需要的寄存器(SP、PC等)保存到G对象上就可以实现现场保护。当这些寄存器数据被保护起来，就随时可以做上下文切换了，在中断之前把现场保存起来。如果此时G任务还没有执行完，M可以将任务重新丢到P的任务队列，等待下一次被调度执行。当再次被调度执行时，M通过访问G的vdsoSP、vdsoPC寄存器进行现场恢复(从上次中断位置继续执行)。 当M从队列中拿到一个可执行的G后，首先会去检查一下P队列中是否还有等待的G，如果还有等待的G，并且也还有空闲的P，此时就会通知runtime分配一个新的M（如果有在睡觉的OS线程，则直接唤醒它，没有的话则生成一个新的OS线程）来分担任务。 如果某个M发现队列为空之后，会首先从全局队列中取一个G来处理。如果全局队列也空了，则会随机从别的P那里直接截取一半的队列过来（偷窃任务），如果发现所有的P都没有可供偷窃的G了，该M就会陷入沉睡。 这种协作调度回导致全剧队列会响应得慢一丢丢，但是在总体上这种调度将处理器的机器性能充分发挥。 P 队列通过上图可以发现，P有两种队列：本地队列和全局队列。 本地队列： 当前P的队列，本地队列是Lock-Free，没有数据竞争问题，无需加锁处理，可以提升处理速度。 全局队列： 全局队列为了保证多个P之间任务的平衡。所有M共享P全局队列，为保证数据竞争问题，需要加锁处理。相比本地队列处理速度要低于全局队列。 上线文切换简单理解为当时的环境即可，环境可以包括当时程序状态以及变量状态。例如线程切换的时候在内核会发生上下文切换，这里的上下文就包括了当时寄存器的值，把寄存器的值保存起来，等下次该线程又得到cpu时间的时候再恢复寄存器的值，这样线程才能正确运行。 对于代码中某个值说，上下文是指这个值所在的局部(全局)作用域对象。相对于进程而言，上下文就是进程执行时的环境，具体来说就是各个变量和数据，包括所有的寄存器变量、进程打开的文件、内存(堆栈)信息等。 线程清理Goroutine被调度执行必须保证P/M进行绑定，所以线程清理只需要将P释放就可以实现线程的清理。什么时候P会释放，保证其它G可以被执行。P被释放主要有两种情况。 主动释放： 最典型的例子是，当执行G任务时有系统调用，当发生系统调用时M会处于Block状态。调度器会设置一个超时时间，当超时时会将P释放。 被动释放： 如果发生系统调用，有一个专门监控程序，进行扫描当前处于阻塞的P/M组合。当超过系统程序设置的超时时间，会自动将P资源抢走。去执行队列的其它G任务。","categories":[{"name":"Golang基础","slug":"Golang基础","permalink":"https://htchz.cc/categories/Golang基础/"}],"tags":[{"name":"goroutine","slug":"goroutine","permalink":"https://htchz.cc/tags/goroutine/"}],"author":"土川"},{"title":"[Java基础]ForkJoinPool","slug":"Java基础-ForkJoinPool","date":"2018-09-20T09:01:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"2843017067.html","link":"","permalink":"https://htchz.cc/2843017067.html","excerpt":"jdk8的parallerStream的实现依赖这种线程池。这个类带上注释3478行，表示很慌。","text":"jdk8的parallerStream的实现依赖这种线程池。这个类带上注释3478行，表示很慌。 前言设计这个线程池的原因不是为了取代ThreadPoolExecutor，ForkJoinPool 最适合的是计算密集型的任务，如果存在 I/O，线程间同步，sleep() 等会造成线程长时间阻塞的情况时，最好配合使用 ManagedBlocker。 使用例子核心思想就是拆分任务，这很快排的原理是一样的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889package com.htc.learning.main;import java.util.concurrent.ForkJoinPool;import java.util.concurrent.RecursiveAction;import java.util.concurrent.RecursiveTask;import java.util.stream.LongStream;public class ForkJoinPoolTest &#123; public static void main(String[] args) &#123; long[] numbers = LongStream.rangeClosed(1, 100).toArray(); fork(numbers); forkAndJoin(numbers); &#125; private static void fork(long[] numbers) &#123; ForkJoinPool pool = ForkJoinPool.commonPool(); pool.invoke(new PrintTask(0, numbers.length -1 , numbers)); &#125; private static void forkAndJoin(long[] numbers) &#123; ForkJoinPool pool = ForkJoinPool.commonPool(); long sum = pool.invoke(new SumTask(0, numbers.length - 1, numbers)); System.out.println(\"sum is :\" + sum); &#125;&#125;// 这是没有join结果的class PrintTask extends RecursiveAction &#123; // 小任务的打印量 private static final int THRESHOLD = 10; private int start; private int end; private long[] list; public PrintTask(int start, int end, long[] List) &#123; this.start = start; this.end = end; this.list = List; &#125; @Override protected void compute() &#123; if (end - start &lt; THRESHOLD) &#123; for (int i = start; i &lt;= end; i++) &#123; System.out.print(list[i] + \",\"); &#125; System.out.println(); &#125; else &#123; int middle = (start + end) / 2; PrintTask leftTask = new PrintTask(start, middle, list); PrintTask rightTask = new PrintTask(middle + 1, end, list); leftTask.fork(); rightTask.fork(); &#125; &#125;&#125;// 这是join结果的class SumTask extends RecursiveTask&lt;Long&gt; &#123; // 小任务的计算量 private static final int THRESHOLD = 10; private int start; private int end; private long[] list; public SumTask(int start, int end, long[] list) &#123; this.start = start; this.end = end; this.list = list; &#125; @Override protected Long compute() &#123; if (end - start &lt; THRESHOLD) &#123; long sum = 0; for (int i = start; i &lt;= end; i++) &#123; sum += list[i]; &#125; return sum; &#125; else &#123; int middle = (start + end) / 2; SumTask leftTask = new SumTask(start, middle, list); SumTask rightTask = new SumTask(middle + 1, end, list); leftTask.fork(); rightTask.fork(); return leftTask.join() + rightTask.join(); &#125; &#125;&#125; 运行结果 结果很乱，可以看出fork()是异步的，如果使用join()阻塞的话，可以将计算变为同步。 原理老李的论文 分治。这个从使用方式就可以看出来。 工作窃取（work-stealing）。 每个工作队列一个线程。 那么为什么需要使用工作窃取算法呢？假如我们需要做一个比较大的任务，我们可以把这个任务分割为若干互不依赖的子任务，为了减少线程间的竞争，于是把这些子任务分别放到不同的队列里，并为每个队列创建一个单独的线程来执行队列里的任务，线程和队列一一对应，比如A线程负责处理A队列里的任务。但是有的线程会先把自己队列里的任务干完，而其他线程对应的队列里还有任务等待处理。干完活的线程与其等着，不如去帮其他线程干活，于是它就去其他线程的队列里窃取一个任务来执行。而在这时它们会访问同一个队列，所以为了减少窃取任务线程和被窃取任务线程之间的竞争，通常会使用双端队列，被窃取任务线程永远从双端队列的头部拿任务执行，而窃取任务的线程永远从双端队列的尾部拿任务执行。 工作窃取算法的优点是充分利用线程进行并行计算，并减少了线程间的竞争，其缺点是在某些情况下还是存在竞争，比如双端队列里只有一个任务时。并且消耗了更多的系统资源，比如创建多个线程和多个双端队列。 据说ForkJoinPool在jdk7和jdk8的实现不一样。现在是jdk8的时代，我暂时不去看jdk7的实现啦。 ForkJoinPool 的每个工作线程都维护着一个工作队列（WorkQueue），这是一个双端队列（Deque），里面存放的对象是任务（ForkJoinTask）。 每个工作线程在运行中产生新的任务（通常是因为调用了 fork()）时，会放入工作队列的队尾，并且工作线程在处理自己的工作队列时，使用的是 LIFO 方式，也就是说每次从队尾取出任务来执行。 每个工作线程在处理自己的工作队列同时，会尝试窃取一个任务（或是来自于刚刚提交到 pool 的任务，或是来自于其他工作线程的工作队列），窃取的任务位于其他线程的工作队列的队首，也就是说工作线程在窃取其他工作线程的任务时，使用的是 FIFO 方式。 在遇到 join() 时，如果需要 join 的任务尚未完成，则会先处理其他任务，并等待其完成。（其实我不理解这句话，什么叫遇到join()时） 在既没有自己的任务，也没有可以窃取的任务时，进入休眠。 那么fork()每次调用都会创建一个线程吗，答案并不是，对于ForkJoinPool构造函数给出线程数就创建多少线程。那么join()也会阻塞吗，不一定，具体我们后面看源码实现。 概念 ForkJoinPool: 用于执行ForkJoinTask任务的执行池,不再是传统执行池 Worker+Queue 的组合模式,而是维护了一个队列数组WorkQueue,这样在提交任务和线程任务的时候大幅度的减少碰撞。] WorkQueue: 双向列表,用于任务的有序执行,如果WorkQueue用于自己的执行线程Thread,线程默认将会从top端选取任务用来执行 - LIFO。因为只有owner的Thread才能从top端取任务,所以在设置变量时, int top; 不需要使用 volatile。 ForkJoinWorkThread: 用于执行任务的线程,用于区别使用非ForkJoinWorkThread线程提交的task;启动一个该Thread,会自动注册一个WorkQueue到Pool,这里规定,拥有Thread的WorkQueue只能出现在WorkQueue数组的奇数位 ForkJoinTask: 任务, 它比传统的任务更加轻量，不再对是RUNNABLE的子类,提供fork/join方法用于分割任务以及聚合结果。 为了充分施展并行运算,该框架实现了复杂的 worker steal算法,当任务处于等待中,thread通过一定策略,不让自己挂起，充分利用资源，当然，它比其他语言的协程要重一些。 sun.misc.Contended打开ForkJoinPool，第一行就是这么个注解： 12@sun.misc.Contendedpublic class ForkJoinPool extends AbstractExecutorService &#123;...&#125; 度娘一下，看到了一个叫缓存行的东西，这个注解就是为了解决缓存行的伪共享False Sharing 缓存系统中是以缓存行（cache line）为单位存储的。缓存行是2的整数幂个连续字节，一般为32-256个字节。最常见的缓存行大小是64个字节。当多线程修改互相独立的变量时，如果这些变量共享同一个缓存行，就会无意中影响彼此的性能，这就是伪共享。缓存行上的写竞争是运行在SMP系统中并行线程实现可伸缩性最重要的限制因素。有人将伪共享描述成无声的性能杀手，因为从代码中很难看清楚是否会出现伪共享。 看图：在缓存行L3 Cache里有x，y，线程1想去修改x，线程2想去修改y，那么这行缓存行就会称谓竞争对象，竞争的过程就会产生性能的损耗。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class FalseSharing implements Runnable &#123; public final static int NUM_THREADS = 4; // change public final static long ITERATIONS = 500L * 1000L * 1000L; private final int arrayIndex; // 这里分别换成不同的类的数组，使用数组是为了内存连续 private static VolatileLong3[] longs = new VolatileLong3[NUM_THREADS]; static &#123; for (int i = 0; i &lt; longs.length; i++) &#123; longs[i] = new VolatileLong3(); &#125; &#125; public FalseSharing(final int arrayIndex) &#123; this.arrayIndex = arrayIndex; &#125; public static void main(final String[] args) throws Exception &#123; long start = System.nanoTime(); runTest(); System.out.println(\"duration = \" + (System.nanoTime() - start)); &#125; private static void runTest() throws InterruptedException &#123; Thread[] threads = new Thread[NUM_THREADS]; for (int i = 0; i &lt; threads.length; i++) &#123; threads[i] = new Thread(new FalseSharing(i)); &#125; for (Thread t : threads) &#123; t.start(); &#125; for (Thread t : threads) &#123; t.join(); &#125; &#125; public void run() &#123; long i = ITERATIONS + 1; while (0 != --i) &#123; longs[arrayIndex].value = i; &#125; &#125; public final static class VolatileLong &#123; public volatile long value = 0L; &#125; // long padding避免false sharing // 按理说jdk7以后long padding应该被优化掉了，但是从测试结果看padding仍然起作用 public final static class VolatileLong2 &#123; volatile long p0, p1, p2, p3, p4, p5, p6; public volatile long value = 0L; volatile long q0, q1, q2, q3, q4, q5, q6; &#125; // jdk8新特性，Contended注解避免false sharing // Restricted on user classpath // Unlock: -XX:-RestrictContended @sun.misc.Contended public final static class VolatileLong3 &#123; public volatile long value = 0L; &#125; &#125; 替换三种声明，测试结果如下 VolatileLong: duration = 31605817365 VolatileLong2:duration = 3725651254 VolatileLong3:duration = 3762335746VolatileLong2的原理：缓冲行有64字节，那么在属性value前面排列7个long，后面排列7个long，放到内存的时候，value无论如何都会和周围的long成员组成一个8个long，即64字节，从而避免缓存行的竞争。 而jdk8提供了@sun.misc.Contended注解后就不用写的这么麻烦了(也是填充了字节，具体看Java8使用@sun.misc.Contended避免伪共享)。 基本说明ForkJoinPoolForkJoinPool有超多的常量,下面是一部分 123456789101112131415161718192021222324252627282930313233343536373839404142434445/* * Bits and masks for field ctl, packed with 4 16 bit subfields: * AC: Number of active running workers minus target parallelism * TC: Number of total workers minus target parallelism * SS: version count and status of top waiting thread * ID: poolIndex of top of Treiber stack of waiters * * When convenient, we can extract the lower 32 stack top bits * (including version bits) as sp=(int)ctl. The offsets of counts * by the target parallelism and the positionings of fields makes * it possible to perform the most common checks via sign tests of * fields: When ac is negative, there are not enough active * workers, when tc is negative, there are not enough total * workers. When sp is non-zero, there are waiting workers. To * deal with possibly negative fields, we use casts in and out of * \"short\" and/or signed shifts to maintain signedness. * * Because it occupies uppermost bits, we can add one active count * using getAndAddLong of AC_UNIT, rather than CAS, when returning * from a blocked join. Other updates entail multiple subfields * and masking, requiring CAS. */ // Lower and upper word masksprivate static final long SP_MASK = 0xffffffffL;private static final long UC_MASK = ~SP_MASK;// Active countsprivate static final int AC_SHIFT = 48;private static final long AC_UNIT = 0x0001L &lt;&lt; AC_SHIFT;private static final long AC_MASK = 0xffffL &lt;&lt; AC_SHIFT;// Total countsprivate static final int TC_SHIFT = 32;private static final long TC_UNIT = 0x0001L &lt;&lt; TC_SHIFT;private static final long TC_MASK = 0xffffL &lt;&lt; TC_SHIFT;private static final long ADD_WORKER = 0x0001L &lt;&lt; (TC_SHIFT + 15); // sign// runState bits: SHUTDOWN must be negative, others arbitrary powers of twoprivate static final int RSLOCK = 1;private static final int RSIGNAL = 1 &lt;&lt; 1;private static final int STARTED = 1 &lt;&lt; 2;private static final int STOP = 1 &lt;&lt; 29;private static final int TERMINATED = 1 &lt;&lt; 30;private static final int SHUTDOWN = 1 &lt;&lt; 31; runstate：如果执行 runState &amp; RSLOCK ==0 就能直接说明,目前的运行状态没有被锁住,其他情况一样。 config：parallelism， mode。parallelism是构造函数的参数，表示并行等级，不等于工作队列的数量。需要注意一下它的界限，最大是0x7fff。 1static final int MAX_CAP = 0x7fff; // max #workers - 1 ctl：ctl是Pool的状态变量,类型是long - 说明有64位,每个部分都有不同的作用。我们使用十六进制来标识ctl，依次说明不同部分的作用。（这和普通线程池一样） 以下是构造函数，可以看到ctl的初始化，我们把ctl标识为4部分，0x xxxx-1 xxxx-2 xxxx-3 xxxx-4 1234567891011121314151617/** * Creates a &#123;@code ForkJoinPool&#125; with the given parameters, without * any security checks or parameter validation. Invoked directly by * makeCommonPool. */private ForkJoinPool(int parallelism, ForkJoinWorkerThreadFactory factory, UncaughtExceptionHandler handler, int mode, String workerNamePrefix) &#123; this.workerNamePrefix = workerNamePrefix; this.factory = factory; this.ueh = handler; this.config = (parallelism &amp; SMASK) | mode; long np = (long)(-parallelism); // offset ctl counts this.ctl = ((np &lt;&lt; AC_SHIFT) &amp; AC_MASK) | ((np &lt;&lt; TC_SHIFT) &amp; TC_MASK);&#125; 1号16位，表示AC(Active counts)并行数的负数。当ctl变成正数的时候表示线程数达到阈值了。(为什么不能用正数，然后负数的时候就表示达到阈值？？) 2号16位，表示TC(Total counts)并行数。Total counts等于挂起的线程数+AC，(也是用负数表示) 3号16位，表示SS，后32位标识idle workers 前面16位第一位标识是active的还是inactive的,其他为是版本标识。 4号16位，表示ID(Index)，标识idle workers在WorkQueue[]数组中的index。这里需要说明的是,ctl的后32位其实只能表示一个idle workers，那么我们如果有很多个idle worker要怎么办呢？老李使用的是stack的概念来保存这些信息。后32位标识的是栈顶的那个,我们能从栈顶中的变量stackPred追踪到下一个idle worker WorkQueueWorkQueue是一个双向列表,存放任务task。WorkQueue类也用了@sun.misc.Contended注解 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@sun.misc.Contended static final class WorkQueue &#123; /** * Capacity of work-stealing queue array upon initialization. * Must be a power of two; at least 4, but should be larger to * reduce or eliminate cacheline sharing among queues. * Currently, it is much larger, as a partial workaround for * the fact that JVMs often place arrays in locations that * share GC bookkeeping (especially cardmarks) such that * per-write accesses encounter serious memory contention. */ static final int INITIAL_QUEUE_CAPACITY = 1 &lt;&lt; 13; /** * Maximum size for queue arrays. Must be a power of two less * than or equal to 1 &lt;&lt; (31 - width of array entry) to ensure * lack of wraparound of index calculations, but defined to a * value a bit less than this to help users trap runaway * programs before saturating systems. */ static final int MAXIMUM_QUEUE_CAPACITY = 1 &lt;&lt; 26; // 64M // Instance fields volatile int scanState; // versioned, &lt;0: inactive; odd:scanning int stackPred; // pool stack (ctl) predecessor int nsteals; // number of steals int hint; // randomization and stealer index hint int config; // pool index and mode volatile int qlock; // 1: locked, &lt; 0: terminate; else 0 volatile int base; // index of next slot for poll int top; // index of next slot for push ForkJoinTask&lt;?&gt;[] array; // the elements (initially unallocated) final ForkJoinPool pool; // the containing pool (may be null) final ForkJoinWorkerThread owner; // owning thread or null if shared volatile Thread parker; // == owner during call to park; else null volatile ForkJoinTask&lt;?&gt; currentJoin; // task being joined in awaitJoin volatile ForkJoinTask&lt;?&gt; currentSteal; // mainly used by helpStealer WorkQueue(ForkJoinPool pool, ForkJoinWorkerThread owner) &#123; this.pool = pool; this.owner = owner; // Place indices in the center of array (that is not yet allocated) base = top = INITIAL_QUEUE_CAPACITY &gt;&gt;&gt; 1; &#125; ... &#125; static final int SCANNING = 1; // false when running tasks static final int INACTIVE = 1 &lt;&lt; 31; // must be negative scanState:负数表示inactive; 奇数表示scanning。如果WorkQueue没有属于自己的owner(下标为偶数的都没有),该值为 inactive 也就是一个负数。如果有自己的owner，该值的初始值为其在WorkQueue[]数组中的下标，也肯定是个奇数。如果这个值，变成了偶数，说明该队列所属的Thread正在执行TaskstackPred: 记录前任的 idle workerconfig：index | mode。 如果下标为偶数的WorkQueue,则其mode是共享类型。如果有自己的owner 默认是 LIFO。mode是由ForkJoinPool其中一个构造函数传进来的， 1234567891011121314151617181920212223242526272829303132333435/** * Creates a &#123;@code ForkJoinPool&#125; with the given parameters. * * @param parallelism the parallelism level. For default value, * use &#123;@link java.lang.Runtime#availableProcessors&#125;. * @param factory the factory for creating new threads. For default value, * use &#123;@link #defaultForkJoinWorkerThreadFactory&#125;. * @param handler the handler for internal worker threads that * terminate due to unrecoverable errors encountered while executing * tasks. For default value, use &#123;@code null&#125;. * @param asyncMode if true, * establishes local first-in-first-out scheduling mode for forked * tasks that are never joined. This mode may be more appropriate * than default locally stack-based mode in applications in which * worker threads only process event-style asynchronous tasks. * For default value, use &#123;@code false&#125;. * @throws IllegalArgumentException if parallelism less than or * equal to zero, or greater than implementation limit * @throws NullPointerException if the factory is null * @throws SecurityException if a security manager exists and * the caller is not permitted to modify threads * because it does not hold &#123;@link * java.lang.RuntimePermission&#125;&#123;@code (\"modifyThread\")&#125; */public ForkJoinPool(int parallelism, ForkJoinWorkerThreadFactory factory, UncaughtExceptionHandler handler, boolean asyncMode) &#123; this(checkParallelism(parallelism), checkFactory(factory), handler, asyncMode ? FIFO_QUEUE : LIFO_QUEUE, \"ForkJoinPool-\" + nextPoolId() + \"-worker-\"); checkPermission();&#125; 英文不太ok，看了注释应该是，asyncMode下工作线程在处理本地任务时也使用 FIFO 顺序。这种模式下的 ForkJoinPool 更接近于是一个消息队列，而不是用来处理递归式的任务。stackoverflow有个回答举了个例子，可以明显看到asyncMode的先进先出的执行方式。我想你的ForkJoinPool不是私有的，那就设置成异步模式吧。 qlock：队列锁base：worker steal的偏移量,因为其他的线程都可以偷该队列的任务,所有base使用volatile标识。top:owner执行任务的偏移量。parker:如果 owner 挂起，则使用该变量做记录currentJoin:当前正在join等待结果的任务。currentSteal:当前执行的任务是steal过来的任务，该变量做记录。 ForkJoinTask这是个抽象类,我们声明的任务是他的子类，下面是他的状态 12345678/** The run status of this task */volatile int status; // accessed directly by pool and workersstatic final int DONE_MASK = 0xf0000000; // mask out non-completion bitsstatic final int NORMAL = 0xf0000000; // must be negativestatic final int CANCELLED = 0xc0000000; // must be &lt; NORMALstatic final int EXCEPTIONAL = 0x80000000; // must be &lt; CANCELLEDstatic final int SIGNAL = 0x00010000; // must be &gt;= 1 &lt;&lt; 16static final int SMASK = 0x0000ffff; // short bits for tags 如果status &lt; 0，表示任务已经结束((s &gt;&gt;&gt; 16) != 0)表示需要signal其他线程 ForkJoinWorkerThread这就是工作线程的封装，继承自Thread类。 12345678910111213141516171819202122public class ForkJoinWorkerThread extends Thread &#123; /* * ForkJoinWorkerThreads are managed by ForkJoinPools and perform * ForkJoinTasks. For explanation, see the internal documentation * of class ForkJoinPool. * * This class just maintains links to its pool and WorkQueue. The * pool field is set immediately upon construction, but the * workQueue field is not set until a call to registerWorker * completes. This leads to a visibility race, that is tolerated * by requiring that the workQueue field is only accessed by the * owning thread. * * Support for (non-public) subclass InnocuousForkJoinWorkerThread * requires that we break quite a lot of encapsulation (via Unsafe) * both here and in the subclass to access and set Thread fields. */ final ForkJoinPool pool; // the pool this thread works in final ForkJoinPool.WorkQueue workQueue; // work-stealing mechanics ...&#125; 从代码中我们可以清楚地看到，ForkJoinWorkThread持有ForkJoinPool和ForkJoinPool.WorkQueue的引用，以表明该线程属于哪个线程池，它的工作队列是哪个 重场戏通用ForkJoinPool的初始化ForkJoinPool类的static代码块初始化了一个全局通用的ForkJoinPool，这是老李推荐的使用方式，不用自己new new new。 1234public static ForkJoinPool commonPool() &#123; // assert common != null : \"static init error\"; return common;&#125; 123456789101112131415161718192021222324252627282930313233343536373839/** * Creates and returns the common pool, respecting user settings * specified via system properties. */private static ForkJoinPool makeCommonPool() &#123; int parallelism = -1; ForkJoinWorkerThreadFactory factory = null; UncaughtExceptionHandler handler = null; try &#123; // ignore exceptions in accessing/parsing properties String pp = System.getProperty (\"java.util.concurrent.ForkJoinPool.common.parallelism\"); String fp = System.getProperty (\"java.util.concurrent.ForkJoinPool.common.threadFactory\"); String hp = System.getProperty (\"java.util.concurrent.ForkJoinPool.common.exceptionHandler\"); if (pp != null) parallelism = Integer.parseInt(pp); if (fp != null) factory = ((ForkJoinWorkerThreadFactory)ClassLoader. getSystemClassLoader().loadClass(fp).newInstance()); if (hp != null) handler = ((UncaughtExceptionHandler)ClassLoader. getSystemClassLoader().loadClass(hp).newInstance()); &#125; catch (Exception ignore) &#123; &#125; if (factory == null) &#123; if (System.getSecurityManager() == null) factory = defaultForkJoinWorkerThreadFactory; else // use security-managed default factory = new InnocuousForkJoinWorkerThreadFactory(); &#125; if (parallelism &lt; 0 &amp;&amp; // default 1 less than #cores (parallelism = Runtime.getRuntime().availableProcessors() - 1) &lt;= 0) parallelism = 1; if (parallelism &gt; MAX_CAP) parallelism = MAX_CAP; return new ForkJoinPool(parallelism, factory, handler, LIFO_QUEUE, \"ForkJoinPool.commonPool-worker-\");&#125; 有几个参数可以通过java -D指定，如果不指定，那么使用默认参数构造，并行数默认情况是计算机处理器数-1 任务提交我们提交的任务，不管是Runnable,Callable，ForkJoinTask，最终都会变成封装为ForkJoinTask。 由于实现了ExecutorService，自然实现了submit(task)、execute(task)方法，而他自己还又一个invoke(task)的方法，这么多个执行，什么时候用什么呢。 12345678910111213141516171819public void execute(ForkJoinTask&lt;?&gt; task) &#123; if (task == null) throw new NullPointerException(); externalPush(task);&#125;public &lt;T&gt; ForkJoinTask&lt;T&gt; submit(ForkJoinTask&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); externalPush(task); return task;&#125;public &lt;T&gt; T invoke(ForkJoinTask&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); externalPush(task); return task.join();&#125; 可以看到execute(task)和普通线程池一样无返回，submit(task)返回了一个ForkJoinTask,而invoke(task)返回直接调用join()阻塞，知道计算得出结果返回。 这几个都是调用externalPush(task);方法，和普通线程池一样，在提交任务的过程中会视情况增加工作线程，和普通线程池不一样的是还要同时增加工作队列。 注意：工作线程和工作队列的不是一对一关系 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * Tries to add the given task to a submission queue at * submitter's current queue. Only the (vastly) most common path * is directly handled in this method, while screening for need * for externalSubmit. * * @param task the task. Caller must ensure non-null. */final void externalPush(ForkJoinTask&lt;?&gt; task) &#123; WorkQueue[] ws; WorkQueue q; int m; // 取得一个随机探查数，可能为0也可能为其它数 // 利用这个数提交到任务队列数组中的随机一个队列 int r = ThreadLocalRandom.getProbe(); int rs = runState; // 他喵的这个if有够复杂 // SQMASK = 0x007e，也就是0000 0000 0111 1110，与这个数与出来的结果，只能是个偶数 // 如果（（任务队列数组非空）且（数组长度&gt;=1）且（数组长度-1与随机数与0x007e得出来的下标处有工作队列）且（随机数!=0）且（线程池在运行）且（获取锁成功）） if ((ws = workQueues) != null &amp;&amp; (m = (ws.length - 1)) &gt;= 0 &amp;&amp; (q = ws[m &amp; r &amp; SQMASK]) != null &amp;&amp; r != 0 &amp;&amp; rs &gt; 0 &amp;&amp; U.compareAndSwapInt(q, QLOCK, 0, 1)) &#123; ForkJoinTask&lt;?&gt;[] a; int am, n, s;// am=数组长度，n=top-base，s=top if ((a = q.array) != null &amp;&amp; // 感觉这个不为true的情况只能是==，不会&lt; (am = a.length - 1) &gt; (n = (s = q.top) - q.base)) &#123; // ABASE是利用Unsafe得到的队列base属性内存地址，因为用Unsafe加入队列，所以要计算出top的内存地址 int j = ((am &amp; s) &lt;&lt; ASHIFT) + ABASE; // 以下三个原子操作首先是将task放入队列, U.putOrderedObject(a, j, task); // 然后将“q”这个submission queue的top标记+1,记得queue的owner线程是默认从top拿的任务 U.putOrderedInt(q, QTOP, s + 1); // 解锁 U.putIntVolatile(q, QLOCK, 0); // 如果条件成立，说明这时处于active的工作线程可能还不够，调用signalWork方法 if (n &lt;= 1) signalWork(ws, q); return; &#125; // 可能上面没有解锁，保证能解锁。 // 这不会解锁了其他小偷吗 = = U.compareAndSwapInt(q, QLOCK, 1, 0); &#125; externalSubmit(task);&#125; 我注意到了这个方法ThreadLocalRandom.getProbe()，这是个一个包级别的方法，只有concurrent包才能用他。这个方法返回一个随机数，而且是固定的，但是如果没执行ThreadLocalRandom.localInit();，调用结果会是0。 把他的源码复制出来后执行得出来的结论。 也就是说，主线程执行externalPush的时候，由于ThreadLocalRandom.getProbe();返回一直0，是直接进入externalSubmit(task) 那坨if块主要做的是按线程给的随机数随机放入workqueue数组中队列，随机方式是m &amp; r &amp; SQMASK，(数组大小-1)与随机数与偶数掩码 入队的方式是放到随机队列的top位置，利用Unsafe来操作，真是🐂🍺，而队列owner拿的时候也是从top拿。 externalSubmit(task)的代码很长。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778private void externalSubmit(ForkJoinTask&lt;?&gt; task) &#123; int r; // initialize caller's probe if ((r = ThreadLocalRandom.getProbe()) == 0) &#123; ThreadLocalRandom.localInit(); r = ThreadLocalRandom.getProbe(); &#125; for (;;) &#123; WorkQueue[] ws; WorkQueue q; int rs, m, k; boolean move = false; if ((rs = runState) &lt; 0) &#123; tryTerminate(false, false); // help terminate throw new RejectedExecutionException(); &#125; // 如果条件成立，就说明当前ForkJoinPool类中，还没有任何队列，所以要进行队列初始化 else if ((rs &amp; STARTED) == 0 || // initialize ((ws = workQueues) == null || (m = ws.length - 1) &lt; 0)) &#123; int ns = 0; // 阻塞等待 rs = lockRunState(); try &#123; if ((rs &amp; STARTED) == 0) &#123; U.compareAndSwapObject(this, STEALCOUNTER, null, new AtomicLong()); // create workQueues array with size a power of two int p = config &amp; SMASK; // ensure at least 2 slots int n = (p &gt; 1) ? p - 1 : 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; n = (n + 1) &lt;&lt; 1; workQueues = new WorkQueue[n]; ns = STARTED; &#125; &#125; finally &#123; unlockRunState(rs, (rs &amp; ~RSLOCK) | ns); &#125; &#125; else if ((q = ws[k = r &amp; m &amp; SQMASK]) != null) &#123; if (q.qlock == 0 &amp;&amp; U.compareAndSwapInt(q, QLOCK, 0, 1)) &#123; ForkJoinTask&lt;?&gt;[] a = q.array; int s = q.top; boolean submitted = false; // initial submission or resizing try &#123; // locked version of push if ((a != null &amp;&amp; a.length &gt; s + 1 - q.base) || (a = q.growArray()) != null) &#123; int j = (((a.length - 1) &amp; s) &lt;&lt; ASHIFT) + ABASE; U.putOrderedObject(a, j, task); U.putOrderedInt(q, QTOP, s + 1); submitted = true; &#125; &#125; finally &#123; U.compareAndSwapInt(q, QLOCK, 1, 0); &#125; // 方法的唯一出口 if (submitted) &#123; signalWork(ws, q); return; &#125; &#125; move = true; // move on failure &#125; // 即上面的队列==null且runstate没有被锁住 else if (((rs = runState) &amp; RSLOCK) == 0) &#123; // create new queue q = new WorkQueue(this, null); q.hint = r; q.config = k | SHARED_QUEUE; q.scanState = INACTIVE; rs = lockRunState(); // publish index if (rs &gt; 0 &amp;&amp; (ws = workQueues) != null &amp;&amp; k &lt; ws.length &amp;&amp; ws[k] == null) ws[k] = q; // else terminated unlockRunState(rs, rs &amp; ~RSLOCK); &#125; else move = true; // move if busy if (move) // 重新获取一个随机数 r = ThreadLocalRandom.advanceProbe(r); &#125;&#125; 总结： 如果hash之后的队列已经存在 lock住队列,将数据塞到top位置。如果该队列任务很少(n &lt;= 1)也会调用signalWork 如果第一次提交(或者是hash之后的队列还未初始化),调用externalSubmit 第一遍循环: (runState不是开始状态): 1.lock; 2.创建数组WorkQueue[n]，这里的n是根据parallelism初始化的; 3. runState设置为开始状态。 第二遍循环:(根据ThreadLocalRandom.getProbe()hash后的数组中相应位置的WorkQueue未初始化): 初始化WorkQueue,通过这种方式创立的WorkQueue均是SUBMISSIONS_QUEUE(owner为null),scanState为INACTIVE 第三遍循环: 找到刚刚创建的WorkQueue,lock住队列,将数据塞到arraytop位置。如添加成功，就用调用接下来要摊开讲的重要的方法signalWork。 parallelism初始化关于parallelism，我们浓缩一下代码 123456789101112131415161718......// SMASK是一个常量，即 00000000 00000000 11111111 11111111static final int SMASK = 0xffff;......// 这是config的来源// mode是ForkJoinPool构造函数中设定的asyncMode，如果为LIFO，则mode为0，否则为1&lt;&lt;16(FIFO_QUEUE),也就是说，config中低16位代表并行度// parallelism 为技术人员设置的（或者程序自行设定的）并发等级this.config = (parallelism &amp; SMASK) | mode;......// ensure at least 2 slots// 取config的低16位int p = config &amp; SMASK; // n这个变量就是要计算的WorkQueue数组的大小int n = (p &gt; 1) ? p - 1 : 1;......n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4;n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; n = (n + 1) &lt;&lt; 1;...... 这么多位操作，在java.util.HashMap#tableSizeFor(本博客有)里也有出现过，tableSizeFor是为了计算出最接近且大于给定的构造容量的2幂数，而这里的位操作，比tableSizeFor多了一个n = (n + 1) &lt;&lt; 1;的计算，也就是计算出最接近且大于给定的构造容量的2幂数——然后在*2，ForkJoinPool中的这些WorkQueue和工作线程ForkJoinWorkerThread并不是一对一的关系，而是随时都有多余ForkJoinWorkerThread数量的WorkQueue元素。而这个ForkJoinPool中的WorkQueue数组中，索引位为非奇数的工作队列用于存储从外部提交到ForkJoinPool中的任务，也就是所谓的submissions queue；索引位为偶数的工作队列用于存储归并计算过程中等待处理的子任务，也就是task queue。 我们看signalWork(ws, q)做了什么，这个会触发构造新队列和新线程 12345678910111213141516171819202122232425262728293031323334/** * Tries to create or activate a worker if too few are active. * * @param ws the worker array to use to find signallees * @param q a WorkQueue --if non-null, don't retry if now empty */final void signalWork(WorkQueue[] ws, WorkQueue q) &#123; // c是ctl，sp是ctl低32位 long c; int sp, i; WorkQueue v; Thread p; while ((c = ctl) &lt; 0L) &#123; // too few active if ((sp = (int)c) == 0) &#123; // no idle workers if ((c &amp; ADD_WORKER) != 0L) // too few workers tryAddWorker(c); break; &#125; if (ws == null) // unstarted/terminated break; if (ws.length &lt;= (i = sp &amp; SMASK)) // terminated break; if ((v = ws[i]) == null) // terminating break; int vs = (sp + SS_SEQ) &amp; ~INACTIVE; // next scanState int d = sp - v.scanState; // screen CAS long nc = (UC_MASK &amp; (c + AC_UNIT)) | (SP_MASK &amp; v.stackPred); if (d == 0 &amp;&amp; U.compareAndSwapLong(this, CTL, c, nc)) &#123; v.scanState = vs; // activate v if ((p = v.parker) != null) U.unpark(p); break; &#125; if (q != null &amp;&amp; q.base == q.top) // no more work break; &#125;&#125; 这个方法主要就是一个while循环循环，当ctl小于0的时候才要进行创建和激活新线程。 如果sp等于0，表示没有空闲线程。此时(c &amp; ADD_WORKER) != 0L即TC符号位是1，TC是个负数，表示worker还可以增加。 12// ADD_WORKER是一个第48位为1，其余为0的64数，可以区分TC的符号位private static final long ADD_WORKER = 0x0001L &lt;&lt; (TC_SHIFT + 15); // sign 下面看tryAddWorker(c), 1234567891011121314151617181920private void tryAddWorker(long c) &#123; boolean add = false; do &#123; // new ctl long nc = ((AC_MASK &amp; (c + AC_UNIT)) | (TC_MASK &amp; (c + TC_UNIT))); if (ctl == c) &#123; int rs, stop; // check if terminating if ((stop = (rs = lockRunState()) &amp; STOP) == 0) add = U.compareAndSwapLong(this, CTL, c, nc); unlockRunState(rs, rs &amp; ~RSLOCK); if (stop != 0) break; if (add) &#123; createWorker(); break; &#125; &#125; &#125; while (((c = ctl) &amp; ADD_WORKER) != 0L &amp;&amp; (int)c == 0);&#125; 我们首先需要使用ctl来记录我们增加的线程, ctl编号-1的16位和编号-2的16位均需要加1,表示active的worker(AC)加一，总的worker(TC)加一。成功后我们将调用createWorker。 12345678910111213141516private boolean createWorker() &#123; ForkJoinWorkerThreadFactory fac = factory; Throwable ex = null; ForkJoinWorkerThread wt = null; try &#123; if (fac != null &amp;&amp; (wt = fac.newThread(this)) != null) &#123; wt.start(); return true; &#125; &#125; catch (Throwable rex) &#123; ex = rex; &#125; // 跑到这里来要注销线程 deregisterWorker(wt, ex); return false;&#125; 看fac.newThread(this)怎么实例化一个线程 123456static final class DefaultForkJoinWorkerThreadFactory implements ForkJoinWorkerThreadFactory &#123; public final ForkJoinWorkerThread newThread(ForkJoinPool pool) &#123; return new ForkJoinWorkerThread(pool); &#125;&#125; 123456protected ForkJoinWorkerThread(ForkJoinPool pool) &#123; // Use a placeholder until a useful name can be set in registerWorker super(\"aForkJoinWorkerThread\"); this.pool = pool; this.workQueue = pool.registerWorker(this);&#125; 看pool.registerWorker(this); 12345678910111213141516171819202122232425262728293031323334353637final WorkQueue registerWorker(ForkJoinWorkerThread wt) &#123; UncaughtExceptionHandler handler; wt.setDaemon(true); // configure thread if ((handler = ueh) != null) wt.setUncaughtExceptionHandler(handler); WorkQueue w = new WorkQueue(this, wt); int i = 0; // assign a pool index int mode = config &amp; MODE_MASK; int rs = lockRunState(); try &#123; WorkQueue[] ws; int n; // skip if no array if ((ws = workQueues) != null &amp;&amp; (n = ws.length) &gt; 0) &#123; int s = indexSeed += SEED_INCREMENT; // unlikely to collide int m = n - 1; i = ((s &lt;&lt; 1) | 1) &amp; m; // odd-numbered indices if (ws[i] != null) &#123; // collision int probes = 0; // step by approx half n int step = (n &lt;= 4) ? 2 : ((n &gt;&gt;&gt; 1) &amp; EVENMASK) + 2; while (ws[i = (i + step) &amp; m] != null) &#123; if (++probes &gt;= n) &#123; workQueues = ws = Arrays.copyOf(ws, n &lt;&lt;= 1); m = n - 1; probes = 0; &#125; &#125; &#125; w.hint = s; // use as random seed w.config = i | mode; w.scanState = i; // publication fence ws[i] = w; &#125; &#125; finally &#123; unlockRunState(rs, rs &amp; ~RSLOCK); &#125; wt.setName(workerNamePrefix.concat(Integer.toString(i &gt;&gt;&gt; 1))); return w;&#125; 我们使用ForkJoinWorkerThreadFactory来产生一个ForkJoinWorkerThread类型的线程，该线程将会把自己注册到Pool上,怎么注册的呢？实现在方法registerWorker,前文我们已经提及,拥有线程的WorkQueue只能出现在数组的奇数下标处。所以线程首先,创建一个新的WorkQueue，其次在数组WorkQueue[]寻找奇数下标尚未初始化的位置,如果循环的次数大于数组长度,还可能需要对数组进行扩容，然后，设置这个WorkQueue的 config 为 index | mode (下标和模式),scanState为 index (下标&gt;0)。最后启动这个线程。线程的处理我们接下来的章节介绍。 回到signalWork方法,如果(sp = (int)c) == 0不成立，表示又空闲线程，那么不用新增worker，直接唤醒工作队列的owner 我们上文说过SP的高16位SS,标记inactive和版本控制,我们将SS设置为激活状态并且版本加一。ID的16位我们之前也说过,放置了挂起线程栈的index所以我们可以根据这个index拿到WorkQueue——意味着就是这个WorkQueue的Owner线程被挂起了。 worker什么时候挂起？ 我们将要把栈顶挂起线程唤醒,意味着我们要讲下一个挂起的线程的信息记录到ctl上。前文也说在上一个挂起的线程的index信息在这个挂起的线程的stackPred。利用cas进行更新。 123456789int vs = (sp + SS_SEQ) &amp; ~INACTIVE; // next scanStateint d = sp - v.scanState; // screen CASlong nc = (UC_MASK &amp; (c + AC_UNIT)) | (SP_MASK &amp; v.stackPred);if (d == 0 &amp;&amp; U.compareAndSwapLong(this, CTL, c, nc)) &#123; v.scanState = vs; // activate v if ((p = v.parker) != null) U.unpark(p); break;&#125; 工作线程的运行Thread添加完成之后，执行wt.start();，这个方法会使得run()方法开始运行。 看ForkJoinWorkerThread的run()方法。 123456789101112131415161718192021public void run() &#123; if (workQueue.array == null) &#123; // only run once Throwable exception = null; try &#123; onStart(); // 看节里 pool.runWorker(workQueue); &#125; catch (Throwable ex) &#123; exception = ex; &#125; finally &#123; try &#123; onTermination(exception); &#125; catch (Throwable ex) &#123; if (exception == null) exception = ex; &#125; finally &#123; pool.deregisterWorker(this, exception); &#125; &#125; &#125;&#125; 123456789101112131415/** * Top-level runloop for workers, called by ForkJoinWorkerThread.run. */final void runWorker(WorkQueue w) &#123; w.growArray(); // allocate queue int seed = w.hint; // initially holds randomization hint int r = (seed == 0) ? 1 : seed; // avoid 0 for xorShift for (ForkJoinTask&lt;?&gt; t;;) &#123; if ((t = scan(w, r)) != null) w.runTask(t); else if (!awaitWork(w, r)) break; r ^= r &lt;&lt; 13; r ^= r &gt;&gt;&gt; 17; r ^= r &lt;&lt; 5; // xorshift 随机数算法 &#125;&#125; 工作线程先尝试scan窃取任务并执行，否则执行awaitWork()，如果awaitWork()返回false，break结束死循环。 scan又是一个长长的方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556private ForkJoinTask&lt;?&gt; scan(WorkQueue w, int r) &#123; WorkQueue[] ws; int m; if ((ws = workQueues) != null &amp;&amp; (m = ws.length - 1) &gt; 0 &amp;&amp; w != null) &#123; int ss = w.scanState; // initially non-negative for (int origin = r &amp; m, k = origin, oldSum = 0, checkSum = 0;;) &#123; WorkQueue q; ForkJoinTask&lt;?&gt;[] a; ForkJoinTask&lt;?&gt; t; int b, n; long c; if ((q = ws[k]) != null) &#123; if ((n = (b = q.base) - q.top) &lt; 0 &amp;&amp; (a = q.array) != null) &#123; // non-empty long i = (((a.length - 1) &amp; b) &lt;&lt; ASHIFT) + ABASE; if ((t = ((ForkJoinTask&lt;?&gt;) U.getObjectVolatile(a, i))) != null &amp;&amp; q.base == b) &#123; if (ss &gt;= 0) &#123; if (U.compareAndSwapObject(a, i, t, null)) &#123; q.base = b + 1; if (n &lt; -1) // signal others signalWork(ws, q); return t; &#125; &#125; else if (oldSum == 0 &amp;&amp; // try to activate w.scanState &lt; 0) tryRelease(c = ctl, ws[m &amp; (int)c], AC_UNIT); &#125; if (ss &lt; 0) // refresh ss = w.scanState; r ^= r &lt;&lt; 1; r ^= r &gt;&gt;&gt; 3; r ^= r &lt;&lt; 10; origin = k = r &amp; m; // move and rescan oldSum = checkSum = 0; continue; &#125; checkSum += b; &#125; if ((k = (k + 1) &amp; m) == origin) &#123; // continue until stable if ((ss &gt;= 0 || (ss == (ss = w.scanState))) &amp;&amp; oldSum == (oldSum = checkSum)) &#123; if (ss &lt; 0 || w.qlock &lt; 0) // already inactive break; int ns = ss | INACTIVE; // try to inactivate long nc = ((SP_MASK &amp; ns) | (UC_MASK &amp; ((c = ctl) - AC_UNIT))); w.stackPred = (int)c; // hold prev stack top U.putInt(w, QSCANSTATE, ns); if (U.compareAndSwapLong(this, CTL, c, nc)) ss = ns; else w.scanState = ss; // back out &#125; checkSum = 0; &#125; &#125; &#125; return null;&#125; 因为我们的WorkQueue是有owner线程的队列，我们可以知道以下信息: config = index | mode scanState = index &gt; 0我们首先通过随机数r来寻找窃取队列。 如果我们准备偷取的队列刚好有任务(也有可能是owner自己的那个队列)； 从队列的队尾即base位置取到任务返回 base + 1 如果我们遍历了一圈(((k = (k + 1) &amp; m) == origin))都没有偷到,我们就认为当前的active线程过剩了,我们准备将当前的线程(即owner)挂起,我们首先 index | INACTIVE 形成 ctl的后32位;并行将AC减一。其次，将原来的挂起的栈顶的index记录到stackPred中。 继续遍历如果仍然一无所获,将跳出循环；如果偷到了一个任务,我们将使用tryRelease激活。 runTask获取到任务之后，执行 12345678910111213141516final void runTask(ForkJoinTask&lt;?&gt; task) &#123; if (task != null) &#123; scanState &amp;= ~SCANNING; // mark as busy // 执行窃取来的任务 (currentSteal = task).doExec(); U.putOrderedObject(this, QCURRENTSTEAL, null); // release for GC // 这里执行自己的线程的任务 execLocalTasks(); ForkJoinWorkerThread thread = owner; if (++nsteals &lt; 0) // collect on overflow transferStealCount(pool); scanState |= SCANNING; if (thread != null) thread.afterTopLevelExec(); &#125;&#125; 首先scanState &amp;= ~SCANNING;标识该线程处于繁忙状态。 执行偷取的Task。 调用execLocalTasks对线程所属的WorkQueue内的任务进行执行,按config设置的mode进行FIFO或者LIFO执行。1234567891011121314151617181920final void execLocalTasks() &#123; int b = base, m, s; ForkJoinTask&lt;?&gt;[] a = array; if (b - (s = top - 1) &lt;= 0 &amp;&amp; a != null &amp;&amp; (m = a.length - 1) &gt;= 0) &#123; if ((config &amp; FIFO_QUEUE) == 0) &#123; for (ForkJoinTask&lt;?&gt; t;;) &#123; if ((t = (ForkJoinTask&lt;?&gt;)U.getAndSetObject (a, ((m &amp; s) &lt;&lt; ASHIFT) + ABASE, null)) == null) break; U.putOrderedInt(this, QTOP, s); t.doExec(); if (base - (s = top - 1) &gt; 0) break; &#125; &#125; else pollAndExecAll(); &#125;&#125; awaitWorkscan不到任务的时候，就执行挂起，如果挂起返回false，表示线程池终止。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152private boolean awaitWork(WorkQueue w, int r) &#123; if (w == null || w.qlock &lt; 0) // w is terminating return false; for (int pred = w.stackPred, spins = SPINS, ss;;) &#123; if ((ss = w.scanState) &gt;= 0) break; else if (spins &gt; 0) &#123; r ^= r &lt;&lt; 6; r ^= r &gt;&gt;&gt; 21; r ^= r &lt;&lt; 7; if (r &gt;= 0 &amp;&amp; --spins == 0) &#123; // randomize spins WorkQueue v; WorkQueue[] ws; int s, j; AtomicLong sc; if (pred != 0 &amp;&amp; (ws = workQueues) != null &amp;&amp; (j = pred &amp; SMASK) &lt; ws.length &amp;&amp; (v = ws[j]) != null &amp;&amp; // see if pred parking (v.parker == null || v.scanState &gt;= 0)) spins = SPINS; // continue spinning &#125; &#125; else if (w.qlock &lt; 0) // recheck after spins return false; else if (!Thread.interrupted()) &#123; long c, prevctl, parkTime, deadline; int ac = (int)((c = ctl) &gt;&gt; AC_SHIFT) + (config &amp; SMASK); if ((ac &lt;= 0 &amp;&amp; tryTerminate(false, false)) || (runState &amp; STOP) != 0) // pool terminating return false; if (ac &lt;= 0 &amp;&amp; ss == (int)c) &#123; // is last waiter prevctl = (UC_MASK &amp; (c + AC_UNIT)) | (SP_MASK &amp; pred); int t = (short)(c &gt;&gt;&gt; TC_SHIFT); // shrink excess spares if (t &gt; 2 &amp;&amp; U.compareAndSwapLong(this, CTL, c, prevctl)) return false; // else use timed wait parkTime = IDLE_TIMEOUT * ((t &gt;= 0) ? 1 : 1 - t); deadline = System.nanoTime() + parkTime - TIMEOUT_SLOP; &#125; else prevctl = parkTime = deadline = 0L; Thread wt = Thread.currentThread(); U.putObject(wt, PARKBLOCKER, this); // emulate LockSupport w.parker = wt; if (w.scanState &lt; 0 &amp;&amp; ctl == c) // recheck before park U.park(false, parkTime); U.putOrderedObject(w, QPARKER, null); U.putObject(wt, PARKBLOCKER, null); if (w.scanState &gt;= 0) break; if (parkTime != 0L &amp;&amp; ctl == c &amp;&amp; deadline - System.nanoTime() &lt;= 0L &amp;&amp; U.compareAndSwapLong(this, CTL, c, prevctl)) return false; // shrink pool &#125; &#125; return true;&#125; 如果ac还没到达阈值,但是TC&gt;2说明现在仍然运行中的线程和挂起的线程加一起处于过剩状态,我们将放弃该线程的挂起,直接让它执行结束，不再循环执行任务。 否则，我们计算一个挂起的时间，等到了时间之后(或者被外部唤醒),线程醒了之后,如果发现自己状态是active状态(w.scanState &gt;= 0),则线程继续回去scan任务，如果挂起时间结束，自己还是inactive状态,。线程也会执行结束，不再循环执行任务。 任务执行任务的执行是调用了task.doExec()方法，可以在runTask(task)方法看到 12345678910111213final int doExec() &#123; int s; boolean completed; if ((s = status) &gt;= 0) &#123; try &#123; completed = exec(); &#125; catch (Throwable rex) &#123; return setExceptionalCompletion(rex); &#125; if (completed) s = setCompletion(NORMAL); &#125; return s;&#125; 以RecursiveTask为例， 1234protected final boolean exec() &#123; result = compute(); return true;&#125; 最终调用了我们重写的compute()方法。 forkfork()像叉子把新任务提交， 12345678public final ForkJoinTask&lt;V&gt; fork() &#123; Thread t; if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) ((ForkJoinWorkerThread)t).workQueue.push(this); else ForkJoinPool.common.externalPush(this); return this;&#125; 如果当前线程是工作线程,直接push到自己所拥有的队列的top位置。 如果是非工作线程,就是一个提交到通用pool的过程。 joinjoin是等待任务完成 123456public final V join() &#123; int s; if ((s = doJoin() &amp; DONE_MASK) != NORMAL) reportException(s); return getRawResult();&#125; 如果得到的结果异常，则抛出异常； 如果得到的正常，则获取返回值。 看doJoin()， 123456789private int doJoin() &#123; int s; Thread t; ForkJoinWorkerThread wt; ForkJoinPool.WorkQueue w; return (s = status) &lt; 0 ? s : ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) (w = (wt = (ForkJoinWorkerThread)t).workQueue). tryUnpush(this) &amp;&amp; (s = doExec()) &lt; 0 ? s : wt.pool.awaitJoin(w, this, 0L) : externalAwaitDone();&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041/** * Helps and/or blocks until the given task is done or timeout. * * @param w caller * @param task the task * @param deadline for timed waits, if nonzero * @return task status on exit */final int awaitJoin(WorkQueue w, ForkJoinTask&lt;?&gt; task, long deadline) &#123; int s = 0; if (task != null &amp;&amp; w != null) &#123; ForkJoinTask&lt;?&gt; prevJoin = w.currentJoin; U.putOrderedObject(w, QCURRENTJOIN, task); // 这里好像是jdk8什么不得了的东西，晚点再看 CountedCompleter&lt;?&gt; cc = (task instanceof CountedCompleter) ? (CountedCompleter&lt;?&gt;)task : null; for (;;) &#123; if ((s = task.status) &lt; 0) break; if (cc != null) helpComplete(w, cc, 0); else if (w.base == w.top || w.tryRemoveAndExec(task)) helpStealer(w, task); if ((s = task.status) &lt; 0) break; long ms, ns; if (deadline == 0L) ms = 0L; else if ((ns = deadline - System.nanoTime()) &lt;= 0L) break; else if ((ms = TimeUnit.NANOSECONDS.toMillis(ns)) &lt;= 0L) ms = 1L; if (tryCompensate(w)) &#123; task.internalWait(ms); U.getAndAddLong(this, CTL, AC_UNIT); &#125; &#125; U.putOrderedObject(w, QCURRENTJOIN, prevJoin); &#125; return s;&#125; 如果是status&lt;0,表示完成，直接返回 如果是工作线程，尝试把task从top位置弹出，成功则执行task 如果该任务不在top位置,则调用awaitJoin方法： 设置currentJoin表明自己正在等待该任务； 如果发现 w.base == w.top(没任务) 或者 tryRemoveAndExec返回true说明自己所属的队列为空，也说明本线程的任务已经被别的线程偷走，该线程也不会闲着，将会helpStealer帮助帮助自己执行任务的线程执行任务(互惠互利,你来我往) 如果tryCompensate为 true,则阻塞本线程，等待任务执行结束的唤醒 如果不是工作线程在join，则阻塞直到任务执行完毕。 tryRemoveAndExec1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * If present, removes from queue and executes the given task, * or any other cancelled task. Used only by awaitJoin. * * @return true if queue empty and task not known to be done */final boolean tryRemoveAndExec(ForkJoinTask&lt;?&gt; task) &#123; ForkJoinTask&lt;?&gt;[] a; int m, s, b, n; if ((a = array) != null &amp;&amp; (m = a.length - 1) &gt;= 0 &amp;&amp; task != null) &#123; while ((n = (s = top) - (b = base)) &gt; 0) &#123; for (ForkJoinTask&lt;?&gt; t;;) &#123; // traverse from s to b long j = ((--s &amp; m) &lt;&lt; ASHIFT) + ABASE; if ((t = (ForkJoinTask&lt;?&gt;)U.getObject(a, j)) == null) return s + 1 == top; // shorter than expected else if (t == task) &#123; boolean removed = false; if (s + 1 == top) &#123; // pop if (U.compareAndSwapObject(a, j, task, null)) &#123; U.putOrderedInt(this, QTOP, s); removed = true; &#125; &#125; else if (base == b) // replace with proxy removed = U.compareAndSwapObject( a, j, task, new EmptyTask()); if (removed) task.doExec(); break; &#125; else if (t.status &lt; 0 &amp;&amp; s + 1 == top) &#123; if (U.compareAndSwapObject(a, j, t, null)) U.putOrderedInt(this, QTOP, s); break; // was cancelled &#125; if (--n == 0) return false; &#125; if (task.status &lt; 0) return false; &#125; &#125; return true;&#125; 如果刚好在top位置，pop出来执行。 如果在队列中间,则使用EmptyTask来占位,将任务取出来执行。 如果执行的任务还没结束。则返回false，外部不进行helpStealer。 helpStealer 遍历WorkQueue[]的奇数下标，WorkQueue的currentSteal如果是自己在找的任务，说明这个队列A是小偷 如果A有任务，则从队尾(base)取出执行 如果A没有任务，则根据A的owner线程正在join的任务,在拓扑找到相关的队列B去偷取任务执行。（代码好鸡儿复杂） 123456do &#123; U.putOrderedObject(w, QCURRENTSTEAL, t); t.doExec(); // clear local tasks too&#125; while (task.status &gt;= 0 &amp;&amp; // 小于0表示任务结束 w.top != top &amp;&amp; // top位置相同表示没fork新的子任务到自己queue上 (t = w.pop()) != null); // top位置不同，把子任务pop出来。 帮忙执行任务完成后，如果发现自己的队列有任务了(w.base != w.top)，在不再帮助执行任务了。 否则在等待自己的join的那个任务结束之前，可以不断的偷取任务执行。 tryCompensate如果自己等待的任务被偷走执行还没结束,自己的队列还有任务，我们需要做一些补偿 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * Tries to decrement active count (sometimes implicitly) and * possibly release or create a compensating worker in preparation * for blocking. Returns false (retryable by caller), on * contention, detected staleness, instability, or termination. * * @param w caller */private boolean tryCompensate(WorkQueue w) &#123; boolean canBlock; WorkQueue[] ws; long c; int m, pc, sp; if (w == null || w.qlock &lt; 0 || // caller terminating (ws = workQueues) == null || (m = ws.length - 1) &lt;= 0 || (pc = config &amp; SMASK) == 0) // parallelism disabled canBlock = false; else if ((sp = (int)(c = ctl)) != 0) // release idle worker canBlock = tryRelease(c, ws[sp &amp; m], 0L); else &#123; int ac = (int)(c &gt;&gt; AC_SHIFT) + pc; int tc = (short)(c &gt;&gt; TC_SHIFT) + pc; int nbusy = 0; // validate saturation for (int i = 0; i &lt;= m; ++i) &#123; // two passes of odd indices WorkQueue v; if ((v = ws[((i &lt;&lt; 1) | 1) &amp; m]) != null) &#123; if ((v.scanState &amp; SCANNING) != 0) break; ++nbusy; &#125; &#125; if (nbusy != (tc &lt;&lt; 1) || ctl != c) canBlock = false; // unstable or stale else if (tc &gt;= pc &amp;&amp; ac &gt; 1 &amp;&amp; w.isEmpty()) &#123; long nc = ((AC_MASK &amp; (c - AC_UNIT)) | (~AC_MASK &amp; c)); // uncompensated canBlock = U.compareAndSwapLong(this, CTL, c, nc); &#125; else if (tc &gt;= MAX_CAP || (this == common &amp;&amp; tc &gt;= pc + commonMaxSpares)) throw new RejectedExecutionException( \"Thread limit exceeded replacing blocked worker\"); else &#123; // similar to tryAddWorker boolean add = false; int rs; // CAS within lock long nc = ((AC_MASK &amp; c) | (TC_MASK &amp; (c + TC_UNIT))); if (((rs = lockRunState()) &amp; STOP) == 0) add = U.compareAndSwapLong(this, CTL, c, nc); unlockRunState(rs, rs &amp; ~RSLOCK); canBlock = add &amp;&amp; createWorker(); // throws on exception &#125; &#125; return canBlock;&#125; 如果 ((sp = (int)(c = ctl)) != 0) 说明还有 idle worker则可以选择唤醒线程替代自己,挂起自己等待任务来唤醒自己。 如果没有idle worker 则额外创建一个新的工作线程替代自己,挂起自己等待任务来唤醒自己。 后记很多没细看，了解一下思路就没了 = =","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}],"author":"土川"},{"title":"[Java基础]ScheduledThreadPoolExecutor","slug":"Java基础-ScheduledThreadPoolExecutor","date":"2018-09-02T02:56:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"967765342.html","link":"","permalink":"https://htchz.cc/967765342.html","excerpt":"提到定时任务，就会想到Quartz，事实上Quartz起到了调度的作用，真正的执行者还是JDK的ScheduledThreadPoolExecutor","text":"提到定时任务，就会想到Quartz，事实上Quartz起到了调度的作用，真正的执行者还是JDK的ScheduledThreadPoolExecutor Java提供的Time类可以周期性地或者延期执行任务，但是有时我们需要并行执行同样的任务，这个时候如果创建多个Time对象会给系统带来负担，解决办法是将定时任务放到线程池中执行。 Timer的任务挂了会让其他不想干的任务挂掉的。 ScheduledThreadPoolExecutor类实现了ScheduledExecutorService接口，继承了ThreadPoolExecutor，主要是利用延迟队列的特性来实现延迟执行。 ScheduledExecutorService12345678910111213141516171819public interface ScheduledExecutorService extends ExecutorService &#123; public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit); public &lt;V&gt; ScheduledFuture&lt;V&gt; schedule(Callable&lt;V&gt; callable, long delay, TimeUnit unit); public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit); public ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit);&#125; schedule方法需要提供一个延迟的时间，可以传入Runnable或者Callable，不同于ThreadPoolExecutor的execute(Runnable command)返回void，schedule(Runnable command,...)返回的是一个Future：ScheduledFuture。 scheduleAtFixedRate：周期性执行任务。 scheduleWithFixedDelay：以给定的延迟时间执行任务，一个任务执行完，等待delay时间再执行下一个 ScheduledThreadPoolExecutor事实上，ScheduledThreadPoolExecutor的构造方法都是如下调用了super(…) 1234567891011121314151617181920212223public ScheduledThreadPoolExecutor(int corePoolSize) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue());&#125;public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory);&#125;public ScheduledThreadPoolExecutor(int corePoolSize, RejectedExecutionHandler handler) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), handler);&#125;public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory, handler);&#125; 可以看到不能定制BlockingQueue，只能用内置的DelayedWorkQueue ScheduledFutureTask上一篇说到submit(Runnabel task)会将任务封装，这里同样是是封装，而且不论是Callable还是Runnable。 12345678910111213141516171819private class ScheduledFutureTask&lt;V&gt; extends FutureTask&lt;V&gt; implements RunnableScheduledFuture&lt;V&gt; &#123; // 任务序号 private final long sequenceNumber; // 任务执行的时间 private long time; // 0：不重复 // 正数，固定周期，即scheduleAtFixedRate // 负数，固定延迟，即scheduleWithFixedDelay private final long period; /** The actual task to be re-enqueued by reExecutePeriodic */ RunnableScheduledFuture&lt;V&gt; outerTask = this; // 这里看出任务队列的数据结构依旧是个堆，这个表示在任务队列的数组下标 int heapIndex; 构造方法 1234567891011121314151617181920212223242526272829/** * Creates a one-shot action with given nanoTime-based trigger time. */ScheduledFutureTask(Runnable r, V result, long ns) &#123; super(r, result); this.time = ns; this.period = 0; this.sequenceNumber = sequencer.getAndIncrement();&#125;/** * Creates a periodic action with given nano time and period. */ScheduledFutureTask(Runnable r, V result, long ns, long period) &#123; super(r, result); this.time = ns; this.period = period; this.sequenceNumber = sequencer.getAndIncrement();&#125;/** * Creates a one-shot action with given nanoTime-based trigger time. */ScheduledFutureTask(Callable&lt;V&gt; callable, long ns) &#123; super(callable); this.time = ns; this.period = 0; this.sequenceNumber = sequencer.getAndIncrement();&#125; 由于任务队列是个堆，入队的时候需要比较大小，看compareTo方法 12345678910111213141516171819public int compareTo(Delayed other) &#123; if (other == this) // compare zero if same object return 0; if (other instanceof ScheduledFutureTask) &#123; ScheduledFutureTask&lt;?&gt; x = (ScheduledFutureTask&lt;?&gt;)other; long diff = time - x.time; if (diff &lt; 0) return -1; else if (diff &gt; 0) return 1; // 如果执行时间相同，则按入队顺序 else if (sequenceNumber &lt; x.sequenceNumber) return -1; else return 1; &#125; long diff = getDelay(NANOSECONDS) - other.getDelay(NANOSECONDS); return (diff &lt; 0) ? -1 : (diff &gt; 0) ? 1 : 0; &#125; 任务队列任务队列使用的是WorkDelayQueue，和PriorityBlockingQueue的实现差不多，不过元素的大小比较只能用上一节内置的compareTo(Delayed other)方法。 除此之外，每次添加元素完成之后会在ScheduledFutureTask设置heapIndex 1234private void setIndex(RunnableScheduledFuture&lt;?&gt; f, int idx) &#123; if (f instanceof ScheduledFutureTask) ((ScheduledFutureTask)f).heapIndex = idx;&#125; 由于任务按已经按执行时间排好序，那么队首任务肯定是最迫切需要执行的任务。 ScheduledThreadPoolExecutor的延迟执行实际上是通过DelayWorkQueue的阻塞获取来实现的，这部分代码和前面DelayQueue的实现一毛一样，不作说明 123456789101112131415161718192021222324252627282930313233public RunnableScheduledFuture&lt;?&gt; take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; for (;;) &#123; RunnableScheduledFuture&lt;?&gt; first = queue[0]; if (first == null) available.await(); else &#123; long delay = first.getDelay(NANOSECONDS); if (delay &lt;= 0) return finishPoll(first); first = null; // don't retain ref while waiting if (leader != null) available.await(); else &#123; Thread thisThread = Thread.currentThread(); leader = thisThread; try &#123; available.awaitNanos(delay); &#125; finally &#123; if (leader == thisThread) leader = null; &#125; &#125; &#125; &#125; &#125; finally &#123; if (leader == null &amp;&amp; queue[0] != null) available.signal(); lock.unlock(); &#125;&#125; 提交任务submit()方法依旧是提供的，不过是以延迟时间为0的方式调用schedule方法。 123public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; return schedule(task, 0, NANOSECONDS);&#125; 看schedule方法。 12345678910111213141516171819202122232425262728293031/** * @throws RejectedExecutionException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; */public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit) &#123; if (command == null || unit == null) throw new NullPointerException(); RunnableScheduledFuture&lt;?&gt; t = decorateTask(command, new ScheduledFutureTask&lt;Void&gt;(command, null, triggerTime(delay, unit))); delayedExecute(t); return t;&#125;/** * @throws RejectedExecutionException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; */public &lt;V&gt; ScheduledFuture&lt;V&gt; schedule(Callable&lt;V&gt; callable, long delay, TimeUnit unit) &#123; if (callable == null || unit == null) throw new NullPointerException(); RunnableScheduledFuture&lt;V&gt; t = decorateTask(callable, new ScheduledFutureTask&lt;V&gt;(callable, triggerTime(delay, unit))); delayedExecute(t); return t;&#125; 两种实现大同小异，对于Runnable任务，实际上new ScheduledFutureTask&lt;Void&gt;(command, null,triggerTime(delay, unit)));封装成了一个返回null的Callable任务 12345678910111213ScheduledFutureTask(Runnable r, V result, long ns) &#123; // 父类构造 super(r, result); this.time = ns; this.period = 0; this.sequenceNumber = sequencer.getAndIncrement();&#125;// 上面的super构造函数public FutureTask(Runnable runnable, V result) &#123; this.callable = Executors.callable(runnable, result); this.state = NEW; // ensure visibility of callable&#125; 接下来看看delayedExecute(t)会根据执行时间添加进有序任务队列 12345678910111213141516171819202122private void delayedExecute(RunnableScheduledFuture&lt;?&gt; task) &#123; if (isShutdown()) reject(task); else &#123; super.getQueue().add(task); if (isShutdown() &amp;&amp; !canRunInCurrentRunState(task.isPeriodic()) &amp;&amp; remove(task)) task.cancel(false); else // 好像ScheduledThreadPoolExecutor其他地方没有addWorker的代码，这里addWorker部分 ensurePrestart(); &#125;&#125;void ensurePrestart() &#123; int wc = workerCountOf(ctl.get()); if (wc &lt; corePoolSize) addWorker(null, true); else if (wc == 0) addWorker(null, false);&#125; 任务运行123456789101112131415161718public boolean isPeriodic() &#123; return period != 0;&#125;public void run() &#123; // 是否周期性 boolean periodic = isPeriodic(); if (!canRunInCurrentRunState(periodic)) // 取消任务,唤醒所有`get()`调用，任务移出队列 cancel(false); else if (!periodic) ScheduledFutureTask.super.run(); // else if (ScheduledFutureTask.super.runAndReset()) &#123; setNextRunTime(); reExecutePeriodic(outerTask); &#125;&#125; 主流程分为三步： 判断当前task是否可以执行，如果不能执行，调用cancel方法取消task执行，否则，跳转到步骤2； 判断当前task是否周期性任务，是则调用父类普通执行该task，否则跳转到步骤3； 重置状态，计算任务下次执行时间，重新把任务添加到工作队列中，让该任务可重复执行 1234567891011boolean canRunInCurrentRunState(boolean periodic) &#123; // 下面两个长长的策略是可以通过set来修改的 return isRunningOrShutdown(periodic ? continueExistingPeriodicTasksAfterShutdown : executeExistingDelayedTasksAfterShutdown);&#125;final boolean isRunningOrShutdown(boolean shutdownOK) &#123; int rs = runStateOf(ctl.get()); return rs == RUNNING || (rs == SHUTDOWN &amp;&amp; shutdownOK);&#125; 上一篇没有说到runAndReset(),我们看一下代码 123456789101112131415161718192021222324252627282930protected boolean runAndReset() &#123; if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return false; boolean ran = false; int s = state; try &#123; Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; s == NEW) &#123; try &#123; c.call(); // don't set result ran = true; &#125; catch (Throwable ex) &#123; setException(ex); &#125; // 没有调用setResult(...) &#125; &#125; finally &#123; // runner must be non-null until state is settled to // prevent concurrent calls to run() runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); &#125; return ran &amp;&amp; s == NEW;&#125; run()方法是有setResult(…)的调用，更新FutureTask的state，runAndReset()没有调用，则正常完成的情况下是s == NEW。 还有一点，ran==false的情况下runAndReset()是返回失败的，所以出异常的话周期任务是不会继续执行的。 接下来我们专注于这一部分任务重复执行 1234else if (ScheduledFutureTask.super.runAndReset()) &#123; setNextRunTime(); reExecutePeriodic(outerTask); &#125; 1234567891011121314private void setNextRunTime() &#123; long p = period; // 大于0是fixRate if (p &gt; 0) time += p; // 小于0是fixDelay else time = triggerTime(-p);&#125;long triggerTime(long delay) &#123; return now() + ((delay &lt; (Long.MAX_VALUE &gt;&gt; 1)) ? delay : overflowFree(delay));&#125; 123456789void reExecutePeriodic(RunnableScheduledFuture&lt;?&gt; task) &#123; if (canRunInCurrentRunState(true)) &#123; super.getQueue().add(task); if (!canRunInCurrentRunState(true) &amp;&amp; remove(task)) task.cancel(false); else ensurePrestart(); &#125;&#125; 任务的串行现在有个问题，如果我的线程执行需要2s，而运行周期是是1s，线程数量设置5。那么第二次任务的执行时间是第一个任务开始后1s执行，还是等待第一个任务执行完再执行？ 看了上面的run()的实现后，可以看到reExecutePeriodic(...)是在第一次跑完之后，才执行，任务才重新加入队列中，所以上面的场景是：第二次任务需要等待第一次任务执行完，无论有多少空闲线程都无法保证任务1s周期运行。 写在最后Java好像常用的多线程编程工具都看完了，感觉用到大量的cas+自旋+挂起/唤醒+加锁/解锁。感觉为了做到线程安全Java付出性能代价挺大的。这方面是不是Go就稳的多了呢🧐Go的官方有定时任务包cron，暂时也不清楚是怎么实现的。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}],"author":"土川"},{"title":"[Java基础]ThreadPoolExecutor","slug":"Java基础-ThreadPoolExecutor","date":"2018-08-31T04:00:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"1860367337.html","link":"","permalink":"https://htchz.cc/1860367337.html","excerpt":"前面已经铺垫好，BOSS登场","text":"前面已经铺垫好，BOSS登场 线程池总览线程池的工作流程线程池的执行过程，图源，java的线程池是没有调度器的。 java线程池的继承体系java线程池相对前面几篇容易看得多，因为用了一堆现成的东西🙄 Executor接口：Executor接口中定义了一个execute方法，用来提交线程的执行。 ExecutorService：Executor接口的子接口，用来管理线程的执行，比如关闭线程池(shutdown)等。 ThreadPoolExecutor：大部分线程池的实现，通过不同的传入参数实现不同特性的线程池。 ScheduledExecutorService：延迟或周期性线程池接口，定义了延迟和周期执行接口 ScheduledThreadPoolExecutor：延迟或周期性线程池实现。 Executors：Java提供的一个专门用于创建线程池的工厂类，ExecutorService的初始化可以使用Executors类的静态方法。 shutdown只是将线程池的状态设置为SHUTWDOWN状态，正在执行的任务会继续执行下去，没有被执行的则中断。而shutdownNow则是将线程池的状态设置为STOP，正在执行的任务则被停止，没被执行任务的则返回。 ThreadPoolExecutor线程池的有许多初始化方式，最终落到这个构造函数: 123456789101112131415161718192021222324public ThreadPoolExecutor(int corePoolSize, // 核心线程数 int maximumPoolSize, // 最大线程数 long keepAliveTime, // 多余线程的活跃时间 TimeUnit unit, // 活跃时间单位 BlockingQueue&lt;Runnable&gt; workQueue, // 任务队列 ThreadFactory threadFactory, // 线程工厂 RejectedExecutionHandler handler) &#123; // 任务队列满了的执行策略 if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; 下面还有一个属性allowCoreThreadTimeOut，通过allowCoreThreadTimeOut(boolean)设置，表示核心工作线程是否要超时销毁，反正我是没设置过 - - 123456789public void allowCoreThreadTimeOut(boolean value) &#123; if (value &amp;&amp; keepAliveTime &lt;= 0) throw new IllegalArgumentException(\"Core threads must have nonzero keep alive times\"); if (value != allowCoreThreadTimeOut) &#123; allowCoreThreadTimeOut = value; if (value) interruptIdleWorkers(); &#125;&#125; 可以通过Executors类实例化不同的线程池： Executors.newCachedThreadPool Executors.newFixedThreadPool Executors.newWorkStealingPool Executors.newSingleThreadExecutor Executors.newScheduledThreadPool ThreadPoolExecutor的重要属性 corePoolSize：线程的核心数量 maximumPoolSize：当任务队列满的时候，提交新任务会创建新线程，这个值即最大线程数量，&gt;=核心线程数量 keepAliveTime：超过核心数量时，线程的最大空闲时间/ threadFactory：创建线程的工厂类，默认是默认为Executors.DefaultThreadFactory，定义了线程的名字 handler：满任务队列满线程数的情况下的拒绝策略，默认为AbortPolicy,抛一个运行时异常 ctl：ctl 是一个 AtomicInteger 类型, 它的 低29位 用于存放当前的线程数, 因此一个线程池在理论上最大的线程数是 536870911; 高 3 位是用于表示当前线程池的状态, 其中高三位的值和状态对应如下: 1234567891011// COUNT_BITS = 32 - 3// 可以接受新的任务，也可以处理阻塞队列里的任务private static final int RUNNING = -1 &lt;&lt; COUNT_BITS;// 不接受新的任务，但是可以处理阻塞队列里的任务private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;// 不接受新的任务，不处理阻塞队列里的任务，中断正在处理的任务private static final int STOP = 1 &lt;&lt; COUNT_BITS;// 过渡状态，也就是说所有的任务都执行完了，当前线程池已经没有有效的线程，这个时候线程池的状态将会TIDYING，并且将要调用terminated方法private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;// 终止状态。terminated方法调用完成以后的状态private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; 这些状态是按着大小排序的，线程的代码许多地方将状态进行大小比较，得出线程池的终止的程度。 其他属性，有些上面已经介绍了,主要有个独占锁mainLcok,终止条件变量termination,工作线程封装workers 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051 public class ThreadPoolExecutor extends AbstractExecutorService &#123; // 这个是一个复用字段, 它复用地表示了当前线程池的状态, 当前线程数信息. private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); // 用于存放提交到线程池中, 但是还未执行的那些任务. private final BlockingQueue&lt;Runnable&gt; workQueue; // 线程池内部锁, 对线程池内部操作加锁, 防止竞态条件 // 对 workers 字段的操作前, 需要获取到这个锁. private final ReentrantLock mainLock = new ReentrantLock(); // 一个 Set 结构, 包含了当前线程池中的所有工作线程. private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); // 条件变量, 用于支持 awaitTermination 操作 private final Condition termination = mainLock.newCondition(); // 记录线程池中曾经到达过的最大的线程数. // 这个字段在获取 mainLock 锁的前提下才能操作. private int largestPoolSize; // 记录已经完成的任务数. 仅仅当工作线程结束时才更新此字段. // 这个字段在获取 mainLock 锁的前提下才能操作. private long completedTaskCount; // 线程工厂. 当需要一个新的线程时, 这里生成. private volatile ThreadFactory threadFactory; // 任务提交失败后的处理 handler private volatile RejectedExecutionHandler handler; // 空闲线程的等待任务时间, 以纳秒为单位. // 当当前线程池中的线程数大于 corePoolSize 时, // 或者 allowCoreThreadTimeOut 为真时, 线程才有 idle 等待超时时间, // 如果超时则此线程会停止.; // 反之线程会一直等待新任务到来. private volatile long keepAliveTime; // 默认为 false. // 当为 false 时, keepAliveTime 不起作用, 线程池中的 core 线程会一直存活, // 即使这些线程是 idle 状态. // 当为 true 时, core 线程使用 keepAliveTime 作为 idle 超时 // 时间来等待新的任务. private volatile boolean allowCoreThreadTimeOut; // 核心线程数. private volatile int corePoolSize; // 最大线程数. private volatile int maximumPoolSize;&#125; 提交任务这个方法就是提交任务的主流程了，分为三步 线程数小于corePoolSize，尝试添加Worker并提交任务到任务到worker,true表示核心线程 任务入队成功，二次校验线程池运行状态，是否需要拒绝任务或者增加worker 增加工作线程，false表示超核心数量的线程 12345678910111213141516171819202122232425public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); // step 1 // workerCountOf(c)取低29位 if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; // step 2 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); // 如果不在运行状态且任务未被消费，remove(command)==true，则拒绝任务 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; // step 3 else if (!addWorker(command, false)) reject(command);&#125; 看addWorker(command, true)前，看Worker类，是对线程的封装,实现了Runnable，继承了AQS，所有有锁的能力。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263 private final class Worker extends AbstractQueuedSynchronizer implements Runnable &#123; private static final long serialVersionUID = 6138294804551838833L; // 线程引用 final Thread thread; // 创建线程时带的任务 Runnable firstTask; /** Per-thread task counter */ volatile long completedTasks;// 构造方法 Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); &#125; /** Delegates main run loop to outer runWorker */ public void run() &#123; runWorker(this); &#125; // Lock methods // // The value 0 represents the unlocked state. // The value 1 represents the locked state.// 非0表示该工作线程被占有 protected boolean isHeldExclusively() &#123; return getState() != 0; &#125; protected boolean tryAcquire(int unused) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; protected boolean tryRelease(int unused) &#123; setExclusiveOwnerThread(null); setState(0); return true; &#125; public void lock() &#123; acquire(1); &#125; public boolean tryLock() &#123; return tryAcquire(1); &#125; public void unlock() &#123; release(1); &#125; public boolean isLocked() &#123; return isHeldExclusively(); &#125; void interruptIfStarted() &#123; Thread t; if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; &#125; &#125; &#125; 运行任务可以看到newThread(this)方法是传入自身，我们看他的run()方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public void run() &#123; runWorker(this);&#125;final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); // 取出第一个任务 Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; 这里就是线程不断拿任务的原理，通过一个while实现 while (task != null || (task = getTask()) != null) &#123; w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt // 一些中断的判断，lock()调用了AQS的acquire()方法，中断是不会释放锁的 if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; // 好吧，默认实现这里是空的，如果要自己定义线程池可以 beforeExecute(wt, task); Throwable thrown = null; try &#123; // 跑task啦 task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; // 依旧空实现 afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125; 没任务可以拿的时候，工作线程就会跳出while从而终止了，所以没任务的时候想保持线程不被销毁，就得在getTask()阻塞，具体后面小节会讲。 当任务拿完的时候，线程会执行processWorkerExit(w, completedAbruptly) 123456789101112131415161718192021222324252627282930private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; // 非正常结束（抛异常了），那么要减去线程数量补救一下 if (completedAbruptly) // If abrupt, then workerCount wasn't adjusted decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; completedTaskCount += w.completedTasks; workers.remove(w); &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate(); // 清除线程后的检查 int c = ctl.get(); if (runStateLessThan(c, STOP)) &#123; if (!completedAbruptly) &#123; int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; if (workerCountOf(c) &gt;= min) return; // replacement not needed &#125; // 如果是意外中断，且核心工作线程不够，要补回worker addWorker(null, false); &#125;&#125; 这个方法一开始会判断是否正常终止，非正常终止会执行decrementWorkerCount()来减少工作线程数量。 那正常终止呢怎么减数量呢，runWorker没写，这一步骤也放到getTask()里去执行了 工作线程结束后，看是否需要终止线程池，tryTerminate() 123456789101112131415161718192021222324252627282930313233 final void tryTerminate() &#123; for (;;) &#123; int c = ctl.get(); // 如果在运行，或者已经在终止中（TIDYING），或者刚发起终止指令（SHUTDOWN）但是任务队列还没完（isEmpty），那么不需要执行终止线程池。 if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty())) return; if (workerCountOf(c) != 0) &#123; // Eligible to terminate // 线程池SHUTFDOWN，任务对列已空，中断所有工作线程 interruptIdleWorkers(ONLY_ONE); return; &#125; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // cas设置终止中 if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) &#123; try &#123; terminated(); &#125; finally &#123; ctl.set(ctlOf(TERMINATED, 0)); termination.signalAll(); &#125; return; &#125; &#125; finally &#123; mainLock.unlock(); &#125; // cas失败，继续下一轮吧 &#125;&#125; tryTerminate()返回之后，主流程检查线程池的状态，看需要不需要补回销毁的工作线程。 以上是工作线程的运行过程。 添加工作线程下面是添加addWorker的部分 retry:是标签(Label)语法，可以执行多层循环的break和continue 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); // 获取线程池运行状态 int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; // 通过控制数量来防止并发 if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl // 如果运行状态不一致了，重新执行外层的运行状态校验 if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); // rs &lt; SHUTDOWN 即 rs = RUNNING if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); // 更新最大记录 if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; // 如果成功创建并添加到工作线程集合里，线程开始跑 t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; // 善后工作 if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125; 返回工作线程是否启动，否的情况下，外部调用会执行拒绝策略，默认抛异常。 工作线程的 idle 超时处理在运行任务的小节，有个getTask()方法，如果拿不到任务，那工作线程就得结束了，所以我们看看getTask()的策略是什么。 工作线程的 idle 超出处理在底层依赖于 BlockingQueue 带超时的 poll 方法, 即工作线程会不断地从 workQueue 这个 BlockingQueue 中获取任务, 如果 allowCoreThreadTimeOut 字段为 true, 或者当前的工作线程数大于 corePoolSize, 那么线程的 idle 超时机制就生效了, 此时工作线程会以带超时的 poll 方式从 workQueue 中获取任务. 当超时了还没有获取到任务, 那么我们就知道此线程一个到达 idle 超时时间, 因此终止此工作线程. 12345678910111213141516171819202122232425262728293031323334353637private Runnable getTask() &#123; boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // Are workers subject to culling? boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); // 阻塞 if (r != null) return r; timedOut = true; &#125; catch (InterruptedException retry) &#123; timedOut = false; &#125; &#125;&#125; Future Future 可以拿到线程池任务的运行结果，是对任务的封装， 任务必需是Callable类型的任务123456789public interface Callable&lt;V&gt; &#123; /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception;&#125; 123456789101112131415public interface Future&lt;V&gt; &#123; // mayInterruptIfRunning 任务在worker跑的时候是否能被取消 boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); // 阻塞直到拿到运行结果 V get() throws InterruptedException, ExecutionException; // 带超时的get(0 V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; ThreadPoolExecutor通过父类AbstractExecutorService的submit(Runnable task)方法， 123456public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask;&#125; 123456public FutureTask(Callable&lt;V&gt; callable) &#123; if (callable == null) throw new NullPointerException(); this.callable = callable; this.state = NEW; // ensure visibility of callable&#125; 可以看到Future的原理是用一个FutureTask(我们这篇就只看这个类)类对任务进行封装，下面是 FutureTask的几个状态和一些属性，从字面上可以看出各个状态代表的意思，这几个状态和线程池的状态一样是大小不是随便定的 12345678910111213141516171819202122/** * Possible state transitions: * NEW -&gt; COMPLETING -&gt; NORMAL * NEW -&gt; COMPLETING -&gt; EXCEPTIONAL * NEW -&gt; CANCELLED * NEW -&gt; INTERRUPTING -&gt; INTERRUPTED */ private volatile int state; private static final int NEW = 0; private static final int COMPLETING = 1; private static final int NORMAL = 2; private static final int EXCEPTIONAL = 3; private static final int CANCELLED = 4; private static final int INTERRUPTING = 5; private static final int INTERRUPTED = 6; // 运行这个run的线程，即线程池的工作线程 private volatile Thread runner; // 调用了get()的等待线程，是个链表 private volatile WaitNode waiters; 运行任务当线程池的工作线程的运行任务的run()的的时候，FutureTask就会调用任务的call()，并将存储运行结果。 我们看FutureTask的run()方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public void run() &#123; // 没有人终止任务，state依旧是NEW，则cas设置工作线程，失败则直接结束 if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return; try &#123; Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; state == NEW) &#123; V result; boolean ran; try &#123; result = c.call(); ran = true; &#125; catch (Throwable ex) &#123; result = null; ran = false; // 异常完成的处理方式 setException(ex); &#125; if (ran) // 正常完成，更新状态，唤醒所有等待的线程 set(result); &#125; &#125; finally &#123; // runner must be non-null until state is settled to // prevent concurrent calls to run() runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts int s = state; // 如果任务被取消，调用Thread.yield();直到善后工作做完，状态变成INTERRUPTED if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); &#125;&#125;// protected void set(V v) &#123; if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123; outcome = v; UNSAFE.putOrderedInt(this, stateOffset, NORMAL); // final state // 更新状态，唤醒所有等待的线程 finishCompletion(); &#125;&#125; 任务完成任务完成的方法，只有四种：正常、异常、取消、中断工作线程，每种分别调用set(result),setException(ex),cancel(boolean)，其中取消和中断都是调用cancel(boolean)，通过参数控制，这几种方法都会调用finishCompletion(),逐一唤醒挂起的线程（比如上面set(V v)的调用） 1234567891011121314151617181920212223242526private void finishCompletion() &#123; // assert state &gt; COMPLETING; for (WaitNode q; (q = waiters) != null;) &#123; // 将整个waiters链表引用置为null，方便gc if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) &#123; // 一一唤醒 for (;;) &#123; Thread t = q.thread; if (t != null) &#123; q.thread = null; LockSupport.unpark(t); &#125; WaitNode next = q.next; if (next == null) break; q.next = null; // unlink to help gc q = next; &#125; break; &#125; &#125; // 预留给子类的空函数 done(); callable = null; // to reduce footprint&#125; 获取结果挺容易理解的代码，接下来看get() 1234567public V get() throws InterruptedException, ExecutionException &#123; int s = state; if (s &lt;= COMPLETING) // 0L是无超时时间 s = awaitDone(false, 0L); return report(s);&#125; 如果get()调用的时候s &lt;= COMPLETING,即未终止或者未完成，则调用awaitDone(false, 0L)， 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374// 链表，因为get()可以被多个线程调用，所以维护一个链表来存储这些线程。任务完成的时候（无论意外还是正常）会调用`finishCompletion()`唤醒所有还在挂起的线程// 这是一个新节点插在头部的链表static final class WaitNode &#123; volatile Thread thread; volatile WaitNode next; WaitNode() &#123; thread = Thread.currentThread(); &#125;&#125;// 将线程从列表private void removeWaiter(WaitNode node) &#123; // node == null 什么都不做 if (node != null) &#123; node.thread = null; retry: for (;;) &#123; // restart on removeWaiter race for (WaitNode pred = null, q = waiters, s; q != null; q = s) &#123; s = q.next; if (q.thread != null) pred = q; else if (pred != null) &#123; pred.next = s; if (pred.thread == null) // check for race continue retry; &#125; else if (!UNSAFE.compareAndSwapObject(this, waitersOffset, q, s)) continue retry; &#125; break; &#125; &#125;&#125;private int awaitDone(boolean timed, long nanos) throws InterruptedException &#123; final long deadline = timed ? System.nanoTime() + nanos : 0L; WaitNode q = null; boolean queued = false; for (;;) &#123; // 如果线程被中断 if (Thread.interrupted()) &#123; removeWaiter(q); throw new InterruptedException(); &#125; int s = state; if (s &gt; COMPLETING) &#123; if (q != null) q.thread = null; return s; &#125; else if (s == COMPLETING) // cannot time out yet Thread.yield(); else if (q == null) q = new WaitNode(); else if (!queued) // 很花哨地把新地阻塞线程节点放到链表头 queued = UNSAFE.compareAndSwapObject(this, waitersOffset, q.next = waiters, q); // 设置了超时的挂起方式 else if (timed) &#123; nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) &#123; removeWaiter(q); return state; &#125; // 定时挂起 LockSupport.parkNanos(this, nanos); &#125; else // 无限挂起，直到完成唤醒 LockSupport.park(this); &#125;&#125;","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}],"author":"土川"},{"title":"[Java基础]BlockingQueue","slug":"Java基础-BlockingQueue","date":"2018-08-28T12:54:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"3516892559.html","link":"","permalink":"https://htchz.cc/3516892559.html","excerpt":"java的BlockingQueue解读","text":"java的BlockingQueue解读 Java的BlockingQueue有以下 ArrayBlockingQueue LinkedBlockingQueue SynchronousQueue PriorityBlockingQueue DelayQueue 对于 BlockingQueue，我们的关注点应该在 put(e) 和 take() 这两个方法，因为这两个方法是带阻塞的。 ArrayBlockingQueue1234567891011121314151617181920212223242526/** The queued items */final Object[] items;/** items index for next take, poll, peek or remove */int takeIndex;/** items index for next put, offer, or add */int putIndex;/** Number of elements in the queue */int count;/* * Concurrency control uses the classic two-condition algorithm * found in any textbook. *//** Main lock guarding all access */// 只有一个锁final ReentrantLock lock;/** Condition for waiting takes */private final Condition notEmpty;/** Condition for waiting puts */private final Condition notFull; 上一节讲过实现，先略过。 注意： 这是一个循环数组，putIndex、takeIndex在等于items.length的时候会重置为0 用的悲观锁，take()和put()不能并行执行。 LinkedBlockingQueue12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * Linked list node class */static class Node&lt;E&gt; &#123; E item; /** * One of: * - the real successor Node * - this Node, meaning the successor is head.next * - null, meaning there is no successor (this is the last node) */ Node&lt;E&gt; next; Node(E x) &#123; item = x; &#125;&#125;/** The capacity bound, or Integer.MAX_VALUE if none */private final int capacity;/** Current number of elements */private final AtomicInteger count = new AtomicInteger();/** * Head of linked list. * Invariant: head.item == null */transient Node&lt;E&gt; head;/** * Tail of linked list. * Invariant: last.next == null */private transient Node&lt;E&gt; last;/** Lock held by take, poll, etc */private final ReentrantLock takeLock = new ReentrantLock();/** Wait queue for waiting takes */private final Condition notEmpty = takeLock.newCondition();/** Lock held by put, offer, etc */private final ReentrantLock putLock = new ReentrantLock();/** Wait queue for waiting puts */private final Condition notFull = putLock.newCondition(); 可以有界可以无界（无界其实容量为Integer.MAX_VALUE），依旧略过。 注意： 用了分离的两个独占锁，put()和take()可并行执行 想不通为什么ArrayBlockingQueue不使用分离的锁，这里说是因为Queue接口继承了Collection接口，所以循环数组迭代在双锁下迭代比较复杂 = = ArrayBlockingQueue和LinkedBlockingQueue对比 ArrayBlockingQueue占用内存小，但是不能并行生产消费，需要确定好队列容量 LinkedBlockingQueue占用内存大，但是可以并行生产消费，可以不指定队列容量 SynchronousQueue这个同步队列，当一个线程往队列中写入一个元素时，写入操作不会立即返回，需要等待另一个线程来将这个元素拿走；同理，当一个读线程做读操作的时候，同样需要一个相匹配的写线程的写操作。这里的 Synchronous 指的就是读线程和写线程需要同步，一个读线程匹配一个写线程。 这让我想到go不带缓冲的channel也有这种特点 SynchronousQueue不提供任何空间来存储元素（它存在一个node元素里），peek()返回的是null，和其他并发容器一样不允许插入null。 1234567// 指定公平模式还是非公平模式public SynchronousQueue(boolean fair) &#123; transferer = fair ? new TransferQueue() : new TransferStack();&#125;abstract static class Transferer &#123; abstract Object transfer(Object e, boolean timed, long nanos);&#125; 这里面需要说明一下的是，这个方法会根据参数e来区分调用方法的是一个生产者线程还是一个消费者线程，如果e为null，则说明这是一个消费者线程，比如一个take操作，如果e不为null，那么就是一个生产者线程，这个数据就是这个线程需要交付的数据，比如一个put操作。SynchronousQueue有两个版本的Transferer实现，一种为公平交易类型，一种为非公平交易类型，公平交易类型的实现类为TransferQueue，它使用队列来作为交易媒介，请求交易的线程总是先尝试跟队列头部（或者尾部）的线程进行交易，如果失败再将请求的线程添加到队列尾部，而非公平类型的实现类为TransferStack，它使用一个stack来作为交易媒介，请求交易的线程总是试图与栈顶线程进行交易，失败则添加到栈顶。所以SynchronousQueue就是使用队列和栈两种数据结构来模拟公平交易和非公平交易的。下面分别对两种交易类型进行分析。 看put()和take() 12345678910111213141516// 写入值public void put(E o) throws InterruptedException &#123; if (o == null) throw new NullPointerException(); if (transferer.transfer(o, false, 0) == null) &#123; // 1 Thread.interrupted(); throw new InterruptedException(); &#125;&#125;// 读取值并移除public E take() throws InterruptedException &#123; Object e = transferer.transfer(null, false, 0); // 2 if (e != null) return (E)e; Thread.interrupted(); throw new InterruptedException();&#125; 公平模式可以看到用的是同一个方法，根据null或非空object来判断出队或者入队。 我们看看他的等待队列的实现方式，这里是等待队列的数据结构，还带有一些CAS方法 12345678910111213/** Node class for TransferQueue. */static final class QNode &#123; volatile QNode next; // 单链表 volatile Object item; // CAS'ed to or from null volatile Thread waiter; // 挂起、唤起线程 final boolean isData; QNode(Object item, boolean isData) &#123; this.item = item; this.isData = isData; &#125; ... &#125; 关于这个item，这是一个用来匹配的关键字，称作match 当tryCancel(e)，被调用时，它被cas成节点本身 当消费者进入transfer出队时，被出队的节点的item被cas成null 当生产者进入transfer入队时，被入队的节点的item被cas成E（生产元素） 通常原来的cas前的值会被保存起来，返回到方法调用上层以供判断当前处于什么情况。 接下来看transfer方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495 E transfer(E e, boolean timed, long nanos) &#123; /* Basic algorithm is to loop trying to take either of * two actions: * * 1. If queue apparently empty or holding same-mode nodes, * try to add node to queue of waiters, wait to be * fulfilled (or cancelled) and return matching item. * * 2. If queue apparently contains waiting items, and this * call is of complementary mode, try to fulfill by CAS'ing * item field of waiting node and dequeuing it, and then * returning matching item. * * In each case, along the way, check for and try to help * advance head and tail on behalf of other stalled/slow * threads. * * The loop starts off with a null check guarding against * seeing uninitialized head or tail values. This never * happens in current SynchronousQueue, but could if * callers held non-volatile/final ref to the * transferer. The check is here anyway because it places * null checks at top of loop, which is usually faster * than having them implicitly interspersed. */// 索引要插入的节点 QNode s = null; // constructed/reused as needed // 是否写入 boolean isData = (e != null); for (;;) &#123; QNode t = tail; QNode h = head; if (t == null || h == null) // saw uninitialized value continue; // spin // 空或者已有node和新的node模式一致，则插入 if (h == t || t.isData == isData) &#123; QNode tn = t.next; // 脏读，已经不是队尾 if (t != tail) continue; // 队尾的next指针已经并发被设置，提前将新元素置为队尾，继续自旋 if (tn != null) &#123; advanceTail(t, tn); continue; &#125; // 超时 if (timed &amp;&amp; nanos &lt;= 0) return null; // 初始新来的小老弟 if (s == null) s = new QNode(e, isData); // cas将新来的小老弟放到队尾next指针 if (!t.casNext(null, s)) continue; // 提前将队尾置为小老弟 advanceTail(t, s); // 阻塞至有人匹配，返回匹配的节点 Object x = awaitFulfill(s, e, timed, nanos); // wait was cancelled if (x == s) &#123; clean(t, s); return null; &#125; if (!s.isOffList()) &#123; // not already unlinked advanceHead(t, s); // unlink if head if (x != null) // and forget fields s.item = s; s.waiter = null; &#125; return (x != null) ? (E)x : e; // 下面的看英文注释好了 &#125; else &#123; // complementary-mode QNode m = h.next; // node to fulfill if (t != tail || m == null || h != head)x continue; // inconsistent read Object x = m.item; if (isData == (x != null) || // m already fulfilled x == m || // m cancelled // 这一步是会执行的 !m.casItem(x, e)) &#123; // lost CAS advanceHead(h, m); // dequeue and retry continue; &#125; advanceHead(h, m); // successfully fulfilled LockSupport.unpark(m.waiter); return (x != null) ? (E)x : e; &#125; &#125; &#125; 123456789101112// 提前置为队尾void advanceTail(QNode t, QNode nt) &#123; if (tail == t) UNSAFE.compareAndSwapObject(this, tailOffset, t, nt);&#125;//void advanceHead(QNode h, QNode nh) &#123; if (h == head &amp;&amp; UNSAFE.compareAndSwapObject(this, headOffset, h, nh)) h.next = h; // forget old next&#125; 根据注释，下面来说明一下整个方法的运行流程： 如果队列为空，或者请求交易的节点和队列中的节点具有相同的交易类型，那么就将该请求交易的节点添加到队列尾部等待交易，直到被匹配或者被取消 如果队列中包含了等待的节点，并且请求的节点和等待的节点是互补的，那么进行匹配并且进行交易 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * The number of times to spin before blocking in timed waits. * The value is empirically derived -- it works well across a * variety of processors and OSes. Empirically, the best value * seems not to vary with number of CPUs (beyond 2) so is just * a constant. */static final int maxTimedSpins = (NCPUS &lt; 2) ? 0 : 32;/** * The number of times to spin before blocking in untimed waits. * This is greater than timed value because untimed waits spin * faster since they don't need to check times on each spin. */static final int maxUntimedSpins = maxTimedSpins * 16; /** * Spins/blocks until node s is fulfilled. * 自旋或者阻塞直到有其他线程匹配 * * @param s the waiting node * @param e the comparison value for checking match * @param timed true if timed wait * @param nanos timeout value * @return matched item, or s if cancelled */ Object awaitFulfill(QNode s, E e, boolean timed, long nanos) &#123; /* Same idea as TransferStack.awaitFulfill */ final long deadline = timed ? System.nanoTime() + nanos : 0L; Thread w = Thread.currentThread(); // 头节点的next指针才要自旋 int spins = ((head.next == s) ? (timed ? maxTimedSpins : maxUntimedSpins) : 0); for (;;) &#123; if (w.isInterrupted()) s.tryCancel(e); Object x = s.item; // 方法的唯一出口 // 在tryCancel(e)取消的时候s.item可能变成QNode类型，从而下一步退出方法，返回被cas的结果，可以用来判断是否取消 // 在匹配的时候，s.item会按场景cas成null或者是E（生成元素），从而下一步退出方法，返回被cas的结果 if (x != e) return x; if (timed) &#123; nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) &#123; s.tryCancel(e); continue; &#125; &#125; // 日常自减 if (spins &gt; 0) --spins; else if (s.waiter == null) s.waiter = w; // 如果自旋次数完毕，又没超时那就挂起吧 else if (!timed) LockSupport.park(this); // 只有&gt; 1ms 才要挂起线程，不然还是自旋，这在Condition篇有提到 else if (nanos &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanos); &#125; &#125; 这里看下取消交易的代码 123456/** * Tries to cancel by CAS'ing ref to this as item. */void tryCancel(Object cmp) &#123; UNSAFE.compareAndSwapObject(this, itemOffset, cmp, this);&#125; 可以看到，取消交易就是将match指向自己，而在awaitFulfill方法中返回的就是match，那么awaitFulfill方法返回之后做一下判断，如果和自己相等，那么就是被取消交易了，那么就需要调用方法clean来清理一下，下面是clean方法的细节： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * Gets rid of cancelled node s with original predecessor pred. */void clean(QNode pred, QNode s) &#123; s.waiter = null; // forget thread /* * At any given time, exactly one node on list cannot be * deleted -- the last inserted node. To accommodate this, * if we cannot delete s, we save its predecessor as * \"cleanMe\", deleting the previously saved version * first. At least one of node s or the node previously * saved can always be deleted, so this always terminates. */ while (pred.next == s) &#123; // Return early if already unlinked QNode h = head; QNode hn = h.next; // Absorb cancelled first node as head if (hn != null &amp;&amp; hn.isCancelled()) &#123; advanceHead(h, hn); continue; &#125; QNode t = tail; // Ensure consistent read for tail if (t == h) return; QNode tn = t.next; if (t != tail) continue; if (tn != null) &#123; advanceTail(t, tn); continue; &#125; if (s != t) &#123; // If not tail, try to unsplice QNode sn = s.next; if (sn == s || pred.casNext(s, sn)) return; &#125; QNode dp = cleanMe; if (dp != null) &#123; // Try unlinking previous cancelled node QNode d = dp.next; QNode dn; if (d == null || // d is gone or d == dp || // d is off list or !d.isCancelled() || // d not cancelled or (d != t &amp;&amp; // d not tail and (dn = d.next) != null &amp;&amp; // has successor dn != d &amp;&amp; // that is on list dp.casNext(d, dn))) // d unspliced casCleanMe(dp, null); if (dp == pred) return; // s is already saved node &#125; else if (casCleanMe(null, pred)) return; // Postpone cleaning s &#125;&#125; 可以发现这个方法较为复杂，现在要提到一个成员变量：cleanMe，这个变量保存的是一个被取消交易但是没有被移除队列的节点，这个节点总是最后被添加到队列的。 非公平模式非公平模式的更难一些，暂不说明。 PriorityBlockingQueue带排序的 BlockingQueue 实现，其并发控制采用的是 ReentrantLock，队列为无界队列（ArrayBlockingQueue 是有界队列，LinkedBlockingQueue 也可以通过在构造函数中传入 capacity 指定队列最大的容量，但是 PriorityBlockingQueue 只能指定初始的队列大小，后面插入元素的时候，如果空间不够的话会自动扩容）。 简单地说，它就是 PriorityQueue 的线程安全版本。不可以插入 null 值，同时，插入队列的对象必须是可比较大小的（comparable），否则报 ClassCastException 异常。它的插入操作 put 方法不会 block，因为它是无界队列（take 方法在队列为空的时候会阻塞）。 12345678910111213141516171819202122232425// 构造方法中，如果不指定大小的话，默认大小为 11private static final int DEFAULT_INITIAL_CAPACITY = 11;// 数组的最大容量private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;// 存放数据的数组private transient Object[] queue;// 队列当前大小private transient int size;// 大小比较器，如果按照自然序排序，那么此属性可设置为 nullprivate transient Comparator&lt;? super E&gt; comparator;// 并发控制所用的锁，所有的 public 且涉及到线程安全的方法，都必须先获取到这个锁private final ReentrantLock lock;// 非空conditionprivate final Condition notEmpty;// 这个也是用于锁，用于数组扩容的时候，需要先获取到这个锁，才能进行扩容操作，使用 CAS 操作private transient volatile int allocationSpinLock;// 用于序列化和反序列化的时候用，对于 PriorityBlockingQueue 我们应该比较少使用到序列化private PriorityQueue q; 看初始化代码, 比较器默认为空 1234567891011121314151617181920212223// DEFAULT_INITIAL_CAPACITY = 11public PriorityBlockingQueue() &#123; this(DEFAULT_INITIAL_CAPACITY, null);&#125;public PriorityBlockingQueue(int initialCapacity) &#123; this(initialCapacity, null);&#125;public PriorityBlockingQueue(int initialCapacity, Comparator&lt;? super E&gt; comparator) &#123; if (initialCapacity &lt; 1) throw new IllegalArgumentException(); this.lock = new ReentrantLock(); this.notEmpty = lock.newCondition(); this.comparator = comparator; this.queue = new Object[initialCapacity];&#125;// 初始化填充指定集合public PriorityBlockingQueue(Collection&lt;? extends E&gt; c)&#123; ...&#125; 扩容机制 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * Tries to grow array to accommodate at least one more element * (but normally expand by about 50%), giving up (allowing retry) * on contention (which we expect to be rare). Call only while * holding lock. * * @param array the heap array * @param oldCap the length of the array */private void tryGrow(Object[] array, int oldCap) &#123; // 先释放锁，扩容后再获取锁 lock.unlock(); // must release and then re-acquire main lock Object[] newArray = null; if (allocationSpinLock == 0 &amp;&amp; // cas获取扩容锁 UNSAFE.compareAndSwapInt(this, allocationSpinLockOffset, 0, 1)) &#123; try &#123; // 以64为为界限，不同的增长策略，64以下+2 int newCap = oldCap + ((oldCap &lt; 64) ? (oldCap + 2) : // grow faster if small (oldCap &gt;&gt; 1)); if (newCap - MAX_ARRAY_SIZE &gt; 0) &#123; // possible overflow int minCap = oldCap + 1; if (minCap &lt; 0 || minCap &gt; MAX_ARRAY_SIZE) throw new OutOfMemoryError(); newCap = MAX_ARRAY_SIZE; &#125; if (newCap &gt; oldCap &amp;&amp; queue == array) newArray = new Object[newCap]; &#125; finally &#123; // 解锁 allocationSpinLock = 0; &#125; &#125; // 没获取扩容锁 if (newArray == null) // back off if another thread is allocating Thread.yield(); // 上锁复制 lock.lock(); if (newArray != null &amp;&amp; queue == array) &#123; queue = newArray; System.arraycopy(array, 0, newArray, 0, oldCap); &#125;&#125; 老李把数组扩容和复制分为两步，扩容交给扩容锁，复制交给拍他🔒，这样扩容的时候原数组可以继续被访问，增加吞吐量。 put(e)123456789101112131415161718192021222324252627282930313233343536373839404142// 不用阻塞，因为无界（大爱无疆） public void put(E e) &#123; offer(e); // never need to block &#125; public boolean offer(E e) &#123; if (e == null) throw new NullPointerException(); final ReentrantLock lock = this.lock; lock.lock(); int n, cap; Object[] array; while ((n = size) &gt;= (cap = (array = queue).length)) tryGrow(array, cap); try &#123; Comparator&lt;? super E&gt; cmp = comparator; if (cmp == null) siftUpComparable(n, e, array); else siftUpUsingComparator(n, e, array, cmp); size = n + 1; notEmpty.signal(); &#125; finally &#123; lock.unlock(); &#125; return true; &#125; // 二叉堆的插入，使用插入元素默认的比较方法 private static &lt;T&gt; void siftUpComparable(int k, T x, Object[] array) &#123; Comparable&lt;? super T&gt; key = (Comparable&lt;? super T&gt;) x; while (k &gt; 0) &#123; // 二叉堆中 a[k] 节点的父节点位置 int parent = (k - 1) &gt;&gt;&gt; 1; Object e = array[parent]; if (key.compareTo((T) e) &gt;= 0) break; array[k] = e; k = parent; &#125; array[k] = key; &#125; 继续盗图 = = take()123456789101112public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); E result; try &#123; while ( (result = dequeue()) == null) notEmpty.await(); &#125; finally &#123; lock.unlock(); &#125; return result;&#125; 上锁出队，看出队方法 123456789101112131415161718private E dequeue() &#123; int n = size - 1; if (n &lt; 0) return null; else &#123; Object[] array = queue; E result = (E) array[0]; E x = (E) array[n]; array[n] = null; Comparator&lt;? super E&gt; cmp = comparator; if (cmp == null) siftDownComparable(0, x, array, n); else siftDownUsingComparator(0, x, array, n, cmp); size = n; return result; &#125;&#125; 出队比较容易，因为二叉堆的第一个元素就是最小元素 12345678910111213141516171819202122232425262728293031private static &lt;T&gt; void siftDownComparable(int k, T x, Object[] array, int n) &#123; if (n &gt; 0) &#123; Comparable&lt;? super T&gt; key = (Comparable&lt;? super T&gt;)x; // 这里得到的 half 肯定是非叶节点 // a[n] 是最后一个元素，其父节点是 a[(n-1)/2]。所以 n &gt;&gt;&gt; 1 代表的节点肯定不是叶子节点 // 下面，我们结合图来一行行分析，这样比较直观简单 // 此时 k 为 0, x 为 17，n 为 9 int half = n &gt;&gt;&gt; 1; // 得到 half = 4 while (k &lt; half) &#123; // 先取左子节点 int child = (k &lt;&lt; 1) + 1; // 得到 child = 1 Object c = array[child]; // c = 12 int right = child + 1; // right = 2 // 如果右子节点存在，而且比左子节点小 // 此时 array[right] = 20，所以条件不满足 if (right &lt; n &amp;&amp; ((Comparable&lt;? super T&gt;) c).compareTo((T) array[right]) &gt; 0) c = array[child = right]; // key = 17, c = 12，所以条件不满足 if (key.compareTo((T) c) &lt;= 0) break; // 把 12 填充到根节点 array[k] = c; // k 赋值后为 1 k = child; // 一轮过后，我们发现，12 左边的子树和刚刚的差不多，都是缺少根节点，接下来处理就简单了 &#125; array[k] = key; &#125;&#125; 记住二叉堆是一棵完全二叉树，那么根节点 10 拿掉后，最后面的元素 17 必须找到合适的地方放置。首先，17 和 10 不能直接交换，那么先将根节点 10 的左右子节点中较小的节点往上滑，即 12 往上滑，然后原来 12 留下了一个空节点，然后再把这个空节点的较小的子节点往上滑，即 13 往上滑，最后，留出了位子，17 补上即可。 调整图 DelayQueue这是个依赖于PriorityQueue延迟队列，上节说到PriorityBlcokingQueue是PriorityQueue的线程安全版本。DelayQueue的元素需要实现Delayed接口，Delayed接口又继承了Comparable,需要实现的方法有两个，一个用于获取当前剩余时间，一个比较大小，因为PriorityQueue是优先级队列。 12345678910111213141516171819202122private final transient ReentrantLock lock = new ReentrantLock();private final PriorityQueue&lt;E&gt; q = new PriorityQueue&lt;E&gt;();/** * Thread designated to wait for the element at the head of * the queue. This variant of the Leader-Follower pattern * (http://www.cs.wustl.edu/~schmidt/POSA/POSA2/) serves to * minimize unnecessary timed waiting. When a thread becomes * the leader, it waits only for the next delay to elapse, but * other threads await indefinitely. The leader thread must * signal some other thread before returning from take() or * poll(...), unless some other thread becomes leader in the * interim. Whenever the head of the queue is replaced with * an element with an earlier expiration time, the leader * field is invalidated by being reset to null, and some * waiting thread, but not necessarily the current leader, is * signalled. So waiting threads must be prepared to acquire * and lose leadership while waiting. */private Thread leader = null;private final Condition available = lock.newCondition(); put(e)由于使用的是无界优先级队列，所以put也是调用offer 12345678910111213141516171819public void put(E e) &#123; offer(e);&#125;// q 即 PriorityQueuepublic boolean offer(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; q.offer(e); if (q.peek() == e) &#123; leader = null; available.signal(); &#125; return true; &#125; finally &#123; lock.unlock(); &#125;&#125; take()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * Retrieves and removes the head of this queue, waiting if necessary * until an element with an expired delay is available on this queue. * * @return the head of this queue * @throws InterruptedException &#123;@inheritDoc&#125; */public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; for (;;) &#123; // 查询首元素 E first = q.peek(); if (first == null) // condition组素 available.await(); else &#123; long delay = first.getDelay(NANOSECONDS); if (delay &lt;= 0) // 午时已到，元素出队 return q.poll(); first = null; // don't retain ref while waiting if (leader != null) // condition阻塞 available.await(); else &#123; Thread thisThread = Thread.currentThread(); // 占用队列 leader = thisThread; try &#123; // 等待delay时间，然后进行下一波自旋 available.awaitNanos(delay); &#125; finally &#123; if (leader == thisThread) leader = null; &#125; &#125; &#125; &#125; &#125; finally &#123; // 没人占用队列了 if (leader == null &amp;&amp; q.peek() != null) available.signal(); lock.unlock(); &#125;&#125; 参考解读 Java 并发队列 BlockingQueue","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}],"author":"土川"},{"title":"[Java基础]AQS与共享锁","slug":"Java基础-AQS与共享锁","date":"2018-08-27T13:58:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"4255302597.html","link":"","permalink":"https://htchz.cc/4255302597.html","excerpt":"占个坑、不拉💩","text":"占个坑、不拉💩","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}],"author":"土川"},{"title":"[Java基础]AQS与Condition","slug":"Java基础-Condition","date":"2018-08-27T03:43:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"2912753191.html","link":"","permalink":"https://htchz.cc/2912753191.html","excerpt":"这是依赖于ReentrantLock的一个类","text":"这是依赖于ReentrantLock的一个类 Condition基于ReentrantLock，这里有 Doug Lea 举的🌰。 1234567891011121314151617181920212223242526272829303132333435363738394041424344import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;class BoundedBuffer &#123; final Lock lock = new ReentrantLock(); // condition 依赖于 lock 来产生 final Condition notFull = lock.newCondition(); final Condition notEmpty = lock.newCondition(); final Object[] items = new Object[100]; int putptr, takeptr, count; // 生产 public void put(Object x) throws InterruptedException &#123; lock.lock(); try &#123; while (count == items.length) notFull.await(); // 队列已满，等待，直到 not full 才能继续生产 items[putptr] = x; if (++putptr == items.length) putptr = 0; ++count; notEmpty.signal(); // 生产成功，队列已经 not empty 了，发个通知出去 &#125; finally &#123; lock.unlock(); &#125; &#125; // 消费 public Object take() throws InterruptedException &#123; lock.lock(); try &#123; while (count == 0) notEmpty.await(); // 队列为空，等待，直到队列 not empty，才能继续消费 Object x = items[takeptr]; if (++takeptr == items.length) takeptr = 0; --count; notFull.signal(); // 被我消费掉一个，队列 not full 了，发个通知出去 return x; &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; 这个其实就是ArrayBlockingQueue的原理。 获取一个Condition实例要通过ReentrantLock实例 123public Condition newCondition() &#123; return sync.newCondition();&#125; 123final ConditionObject newCondition() &#123; return new ConditionObject();&#125; 12345678public class ConditionObject implements Condition, java.io.Serializable &#123; private static final long serialVersionUID = 1173984872572414699L; /** First node of condition queue. */ private transient Node firstWaiter; /** Last node of condition queue. */ private transient Node lastWaiter; ...&#125; 实际上利用Node的nextWaiter属性，condition维护了一个单向链表 1234567891011/** * Link to next node waiting on condition, or the special * value SHARED. Because condition queues are accessed only * when holding in exclusive mode, we just need a simple * linked queue to hold nodes while they are waiting on * conditions. They are then transferred to the queue to * re-acquire. And because conditions can only be exclusive, * we save a field by using special value to indicate shared * mode. */Node nextWaiter; 偷来一张图，我们把上一节的队列称为阻塞队列，把condition的队列叫做条件队列。 当condition调用await()的时候就把当前线程封装为一个Node放到lastWaiter，并且挂起当前线程。 当condition调用signal()的时候就把firstWaiter放到阻塞队列。 线程挂起1234567891011121314151617181920212223242526// 首先，这个方法是可被中断的，不可被中断的是另一个方法 awaitUninterruptibly()// 这个方法会阻塞，直到调用 signal 方法（指 signal() 和 signalAll()，下同），或被中断public final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); // 添加到 condition 的条件队列中 Node node = addConditionWaiter(); // 释放锁，返回值是释放锁之前的 state 值 int savedState = fullyRelease(node); int interruptMode = 0; // 这里退出循环有两种情况，之后再仔细分析 // 1. isOnSyncQueue(node) 返回 true，即当前 node 已经转移到阻塞队列了 // 2. checkInterruptWhileWaiting(node) != 0 会到 break，然后退出循环，代表的是线程中断 while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; // 被唤醒后，将进入阻塞队列，等待获取锁 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode);&#125; 看addConditionWaiter()，把当前线程加入条件队列 12345678910111213141516171819/** * Adds a new waiter to wait queue. * @return its new wait node */private Node addConditionWaiter() &#123; Node t = lastWaiter; // If lastWaiter is cancelled, clean out. if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); t = lastWaiter; &#125; Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node;&#125; 为什么没有线程安全问题？因为Condition需要和ReentrantLock.lock()一起使用，不一起使用会怎么样呢？就不安全了 取消节点的代码如下： 123456789101112131415161718192021// 等待队列是一个单向链表，遍历链表将已经取消等待的节点清除出去private void unlinkCancelledWaiters() &#123; Node t = firstWaiter; Node trail = null; while (t != null) &#123; Node next = t.nextWaiter; // 如果节点的状态不是 Node.CONDITION 的话，这个节点就是被取消的 if (t.waitStatus != Node.CONDITION) &#123; t.nextWaiter = null; if (trail == null) firstWaiter = next; else trail.nextWaiter = next; if (next == null) lastWaiter = trail; &#125; else trail = t; t = next; &#125;&#125; 加入条件队列之后，就完全释放独占锁，让出锁。 123456789101112131415161718192021// 首先，我们要先观察到返回值 savedState 代表 release 之前的 state 值// 对于最简单的操作：先 lock.lock()，然后 condition1.await()。// 那么 state 经过这个方法由 1 变为 0，锁释放，此方法返回 1// 相应的，如果 lock 重入了 n 次，savedState == n// 如果这个方法失败，会将节点设置为\"取消\"状态，并抛出异常 IllegalMonitorStateExceptionfinal int fullyRelease(Node node) &#123; boolean failed = true; try &#123; int savedState = getState(); // 这里使用了当前的 state 作为 release 的参数，也就是完全释放掉锁，将 state 置为 0 if (release(savedState)) &#123; failed = false; return savedState; &#125; else &#123; throw new IllegalMonitorStateException(); &#125; &#125; finally &#123; if (failed) node.waitStatus = Node.CANCELLED; &#125;&#125; 释放掉锁之后，判断是否当前节点是否在阻塞队列里面，如果不在，挂起，自旋直到进入阻塞队列。 12345678int interruptMode = 0;while (!isOnSyncQueue(node)) &#123; // 线程挂起 LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break;&#125; isOnSyncQueue(Node node)用于判断节点是否已经转移到阻塞队列 1234567891011final boolean isOnSyncQueue(Node node) &#123; // 移动过去的时候，node 的 waitStatus 会置为 0，这个之后在说 signal 方法的时候会说到 // node.prev == null，那么肯定没有进入阻塞队列，node.prev != null, 不一定进入阻塞队列，因为上篇的AQS讲到Node入队首先设置的是 node.prev 指向 tail， // 然后是 CAS 操作将自己设置为新的 tail，可是这次的 CAS 是可能失败的。 if (node.waitStatus == Node.CONDITION || node.prev == null) return false; if (node.next != null) // If has successor, it must be on queue return true; // return findNodeFromTail(node); &#125; 1234567891011// 从同步队列(阻塞队列)的队尾往前遍历，如果找到，返回 trueprivate boolean findNodeFromTail(Node node) &#123; Node t = tail; for (;;) &#123; if (t == node) return true; if (t == null) return false; t = t.prev; &#125;&#125; 线程唤醒12345678910// 唤醒等待了最久的线程// 其实就是，将这个线程对应的 node 从条件队列转移到阻塞队列public final void signal() &#123; // 调用 signal 方法的线程必须持有当前的独占锁 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first);&#125; 1234567891011121314// 从条件队列队头往后遍历，找出第一个需要转移的 node// 因为前面我们说过，有些线程会取消排队，但是还在队列中private void doSignal(Node first) &#123; do &#123; // 将 firstWaiter 指向 first 节点后面的第一个 // 如果将队头移除后，后面没有节点在等待了，那么需要将 lastWaiter 置为 null if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; // 因为 first 马上要被移到阻塞队列了，和条件队列的链接关系在这里断掉 first.nextWaiter = null; &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null); // 这里 while 循环，如果 first 转移不成功，那么选择 first 后面的第一个节点进行转移，依此类推&#125; 转移节点的代码，并且唤醒阻塞线程 12345678910111213141516171819202122// 将节点从条件队列转移到阻塞队列// true 代表成功转移// false 代表在 signal 之前，节点已经取消了final boolean transferForSignal(Node node) &#123; // CAS 如果失败，说明此 node 的 waitStatus 已不是 Node.CONDITION，说明节点已经取消， // 既然已经取消，也就不需要转移了，方法返回，转移后面一个节点 // 否则，将 waitStatus 置为 0 if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; // enq(node): 自旋进入阻塞队列的队尾 // 注意，这里的返回值 p 是 node 在阻塞队列的前驱节点 Node p = enq(node); int ws = p.waitStatus; // ws &gt; 0 说明 node 在阻塞队列中的前驱节点取消了等待锁，直接唤醒 node 对应的线程。唤醒之后会怎么样，后面再解释 // 如果 ws &lt;= 0, 那么 compareAndSetWaitStatus 将会被调用，上篇介绍的时候说过，节点入队后，需要把前驱节点的状态设为 Node.SIGNAL(-1) if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) // 如果前驱节点取消或者 CAS 失败，会进到这里唤醒线程，之后的操作看下一节 LockSupport.unpark(node.thread); return true;&#125; 正常情况下，ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL) 这句中，如果ws &lt;= 0，那么一般 compareAndSetWaitStatus(p, ws, Node.SIGNAL) 会返回 true，所以一般也不会进去 if 语句块中唤醒 node 对应的线程。然后这个方法返回 true，也就意味着 signal 方法结束了，节点进入了阻塞队列。 假设发生了阻塞队列中的前驱节点取消等待，或者 CAS 失败，只要唤醒线程，让其进到下一步即可 没有唤醒的话，因为已经加入阻塞队列，等待前驱节点去唤醒。 唤醒后的操作上一步 signal 之后，我们的线程由条件队列转移到了阻塞队列，之后就准备获取锁了。只要重新获取到锁了以后，继续往下执行。 等线程从挂起中恢复过来，继续往下看 12345678int interruptMode = 0;while (!isOnSyncQueue(node)) &#123; // 线程挂起 LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break;&#125; 关于interruptMode REINTERRUPT： 代表 await 返回的时候，需要重新设置中断状态 THROW_IE： 代表 await 返回的时候，需要抛出InterruptedException 异常 0 ：说明在 await 期间，没有发生中断 有三种情况可以让LockSupport.park(this);返回： 常规路径。signal -&gt; 转移节点到阻塞队列 -&gt; 等待前驱节点唤醒 线程中断。在 park 的时候，另外一个线程对这个线程进行了中断 signal()的时候，转移以后的前驱节点取消了，或者对前驱节点的CAS操作失败了 假唤醒。这个也是存在的，和 Object.wait() 类似，都有这个问题 线程唤醒后第一步是调用 checkInterruptWhileWaiting(node) 这个方法，此方法用于判断是否在线程挂起期间发生了中断，如果发生了中断，是 signal 调用之前中断的，还是 signal 之后发生的中断。 12345678// 1. 如果在 signal 之前已经中断，返回 THROW_IE// 2. 如果是 signal 之后中断，返回 REINTERRUPT// 3. 没有发生中断，返回 0private int checkInterruptWhileWaiting(Node node) &#123; return Thread.interrupted() ? (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) : 0;&#125; 判断signal之前还是之后中断的方法： 1234567891011121314151617181920// 只有线程处于中断状态，才会调用此方法// 如果需要的话，将这个已经取消等待的节点转移到阻塞队列// 返回 true：如果此线程在 signal 之前被取消，final boolean transferAfterCancelledWait(Node node) &#123; // 用 CAS 将节点状态设置为 0 // 如果这步 CAS 成功，说明是 signal 方法之前发生的中断，因为如果 signal 先发生的话，signal 中会将 waitStatus 设置为 0 if (compareAndSetWaitStatus(node, Node.CONDITION, 0)) &#123; // 将节点放入阻塞队列 // 这里我们看到，即使中断了，依然会转移到阻塞队列 enq(node); return true; &#125; // 到这里是因为 CAS 失败，肯定是因为 signal 方法已经将 waitStatus 设置为了 0 // signal 方法会将节点转移到阻塞队列，但是可能还没完成，这边自旋等待其完成 // 当然，这种事情还是比较少的吧：signal 调用之后，没完成转移之前，发生了中断 while (!isOnSyncQueue(node)) Thread.yield(); return false;&#125; 上面的代码就是讨论线程中断后怎么让程序恢复正常。 signal之前中断，执行enq(node)，确保进入阻塞队列。 signal之后中断，没转移完成（判断waitStatus==0),让出cpu，自旋直至enq(node)执行完成。 接着获取独占锁，看接下来的代码 12if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; 由于 while 出来后，我们确定节点已经进入了阻塞队列，准备获取锁。 这里的 acquireQueued(node, savedState) 的第一个参数 node 之前已经经过 enq(node) 进入了队列，参数 savedState 是之前释放锁前的 state，这个方法返回的时候，代表当前线程获取了锁，而且 state == savedState了, 原来重入了几次，现在还是算几次。 注意，前面我们说过，不管有没有发生中断，都会进入到阻塞队列，而 acquireQueued(node, savedState) 的返回值就是代表线程是否被中断。如果返回 true，说明被中断了，而且 interruptMode != THROW_IE，说明在 signal 之前就发生中断了，这里将 interruptMode 设置为 REINTERRUPT，用于待会重新中断。 继续 1234 if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters();if (interruptMode != 0) reportInterruptAfterWait(interruptMode); node.nextWaiter != null依旧是对中断的善后，前面signal 的时候会将节点转移到阻塞队列，有一步是 node.nextWaiter = null，将断开节点和条件队列的联系。 可是，在判断发生中断的情况下，是 signal 之前还是之后发生的？ 这部分的时候，我也介绍了，如果 signal 之前就中断了，也需要将节点进行转移到阻塞队列，这部分转移的时候，是没有设置 node.nextWaiter = null 的。 之前我们说过，如果有节点取消，也会调用 unlinkCancelledWaiters 这个方法，就是这里了。 接下来是进入reportInterruptAfterWait代码块： 1234567891011121314/** * Throws InterruptedException, reinterrupts current thread, or * does nothing, depending on mode. */ private void reportInterruptAfterWait(int interruptMode) throws InterruptedException &#123; // THROW_IE 跑出异常 if (interruptMode == THROW_IE) throw new InterruptedException(); // 重新中断，自我了断 else if (interruptMode == REINTERRUPT) selfInterrupt(); // 0不处理 &#125; 其他await超时await超时的await都差不多， 123456public final long awaitNanos(long nanosTimeout) throws InterruptedExceptionpublic final boolean awaitUntil(Date deadline) throws InterruptedExceptionpublic final boolean await(long time, TimeUnit unit) throws InterruptedException 看第一个方法 12345678910111213141516171819202122232425262728293031public final long awaitNanos(long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); final long deadline = System.nanoTime() + nanosTimeout; int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; // 超时啦 if (nanosTimeout &lt;= 0L) &#123; transferAfterCancelledWait(node); break; &#125; // spinForTimeoutThreshold = 1000（1ms），当超时时间大于1ms才挂起，否则继续自旋 if (nanosTimeout &gt;= spinForTimeoutThreshold) // 指定时间的挂起 LockSupport.parkNanos(this, nanosTimeout); // 醒来检查是否signal发生中断 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; nanosTimeout = deadline - System.nanoTime(); &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); return deadline - System.nanoTime();&#125; 超时的思路还是很简单的，不带超时参数的 await 是 park，然后等待别人唤醒。而现在就是调用 parkNanos 方法来休眠指定的时间，醒来后判断是否 signal 调用了，调用了就是没有超时，否则就是超时了。超时的话，自己来进行转移到阻塞队列（checkInterruptWhileWaiting方法），然后acquireQueued抢锁。 不抛中断异常的await123456789101112public final void awaitUninterruptibly() &#123; Node node = addConditionWaiter(); int savedState = fullyRelease(node); boolean interrupted = false; while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if (Thread.interrupted()) interrupted = true; &#125; if (acquireQueued(node, savedState) || interrupted) selfInterrupt();&#125; 醒来后检查中断，把中断吞了,使用时确保别人不会来中断他。 ReentrantLock的中断锁这篇讲了很多中断的处理，那么回头看ReentrantLock的lock()方法，它里面实际上默认是吞了中断的，想通过中断线程来取消一个锁的获取是不可以的 123456789101112131415161718192021final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 可以看到interrupted = true;之后又开始自旋了，打了个标志之后还是像没事人一样获取🔒。 这时候请看lockInterruptibly()方法： 123public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1);&#125; 1234567public final void acquireInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg);&#125; 如果线程中断，开始疯狂抛异常 123456789101112131415161718192021222324252627/** * Acquires in exclusive interruptible mode. * @param arg the acquire argument */private void doAcquireInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) // 疯狂抛异常 throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 这里抛异常的话，failed是true的，终于有机会进入cancelAcquire(node)了， 12345678910111213141516171819202122232425262728293031323334353637383940414243private void cancelAcquire(Node node) &#123; // Ignore if node doesn't exist if (node == null) return; node.thread = null; // Skip cancelled predecessors Node pred = node.prev; while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; // predNext is the apparent node to unsplice. CASes below will // fail if not, in which case, we lost race vs another cancel // or signal, so no further action is necessary. Node predNext = pred.next; // Can use unconditional write instead of CAS here. // After this atomic step, other Nodes can skip past us. // Before, we are free of interference from other threads. node.waitStatus = Node.CANCELLED; // If we are the tail, remove ourselves. if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123; compareAndSetNext(pred, predNext, null); &#125; else &#123; // If successor needs signal, try to set pred's next-link // so it will get one. Otherwise wake it up to propagate. int ws; if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) &#123; Node next = node.next; if (next != null &amp;&amp; next.waitStatus &lt;= 0) compareAndSetNext(pred, predNext, next); &#125; else &#123; unparkSuccessor(node); &#125; node.next = node; // help GC &#125;&#125; 这里会把node.waitStatus = Node.CANCELLED;，如果是头节点，则唤醒挂起的下一个节点，否则cas将前驱节点的next指向当前节点的next，把自己从阻塞队列清除。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}],"author":"土川"},{"title":"[Java基础]AQS与ReentrantLock","slug":"Java基础-AQS与Lock","date":"2018-08-22T15:54:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"2430429572.html","link":"","permalink":"https://htchz.cc/2430429572.html","excerpt":"AQS是一个抽象类，是java许多Lock实现必不可少的一个数据结构。","text":"AQS是一个抽象类，是java许多Lock实现必不可少的一个数据结构。 AQS，人称AbstractQueuedSynchronizer，它的子类有如下： 有ReentrantLock内部类FairSync、NonfairSync即公平锁与非公平锁等。他有一个volatile int state属性，表明锁的占有情况： 1234/** * The synchronization state. */private volatile int state; 这里先剧透一下，AQS是个队列，那么队头线程理应拿到锁，这是公平锁的情况。而非公平锁的情况下，锁在刚释放的时候（state==0），队头线程可能被新来的插队，新来的插队失败，才乖乖地排到队尾，所以非公平锁并不是就没有队列的概念。 我们结合ReentrantLock来看AQS在Lock里的使用例子。 加锁看ReentrantLock的构造方法如下： 123456789101112131415161718 /** * Creates an instance of &#123;@code ReentrantLock&#125;. * This is equivalent to using &#123;@code ReentrantLock(false)&#125;. */ public ReentrantLock() &#123; sync = new NonfairSync(); &#125; /** * Creates an instance of &#123;@code ReentrantLock&#125; with the * given fairness policy. * * @param fair &#123;@code true&#125; if this lock should use a fair ordering policy */ public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync(); &#125;` 很明显，ReentrantLock能构造公平或者不公平的锁，默认是非公平的。我们先看非公平锁的实现。 123456789101112131415161718192021/** * Sync object for non-fair locks */static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = 7316153563782823691L; /** * Performs lock. Try immediate barge, backing up to normal * acquire on failure. */ final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125;&#125; 这个类继承了Sync，也是AQS的子类。lock()方法先通过CAS尝试将状态从0修改为1。若直接修改成功，前提条件自然是锁的状态为0，则直接将线程的OWNER修改为当前线程，这是一种理想情况，如果并发粒度设置适当也是一种乐观情况。若上一个动作未成功，则会间接调用了acquire(1)来继续操作，这个acquire(int)方法就是在AbstractQueuedSynchronizer当中了。 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 首先看tryAcquire(arg)这里的调用（当然传入的参数是1）,这个方法又交给子类实现了，最终是落到Sync里 123456789101112131415161718final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false;&#125; 判断锁是否被占有：首先获取这个锁的状态，如果状态为0，则尝试设置状态为传入的参数（这里就是1），若设置成功就代表自己获取到了锁，返回true了。状态为0设置1的动作在外部就有做过一次，内部再一次做只是提升概率，而且这样的操作相对锁来讲不占开销。 判断能否重入：如果状态不是0，则判定当前线程是否为排它锁的Owner，如果是Owner则尝试将状态增加acquires（也就是增加1），如果这个状态值越界，则会抛出异常提示，若没有越界，将状态设置进去后返回true（实现了类似于偏向的功能，可重入，但是无需进一步征用）。 如果状态不是0，且自身不是owner，则返回false，获取锁失败 回到AQS的acquire方法，判定中是通过if(!tryAcquire())作为第1个条件的，如果返回获取失败的话，继续acquireQueued(addWaiter(Node.EXCLUSIVE), arg))代码，先看第一个 1234567891011121314151617181920/** * Creates and enqueues node for current thread and given mode. * * @param mode Node.EXCLUSIVE for exclusive, Node.SHARED for shared * @return the new node */private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125; 这里的参数使用了Node.EXCLUSIVE,即排他的意思。Node的结构如下： 1234567891011121314151617181920212223242526272829303132333435363738static final class Node &#123; /** Marker to indicate a node is waiting in shared mode */ // 标识节点当前在共享模式下 static final Node SHARED = new Node(); /** Marker to indicate a node is waiting in exclusive mode */ // 标识节点当前在独占模式下 static final Node EXCLUSIVE = null; // ======== 下面的几个int常量是给waitStatus用的 =========== /** waitStatus value to indicate thread has cancelled */ // 代码此线程取消了争抢这个锁 static final int CANCELLED = 1; /** waitStatus value to indicate successor's thread needs unparking */ // 官方的描述是，其表示当前node的后继节点对应的线程需要被唤醒 static final int SIGNAL = -1; /** waitStatus value to indicate thread is waiting on condition */ // 本文不分析condition，所以略过吧，下一篇文章会介绍这个 static final int CONDITION = -2; /** * waitStatus value to indicate the next acquireShared should * unconditionally propagate */ // 同样的不分析，略过吧 static final int PROPAGATE = -3; // ===================================================== // 取值为上面的1、-1、-2、-3，或者0(以后会讲到) // 这么理解，暂时只需要知道如果这个值 大于0 代表此线程取消了等待， // 也许就是说半天抢不到锁，不抢了，ReentrantLock是可以指定timeouot的。。。 volatile int waitStatus; // 前驱节点的引用 volatile Node prev; // 后继节点的引用 volatile Node next; // 这个就是线程本尊 volatile Thread thread;&#125; 很明显，AQS是个链表结构，还是双向的。Node初始化，保存了当前线程，并赋值给nextWaiter属性。 1234Node(Thread thread, Node mode) &#123; // Used by addWaiter this.nextWaiter = mode; this.thread = thread;&#125; 而最初，tail肯定是null的，直接看enq(node)方法： 1234567891011121314151617181920/** * Inserts node into queue, initializing if necessary. See picture above. * @param node the node to insert * @return node's predecessor */private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 一个死循环，这段代码利用cas插入node，如果cas失败，进入下一次循环继续尝试。最终返回的是Node的前驱节点(addWaiter没有用到这个返回值)，第一个插入的，会初始化一个空（实例化但没有信息）的头节点再append操作。回到addWaiter，可以发现如果tail==null，接下来执行的代码块和enq（node）的部分代码是一样的，总之，addWaiter会初始化一个保存初始化线程的node，加入AQS，并返回。返回的Node和arg=1传入acquireQueued方法， 123456789101112131415161718192021222324252627282930/** * Acquires in exclusive uninterruptible mode for thread already in * queue. Used by condition wait methods as well as acquire. * * @param node the node * @param arg the acquire argument * @return &#123;@code true&#125; if interrupted while waiting */final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; // 这里判断前驱节点是不是head，而不是判断当前节点，因为队头是已经占有锁的/或者是空节点（请看enq方法），所以只要队列老二就可以开始tryAcquire了 final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed)// 没有正确退出，将本节点取消 cancelAcquire(node); &#125;&#125; 这里又是一个死循环，addWaiter是插入的node节点，那么这里如果前驱节点为head的话，说明线程来到了队头，继续执行tryRequire方法，tryAcquire(arg)这个方法我们前面介绍过，成立的条件为：锁的状态为0，且通过CAS尝试设置状态成功或线程的持有者本身是当前线程才会返回true，我们现在来详细拆分这部分代码。 如果这个条件成功后，发生的几个动作包含： 首先调用setHead(Node)的操作，这个操作内部会将传入的node节点作为AQS的head所指向的节点。线程属性设置为空（因为现在已经获取到锁，不再需要记录下这个节点所对应的线程了），再将这个节点的perv引用赋值为null。 进一步将的前一个节点的next引用赋值为null。 在进行了这样的修改后，队列就可以让执行完的节点释放掉内存区域，而不是无限制增长队列，也就真正形成FIFO了。 12345678910111213141516171819202122232425262728private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ // 如果前面的节点是0（因为前面都没出现过waitStatus的赋值，所以只能是默认值0），0是初始状态，那么就把它置为**等待唤醒**状态，如果下次抢占锁失败，前驱节点就会是-1，从而返回true，挂起线程。 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 如果获取不到锁 判断shouldParkAfterFailedAcquire(p , node)，这个方法内部会判定前一个节点的状态是否为：“Node.SIGNAL”，若是则返回true，若不是都会返回false，不过会再做一些操作：判定节点的状态是否大于0，若大于0则认为被“CANCELLED”掉了（大于0的表示CANCELLED的状态），因此会从前一个节点开始逐步循环找到一个没有被“CANCELLED”节点，然后与这个节点的next、prev的引用相互指向（即删除掉取消的队列元素）；如果前一个节点的状态不是大于0的，则通过CAS尝试将状态修改为“Node.SIGNAL”，自然的如果下一轮循环的时候，如果没拿到锁就会返回true。 如果这个方法返回了true，则会执行：“parkAndCheckInterrupt()”方法，它是通过LockSupport.park(this)将当前线程挂起到WATING状态，它需要等待一个中断、unpark方法来唤醒它，通过这样一种FIFO的机制的等待，来实现了Lock的操作。 这里有个节点状态的对应关系 节点类型 值 说明 CANCELLED 1 线程取消 SIGNAL -1 等待唤醒 CONDITION -2 ReenrantLock没用到 PROPAGATE -3 ReenrantLock没用到 简单地说，队列中的线程获取不到锁又检测到前面有人，那就要挂起，直到有人唤醒，这个唤醒靠前面的人来唤醒。 这里再看下非公平锁和公平锁的有什么区别：直接上截图这是非公平锁 这是公平锁 可以看出，非公平锁无论是在第一次尝试lock，还是到有机会tryAcquire时，上来就compareAndSetState(0,1)，完全不理会自己是不是真正的队头，而公平锁要客气地进行hasQueuedPredecessors()判断自己是不是真正的队头。 公平锁和非公平锁的对比 公平锁保证各个线程可以拿到锁，但是这样大部分线程会经历一个挂起、唤醒的耗性能过程。非公平锁尽量减少这个耗性能的过程，但是不能保证业务的顺序。 如果线程占有锁处理业务的时间远大于挂起、唤醒的时间耗费，那么使用公平锁可以增强可控性。 解锁解锁就没分公平与不公平了，主要任务就是消除锁占有标识，唤醒挂起的线程。 接下来简单看看unlock()解除锁的方式，如果获取到了锁不释放，那自然就成了死锁，所以必须要释放，来看看它内部是如何释放的。同样从排它锁（ReentrantLock）中的unlock()方法开始： 123public void unlock() &#123; sync.release(1);&#125; 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; tryRelease(arg)进入到Sync的方法 123456789101112protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 这些是重入逻辑，如果state==0那么清空锁的占有者。 state减的数量是根据参数的，而不是一下子清空，所以调用多少次lock(),应该调用相对应次数的unlock() 虽然锁状态清空了，这时被队头挂起的线程还需要unparkSuccessor(h)唤醒，参数是一个头节点。先判空和判断头节点的状态是否非0（几个重要的状态都不是0，0的节点要么是空，要么是被消除锁了）。 1234567891011121314151617181920212223242526private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; unparkSuccessor(h)内部首先会发生的动作是获取head节点的next节点，如果获取到的节点不为空，则直接通过“LockSupport.unpark()”方法来释放对应的被挂起的线程(否则从后往前遍历，拿到最前的等待唤醒的线程节点，虽然我不知道这个否则怎进来 = =，待研究)，这样一来将会有一个节点唤醒后继续循环进一步尝试tryAcquire()方法来获取锁，但是也未必能完全获取到哦，因为此时也可能有一些外部的请求正好与之征用(非公平锁)，而且还奇迹般的成功了，那这个线程的运气就有点悲剧了，不过通常乐观认为不会每一次都那么悲剧。 写在最后有些地方还没弄懂，不过对AQS的结构，ReentrantLock是怎么利用AQS来做锁的有了一个大致的认识。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}],"author":"土川"},{"title":"[Java基础]CAS与Atomic","slug":"Java基础-java的CAS","date":"2018-08-22T15:10:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"1213316024.html","link":"","permalink":"https://htchz.cc/1213316024.html","excerpt":"java.util.concurrent.atomic 这个包提供了一系列的原子变量操作方法。","text":"java.util.concurrent.atomic 这个包提供了一系列的原子变量操作方法。 Atomic看看这个包下的类 这个包可以简单分为4类 分别对Boolean、Integer、Long进行操作，提供能进行原子计算的类，jdk8以后还提供了LongAdder、LongAccumulator等进行性能更好、更强大的计算，理论上可以用LongAdder代替AtomicInteger，具体在此博客中也有介绍LongAdder的实现原理。 对引用（Reference）的操作，由于多线程的对同一个Atomic的类型修改，无法避免ABA的问题，所以提供此类型的操作。 数组（Array）操作，针对数组的每个元素读写是线程安全的。 Updater：对普通的变量进行原子性管理，而不用改变原来变量的定义。 CAScas即compare and set，在AtomicInteger里有这么一个方法： 123public final boolean compareAndSet(int expect, int update)&#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update);&#125; 具体调用了public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);这个原生方法，需要传入对象本身、值在内存中的地址偏移、原值、改变后的值，即通过一组对比、修改的原子操作，在写入前读取原值，然后写入时如果值和原值不一致，就会更新失败，否则更新成功。 cas自旋unsafe类有这么一个方法，也是AtomicInteger自增的实现： 12345678public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125; 如果while()里一直返回的cas结果为false，那么程序就继续尝试cas操作，这就是cas自旋","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}],"author":"土川"},{"title":"[Java基础]synchronized关键字","slug":"Java基础-synchronized关键字","date":"2018-08-22T07:42:00.000Z","updated":"2019-07-20T03:59:13.000Z","comments":true,"path":"589479039.html","link":"","permalink":"https://htchz.cc/589479039.html","excerpt":"来讲讲属于jvm级别的锁","text":"来讲讲属于jvm级别的锁 简介这是java同步的最简单的方法（有了这个并不是代码就保证线程安全了） 同步普通方法，锁的是当前对象。 同步静态方法，锁的是当前 Class 对象。 同步块，锁的是 (){} 中的()括起来的对象。 在JVM中monitorenter和monitorexit字节码依赖于底层的操作系统的Mutex Lock来实现的，但是由于使用Mutex Lock需要将当前线程挂起并从用户态切换到内核态来执行，这种切换的代价是非常昂贵的；然而在现实中的大部分情况下，同步方法是运行在单线程环境（无锁竞争环境）如果每次都调用Mutex Lock那么将严重的影响程序的性能。在jdk1.6中对锁的实现引入了大量的优化，如锁粗化（Lock Coarsening）、锁消除（Lock Elimination）、轻量级锁（Lightweight Locking）、偏向锁（Biased Locking）、适应性自旋（Adaptive Spinning）等技术来减少锁操作的开销。 先看看加了这个关键字的代码会发生什么 12345678910111213141516package com.htc.learning.main;public class Sync &#123; public static void main(String[] args) &#123; Sync sync = new Sync(); synchronized (sync) &#123; System.out.println(\"go die\"); &#125; print(); &#125; public static synchronized void print() &#123; System.out.println(\"print oh that's good\"); &#125;&#125; 运行javap -c Sync 123456789101112131415161718192021222324252627282930313233343536373839404142434445$ javap -c Sync警告: 二进制文件Sync包含com.htc.learning.main.SyncCompiled from &quot;Sync.java&quot;public class com.htc.learning.main.Sync &#123; public com.htc.learning.main.Sync(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return public static void main(java.lang.String[]); Code: 0: new #2 // class com/htc/learning/main/Sync 3: dup 4: invokespecial #3 // Method &quot;&lt;init&gt;&quot;:()V 7: astore_1 8: aload_1 9: dup 10: astore_2 11: monitorenter 12: getstatic #4 // Field java/lang/System.out:Ljava/io/PrintStream; 15: ldc #5 // String go die 17: invokevirtual #6 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 20: aload_2 21: monitorexit 22: goto 30 25: astore_3 26: aload_2 27: monitorexit 28: aload_3 29: athrow 30: invokestatic #7 // Method print:()V 33: return Exception table: from to target type 12 22 25 any 25 28 25 any public static synchronized void print(); Code: 0: getstatic #4 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #8 // String print oh that&apos;s good 5: invokevirtual #6 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return&#125; 看20行和27行，在同步块的入口和出口分别有 monitorenter,monitorexit指令。 JVM 是通过进入、退出对象监视器( Monitor ，即下文的monitor record)来实现对方法、同步块的同步的。 具体实现是在编译之后在同步方法调用前加入一个 monitor.enter 指令，在退出方法和异常处插入 monitor.exit 的指令。 其本质就是对一个对象监视器( Monitor )进行获取，而这个获取过程具有排他性从而达到了同一时刻只能一个线程访问的目的。 而对于没有获取到锁的线程将会阻塞到方法入口处，直到获取锁的线程 monitor.exit 之后才能尝试继续获取锁。 这个关键字可以形成三种锁：偏向锁、轻量级锁、重量锁，三种锁依次升级，不能降级，直到解锁。 接下来会涉及到jvm中对象的markword（对象头），关于对象头看对象的组成 monitor recordMonitor Record是线程的数据结构，每一个线程都有一个可用monitor record列表，同时还有一个全局的可用列表；那么这些monitor record有什么用呢？每一个被锁住的对象都会和一个monitor record关联（对象头中的LockWord指向monitor record的起始地址，由于这个地址是8byte对齐的所以LockWord的最低三位可以用来作为状态位），同时monitor record中有一个Owner字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。如下所示：Monitor Record的内部结构 属性 说明 Owner 初始时为NULL表示当前没有任何线程拥有该monitor record，当线程成功拥有该锁后保存线程唯一标识，当锁被释放时又设置为NULL EntryQ 关联一个系统互斥锁（semaphore），阻塞所有试图锁住monitor record失败的线程 RcThis 表示blocked或waiting在该monitor record上的所有线程的个数 Nest 用来实现重入锁的计数 HashCode 保存从对象头拷贝过来的HashCode值（可能还包含GC age） Candidate 用来避免不必要的阻塞或等待线程唤醒，因为每一次只有一个线程能够成功拥有锁，如果每次前一个释放锁的线程唤醒所有正在阻塞或等待的线程，会引起不必要的上下文切换（从阻塞到就绪然后因为竞争锁失败又被阻塞）从而导致性能严重下降。Candidate只有两种可能的值0表示没有需要唤醒的线程1表示要唤醒一个继任线程来竞争锁 下文的lockrecord字段指的就是ptr to lock record 偏向锁Biased Lockmarkword的标志位（bittag）为01，称为biasable。 偏向锁的获取过程 初始时对象处于biasable状态 当一个线程试图锁住一个处于biasable&amp; unbiased状态的对象时，通过一个CAS将自己的ThreadID放置到Mark Word中相应的位置，如果CAS操作成功进入第（3）步否则进入（4）步 当进入到这一步时代表当前没有锁竞争，Object继续保持biasable状态，但是这时ThreadID字段被设置成了偏向锁所有者的ID，然后进入到第（6）步 当前线程执行CAS获取偏向锁失败（这一步是偏向锁的关键），表示在该锁对象上存在竞争并且这个时候另外一个线程获得偏向锁所有权。当到达全局安全点（safepoint，gc时也会用到这个时间点）时获得偏向锁的线程被挂起，并从偏向锁所有者的私有Monitor Record列表中获取一个空闲的记录，并将Object设置为LightWeight Lock状态并且Mark Word中的LockRecord指向刚才持有偏向锁线程的Monitor record，最后被阻塞在安全点的线程被释放，进入到轻量级锁的执行路径中，同时被撤销偏向锁的线程继续往下执行同步代码。 当一个线程试图锁住一个处于biasable &amp; biased并且ThreadID不等于自己的ID时，这时由于存在锁竞争必须进入到第（4）步来撤销偏向锁。 运行同步代码块 偏向锁的解锁偏向锁解锁过程很简单，只需要测试下是否Object上的偏向锁模式是否还存在，如果存在则解锁成功不需要任何其他额外的操作。 由偏向锁转向轻量级锁是耗性能的，尤其再线程竞争激烈的时候，所以关闭偏向锁的话可以在高并发提高性能。-XX:-UseBiasedLocking 轻量级锁一个线程能够通过两种方式锁住一个对象：1、通过膨胀一个处于无锁状态（状态位001）的对象获得该对象的锁；2、对象已经处于膨胀状态（状态位00）但LockWord指向的monitor record的Owner字段为NULL，则可以直接通过CAS原子指令尝试将Owner设置为自己的标识来获得锁。 获取锁（monitorenter） 当对象处于无锁状态时（RecordWord值为HashCode，状态位为001），线程首先从自己的可用moniter record列表中取得一个空闲的moniter record，初始Nest和Owner值分别被预先设置为1和该线程自己的标识，一旦monitor record准备好然后我们通过CAS原子指令安装该monitor record的起始地址到对象头的LockWord字段来膨胀该对象，如果存在其他线程竞争锁的情况而调用CAS失败，则只需要简单的回到monitorenter重新开始获取锁的过程即可。 对象已经被膨胀同时Owner中保存的线程标识为获取锁的线程自己，这就是重入（reentrant）锁的情况，只需要简单的将Nest加1即可。不需要任何原子操作，效率非常高。 对象已膨胀但Owner的值为NULL，当一个锁上存在阻塞或等待的线程同时锁的前一个拥有者刚释放锁时会出现这种状态，此时多个线程通过CAS原子指令在多线程竞争状态下试图将Owner设置为自己的标识来获得锁，竞争失败的线程在则会进入到第四种情况（4）的执行路径。 对象处于膨胀状态同时Owner不为NULL(被锁住)，在调用操作系统的重量级的互斥锁之前先自旋一定的次数，当达到一定的次数时如果仍然没有成功获得锁，则开始准备进入阻塞状态（进入重量级锁，将ptr to heavy monitor的值标志为monitor record的起始地址），首先将rcThis的值原子性的加1，由于在加1的过程中可能会被其他线程破坏Object和monitor record之间的关联，所以在原子性加1后需要再进行一次比较以确保LockWord的值没有被改变，当发现被改变后则要重新进行monitorenter过程。同时再一次观察Owner是否为NULL，如果是则调用CAS参与竞争锁，锁竞争失败则进入到阻塞状态。 释放锁（monitorexit） 首先检查该对象是否处于膨胀状态并且该线程是这个锁的拥有者，如果发现不对则抛出异常； 检查Nest字段是否大于1，如果大于1则简单的将Nest减1并继续拥有锁，如果等于1，则进入到第（3）步； 检查RcThis是否大于0，设置Owner为NULL然后唤醒一个正在阻塞或等待的线程再一次试图获取锁，如果等于0则进入到第（4）步 缩小（deflate）一个对象，通过将对象的LockWord置换回原来的HashCode值来解除和monitor record之间的关联来释放锁，同时将monitor record放回到线程是有的可用monitor record列表。 重量级锁即操作系统的Mutex Lock锁。所有cas失败的线程不会再重试，挂起并等待唤醒。 这里有一篇外文文献：https://www.usenix.org/legacy/event/jvm01/full_papers/dice/dice.pdf","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}],"author":"土川"},{"title":"[Go基础]goroutine的一个精彩用法","slug":"Go基础-goroutine的一个精彩用法","date":"2018-07-22T13:03:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"3042075373.html","link":"","permalink":"https://htchz.cc/3042075373.html","excerpt":"这是一个利用goroutine输出素数的一个算法，找个时间写个java版的实现…","text":"这是一个利用goroutine输出素数的一个算法，找个时间写个java版的实现… goroutine实现算法的核心是，利用合数必定是素数的乘积的性质。用一个协程作为生成器（generate）开始生成“2、3、4.。。”的自然数，利用通道将自然数流入（filter的in、out参数传递）素数过滤器（filter）中，这样生成器生成的自然数如果能从第一个素数流经所有已经生成的filter，那么他是素数，并生成一个新的素数过滤器。第一版 12345678910111213141516171819202122232425262728293031323334353637// Copyright 2009 The Go Authors. All rights reserved.// Use of this source code is governed by a BSD-style// license that can be found in the LICENSE file.package mainpackage mainimport \"fmt\"// Send the sequence 2, 3, 4, ... to channel 'ch'.func generate(ch chan int) &#123; for i := 2; ; i++ &#123; ch &lt;- i // Send 'i' to channel 'ch'. &#125;&#125;// Copy the values from channel 'in' to channel 'out',// removing those divisible by 'prime'.func filter(in, out chan int, prime int) &#123; for &#123; i := &lt;-in // Receive value of new variable 'i' from 'in'. if i%prime != 0 &#123; out &lt;- i // Send 'i' to channel 'out'. &#125; &#125;&#125;// The prime sieve: Daisy-chain filter processes together.func main() &#123; ch := make(chan int) // Create a new channel. go generate(ch) // Start generate() as a goroutine. for &#123; prime := &lt;-ch fmt.Print(prime, \" \") ch1 := make(chan int) go filter(ch, ch1, prime) ch = ch1 &#125;&#125; 第二版 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// Copyright 2009 The Go Authors. All rights reserved.// Use of this source code is governed by a BSD-style// license that can be found in the LICENSE file.package mainimport ( \"fmt\")// Send the sequence 2, 3, 4, ... to returned channelfunc generate() chan int &#123; ch := make(chan int) go func() &#123; for i := 2; ; i++ &#123; ch &lt;- i &#125; &#125;() return ch&#125;// Filter out input values divisible by 'prime', send rest to returned channelfunc filter(in chan int, prime int) chan int &#123; out := make(chan int) go func() &#123; for &#123; if i := &lt;-in; i%prime != 0 &#123; out &lt;- i &#125; &#125; &#125;() return out&#125;func sieve() chan int &#123; out := make(chan int) go func() &#123; ch := generate() for &#123; prime := &lt;-ch ch = filter(ch, prime) out &lt;- prime &#125; &#125;() return out&#125;func main() &#123; primes := sieve() for &#123; fmt.Println(&lt;-primes) &#125;&#125;","categories":[{"name":"Golang基础","slug":"Golang基础","permalink":"https://htchz.cc/categories/Golang基础/"}],"tags":[{"name":"goroutine","slug":"goroutine","permalink":"https://htchz.cc/tags/goroutine/"}],"author":"土川"},{"title":"[Go基础]Go defer的那些坑","slug":"Go基础-Go-defer的那些坑","date":"2018-06-24T17:07:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"3084756888.html","link":"","permalink":"https://htchz.cc/3084756888.html","excerpt":"Go defer的那些坑不得不踩一下才爽","text":"Go defer的那些坑不得不踩一下才爽 闭包函数不会执行1234567891011121314151617181920package mainimport \"fmt\"func main() &#123; db := &amp;database&#123;&#125; defer db.connect() fmt.Println(\"query db...\")&#125;type database struct&#123;&#125;func (db *database) connect() (disconnect func()) &#123; fmt.Println(\"connect\") return func() &#123; fmt.Println(\"disconnect\") &#125;&#125; 你猜输出结果，是这样的： query db... connectdisconnect并没有被打印出来，connect在defer里执行完后保存执行域，返回的disconnect函数并没有被执行，要想执行，得使用这种方式 1234567func main() &#123; db := &amp;database&#123;&#125; defer db.connect()() fmt.Println(\"query db...\")&#125; 题外话，我也不懂这种即连接又关闭的目的是什么，只是做个defer执行闭包的演示 在执行块中使用 deferdefer是在函数执行完运行，而不是代码块执行完运行。 想要在函数执行完后对结果值进行嘿嘿嘿先看java的一段代码 123456789101112131415161718192021222324public class LambdaTest &#123; public static void main(String[] args) &#123; System.out.println(finalIntTest()); System.out.println(finalStringTest()); &#125; private static int finalIntTest()&#123; int i = 0; try &#123; return i; &#125; finally &#123; i++; &#125; &#125; private static String finalStringTest()&#123; String a = \"hi \"; try &#123; return a; &#125;finally &#123; a += \"en\"; &#125; &#125;&#125; java想在函数返回前对返回结果进行修改，可以用finally直接修改，输出是这样的 0 hi 虽然finally块对i自增、对字符串修改，但是丝毫不影响返回结果。 这是因为return操作不是原子性的。返回值是作为临时变量进行暂存，然后finally执行完后在返回临时变量 基本数据类型都属于值类型，没有引用，finally里面进行的操作不会对临时变量造成影响。至于String呢，虽然不是基本数据类型，但是他是final类型，每次操作返回的都是新引用，所以finally依旧不能修改返回结果。 明白这点后，可能对go的defer坑有些理解，上一些代码。 123456func f() (result int) &#123; defer func() &#123; result++ &#125;() return 0&#125; 这个函数返回的是1，go的返回值声明特性使得defer语句里可以持有返回值result。 1234567func f() (r int) &#123; t := 5 defer func() &#123; t = t + 5 &#125;() return t&#125; 这个函数返回的是5，因为return时将t当时的值放入r中，defer中的操作只是对t进行运算 123456func f() (r int) &#123; defer func(r int) &#123; r = r + 5 &#125;(r) return 1&#125; 这个函数返回的是1，因为匿名函数体中的r是局部变量，所以不会影响返回值r。 在golang中只有三种引用类型它们分别是切片slice、字典map、管道channel，其它的全部是值类型。所以defer里的函数拿到这些类型的引用的时候，是无论如何可以修改返回值的。","categories":[{"name":"Golang基础","slug":"Golang基础","permalink":"https://htchz.cc/categories/Golang基础/"}],"tags":[{"name":"坑","slug":"坑","permalink":"https://htchz.cc/tags/坑/"}],"author":"土川"},{"title":"[Json]secure json","slug":"Json-secure-json","date":"2018-06-08T05:31:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"235536411.html","link":"","permalink":"https://htchz.cc/235536411.html","excerpt":"安全的Json..","text":"安全的Json.. 学习go的后端框架gin的时候，官方文档提到了这种代码来返回安全的json 12345678910111213141516func main() &#123; r := gin.Default() // You can also use your own secure json prefix // r.SecureJsonPrefix(&quot;)]&#125;&apos;,\\n&quot;) r.GET(&quot;/someJSON&quot;, func(c *gin.Context) &#123; names := []string&#123;&quot;lena&quot;, &quot;austin&quot;, &quot;foo&quot;&#125; // Will output : while(1);[&quot;lena&quot;,&quot;austin&quot;,&quot;foo&quot;] c.SecureJSON(http.StatusOK, names) &#125;) // Listen and serve on 0.0.0.0:8080 r.Run(&quot;:8080&quot;)&#125; 在不设置前缀的情况下，默认在返回的json加上while(1);stackoverflow查阅一下，说是为了防止json hijacking（json劫持） 关于这方面的资料不是很多，中文的更少了。目前这些漏洞大都修复了。 假设有一个http://www.safe.com/contacts的接口， 返回的内容如下 12345678910[ &#123; &quot;id&quot;: 1, &quot;name&quot;: &quot;Riven&quot; &#125;, &#123; &quot;id&quot;: 2, &quot;name&quot;: &quot;Miss Fortune&quot; &#125;] 由于浏览器的同源策略，使得和安全网站的域名、端口、协议不同的页面是不能直接发起上面请求的，这样恶意网站http://www.evil.com/index.html并不能直接请求安全接口。以下情况是没有同源策略限制的： 页面中的链接。很常见的就是导航页面中的链接。 跨域资源获取，当然，浏览器限制了Javascript不能读写加载的内容。这种允许的跨域请求有:src属性(服务器可以拒绝)、&lt;iframe&gt;（服务器可以拒绝） json劫持是通过&lt;script&gt;来进行的。 首先，恶意者在http://www.evil.com/index.html的写入一行 &lt;script src=&quot;http://www.safe.com/contacts&quot;&gt;&lt;/script&gt;由于这种接口一般利用cookie来保证登录状态，所以恶意者把这个钓鱼网站以邮件的形式发到受害者的邮箱， 受害者懵逼点开网站之后，&lt;script&gt;标签就跑起来了，一个Get请求带上还没过期的cookie信息，返回了json数组。 重点来了，虽然浏览器不允许对资源的操作加载的内容，可是&lt;script&gt;是会运行加载到的东西的(这也是jsonp的运行机制),而json数组文本是可以被js引擎运行的，所以浏览器会构造一个Array，但是并没有赋值给谁。 于是恶意者就从构造函数开始动手，如这篇文章，重写Array的构造函数，或者重写Objects.prototype.__defineSetter__来进行原型函数的替换，从而加入自己的恶意代码，如把数据发送到自己的服务器去。 如果http://www.safe.com/contacts接口返回的是对象而不是数组呢，比如该接口返回{&quot;id&quot;: 2, &quot;name&quot;: &quot;batman&quot;}，那么js引擎就会报错，无法运行这个文本。 或者，在json数组前加上一些垃圾串、死循环代码，再用自己的json解析器解析出正确的json数组。比如在Gmail网页版里，就有这样的带有垃圾串的json数组返回。 在es5之后，这些漏洞都不能被利用了，但是如果我们要接别人这种返回带前缀json的api怎么办呢，这位老哥说JQuery用一个过滤器处理（只针对//, while(true);, for(;;);） 123456789101112131415161718192021$.ajaxSetup(&#123; dataFilter: function(data, type) &#123; var prefixes = [&apos;//&apos;, &apos;while(true);&apos;, &apos;for(;;);&apos;], i, l,, pos; if (type != &apos;json&apos; &amp;&amp; type != &apos;jsonp&apos;) &#123; return data; &#125; for (i = 0, l = prefixes.length; i &lt; l; i++) &#123; pos = data.indexOf(prefixes[i]); if (pos === 0) &#123; return data.substring(prefixes[i].length); &#125; &#125; return data; &#125;&#125;);","categories":[],"tags":[{"name":"Json","slug":"Json","permalink":"https://htchz.cc/tags/Json/"}],"author":"土川"},{"title":"[运维]找到 Java 进程中哪个线程占用了大量 CPU 处理时间","slug":"Java运维-找到-Java-进程中哪个线程占用了大量-CPU-处理时间","date":"2018-06-05T07:32:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"947951116.html","link":"","permalink":"https://htchz.cc/947951116.html","excerpt":"在Linux环境下找到最大线程占用","text":"在Linux环境下找到最大线程占用 原文传送门 本文的目的是在 Java进程中确定哪个线程正在占用CPU的时间。 当您的系统 CPU 负载居高不下时，这是一种有用的故障排除技术。 下面是详细步骤： 1.首先确定进程的 ID ，可以使用 jps -v 或者 top 命令直接查看 2.查看该进程中哪个线程占用大量 CPU，执行 top -H -p [PID] 结果如下： H参数表示显示线程比top高级点的还可以用htop命令，需要自行安装 可以发现编号为 350xx 的共有 9 个线程占用了 100% 的 CPU，好，接下来咱们随便取一个线程 ID ，假设我们想看编号为 35053 这个线程。 首先将 35053 转成 16 进制是 88ED （可以用开源中国在线工具转换） 3.接下来我们将进程中的所有线程输出到一个文件中，执行：jstack [PID] &gt; jstack.txt 4.在进程中查找对应的线程 ID，执行：cat jstack.txt | grep -i 88ED 结果是： &quot;HTTP Request From : /xxxx/blog/323432(120.27.143.239)&quot; #266 daemon prio=5 os_prio=0 tid=0x00007fcda4146800 nid=0x88e runnable [0x00007fcd54178000]由此可以看出在请求 /xxxx/blog/323432 链接的时候，服务器的处理线程占用了 100% 的 CPU。 找到问题后，接下来去解决就好了！","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"运维","slug":"运维","permalink":"https://htchz.cc/tags/运维/"}],"author":"土川"},{"title":"[正则表达式]replaceAll不为人知的故事","slug":"Java基础-replaceAll不为人知的故事","date":"2018-05-09T07:37:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"2850894714.html","link":"","permalink":"https://htchz.cc/2850894714.html","excerpt":"String.replaceAll和String.replace的区别是，String.replaceAll使用的匹配模式是正则表达式。但是第二参数replacement不是简单的字符串，里面有点特殊的东西。","text":"String.replaceAll和String.replace的区别是，String.replaceAll使用的匹配模式是正则表达式。但是第二参数replacement不是简单的字符串，里面有点特殊的东西。 \\的问题已知String str = &quot;a\\\\bc&quot;,请问利用String.replaceAll把str输出为a\\\\bc到控制台怎么做？答案是：System.out.println(str.replaceAll(&quot;\\\\\\\\&quot;, &quot;\\\\\\\\\\\\\\\\&quot;))我们知道一个反斜杠用java正则来表示需要这么写&quot;\\\\\\\\&quot;，所以我一开始这么写str.replaceAll(&quot;\\\\\\\\&quot;, &quot;\\\\\\\\&quot;,结果输出的却是： a\\bc少了一杠，于是我不明白，replacement用&quot;\\\\\\\\&quot;表示两个斜杠有错？ $与\\在String.replaceAll的注释是这样的， Note that backslashes ({@code }) and dollar signs ({@code $}) in the replacement string may cause the results to be different than if it were being treated as a literal replacement string; 接下来他让我详情请看Matcher类注释，而在java.util.regex.Matcher#replaceAll里是这么注释的 Dollar signs may be treated as references to captured subsequences as described above, and backslashes are used to escape literal characters in the replacement string. $在replacement里可以用来表达pattern里的子序列，比如你真的会用java replaceAll函数吗？里举例的 System.out.println(&quot;abac&quot;.replaceAll(&quot;a(\\\\w)&quot;, &quot;$1$1&quot;)); //bbcc System.out.println(&quot;abac&quot;.replaceFirst(&quot;a(\\\\w)&quot;, &quot;$1$1&quot;)); //bbac所以在replacement里，我们要表达$怎么办？用\\来转义，于是代码里就这么写&quot;\\\\$&quot;接着在replacement里，我们要表达特殊的\\怎么办，需要用\\来转义\\，于是代码里就这么写\\\\\\\\。 而在replacement里，其他的转义该怎么写还是怎么写，比如&quot;System.out.println(&quot;abcd&quot;.replaceAll(&quot;a&quot;, &quot;\\t&quot;));&quot;,”a”就被替换成制表符了 按我的理解是存在两种转义，和正则处理一样，当你写&quot;\\\\&quot;的时候，Java第一次转义后在内存里就是\\，replacement检测到反斜杠，会将后面的字符表示为纯文本，所以写System.out.println(s.replaceAll(&quot;a&quot;, &quot;\\\\&quot;));是会报异常的，因为&quot;\\\\&quot;存在第二次转义，而第二次转义的时候后面没跟字符串，所以报异常。idea在写正则的时候，&quot;\\\\&quot;是会提示错误的，但是String.replaceAll里replacement写&quot;\\\\&quot;只有在运行时才检测得到。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"正则","slug":"正则","permalink":"https://htchz.cc/tags/正则/"}],"author":"土川"},{"title":"[Time]一个关于获取系统时间的优化","slug":"Time-一个关于获取系统时间的优化","date":"2018-04-27T18:10:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"3428339883.html","link":"","permalink":"https://htchz.cc/3428339883.html","excerpt":"这是在某个插件里看到的代码[滑稽]","text":"这是在某个插件里看到的代码[滑稽] 查了一下说是把System.currentTimeMillis()放到一个定时任务里可以提高性能，其实写个main测了一下感觉要很大的量级才有效果 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import java.util.concurrent.BrokenBarrierException;import java.util.concurrent.CyclicBarrier;import java.util.concurrent.TimeUnit;/** * 毫秒级系统时间, 显式调用System.currentTimeMillis()据说费性能 * */public class TimeUtil implements Runnable &#123; private static volatile long currentTimeMillis; static &#123; currentTimeMillis = System.currentTimeMillis(); // fetch system time for init Thread deamon = new Thread(new TimeUtil()); deamon.setDaemon(true); deamon.setName(\"time tick thread\"); deamon.start(); &#125; public void run() &#123; while(true)&#123; currentTimeMillis = System.currentTimeMillis(); try &#123; TimeUnit.MILLISECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; //unreachable &#125; &#125; &#125; public static long currentTimeMillis()&#123; return currentTimeMillis; &#125; public static void main(String[] args) &#123; int loop = 100000000; long start = System.currentTimeMillis(); CyclicBarrier barrier = new CyclicBarrier(2, () -&gt; System.out.println(\"begin\")); Thread thread1 = new Thread(() -&gt; &#123; try &#123; System.out.println(\"t1 start\"); barrier.await(); for (int i = 0; i &lt; loop; i++) &#123; System.currentTimeMillis(); &#125; System.out.println(\"t1:\" + (System.currentTimeMillis() - start) +\"ms\"); &#125; catch (InterruptedException | BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125;); Thread thread2 = new Thread(() -&gt; &#123; try &#123; System.out.println(\"t2 start\"); barrier.await(); for (int i = 0; i &lt; loop; i++) &#123; TimeUtil.currentTimeMillis(); &#125; System.out.println(\"t2:\" + (System.currentTimeMillis() - start) +\"ms\"); &#125; catch (InterruptedException | BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125;); thread2.start(); thread1.start(); &#125;&#125; 输出 t2 start t1 start begin t2:50ms t1:1135ms","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[],"author":"土川"},{"title":"[Cron]linux定时任务的坑","slug":"Cron-linux定时任务的坑","date":"2018-04-17T18:23:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"3058313917.html","link":"","permalink":"https://htchz.cc/3058313917.html","excerpt":"写了个脚本定时执行，有天发现命令没有正确找到我配在PATH的环境变量。","text":"写了个脚本定时执行，有天发现命令没有正确找到我配在PATH的环境变量。 用了gdrive来备份博客，日志看到 /root/gdrive-bak-blog.sh: line 2: gdrive: command not found百度一波发现cron读取环境变量有点搓，有两个解决方案 crontab里的命令先执行source 0 8 * * * source /etc/profile &amp;&amp; /root/gdrive-bak-blog.sh &gt; /root/blog-bak.out 2&gt;&amp;1 脚本里执行加载环境变量 #!/bin/sh source /etc/profile ...附上备份脚本 #! /bin/bash oldFileId=`gdrive list | grep &apos;hzblog.bak.tar.gz&apos; | awk &apos;{print $1}&apos;` if [ -z $oldFileId ] then echo &quot;no backup for hzblog.bak.tar.gz&quot; else gdrive delete $oldFileId echo &quot;hzblog.bak.tar.gz[id:$oldFileId] deleted&quot; fi rm -f /root/hzblog.bak.tar.gz tar -czPf hzblog.bak.tar.gz /root/hzblog parentId=`gdrive list | grep &apos;hzblog&apos; | awk &apos;{print $1}&apos;` gdrive upload -p $parentId /root/hzblog.bak.tar.gz echo &quot;hzblog.bak.tar.gz uploaded&quot;","categories":[{"name":"Linux","slug":"Linux","permalink":"https://htchz.cc/categories/Linux/"}],"tags":[],"author":"土川"},{"title":"[JDK8]Stream toMap遇到的坑","slug":"JDK8-Stream-toMap遇到的坑","date":"2018-04-17T03:19:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"2688045267.html","link":"","permalink":"https://htchz.cc/2688045267.html","excerpt":"略懂略懂。","text":"略懂略懂。 key重复写了这么一句代码 Map&lt;Long, Integer&gt; map = module.getStocks().stream().collect(Collectors.toMap(SkuStockDTO::getSkuId, SkuStockDTO::getSkuStock));当SkuStockDTO::getSkuId拿到相同id时会报java.lang.IllegalStateException: Duplicate key xxx其实java8已经给我们提供了解决的方式: 方法的第三个参数体现的第三个参数是一个merge策略 value为nullvalue为null的时候是会报空指针，java.util.stream.Collectors#toMap其实最终都是调用一个方法 12345678910111213141516171819202122232425262728293031 * @param &lt;T&gt; the type of the input elements * @param &lt;K&gt; the output type of the key mapping function * @param &lt;U&gt; the output type of the value mapping function * @param &lt;M&gt; the type of the resulting &#123;@code Map&#125; * @param keyMapper a mapping function to produce keys * @param valueMapper a mapping function to produce values * @param mergeFunction a merge function, used to resolve collisions between * values associated with the same key, as supplied * to &#123;@link Map#merge(Object, Object, BiFunction)&#125; * @param mapSupplier a function which returns a new, empty &#123;@code Map&#125; into * which the results will be inserted * @return a &#123;@code Collector&#125; which collects elements into a &#123;@code Map&#125; * whose keys are the result of applying a key mapping function to the input * elements, and whose values are the result of applying a value mapping * function to all input elements equal to the key and combining them * using the merge function * * @see #toMap(Function, Function) * @see #toMap(Function, Function, BinaryOperator) * @see #toConcurrentMap(Function, Function, BinaryOperator, Supplier) */public static &lt;T, K, U, M extends Map&lt;K, U&gt;&gt;Collector&lt;T, ?, M&gt; toMap(Function&lt;? super T, ? extends K&gt; keyMapper, Function&lt;? super T, ? extends U&gt; valueMapper, BinaryOperator&lt;U&gt; mergeFunction, Supplier&lt;M&gt; mapSupplier) &#123; BiConsumer&lt;M, T&gt; accumulator = (map, element) -&gt; map.merge(keyMapper.apply(element), valueMapper.apply(element), mergeFunction); return new CollectorImpl&lt;&gt;(mapSupplier, accumulator, mapMerger(mergeFunction), CH_ID);&#125; 可以看到始终都会调用Map.merge，而这个方法有如下代码 1Objects.requireNonNull(value); 解决方法是不用java.util.stream.Collectors#toMap，改用下面的姿势 12Map&lt;Integer, Boolean&gt; collect = list.stream() .collect(HashMap::new, (m,v)-&gt;m.put(v.getId(), v.getAnswer()), HashMap::putAll);","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"jdk8","slug":"jdk8","permalink":"https://htchz.cc/tags/jdk8/"}],"author":"土川"},{"title":"[JVM]GC那些事(八)G1","slug":"JVM-GC那些事-八-G1","date":"2018-04-02T09:23:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"2687941502.html","link":"","permalink":"https://htchz.cc/2687941502.html","excerpt":"G1（Garbage First或者垃圾优先收集器）是CMS的下一代垃圾收集器，设计初衷是为了尽量缩短处理超大堆（大于4GB）时产生的停顿。相对于CMS的优势而言是内存碎片的产生率大大降低。","text":"G1（Garbage First或者垃圾优先收集器）是CMS的下一代垃圾收集器，设计初衷是为了尽量缩短处理超大堆（大于4GB）时产生的停顿。相对于CMS的优势而言是内存碎片的产生率大大降低。 参考深入理解 Java G1 垃圾收集器 启用G1在启动参数加上下面配置 -XX:+UseG1GC -Xmx32g -XX:MaxGCPauseMillis=200 其中-XX:+UseG1GC为开启G1垃圾收集器，-Xmx32g 设计堆内存的最大内存为32G，-XX:MaxGCPauseMillis=200设置GC的最大暂停时间为200ms。如果我们需要调优，在内存大小一定的情况下，我们只需要修改最大暂停时间即可。 物理空间分代取消分代现在只存在概念上，每一块内存可以设置为老年代或者新生代。 取而代之的是，G1算法将堆划分为若干个区域（Region），它仍然属于分代收集器。不过，这些区域的一部分包含新生代，新生代的垃圾收集依然采用暂停所有应用线程的方式，将存活对象拷贝到老年代或者Survivor空间。老年代也分成很多区域，G1收集器通过将对象从一个区域复制到另外一个区域，完成了清理工作。这就意味着，在正常的处理过程中，G1完成了堆的压缩（至少是部分堆的压缩），这样也就不会有cms内存碎片问题的存在了。 在G1中，还有一种特殊的区域，叫Humongous区域。 如果一个对象占用的空间超过了分区容量50%以上，G1收集器就认为这是一个巨型对象。这些巨型对象，默认直接会被分配在年老代，但是如果它是一个短期存在的巨型对象，就会对垃圾收集器造成负面影响。为了解决这个问题，G1划分了一个Humongous区，它用来专门存放巨型对象。如果一个H区装不下一个巨型对象，那么G1会寻找连续的H分区来存储。为了能找到连续的H区，有时候不得不启动Full GC。 在java 8中，永久代也移动到了普通的堆内存空间中，改为元空间。 对象分配策略说起大对象的分配，我们不得不谈谈对象的分配策略。它分为3个阶段： TLAB(Thread Local Allocation Buffer)线程本地分配缓冲区 Eden区中分配 Humongous区分配 TLAB为线程本地分配缓冲区，它的目的为了使对象尽可能快的分配出来。如果对象在一个共享的空间中分配，我们需要采用一些同步机制来管理这些空间内的空闲空间指针。在Eden空间中，每一个线程都有一个固定的分区用于分配对象，即一个TLAB。分配对象时，线程之间不再需要进行任何的同步。 对TLAB空间中无法分配的对象，JVM会尝试在Eden空间中进行分配。如果Eden空间无法容纳该对象，就只能在老年代中进行分配空间。 Minor GC和Mix GCMinor GCMinor GC主要是对Eden区进行GC，它在Eden空间耗尽时会被触发。在这种情况下，Eden空间的数据移动到Survivor空间中，如果Survivor空间不够，Eden空间的部分数据会直接晋升到年老代空间。Survivor区的数据移动到新的Survivor区中，也有部分数据晋升到老年代空间中。最终Eden空间的数据为空，GC停止工作，应用线程继续执行。 这时，我们需要考虑一个问题，如果仅仅GC 新生代对象，我们如何找到所有的根对象呢？ 老年代的所有对象都是根么？那这样扫描下来会耗费大量的时间。于是，G1引进了RSet的概念。它的全称是Remembered Set，作用是跟踪指向某个heap区内的对象引用。在CMS中，也有RSet的概念，在老年代中有一块区域用来记录指向新生代的引用。这是一种point-out，在进行Minor GC时，扫描根时，仅仅需要扫描这一块区域，而不需要扫描整个老年代。 但在G1中，并没有使用point-out，这是由于一个分区太小，分区数量太多，如果是用point-out的话，会造成大量的扫描浪费，因为每次只处理一小部分分区，有些根本不需要GC的分区引用也扫描了。于是G1中使用point-in来解决。point-in的意思是哪些分区引用了当前分区中的对象。这样，仅仅将这些对象当做根来扫描就避免了无效的扫描。由于新生代有多个，那么我们需要在新生代之间记录引用吗？这是不必要的，原因在于每次GC时，所有新生代都会被扫描，所以只需要记录老年代到新生代之间的引用即可。 需要注意的是，如果引用的对象很多，赋值器需要对每个引用做处理，赋值器开销会很大，为了解决赋值器开销这个问题，在G1 中又引入了另外一个概念，卡表（Card Table）。一个Card Table将一个分区在逻辑上划分为固定大小的连续区域，每个区域称之为卡。卡通常较小，介于128到512字节之间。Card Table通常为字节数组，由Card的索引（即数组下标）来标识每个分区的空间地址。默认情况下，每个卡都未被引用。当一个地址空间被引用时，这个地址空间对应的数组索引的值被标记为”0″，即标记为脏被引用，此外RSet也将这个数组下标记录下来。一般情况下，这个RSet其实是一个Hash Table，Key是别的Region的起始地址，Value是一个集合，里面的元素是Card Table的Index。 Minor GC 阶段： 阶段1：根扫描静态和本地对象被扫描 阶段2：更新RS处理dirty card队列更新RS 阶段3：处理RS检测从年轻代指向年老代的对象 阶段4：对象拷贝拷贝存活的对象到survivor/old区域 阶段5：处理引用队列软引用，弱引用，虚引用处理 Mix GCMix GC不仅进行正常的新生代垃圾收集，同时也回收部分后台扫描线程标记的老年代分区。 它的GC步骤分2步： 全局并发标记（global concurrent marking） 拷贝存活对象（evacuation） 在进行Mix GC之前，会先进行global concurrent marking（全局并发标记）。 global concurrent marking的执行过程是怎样的呢？ 在G1 GC中，它主要是为Mixed GC提供标记服务的，并不是一次GC过程的一个必须环节。global concurrent marking的执行过程分为五个步骤： 初始标记（initial mark，STW）在此阶段，G1 GC 对根进行标记。该阶段与常规的 (STW) 年轻代垃圾回收密切相关。 根区域扫描（root region scan）G1 GC 在初始标记的存活区扫描对老年代的引用，并标记被引用的对象。该阶段与应用程序（非 STW）同时运行，并且只有完成该阶段后，才能开始下一次 STW 年轻代垃圾回收。 并发标记（Concurrent Marking）G1 GC 在整个堆中查找可访问的（存活的）对象。该阶段与应用程序同时运行，可以被 STW 年轻代垃圾回收中断 最终标记（Remark，STW）该阶段是 STW 回收，帮助完成标记周期。G1 GC 清空 SATB 缓冲区，跟踪未被访问的存活对象，并执行引用处理。 清除垃圾（Cleanup，STW）在这个最后阶段，G1 GC 执行统计和 RSet 净化的 STW 操作。在统计期间，G1 GC 会识别完全空闲的区域和可供进行混合垃圾回收的区域。清理阶段在将空白区域重置并返回到空闲列表时为部分并发。 三色标记算法提到并发标记，我们不得不了解并发标记的三色标记算法。它是描述追踪式回收器的一种有用的方法，利用它可以推演回收器的正确性。 首先，我们将对象分成三种类型的。 黑色:根对象，或者该对象与它的子对象都被扫描 灰色:对象本身被扫描,但还没扫描完该对象中的子对象 白色:未被扫描对象，扫描完成所有对象之后，最终为白色的为不可达对象，即垃圾对象 当GC开始扫描对象时，按照如下图步骤进行对象的扫描： 根对象被置为黑色，子对象被置为灰色。继续由灰色遍历,将已扫描了子对象的对象置为黑色。 遍历了所有可达的对象后，所有可达的对象都变成了黑色。不可达的对象即为白色，需要被清理。这看起来很美好，但是如果在标记过程中，应用程序也在运行，那么对象的指针就有可能改变。这样的话，我们就会遇到一个问题：对象丢失问题 我们看下面一种情况，当垃圾收集器扫描到下面情况时： A.c=C B.c=null这样，对象的状态图变成如下情形：这时候垃圾收集器再标记扫描的时候就会下图成这样：很显然，此时C是白色，并且A已经遍历完，C不会被扫描到，被认为是垃圾需要清理掉，显然这是不合理的。那么我们如何保证应用程序在运行的时候，GC标记的对象不丢失呢？有如下2中可行的方式： 在插入的时候记录对象 在删除的时候记录对象 刚好这对应CMS和G1的2种不同实现方式： 在CMS采用的是增量更新（Incremental update），只要在写屏障（write barrier）里发现要有一个白对象的引用被赋值到一个黑对象 的字段里，那就把这个白对象变成灰色的。即插入的时候记录下来。 写屏障(write-barrier)。写入屏障意思就是，如果应用线程修改了对象A的成员变量对象引用，那么就把A在的卡表置为脏卡，并交由下一次remark处理。读屏障(read-barrier)。效率较低。在标记复制算法中，处里A的子对象B，如果B未被扫描，则将对象复制，置为活对象。hotspot 虚拟机使用字节码解释器、JIT编译器、 write barrier维护 card table。当字节码解释器或者JIT编译器更新了引用，就会触发write barrier操作card table. 在G1中，使用的是STAB（snapshot-at-the-beginning）的方式，删除的时候记录所有的对象，它有3个步骤： 1，在开始标记的时候生成一个快照图标记存活对象 2，在并发标记的时候所有被改变的对象入队（在write barrier里把所有旧的引用所指向的对象都变成非白的，比如C变成非白的） 3，C如果是游离的垃圾，将在下次被收集，总之这一次不会被清理。 这样，G1到现在可以知道哪些老的分区可回收垃圾最多。 当全局并发标记完成后，在某个时刻，就开始了Mix GC。这些垃圾回收被称作“混合式”是因为他们不仅仅进行正常的新生代垃圾收集，同时也回收部分后台扫描线程标记的分区。混合式垃圾收集如下图：混合式GC也是采用的复制的清理策略，当GC完成后，会重新释放空间。 G1调优实践未完…","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://htchz.cc/tags/JVM/"},{"name":"GC","slug":"GC","permalink":"https://htchz.cc/tags/GC/"}],"author":"土川"},{"title":"[JVM]GC那些事(七)CMS","slug":"JVM-GC那些事-七-CMS","date":"2018-04-02T00:20:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"4242301031.html","link":"","permalink":"https://htchz.cc/4242301031.html","excerpt":"详细说一下CMS","text":"详细说一下CMS 什么是CMSConcurrent Mark Sweep。看名字就知道，CMS是一款并发、使用标记-清除算法的gc。CMS是针对老年代进行回收的GC。 CMS有什么用CMS以获取最小停顿时间为目的。在一些对响应时间有很高要求的应用或网站中，用户程序不能有长时间的停顿，CMS 可以用于此场景。 执行流程(6个阶段) 初始标记(STW) 并发标记 并发预清理 重标记(STW) 并发清理 重置 初始标记（扫描新生代） 需要stw，暂停用户线程 标记GC ROOT直接关联到的对象 并发标记 GC ROOT TRACING，继续运行用户线程，标记活动和用户线程并发进行 由初始标记出发，所有可到达的对象都在本阶段中标记 并发预清理阶段 与重标记的功能相似 由于重标记会导致stw，所以这个阶段目的为了尽可能减少stw时间 此阶段标记从新生代晋升的对象、新分配到老年代的对象以及在并发阶段被修改了的对象。 虽然CMS是针对老年代进行回收的GC，但为了完成GC ROOT TRACING, 仍要扫描新生代 rescan阶段扫描新生代和老年代拖慢时间CMS号称是停顿时间最短的GC，如此长的停顿时间肯定是不能接受的。如何解决呢？ 必须要有一个能够快速识别新生代和老年代活着的对象的机制 先说新生代。你应该已经知道，新生代垃圾回收完剩下的对象全是活着的，并且活着的对象很少。如果在扫描新生代前进行一次Minor GC，情况是不是就变得好很多？CMS 有两个参数：CMSScheduleRemarkEdenSizeThreshold、CMSScheduleRemarkEdenPenetration，默认值分别是2M、50%。两个参数组合起来的意思是预清理后，eden空间使用超过2M时启动可中断的并发预清理（CMS-concurrent-abortable-preclean），直到eden空间使用率达到50%时中断，进入remark阶段。如果能在可中止的预清理阶段发生一次Minor GC,那就万事大吉、天下太平了。这里有一个小问题,可终止的预清理要执行多长时间来保证发生一次Minor GC? 答案是没法保证。道理很简单，因为垃圾回收是JVM自动调度的,什么时候进行GC我们控制不了。但此阶段总有一个执行时间吧？是的。CMS提供了一个参数CMSMaxAbortablePrecleanTime ，默认为5S。只要到了5S，不管发没发生Minor GC，有没有到CMSScheduleRemardEdenPenetration都会中止此阶段，进入remark。 如果在5S内还是没有执行Minor GC怎么办？CMS提供CMSScavengeBeforeRemark参数，使remark前强制进行一次Minor GC。这样做利弊都有。好的一面是减少了remark阶段的停顿时间;坏的一面是Minor GC后紧跟着一个remark pause。如此一来，停顿时间也比较久。 实际上为了减少remark阶段的STW时间，预清理阶段会尽可能多做一些事情来减少remark停顿时间。remark的rescan阶段是多线程的，为了便于多线程扫描新生代，预清理阶段会将新生代分块。每个块中存放着多个对象，这样remark阶段就不需要从头开始识别每个对象的起始位置。多个线程的职责就很明确了，把分块分配给多个线程，很快就扫描完。遗憾的是，这种办法仍然是建立在发生了Minor GC的条件下。如果没有发生Minor GC，top（下一个可以分配的地址空间）以下的所有空间被认为是一个块(这个块包含了新生代大部分内容)。这种块对于remark阶段并不会起到多少作用，因此并行效率也会降低。 老年代老年代维护了一个Remembered Set，这个其实是为了Minor GC服务的。通过在老年代中有一块区域用来记录指向新生代的引用，在进行Minor GC扫描根时，仅仅需要扫描这一块区域，而不需要扫描整个老年代。 重标记 重标记需要STW（Stop The World） 暂停所有用户线程，重新扫描堆中的对象，进行可达性分析,标记活着的对象。 有一个rescan阶段，并行进行，扫描新生代和老年代 多线程操作 并发清理并发清理。用户线程被重新激活，同时清理那些无效的对象。 重置CMS清除内部状态，为下次回收做准备。 存在的问题 并发进行，占用cpu资源。有个增量模式（i-CMS）使gc线程和用户线程交替进行，jdk8已经被声明为“deprecated” 并发清理阶段用户线程还在运行，这段时间就可能产生新的垃圾，新的垃圾在此次GC无法清除，只能等到下次清理。这些垃圾有个专业名词：浮动垃圾。由于垃圾回收阶段用户线程仍在执行，必需预留出内存空间给用户线程使用。因此不能像其他回收器那样，等到老年代满了再进行GC。有个CMSInitiatingOccupancyFraction设置一个百分比，表明达到这个值就进行垃圾回收，见《[JVM]GC那些事(六)MinorGC与FullGC》的concurrent mode failure关键字 前两个是并发造成的，接下来是‘标记-清除’算法造成的，这个算法造成空间碎片，虚拟机还提供了另外一个参数CMSFullGCsBeforeCompaction，用于设置执行多少次不压缩的Full GC后，跟着来一次带压缩的（默认为0，每次进入Full GC时都进行碎片整理）。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://htchz.cc/tags/JVM/"},{"name":"GC","slug":"GC","permalink":"https://htchz.cc/tags/GC/"}],"author":"土川"},{"title":"[JVM]GC那些事(六)MinorGC与FullGC","slug":"JVM-GC那些事-六-MinorGC与FullGC","date":"2018-04-02T00:11:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"527051980.html","link":"","permalink":"https://htchz.cc/527051980.html","excerpt":"面试只要沾到jvm，就肯定会沾到GC，沾到GC，就肯定会沾到这两个家伙。不同的垃圾收集器的GC方式不一样，我们在讨论的时候最好基于某种垃圾收集器来讲。","text":"面试只要沾到jvm，就肯定会沾到GC，沾到GC，就肯定会沾到这两个家伙。不同的垃圾收集器的GC方式不一样，我们在讨论的时候最好基于某种垃圾收集器来讲。 Minor GC？Full GC？ minor gc指的是在年轻代的gc full gc指的是整个堆的清理，包括年轻代和老年代(老年代的gc一般叫major gc) 什么时候会触发Minor GC我们拿CMS来举例子。 Eden区域满了，或者新创建的对象大小 &gt; Eden所剩空间 CMS设置了CMSScavengeBeforeRemark参数，这样在CMS的Remark之前会先做一次Minor GC来清理新生代，加速之后的Remark的速度。这样整体的stop-the world时间反而短 Full GC的时候会先触发Minor GC 什么时候触发Full GC Minor GC后对象晋升老年代，由于担保机制(看《[JVM]GC那些事(四)对象的分配回收策略》)，两种情况触发Full GC，一种晋升平均大小 &gt; 老年代剩余空间（基于历史平均水平），另一种存活对象 &gt; 老年代剩余空间（基于下一次可能要晋升的最大水平），两种情况都属于promotion failure 发生concurrent mode failure会引起Full GC，这种情况下会使用Serial Old收集器，是单线程的，对GC的影响很大。大对象(由PretenureSizeThreshold控制新生代直接晋升老年代的对象size阀值)不能进入到老年代，只有stop the world来暂停用户线程，执行GC清理。可以通过设置CMSInitiatingOccupancyFraction预留合适的CMS执行时剩余的空间 （jdk8 已完全移除永久die，将此类信息放入本地内存）Perm永久代空间不足会触发Full GC，可以让CMS清理永久代的空间。设置CMSClassUnloadingEnabled即可 System.gc()引起的Full GC，可以设置DisableExplicitGC来禁止调用System.gc引发Full GC concurrent mode failure，即启动不了并发清理，因为内存不足导致并发情况下，还没来得及清理内存就爆了，所以要退化为串行的垃圾收集promotion failure，即担保机制失败 什么时候OOM OOM不是内存达到100%才报的 当花在GC的时间超过了GCTimeLimit，这个值默认是98% 当GC后的容量小于GCHeapFreeLimit，这个值默认是2% 什么是空间不够 剩余空间不够不是说整体的空间不够分配某个对象，而是说连续的空间不够分配给某个对象。所以一旦内存碎片大多就可能发生剩余空间不够的问题，所以CMS这种收集器，需要在标记-清除几次之后进行压缩，进行优化。CMSFullGCsBeforeCompaction可以设置进行几次清除之后进行压缩 其他的一些tip JMI默认会一个小时调用一次System.gc()清理缓存，所以可以DisableExplicitGC，也可以设置sun.rmi.dgc.client.gcInterval和sun.rmi.dgc.server.gcInterval参数来规定JMI清理的时间 一旦对象进入了老年代，那么只有触发CMS(只针对CMS而言)或者Full GC的时候才能被清除。 CMS不等于Full GC，很多人会认为CMS肯定会引发Minor GC。CMS是针对老年代的GC策略，原则上它不会去清理新生代，只有设置CMSScavengeBeforeRemark优化时，或者是concurrent mode failure的时候才会去做Minor GC。 对于性能调优来说，应该理解对于给定的硬件，给定的算法(垃圾收集器)，单个/多个线程单位时间内能够回收的空间是接近一个常量的。如果想要缩短GC的时候，就要考虑是否要相应调小空间 CMS收集器会了减少stop the world的时间，让GC线程和业务线程并发，这样也就相对拉长了CMS收集器单次GC的时间 尽可能地让对象停留在新生代，因为新生代采用了复制算法，相对收回得更快，而且Minor GC的次数肯定比Full GC多，那么对象在新生代被清除的更能性会更高。而对象一旦进入到老年代，那么只有Full GC时才会回收，对象在整个系统停留的时间就会很长，很可能创建的它的线程早就死了，而它还活着 为了尽可能让对象停留在新生代，就要注意设置Survivor区域的大小，因为它直接和对象是否进入老年代相关。之前就遇到过这种情况，明明新生代还有很大的空间，但是每次Minor GC后总是有对象进入到了老年代。后来发现由于Survivor太小，导致Tenuring Threshold为1，意思是年龄为1的对象大小超过了Survivor / 2(可通过TargetSurvivorRatio来调节，默认是50，即1/2)，年龄只要超过1的对象这时候就要直接进入老年代了。而进入老年代，对象就只有在Full GC的时候才会被清除。而如果调大了Survivor空间，让对象对象尽量接近Max Tenuring Threshold时才进入到老年代，这时候会大大减少老年代的对象大小，并且让对象在新生代停留时间变长，提高了它们被快速清理出系统的概率。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://htchz.cc/tags/JVM/"},{"name":"GC","slug":"GC","permalink":"https://htchz.cc/tags/GC/"}],"author":"土川"},{"title":"[JVM]GC那些事(五)垃圾收集器","slug":"JVM-GC那些事-五-垃圾收集器","date":"2018-04-01T23:52:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"1597842502.html","link":"","permalink":"https://htchz.cc/1597842502.html","excerpt":"其实到这篇，个人感觉GC最重要东西还没讲到。在这些收集器中，CMS、G1是要着重了解的。","text":"其实到这篇，个人感觉GC最重要东西还没讲到。在这些收集器中，CMS、G1是要着重了解的。 列一下从古到今主流的垃圾收集器 Serial收集器——最基本、发展历史最悠久的代收集器Serial收集器是一个单线程的收集器，而且进行垃圾回收时，必须停掉所有其他线程优点：简单高效，单线程可以获得最高的收集效率 Client端下的虚拟机是个很好的新生代收集器 ParNew 收集器——Serial的多线程版本除了使用多条线程进行垃圾收集之外，其余行为包括Serial收集器可用的所有控制参数、收集算法、stop the world、对象分配规则、回收策略等都与Serial收集器一样 Server模式下的的首选新生代收集器，可以和CMS配合工作 效果不一定超过Serial，但随着CPU数量的增加，他对于GC是系统资源的有效利用还是很有好处的。 Parallel Scavenge收集器Parallel Scavenge是一个新生代收集器，也使用复制算法，并行的多线程收集器。Parallel Scavenge的目标是达到一个可控制的吞吐量 吞吐量 = 运行用户代码时间 / （运行用户代码时间 + 垃圾收集时间） 虚拟机总共运行了100分钟，其中垃圾手机花掉1分钟，吞吐量就99% Parallel Scavenge用了两个参数用于精确控制吞吐量，分别是控制最大垃圾收集停顿时间（-XX:MaxGCPauseMillis）和直接设置吞吐量大小（GCTimeRatio）的参数 MaxGCPauseMillis参数允许的值是一个大于0的毫秒数，收集器尽可能地保证内存回收花费时间不超过设定值。 若参数太小，GC停顿时间是以牺牲吞吐量和新生代空间来换取。把新生代调小，收集速度变快，但GC会更频繁，吞吐量就下降了。 GCTimeRatio是一个[0,100]的整数，也就是垃圾收集时间占总时间的比率，相当于吞吐量的倒数。 如果把参数设置为19， 则允许的最大GC时间就占总时间的5%5（即1/（1+19 ）） 由于和吞吐量关系密切，Parallel Scavenge也被称为“吞吐量优先”收集器 Parallel Scavenge还有一个参数 -XX:+UseAdaptiveSizePolicy,这是个开关参数，当开关打开后，就不需要手工指定：新生代的大小（-Xmn）、Eden与Survivor的比例（-XX:SurvivorRatio）、晋升老年代对象大小（-XX:PretenureSizeThreshold）等细节参数了。虚拟机会根据当前系统情况收集性能监控信息，动态调整这些参数以达到最合适的停顿时间或吞吐量，这叫GC自适应的调节策略（GC Ergonomics） 如果用户对收集器运作不了解，可以将优化任务交给虚拟机，只要设置好基本参数（如最大堆），然后使用控制最大垃圾收集停顿时间（-XX:MaxGCPauseMillis）和直接设置吞吐量大小（GCTimeRatio）给虚拟机设定一个优化目标 自适应调节策略也是Parallel Scavenge和ParNew的重要区别 Serial Old收集器Serial Old是Serial的老年代版本，主要也是给Client模式下的虚拟机使用。如果在Server 模式下，还有两大用途： 一种是在jdk1.5及以前版本中与Parallel Scavenge收集器搭配使用 一种是作为CMS的后备预案，在并发收集发生Concurrent Mode Failure时使用 Parallel Old 收集器Parallel Old 是Parallel Scavenge的老年代版本，jdk1.6之后才提供，解决在server端Serial Old性能上的拖累，若使用Serial Old + Parallel Scavenge，这种组合的吞吐量不一定有 ParNew + CMS的组合给力 注重吞吐量和CPU资源敏感的场合，都可以优先考虑 Parallel Old + Parallel Scavengede 组合 CMS 收集器CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器，在网站设计中此收集器就符合需求。 运作过程： 初始标记 并发标记 重新标记 并发清除 其中初始标记和重新标记这两个步骤仍然需要“Stop The World”，初始标记只是标记GC Roots能直接关联的对象，速度很快并发标记进行GC Roots Tracing 的过程，而重新标记阶段是为了修正并发标记期间产生变动的标记，停顿&gt;初始标记，&lt;&lt;并发标记 缺点： 并发阶段，不会导致用户线程停顿，但会占用CPU 资源导致应用变慢，总吞吐量降低。为了应付这种情况，虚拟机提供了一种“增量式并发收集器”的CMS变种，就是在并发标记、清理的时候让GC线程、用户线程交替运行，尽量减少GC线程独占资源的时间，这样整个GC收集时间会变长，但对程序的影响就会变小一些。（事实证明，效果一般，不推荐使用） CMS无法处理浮动垃圾（Floating Garbage），可能出现Concurrent Mode Failure失败导致另一次Full GC的产生 基于“标记-清除”，产生过多碎片。设计者设置了一个参数（默认值为0），用于设置执行多少次不压缩的Full GC 之后来一次压缩的！ G1收集器——最前沿的成果之一 G1收集器已在JDK 1.7 u4版本正式投入使用。 与其他GC收集器相比，特点： 并行与并发：充分利用多核环境，通过并发的方式在GC过程中让java程序继续运行，缩短Stop-The-World的时间 分代收集： 空间整合：不会产生空间碎片 可预测的停顿：相对于CMS的另一大优势，建立可预测的模型，使用者明确指定在一个M秒时间段内GC时间不能超过N秒 在使用G1收集器的时候，java堆内存就和其他收集器有很大的差别。它将内存分为大小相等的独立区域，虽有老年代和新生代，但新老不隔离，都是Region的一部分集合建立可预测的停顿时间模型：不用再堆中全区域收集。 G1收集器估计所有region的价值大小，建立一个优先列表，大的先收集，所以叫“Garbage-First” 除去维护Remembered Set 的操作，G1收集器的运作大致可以分为 初始标记 并发标记 最终标记 筛选回收","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://htchz.cc/tags/JVM/"},{"name":"GC","slug":"GC","permalink":"https://htchz.cc/tags/GC/"}],"author":"土川"},{"title":"[JVM]GC那些事(四)对象的分配回收策略","slug":"JVM-GC那些事-四-对象的分配回收策略","date":"2018-03-29T08:10:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"476673891.html","link":"","permalink":"https://htchz.cc/476673891.html","excerpt":"一个对象被new出来分配在哪呢。一个对象的分配，往大方向上讲，就是在堆分配","text":"一个对象被new出来分配在哪呢。一个对象的分配，往大方向上讲，就是在堆分配 内存分配规则不是固定的，取决于虚拟机参数、GC组合类型 对象优先在Eden分配大多数情况下对象再新生代Eden区中分配，当没有足够的空间时，虚拟机将发起一次Minor GC。 大对象直接进入老年代所谓的大对象就是指需要连续空间的java对象，最典型的是数组和字符串。（应避免短命大对象） 长期存活的对象将进入老年代每个对象有对象年龄（Age）计数器。每次在minor GC后仍存在且能被survivor区容纳的话，年龄就+1（初始为0），达到一个阈值（默认15），就晋升到老年代中 动态对象年龄判定 并不是必须达到年龄才可以晋升老年代 如果在Survivor空间中，相同年龄所有对象大小总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代。 空间分配担保Minor GC之前，如果老年代最大可用的连续空间大于新生代所有对象总空间，则GC安全。否则，检查是否允许担保失败（HandlePromotionFailure的值）。如果允许，则继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小。如果大于，则尝试Minor GC。如果小于或者不允许，则改为Full GC jdk 6u24 之后，HandlePromotionFailure已经不影响分配担保策略了。如果老年代最大可用的连续空间大于新生代所有对象总空间，或者大于历次晋升到老年代对象的平均大小，则进行Minor GC，否则Full GC。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://htchz.cc/tags/JVM/"},{"name":"GC","slug":"GC","permalink":"https://htchz.cc/tags/GC/"}],"author":"土川"},{"title":"[JVM]GC那些事(三)HotSpot算法的实现","slug":"JVM-GC那些事-二","date":"2018-03-29T07:59:00.000Z","updated":"2019-07-20T08:15:30.000Z","comments":true,"path":"1666990746.html","link":"","permalink":"https://htchz.cc/1666990746.html","excerpt":"什么时机适合进行GC","text":"什么时机适合进行GC HotSpot虚拟机实现这些算法的时候，必须对算法的执行效率有严格的考量，才能保证虚拟机的高效执行。 枚举根节点从GC Roots 节点找引用链这个操作，仅方法区就有有几百兆，若逐个检查，必定消耗很多时间而且，在检查的时候必须 stop the world 停顿一下， 即保证操作的原子性，不能在分析的时候引用链还在变化 HotSpot的实现是使用一组OopMap的数据结构来达到这个目的的。在类加载完成的时候，HotSpot就把对象内什么偏移量上的什么类型的数据计算出来。在JIT编译中，也会在特定的位置记录下栈和寄存器。这样GC在扫描的时候就可以通过记录中的指令直接得到引用的位置信息。 安全点（Safe Point）前面提到，OopMap是在特定的位置记录了指令信息，这些位置称为安全点。只有到达安全点的时候，才能进行GC。安全点不能选择太少以至于让GC等待时间太长，不又能过于频繁以至于增大运行时负荷。 安全点的选定是以程序“是否具有让程序长时间执行的特征”为标准进行选定的（之所以不以指令流的长度为标准，因为指令执行时间很短），长时间执行的最明显特征就是指令序列复用，如方法调用，循环跳转，异常跳转等 GC发生时如何让所有线程都跑到最近的安全点停顿，有两种方式：抢先式中断（Preemptive Suspension）和主动式中断（Voluntary Suspension） 抢先式中断：GC时中断所有线程，若某线程中断的地方不是安全点，恢复线程，跑到安全点。现在几乎没人用 主动式中断：GC需要中断时，不对线程直接操作，设置一个标志（与安全点重合，如把安全点的指令的内存页设置为不可读，线程会异常中断并挂起），线程执行时自动轮询这个标志，然后线程运行到中断标志的时候会自动中断并挂起 安全区域（Safe Region）若程序”不执行“（即没有分配CPU时间，典型的例子是线程处于“Sleep”“Blocked”状态），这时程序不能继续运行到中断标志挂起，这时需要安全区域来解决。 当线程执行到安全区域时，标识自己进入了安全区域。若发生GC，就不用管标识为安全区域的线程。线程若要离开安全区域，必须检查系统是否完成了根节点枚举（或者整个GC过程）。如果完成了，就继续线程。否则，等待直到收到可以离开安全区域的信号为止。","categories":[],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://htchz.cc/tags/JVM/"},{"name":"GC","slug":"GC","permalink":"https://htchz.cc/tags/GC/"}],"author":"土川"},{"title":"[JVM]GC那些事(二)垃圾回收算法简介","slug":"JVM-GC那些事-二-垃圾回收算法简介","date":"2018-03-27T03:08:00.000Z","updated":"2019-07-17T07:00:43.000Z","comments":true,"path":"2456754784.html","link":"","permalink":"https://htchz.cc/2456754784.html","excerpt":"识别出了垃圾以后怎么清除呢。","text":"识别出了垃圾以后怎么清除呢。 下面的几种垃圾回收算法在不同的空间都有不同应用。 标记-清除算法（Mark-Sweep）标记出所有要回收的对象，然后统一回收。不足： 效率低下 空间碎片太多（导致分配大对象没有连续空间，不得不触发另一次垃圾收集动作） 复制算法基于前面的算法，把内存按容量分为两部分，第一次使用其中一部分，在gc完成后将存活对象复制到另一部分内存，清除第一部分的内存。 但是按照把内存划分为两半，可用内存就缩小为一半，代价真他妈高 于是现代的商业虚拟机都是采用这种方式，但不是1：1分配内存而是分为一块较大的Eden和两块较小的Survivor(一般来说是8：1：1)。当回收时，将Eden和Survivor中的存活对象一次性地复制到另外一块Survivor空间上，清理掉原来的Eden和Survivor中的空间 为什么要有两块Survivor假设有survivor1和survivor2，那么eden和survivor1进行minor gc后一般survivor1会有内存碎片，这时候把存活对象放进空的survivor2，清空survivor1，就能解决内存碎片化问题。 为什么不设多点survivor两块够了。。 如果空间不足，则使用分配担保机制来申请内存 标记-整理算法复制收集算法在对象存活率较高时就要进行较多的复制操作，效率变低。标记-整理算法在标记之后，将存活对象都往一端移动，最后直接清理端边界以外的内存。 分代收集算法将内存分为“新生代”“老年代”，新生代使用复制算法。老年代是用标记-清除算法、标记-整理算法。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://htchz.cc/tags/JVM/"},{"name":"GC","slug":"GC","permalink":"https://htchz.cc/tags/GC/"}],"author":"土川"},{"title":"[JVM]GC那些事(一)判断对象已死","slug":"JVM-GC那些事","date":"2018-03-26T18:17:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"2872318404.html","link":"","permalink":"https://htchz.cc/2872318404.html","excerpt":"GC这种东西不吹上三天三夜怎么好意思。","text":"GC这种东西不吹上三天三夜怎么好意思。 看过《深入java虚拟机》，里面对GC的讲解看完有个大概了解。于是自己总结一下。 怎么判断一个对象已死，是GC的第一步。 引用计数法引用计数法就是当对象的引用为0时，才进行GC。事实上这是不可行的。看下面的示例。 对象a和b都有一个instance字段，如果执行a.instance = b;b.instance = a;a = null;b = null; 上面的两个对象相互引用着，引用数都为1，但是a和b指的对象都不能再被访问，理论上在内存中是垃圾，但两个对象无法被gc回收。 可达性分析算法我们一般通过可达性分析算法来确认对象的存活。 通过一系列的成为GC Roots的对象作为起始点，从这些节点开始向下搜索，搜索走过的路径称为引用链（Reference Chain） 当一个对象到GC Roots没有任何引用链相连时，证明此对象不可用 在java中可以作为GC Roots的对象包括下面几种 虚拟机栈中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法中JNI引用的对象 Java中什么样的对象才能作为gc root，gc roots有哪些呢？ 再谈引用java引用在jdk1.2之后进行了扩充，分为强引用（Strong Reference）、软引用（Soft Reference）、弱引用（Weak Reference）、虚引用（Phantom Reference） 强引用最普遍，GC不会回收被引用的对象 软银用用来描述还有用但非必需的对象，要发生OOM时进行清理 弱引用用来描述非必需的，只能生存到下次GC收集之前 虚引用也称为幽灵引用和幻影引用。为一个对象设置虚引用的唯一目的：在这个对象被收集器回收时收到一个系统通知 生存还是死亡一个对象进行可达性分析算法后如不可达，也只是进入缓刑。真正宣告一个对象死亡，要经历两次标记： 没有和GC Roots相连接，没有则第一次标记 被第一次标记过的对象进行筛选，若未重写finalize()方法或对象被执行过一次finalize()，则没必要执行finalize()方法，死刑 若对象有必要执行finalize()方法，则对象会被放在一个F-Queue中，并稍后有虚拟机创建的一个低优先级的线程去触发方法。 对象可以在finalize()方法中自救，比如把自己this赋值给某个变量 尽量别使用这个运行代价高昂的方法finalize() 回收方法区此处回收两部分内容： 废弃常量和无用的类 回收废弃常量和回收java堆中的对象很相似：假如一个字符串“abc”被放进常量池，但系统没有一个string对象是“abc”的，那么内存回收时，“abc”会被清理 判断一个类是否是无用的类条件比较苛刻，需满足下面三个： 该类所有实例被回收 加载该类的ClassLoader已经被回收 对应的java.lang.Class 对象没有在任何地方被引用，无法通过反射访问该方法 满足以上三个才“可以”（不是必然）被回收。虚拟机提供了一些参数进行回收 在大量使用反射的框架、动态代理的框架、jsp等频繁自定义ClassLoader的场景都需要具备类卸载功能","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://htchz.cc/tags/JVM/"},{"name":"GC","slug":"GC","permalink":"https://htchz.cc/tags/GC/"}],"author":"土川"},{"title":"[建站]Linode开启Google BBR的正确方法","slug":"建站-Linode开启Google-BBR的正确方法","date":"2018-03-26T15:55:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"1807419896.html","link":"","permalink":"https://htchz.cc/1807419896.html","excerpt":"在linode一直开启不了bbr加速，在一个老哥的博客看到这个传送门","text":"在linode一直开启不了bbr加速，在一个老哥的博客看到这个传送门 简单来说，Linode服务器的内核是要在配置页面修改才能正确引导的，而且4.9.0以上的liux内核都编译了tcp_bbr加速模块，所以不用自己配置了。 还有一点，lsmod找不到tcp_bbr，博主说有一种说法是，Linode自带的内核都是把模块都编译一块的，所以lsmod里看不到正常，lsmod是看额外加载的模块的。 Linode冲5刀送20刀，快去啊，不过填个人信息得填优惠码和另一个忘了什么鬼码，否则没有20刀。","categories":[{"name":"建站","slug":"建站","permalink":"https://htchz.cc/categories/建站/"}],"tags":[{"name":"bbr","slug":"bbr","permalink":"https://htchz.cc/tags/bbr/"}],"author":"土川"},{"title":"[数据库]Mysql查询条件的类型强转","slug":"数据库-Mysql查询条件的类型强转","date":"2018-03-23T08:44:00.000Z","updated":"2019-05-28T17:18:43.000Z","comments":true,"path":"3095735483.html","link":"","permalink":"https://htchz.cc/3095735483.html","excerpt":"网上看到的类型强转的引起了慢查询，自己建表试了一下果真如此。","text":"网上看到的类型强转的引起了慢查询，自己建表试了一下果真如此。 建表CREATE TABLE `users` ( `userID` int(11) NOT NULL AUTO_INCREMENT, `username` varchar(20) NOT NULL, `password` varchar(20) NOT NULL, `age` int(4) DEFAULT NULL, PRIMARY KEY (`userID`), KEY `password` (`password`), KEY `age` (`age`) USING BTREE ) ENGINE=InnoDB AUTO_INCREMENT=100003 DEFAULT CHARSET=utf8;插入了10w条数据 执行explain这是第一种：这是第二种： 两条语句的差别是对于字符索引，查询条件加不加引号的区别 从上面可以很明显的看到由于password是varchar，在where条件中不加’’，会引发全索引查询(type=index比type=all还是快的)，加了就可以用到索引（type=ref），这扫描的行数可是天差地别，对于服务器的压力和响应时间自然也是天差地别的。 我们看第三种： 我们看第四种 对于整型，加了引号与否影响不大，只是差别在Extra栏 rows有5w是因为10w行的age都是1。。。，如果改为离散的值，rows会下降很多。 以下是5.5官方手册的说明： If both arguments in a comparison operation are strings, they are compared as strings.两个参数都是字符串，会按照字符串来比较，不做类型转换。If both arguments are integers, they are compared as integers.两个参数都是整数，按照整数来比较，不做类型转换。Hexadecimal values are treated as binary strings if not compared to a number.十六进制的值和非数字做比较时，会被当做二进制串。If one of the arguments is a TIMESTAMP or DATETIME column and the other argument is a constant, the constant is converted to a timestamp before the comparison is performed. This is done to be more ODBC-friendly. Note that this is not done for the arguments to IN()! To be safe, always use complete datetime, date, or time strings when doing comparisons. For example, to achieve best results when using BETWEEN with date or time values, use CAST() to explicitly convert the values to the desired data type.有一个参数是 TIMESTAMP 或 DATETIME，并且另外一个参数是常量，常量会被转换为 timestampIf one of the arguments is a decimal value, comparison depends on the other argument. The arguments are compared as decimal values if the other argument is a decimal or integer value, or as floating-point values if the other argument is a floating-point value.有一个参数是 decimal 类型，如果另外一个参数是 decimal 或者整数，会将整数转换为 decimal 后进行比较，如果另外一个参数是浮点数，则会把 decimal 转换为浮点数进行比较In all other cases, the arguments are compared as floating-point (real) numbers.所有其他情况下，两个参数都会被转换为浮点数再进行比较 根据以上的说明，当where条件之后的值的类型和表结构不一致的时候，MySQL会做隐式的类型转换，都将其转换为浮点数在比较。 mysql&gt; SELECT CAST(&apos; 1&apos; AS SIGNED)=1; +-------------------------+ | CAST(&apos; 1&apos; AS SIGNED)=1 | +-------------------------+ | 1 | +-------------------------+ 1 row in set (0.00 sec) mysql&gt; SELECT CAST(&apos; 1a&apos; AS SIGNED)=1; +--------------------------+ | CAST(&apos; 1a&apos; AS SIGNED)=1 | +--------------------------+ | 1 | +--------------------------+ 1 row in set, 1 warning (0.00 sec) mysql&gt; SELECT CAST(&apos;1&apos; AS SIGNED)=1; +-----------------------+ | CAST(&apos;1&apos; AS SIGNED)=1 | +-----------------------+ | 1 | +-----------------------+ 1 row in set (0.00 sec) 比如where string = 1，需要将索引中的字符串转换成浮点数，但是由于’1’,’ 1’,’1a’都会比转化成1,故MySQL无法直接使用索引只能进行全表扫描，故造成了慢查询的产生。 同时需要注意一点，由于都会转换成浮点数进行比较，而浮点数只有53bit，故当超过最大值的时候，比较会出现问题。 由于索引建立在int的基础上，而将纯数字的字符串可以百分百转换成数字，故可以使用到索引，虽然也会进行一定的转换，消耗一定的资源，但是最终仍然使用了索引，不会产生慢查询。 mysql&gt; select CAST( &apos;30&apos; as SIGNED) = 30; +----------------------------+ | CAST( &apos;30&apos; as SIGNED) = 30 | +----------------------------+ | 1 | +----------------------------+ 1 row in set (0.00 sec)","categories":[{"name":"DB","slug":"DB","permalink":"https://htchz.cc/categories/DB/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://htchz.cc/tags/Mysql/"}],"author":"土川"},{"title":"[JVM]Java对象的组成、大小计算","slug":"JVM-对象的组成","date":"2018-03-22T14:23:00.000Z","updated":"2019-02-14T10:39:14.000Z","comments":true,"path":"2006878642.html","link":"","permalink":"https://htchz.cc/2006878642.html","excerpt":"基于Hotspot，我们给自己一个对象 :(","text":"基于Hotspot，我们给自己一个对象 :( Java对象模型Hotspot主要是用C++写的，所以它定义的Java对象表示模型也是基于C++实现的。 Java对象的表示模型叫做“OOP-Klass”二分模型，包括两部分: OOP，即Ordinary Object Point，普通对象指针，说白了就是表示对象除了元数数据之外的信息。 Klass，即Java类的C++对等体，用来描述Java类，包含了元数据和方法信息 一个Java对象就包括两部分，数据和方法，分别对应到OOP和Klass。 JVM运行时加载一个Class时，会在JVM内部创建一个instanceKlass对象，表示这个类的运行时元数据。创建一个这个Class的Java对象时，会在JVM内部相应的创建一个instanceOop来表示这个Java对象。熟悉JVM的同学可以明白，instanceKlass对象放在了方法区，instanceOop放在了堆，instanceOop的引用放在了JVM栈。 JVM是基于栈来运行的，当一个线程调用一个对象的方法时，会在它的JVM栈的栈顶创建一个栈帧（Frame）的数据结构，这个数据结构是用来保存方法的局部变量，操作数栈，动态连接和方法返回值的。通过参数传递的值和在方法中new出来的对象的引用都保持在局部变量表里面。 Java的方法调用是值传递，不是引用传递，原因就在这里，传递进来的参数相当于在局部变量表里面拷贝了一份，实际计算时，操作数栈操作的是局部变量变量里面的值，而不是外部的变量。 在堆中创建的Java对象实际只包含数据信息，它主要包含三（四）部分： 对象头，也叫Markword 元数据指针，可以理解为类对象指针，指向方法区的instanceKlass实例。如果是32位的，默认开启对象指针压缩，4个字节 实例数据 (如果是数组对象的话，还多了一个部分，就是数组长度)，4个字节 另外还有Padding(内存对齐)，按照8的倍数对齐 对象头代表的意义是可变的，通过标志位决定。主要存储对象运行时记录信息，如hashcode, GC分代年龄，锁状态标志，偏向线程ID，偏向时间戳等。对象头的长度和JVM的字长一致，比如32位JVM的对象头是32位，64位JVM的对象头是64位。下面是对于64位jvm的markword的说明 偏向锁标识位 锁标识位 锁状态 存储内容 0 01 未锁定 hashcode(31),年龄(4) 1 01 偏向锁 线程ID(54),时间戳(2),年龄(4) 无 00 轻量级锁 栈中锁记录的指针(64) 无 10 重量级锁 monitor的指针(64) 无 11 GC标记 空，不需要记录信息 所谓的给一个对象加锁，其实就是设置了对象头标志位。当其他线程看到这个对象的状态是加锁状态后，就等待释放锁。关于锁我们另开一篇。 在方法区的instanceKlass对象相当于Class加载后创建的运行时对象，它包含了运行时常量池，字段，方法等元数据，当调用一个对象的方法时，如上面的图所示，实际定位到了方法区的instanceKlass对象的方法元数据。 使用HSDB调试 HSDB是一款内置与SA的GUI调试工具，集成了各种JVM监控工具，可以用来深入分析JVM内部状态。这玩意在windows的jdk7才自带，mac和linux吓得jdk6就有了。 首先我们运行一个程序，并打上断点。 1234567891011121314151617181920public class Person &#123; private String name; private int age; private boolean sex; public void sayHi()&#123; System.out.println(&quot;Say hi from ITer_ZC&quot;); &#125; public static void main(String[] args)&#123; Person p = new Person(); p.sayHi(); try &#123; Thread.sleep(500000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 上面断点用sleep代替。好像还可以用jdb工具断点，没研究 - - 启动程序，运行jps命令，查看当前java进程id， 1234C:\\Users\\zack.huang&gt;jps75248276 Jps4552 Person 由4552 Person得知4552是上面java程序的id，接着运行下面的命令， java -cp sa-jdi.jar sun.jvm.hotspot.HSDB sa-jdi.jar在%JAVA_HOME%\\lib目录下，不过我的JAVA_HOME路径好像因为带了空格老启动不了，直接把jar复制到桌面了启动。 界面一片白。 输入pid之后，显示可以看到Personde的地址 在inspector里面查看0x00000007c0060028，我们可以看到instanceKlass的字段，方法，运行时常量池，父类，兄弟类等元数据信息 在Object Histogram里面找到Person对象 查看Person Oop的运行时实例 _mark就是对象头，接着是实例数据信息。HSDB没有显示类对象指针 计算对象的大小程序计算方法 通过java.lang.instrument.Instrumentation的getObjectSize(obj)直接获取对象的大小 通过sun.misc.Unsafe对象的objectFieldOffset(field)等方法结合反射来计算对象的大小 java.lang.instrument.Instrumentation.getObjectSize()的方式讲讲java.lang.instrument.Instrumentation.getObjectSize()的方式，这种方法得到的是Shallow Size，即遇到引用时，只计算引用的长度，不计算所引用的对象的实际大小。如果要计算所引用对象的实际大小，可以通过递归的方式去计算。 java.lang.instrument.Instrumentation的实例必须通过指定javaagent的方式才能获得，具体的步骤如下： 定义一个类，提供一个premain方法: public static void premain(String agentArgs, Instrumentation instP) 创建META-INF/MANIFEST.MF文件，内容是指定PreMain的类是哪个： Premain-Class: sizeof.ObjectShallowSize 把这个类打成jar，然后用java -javaagent XXXX.jar XXX.main的方式执行 下面先定义一个类来获得java.lang.instrument.Instrumentation的实例,并提供了一个static的sizeOf方法对外提供Instrumentation的能力 123456789101112131415package sizeof; import java.lang.instrument.Instrumentation; public class ObjectShallowSize &#123; private static Instrumentation inst; public static void premain(String agentArgs, Instrumentation instP)&#123; inst = instP; &#125; public static long sizeOf(Object obj)&#123; return inst.getObjectSize(obj); &#125; &#125; 定义META-INF/MANIFEST.MF文件 Premain-Class: sizeof.ObjectShallowSize 打成jar包 cd 编译后的类和META-INF文件夹所在目录 jar cvfm java-agent-sizeof.jar META-INF/MANIFEST.MF . 准备好了这个jar之后，我们可以写测试类来测试Instrumentation的getObjectSize方法了。在这之前我们先来看对象在内存中是按照什么顺序排列的，字段的定义按如下顺序 123456789private static class ObjectA &#123; // 注释是对应类型占的字节空间 String str; // 4 int i1; // 4 byte b1; // 1 byte b2; // 1 int i2; // 4 ObjectB obj; //4 byte b3; // 1 &#125; 按照我们之前说的方法来计算一下这个对象所占大小，注意按8对齐： 8(_mark) + 4(元数据指针) + 4(str) + 4(i1) + 1(b1) + 1(b2) + 2(padding) + 4(i2) + 4(obj) + 1(b3) + 7(padding) = 40 ?但事实上是这样的吗？ 我们来用Instrumentation的getObjectSize来计算一下先: 1234567891011121314151617181920212223package test; import sizeof.ObjectShallowSize; public class SizeofWithInstrumetation &#123; private static class ObjectA &#123; String str; // 4 int i1; // 4 byte b1; // 1 byte b2; // 1 int i2; // 4 ObjectB obj; //4 byte b3; // 1 &#125; private static class ObjectB &#123; &#125; public static void main(String[] args)&#123; System.out.println(ObjectShallowSize.sizeOf(new ObjectA())); &#125; &#125; 得到的结果是32！不是会按8对齐吗，b3之前的数据加起来已经是32了，多了1个b3，为33，应该对齐到40才对。事实上，HotSpot创建的对象的字段会先按照给定顺序排列一下,默认的顺序如下，从长到短排列，引用排最后: long/double --&gt; int/float --&gt; short/char --&gt; byte/boolean --&gt; Reference这个顺序可以使用JVM参数: -XX:FieldsAllocationSylte=0(默认是1)来改变。我们使用sun.misc.Unsafe对象的objectFieldOffset方法来验证一下: 1234Field[] fields = ObjectA.class.getDeclaredFields(); for(Field f: fields)&#123; System.out.println(f.getName() + \" offset: \" +unsafe.objectFieldOffset(f)); &#125; 可以看到确实是按照从长到短，引用排最后的方式在内存中排列的。按照这种方法我们来重新计算下ObjectA创建的对象的长度: 8(_mark) + 4(元数据指针) + 4(i1) + + 4(i2) + 1(b1) + 1(b2) + 1(b3) + 1(padding) + 4(str) + 4(obj) = 32这种计算方法和程序计算方法一样 unsafe的方式就不讲了，这篇主要想说怎么计算一个对象占用的内存大小，可以点击原博查看unsafe","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://htchz.cc/tags/JVM/"},{"name":"OOP","slug":"OOP","permalink":"https://htchz.cc/tags/OOP/"}],"author":"土川"},{"title":"[Chrome小绿锁]Https那些事","slug":"Chrome小绿锁-Https那些事","date":"2018-03-22T10:44:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"1103575483.html","link":"","permalink":"https://htchz.cc/1103575483.html","excerpt":"Chrome 68发布，是Google对HTTP页面进行第三次的安全策略，直接将所有的HTTP页面都标上“不安全”标签。","text":"Chrome 68发布，是Google对HTTP页面进行第三次的安全策略，直接将所有的HTTP页面都标上“不安全”标签。 介是原博 HTTPS简介HTTPS其实是有两部分组成：HTTP + SSL / TLS，也就是在HTTP上又加了一层处理加密信息的模块。服务端和客户端的信息传输都会通过TLS进行加密，所以传输的数据都是加密后的数据。具体是如何进行加密，解密，验证的，且看下图。 客户端发起HTTPS请求这个没什么好说的，就是用户在浏览器里输入一个https网址，然后连接到server的443端口(默认443)。 服务端的配置采用HTTPS协议的服务器必须要有一套数字证书，可以自己制作，也可以向组织申请。区别就是自己颁发的证书需要客户端验证通过，才可以继续访问，而使用受信任的公司申请的证书则不会弹出提示页面(startssl就是个不错的选择，有1年的免费服务)。这套证书其实就是一对公钥和私钥。如果对公钥和私钥不太理解，可以想象成一把钥匙和一个锁头，只是全世界只有你一个人有这把钥匙，你可以把锁头给别人，别人可以用这个锁把重要的东西锁起来，然后发给你，因为只有你一个人有这把钥匙，所以只有你才能看到被这把锁锁起来的东西。 传送证书这个证书其实就是公钥，只是包含了很多信息，如证书的颁发机构，过期时间等等。 客户端解析证书这部分工作是有客户端的TLS来完成的，首先会验证公钥是否有效，比如颁发机构，过期时间等等，如果发现异常，则会弹出一个警告框，提示证书存在问题。如果证书没有问题，那么就生成一个随即值。然后用证书对该随机值进行加密。就好像上面说的，把随机值用锁头锁起来，这样除非有钥匙，不然看不到被锁住的内容。 传送加密信息这部分传送的是用证书加密后的随机值，目的就是让服务端得到这个随机值，以后客户端和服务端的通信就可以通过这个随机值作为密钥，进行加密解密。 服务段解密信息服务端用私钥解密后，得到了客户端传过来的随机值(密钥)，然后把内容通过该值进行对称加密。所谓对称加密就是，将信息和密钥通过某种算法混合在一起，这样除非知道密不然无法获取内容，而正好客户端和服务端都知道这个私钥，所以只要加密算法够彪悍，私钥够复杂，数据就够安全。 传输加密后的信息这部分信息是服务段用私钥加密后的信息，可以在客户端被还原 客户端解密信息客户端用之前生成的私钥解密服务段传过来的信息，于是获取了解密后的内容。整个过程第三方即使监听到了数据，也束手无策。 以上是Https的过程。 另一篇关于Https的博文SSL介于应用层和TCP层之间。应用层数据不再直接传递给传输层，而是传递给SSL层，SSL层对从应用层收到的数据进行加密，并增加自己的SSL头。RSA性能是非常低的，原因在于寻找大素数、大数计算、数据分割需要耗费很多的CPU周期，所以一般的HTTPS连接只在第一次握手时使用非对称加密，通过握手交换对称加密密钥，在之后的通信走对称加密。[http://www.cnblogs.com/ttltry-air/archive/2012/08/20/2647898.html]","categories":[{"name":"网络","slug":"网络","permalink":"https://htchz.cc/categories/网络/"}],"tags":[{"name":"Https","slug":"Https","permalink":"https://htchz.cc/tags/Https/"}],"author":"土川"},{"title":"[分布式]哈希一致性","slug":"分布式-哈希一致性","date":"2018-03-22T10:08:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"3621931521.html","link":"","permalink":"https://htchz.cc/3621931521.html","excerpt":"哈希一致性在很多地方都有出现，Redis、MC、Hadoop里都有它的身影。","text":"哈希一致性在很多地方都有出现，Redis、MC、Hadoop里都有它的身影。 一致性哈希算法在1997年由麻省理工学院提出的一种分布式哈希（DHT）实现算法，设计目标是为了解决因特网中的热点(Hot spot)问题，初衷和CARP十分类似。一致性哈希修正了CARP使用的简 单哈希算法带来的问题，使得分布式哈希（DHT）可以在P2P环境中真正得到应用。 一致性hash算法提出了在动态变化的Cache环境中，判定哈希算法好坏的四个条件: 平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。 单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。 在Jdk8的HashMap的扩容就保证了元素的单调性。 分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。 负载(Load)：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。 在分布式集群中，对机器的添加删除，或者机器故障后自动脱离集群这些操作是分布式集群管理最基本的功能。如果采用常用的hash(object)%N算法，那么在有机器添加或者删除后，很多原有的数据就无法找到了，这样严重的违反了单调性原则。接下来主要讲解一下一致性哈希算法是如何设计的： 哈希环按照常用的hash算法来将对应的key哈希到一个具有2^32次方个桶的空间中，即0~(2^32)-1的数字空间中。现在我们可以将这些数字头尾相连，想象成一个闭合的环形。如下图 哈希映射将对象映射现在我们将object1、object2、object3、object4四个对象通过特定的Hash函数计算出对应的key值，然后散列到Hash环上。如下图 Hash(object1) = key1； Hash(object2) = key2； Hash(object3) = key3； Hash(object4) = key4； 将机器映射在采用一致性哈希算法的分布式集群中将新的机器加入，其原理是通过使用与对象存储一样的Hash算法将机器也映射到环中（一般情况下对机器的hash计算是采用机器的IP或者机器唯一的别名作为输入值），然后以顺时针的方向计算，将所有对象存储到离自己最近的机器中。假设现在有NODE1，NODE2，NODE3三台机器，通过Hash算法得到对应的KEY值，映射到环中，其示意图如下： Hash(NODE1) = KEY1; Hash(NODE2) = KEY2; Hash(NODE3) = KEY3; 通过上图可以看出对象与机器处于同一哈希空间中，这样按顺时针转动object1存储到了NODE1中，object3存储到了NODE2中，object2、object4存储到了NODE3中。在这样的部署环境中，hash环是不会变更的，因此，通过算出对象的hash值就能快速的定位到对应的机器中，这样就能找到对象真正的存储位置了。 机器的删除与添加普通hash求余算法最为不妥的地方就是在有机器的添加或者删除之后会照成大量的对象存储位置失效，这样就大大的不满足单调性了。下面来分析一下一致性哈希算法是如何处理的。 部分缓存失效是不可避免的。 节点(机器)的删除以上面的分布为例，如果NODE2出现故障被删除了，那么按照顺时针迁移的方法，object3将会被迁移到NODE3中，这样仅仅是object3的映射位置发生了变化，其它的对象没有任何的改动。如下图： 节点（机器）的添加如果往集群中添加一个新的节点NODE4，通过对应的哈希算法得到KEY4，并映射到环中，如下图： 平衡性根据上面的图解分析，一致性哈希算法满足了单调性和负载均衡的特性以及一般hash算法的分散性，但这还并不能当做其被广泛应用的原由，因为还缺少了平衡性。下面将分析一致性哈希算法是如何满足平衡性的。hash算法是不保证平衡的，如上面只部署了NODE1和NODE3的情况（NODE2被删除的图），object1存储到了NODE1中，而object2、object3、object4都存储到了NODE3中，这样就照成了非常不平衡的状态。在一致性哈希算法中，为了尽可能的满足平衡性，其引入了虚拟节点。 “虚拟节点”（ virtual node ）是实际节点（机器）在 hash 空间的复制品（ replica ），一实际个节点（机器）对应了若干个“虚拟节点”，这个对应个数也成为“复制个数”，“虚拟节点”在 hash 空间中以hash值排列。 以上面只部署了NODE1和NODE3的情况（NODE2被删除的图）为例，之前的对象在机器上的分布很不均衡，现在我们以2个副本（复制个数）为例，这样整个hash环中就存在了4个虚拟节点，最后对象映射的关系图如下： 根据上图可知对象的映射关系：object1-&gt;NODE1-1，object2-&gt;NODE1-2，object3-&gt;NODE3-2，object4-&gt;NODE3-1。通过虚拟节点的引入，对象的分布就比较均衡了。那么在实际操作中，正真的对象查询是如何工作的呢？对象从hash到虚拟节点到实际节点的转换如下图： “虚拟节点”的hash计算可以采用对应节点的IP地址加数字后缀的方式。例如假设NODE1的IP地址为192.168.1.100。引入“虚拟节点”前，计算 cache A 的 hash 值： Hash(“192.168.1.100”);引入“虚拟节点”后，计算“虚拟节”点NODE1-1和NODE1-2的hash值： Hash(“192.168.1.100#1”); // NODE1-1 Hash(“192.168.1.100#2”); // NODE1-2 一句话就是，通过虚拟节点的方式，让元素在机器上分布均匀","categories":[{"name":"分布式","slug":"分布式","permalink":"https://htchz.cc/categories/分布式/"}],"tags":[{"name":"哈希一致性","slug":"哈希一致性","permalink":"https://htchz.cc/tags/哈希一致性/"}],"author":"土川"},{"title":"[碧油鸡]使用HttpClient3的坑","slug":"碧油鸡-使用HttpClient3的坑","date":"2018-03-22T09:57:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"589437945.html","link":"","permalink":"https://htchz.cc/589437945.html","excerpt":"特么登录状态老是丢失。。。","text":"特么登录状态老是丢失。。。 场景使用阿里开源配置中心的diamond-sdk时需要登录配置中心才有权限进行操作。diamond-sdk是使用HttpClient3来进行信息传输的，于是在进行配置的操作之前客户端会先模拟登录获得session。然而在接下来的操作却一直报”未登录”之类的提示。 debug大法后发现Cookie对象好像id一直在变，返回的jsessionid也没保存。一波探索发现HttpClient3需要手动设置cookie策略。 解决方法HttpClient3 默认的cookie策略是每次新建一个Cookie对象，复用Cookie的话，要进行如下设置。 client.getParams().setCookiePolicy(CookiePolicy.BROWSER_COMPATIBILITY)(完)","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"碧油鸡","slug":"碧油鸡","permalink":"https://htchz.cc/tags/碧油鸡/"}],"author":"土川"},{"title":"[Spring]Spring之循环依赖","slug":"Spring-Spring之循环依赖","date":"2018-03-19T17:57:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"3244702836.html","link":"","permalink":"https://htchz.cc/3244702836.html","excerpt":"面试面过这个问题，整理一下。所谓循环依赖就是多个Bean之间依赖关系形成一个闭环，例如A-&gt;B-&gt;C-&gt;…-&gt;A 这种情况，当然，最简单的循环依赖就是2个Bean之间互相依赖：A-&gt;B（A依赖B), B-&gt;A(B依赖A) 。在Spring中，如果A-&gt;B,那么在创建A的过程中会去创建B,在创建B（或B的依赖)的过程中又发现B-&gt;A，这个时候就出现了循环依赖的现象。","text":"面试面过这个问题，整理一下。所谓循环依赖就是多个Bean之间依赖关系形成一个闭环，例如A-&gt;B-&gt;C-&gt;…-&gt;A 这种情况，当然，最简单的循环依赖就是2个Bean之间互相依赖：A-&gt;B（A依赖B), B-&gt;A(B依赖A) 。在Spring中，如果A-&gt;B,那么在创建A的过程中会去创建B,在创建B（或B的依赖)的过程中又发现B-&gt;A，这个时候就出现了循环依赖的现象。 不是循环调用循环依赖就是循环引用，就是两个或多个Bean相互之间的持有对方，比如CircleA引用CircleB，CircleB引用CircleC，CircleC引用CircleA，则它们最终反映为一个环。此处不是循环调用，循环调用是方法之间的环调用，如下图： 而循环调用是无法解决的，除非有终结条件，否则就是死循环，最终导致内存溢出错误。 Spring容器循环依赖包括构造器循环依赖和setter循环依赖，那Spring容器如何检测和解决循环依赖呢？ Spring可以解决的循环依赖spring中的循环依赖只有当 Bean是单例 通过属性注入的情况 这两个条件满足的情况下是没问题的。但是如果是通过构造器依赖，或者不是单例模式的情况下循环依赖就会抛出异常BeanCurrentlyInCreationException。下面从代码层面上解析一下为什么。 至于为什么要有prototype类型的bean，我想典型的应用场景就是struts的Action（有点像springmvc的Controller）实例。struts的request参数是绑定在Action对象的成员变量上的，如果Action的bean是单例的就会造成线程不安全。 Prototype循环依赖抛异常123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129protected &lt;T&gt; T doGetBean( final String name, final Class&lt;T&gt; requiredType, final Object[] args, boolean typeCheckOnly) throws BeansException &#123; final String beanName = transformedBeanName(name); Object bean; // Eagerly check singleton cache for manually registered singletons. Object sharedInstance = getSingleton(beanName); if (sharedInstance != null &amp;&amp; args == null) &#123; ...// 日志代码 bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); &#125; else &#123; // 请看这里，抛异常 // Fail if we're already creating this bean instance: // We're assumably within a circular reference. if (isPrototypeCurrentlyInCreation(beanName)) &#123; throw new BeanCurrentlyInCreationException(beanName); &#125; // Check if bean definition exists in this factory. BeanFactory parentBeanFactory = getParentBeanFactory(); if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) &#123; // Not found -&gt; check parent. String nameToLookup = originalBeanName(name); if (args != null) &#123; // Delegation to parent with explicit args. return (T) parentBeanFactory.getBean(nameToLookup, args); &#125; else &#123; // No args -&gt; delegate to standard getBean method. return parentBeanFactory.getBean(nameToLookup, requiredType); &#125; &#125; if (!typeCheckOnly) &#123; markBeanAsCreated(beanName); &#125; try &#123; final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); checkMergedBeanDefinition(mbd, beanName, args); // Guarantee initialization of beans that the current bean depends on. String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) &#123; for (String dep : dependsOn) &#123; if (isDependent(beanName, dep)) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Circular depends-on relationship between '\" + beanName + \"' and '\" + dep + \"'\"); &#125; registerDependentBean(dep, beanName); getBean(dep); &#125; &#125; // Create bean instance. if (mbd.isSingleton()) &#123; sharedInstance = getSingleton(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; try &#123; return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; // Explicitly remove instance from singleton cache: It might have been put there // eagerly by the creation process, to allow for circular reference resolution. // Also remove any beans that received a temporary reference to the bean. destroySingleton(beanName); throw ex; &#125; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; else if (mbd.isPrototype()) &#123; // It's a prototype -&gt; create a new instance. Object prototypeInstance = null; try &#123; beforePrototypeCreation(beanName); prototypeInstance = createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); &#125; else &#123; String scopeName = mbd.getScope(); final Scope scope = this.scopes.get(scopeName); if (scope == null) &#123; throw new IllegalStateException(\"No Scope registered for scope name '\" + scopeName + \"'\"); &#125; try &#123; Object scopedInstance = scope.get(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; beforePrototypeCreation(beanName); try &#123; return createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; &#125; &#125;); bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &#125; catch (IllegalStateException ex) &#123; throw new BeanCreationException(beanName, \"Scope '\" + scopeName + \"' is not active for the current thread; consider \" + \"defining a scoped proxy for this bean if you intend to refer to it from a singleton\", ex); &#125; &#125; &#125; catch (BeansException ex) &#123; cleanupAfterBeanCreationFailure(beanName); throw ex; &#125; &#125; ...// type校验 return (T) bean;&#125; 可以看出，该流程中就考虑了Prototype的循环依赖的问题，只要在创建Prototype的Bean中出现循环依赖那么就抛出异常。但是在singleton的情况下，则通过另外的方式来解决。 Singleton的循环依赖之构造注入上面的代码有这么一段Singleton的处理 12345678910111213141516171819// Create bean instance.if (mbd.isSingleton()) &#123; sharedInstance = getSingleton(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; try &#123; return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; // Explicitly remove instance from singleton cache: It might have been put there // eagerly by the creation process, to allow for circular reference resolution. // Also remove any beans that received a temporary reference to the bean. destroySingleton(beanName); throw ex; &#125; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd);&#125; 这个getSingleton涉及到了ObjectFactory这个接口类，这个接口的功能和FactoryBean类似，但是主要是用来解决循环依赖的。在初始化过程决定返回的Singleton对象。关于单例的对象的创建，又要介绍一下DefaultSingletonBeanRegistry这个类，这个类主要用来帮助创建单例模式，其中主要的属性： 12345678910111213141516/** 缓存创建的单例对象: bean名字 --&gt; bean对象 */private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;String, Object&gt;(256);/** 缓存单例的factory,就是ObjectFactory这个东西，: bean name --&gt; ObjectFactory */private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;String, ObjectFactory&lt;?&gt;&gt;(16);/** 也是缓存创建的单例对象，功能和singletonObjects不一样，在bean构造成功之后，属性初始化之前会把对象放入到这里，主要是用于解决属性注入的循环引用: bean name --&gt; bean instance */private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;String, Object&gt;(16);/** 记录在创建单例对象中循环依赖的问题，还记得Prototype中又记录创建过程中依赖的map吗？在Prototype中只要出现了循环依赖就抛出异常，而在单例中会尝试解决 */private final Set&lt;String&gt; singletonsCurrentlyInCreation = Collections.newSetFromMap(new ConcurrentHashMap&lt;String, Boolean&gt;(16)); 现在看getSingleton(beanName, new ObjectFactory&lt;Object&gt;()的实现 1234567891011121314151617181920212223242526272829303132333435363738394041public Object getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; Assert.notNull(beanName, \"'beanName' must not be null\"); synchronized (this.singletonObjects) &#123; Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) &#123; if (this.singletonsCurrentlyInDestruction) &#123; throw new BeanCreationNotAllowedException(beanName, \"Singleton bean creation not allowed while singletons of this factory are in destruction \" + \"(Do not request a bean from a BeanFactory in a destroy method implementation!)\"); &#125; //日志代码 ... //把当前beanName加入到singletonsCurrentlyInCreation中 beforeSingletonCreation(beanName); boolean newSingleton = false; boolean recordSuppressedExceptions = (this.suppressedExceptions == null); if (recordSuppressedExceptions) &#123; this.suppressedExceptions = new LinkedHashSet&lt;Exception&gt;(); &#125; try &#123; singletonObject = singletonFactory.getObject(); newSingleton = true; &#125; catch(...)&#123; ... &#125; //从singletonsCurrentlyInCreation中删除beanName finally &#123; if (recordSuppressedExceptions) &#123; this.suppressedExceptions = null; &#125; afterSingletonCreation(beanName); &#125; if (newSingleton) &#123; addSingleton(beanName, singletonObject); &#125; &#125; return (singletonObject != NULL_OBJECT ? singletonObject : null); &#125;&#125; 这段逻辑是不是和Prototype中解决循环类似,这里其实就是调用了ObjectFactory的getObject()获取对象，回过头去看前面代码，ObjectFactory的getObject()方法实际调用的是createBean(beanName, mbd, args)。说到createBean(beanName, mbd, args)又不得不说AbstractAutowireCapableBeanFactory这个类，主要功能就是完成依赖注入的Bean的创建，这个类的createBean方法代码如下,注意注解说明： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657@Overrideprotected Object createBean(String beanName, RootBeanDefinition mbd, Object[] args) throws BeanCreationException &#123; ... Object beanInstance = doCreateBean(beanName, mbdToUse, args); ...&#125;protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final Object[] args) throws BeanCreationException &#123; // 实例化bean BeanWrapper instanceWrapper = null; if (mbd.isSingleton()) &#123; instanceWrapper = this.factoryBeanInstanceCache.remove(beanName); &#125; if (instanceWrapper == null) &#123; //如果没实例化则创建新的BeanWrapper //如果是通过构造器注入，这里是一个关键点 /* 因为在A初始化的时候发现构造函数依赖B，就会去实例化B， 然后B也会运行到这段逻辑，构造函数中发现依赖A， 这个时候就会抛出循环依赖的异常 */ instanceWrapper = createBeanInstance(beanName, mbd, args); &#125; //如果当前是单例，并且allowCircularReferences为true(默认就是true，除非我们不希望Spring帮我们解决) boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) &#123; /* ！！！这里很重要，把构造成功，但属性还没注入的 的bean加到singletonFactory中，这样再解决A的依赖 过程中如果依赖A，就把这个半成品返回回去。 */ addSingletonFactory(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; return getEarlyBeanReference(beanName, mbd, bean); &#125; &#125;); &#125; Object exposedObject = bean; try &#123; //自动注入属性 populateBean(beanName, mbd, instanceWrapper); if (exposedObject != null) &#123; exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; &#125; ... return exposedObject;&#125; 总结 AbstractBeanFactory,这个类中包含了Bean创建的主要流程，在doGetBean这个方法中包含了对Prototype循环依赖处理。逻辑很简单，出现了循环依赖则直接抛出异常 DefaultSingletonBeanRegister 用于管理Singleton的对象的创建，以及解决循环依赖的问题,其中解决循环依赖的关键属性就是了earlySingletonObjects，他会在构造Singleton对象过程中暂时缓存构造成功，但属性还未注入的对象，这样就可以解决循环依赖的问题。 AbstractAutowireCapableBeanFactory,自动注入的相关逻辑，包自动注入的对象的创建、初始化和注入。但如果在调用构造函数中发现了循环依赖，则抛出异常 ObjectFactory,这个接口功能和FactoryBean类似，但是为了解决循环依赖，他决定了在获取的getSingleton()是一个完成品还是一个半成品。 构造函数和属性注入依赖的循环看下面的场景 123456789101112131415@Componentpublic class BeanA &#123; private BeanB beanB; @Autowired public BeanA(BeanB beanB) &#123; this.beanB = beanB; &#125;&#125;@Componentpublic class BeanB &#123; @Autowired private BeanA beanA;&#125; 这种情况会不会报依赖异常？写个demo，报下面的错误信息。 *************************** APPLICATION FAILED TO START *************************** Description: The dependencies of some of the beans in the application context form a cycle: ┌─────┐ | beanA defined in file [C:\\Users\\zack.huang\\IdeaProjects\\xunhuanbean\\target\\classes\\com\\htc\\testbean\\xunhuanbean\\BeanA.class] ↑ ↓ | beanB (field private com.htc.testbean.xunhuanbean.BeanA com.htc.testbean.xunhuanbean.BeanB.beanC) └─────┘按照类名的字典排序，BeanA是会比BeanB先被扫描到的，那么先构造BeanA，BeanA明显构造需要BeanB依赖，初始化BeanB，BeanA没构造完成无法注入，于是GG。 如果BeanA改名为BeanC，就可以解决问题，不过这种谁先谁后是不可靠的，勿写这种代码。","categories":[{"name":"Spring","slug":"Spring","permalink":"https://htchz.cc/categories/Spring/"}],"tags":[{"name":"Bean","slug":"Bean","permalink":"https://htchz.cc/tags/Bean/"},{"name":"IOC","slug":"IOC","permalink":"https://htchz.cc/tags/IOC/"}],"author":"土川"},{"title":"[碧油鸡]浅谈0xFF","slug":"碧油鸡-浅谈0xFF","date":"2018-03-16T07:47:00.000Z","updated":"2019-08-15T16:13:48.158Z","comments":true,"path":"2016889271.html","link":"","permalink":"https://htchz.cc/2016889271.html","excerpt":"这是一个无符号数引发的bug","text":"这是一个无符号数引发的bug 场景项目中使用了Redis的BitMap数据结构，关于它的用法就不赘述了。 我用BitMap来作为ip地址的黑名单模型，使用ip的hashcode作为offset，再合适不过。 但是ip是一个32位的无符号数，而java是没有无符号数的，这就导致有些ip的hashcode是一个负数。 java的做法是通过掩码的操作来进行有符号数到无符号数的转换。 解决方法hashCode() &amp; 0x00000000FFFFFFFFL 通过这行代码把int转为long，而且数值是无符号int的值 java也有BitMap位图模型——java.util.BitSet,而且java的BitSet的api只能使用大于0的int作为offset，而redis是可以用long作为offset的。 二进制那些事 在java.io.FilterOutputStream.DataOutputStream：与机器无关地写入各种类型的数据以及String对象的二进制形式，从高位开始写。这样一来，任何机器上任何DataInputStream都能够读取它们。所有方法都以“write”开头，例如writeByte()，writeFloat()等。java.io.FilterOutputStream.PrintStream最初的目的是为了以可视化格式打印所有的基本数据类型以及String对象。这和DataOutputStream不同，它目的是将数据元素置入“流”中，使DataInputStream能够可移植地重构它们。 如何把一串字符串写成二进制？ 字符串的本质是char的序列，也就是char []。因此，遍历写入每一个char，就完成了写一个字符串的功能。 char写成二进制？英语字母有ASCII码，可以把每个字符转换成对应的数字，那么汉字日语呢泰国语呢？这个问题前人早就已经解决。世界上的绝大部分字符都有一张类似于ASCII码表的字符和编码间的映射，那就是Unicode码表。 Unicode 字符编码标准是固定长度的字符编码方案，它包含了世界上几乎所有现用语言的字符。有关 Unicode 的信息可在最新版本的 The Unicode Standard 一书中找到，并可从 Unicode 协会 Web 站点（www.unicode.org）中找到。 Unicode 根据要编码的数据类型使用两种编码格式：8 位和 16 位。缺省编码格式是 16 位，即每个字符是 16 位（两个字节）宽，并且通常显示为 U+hhhh，其中 hhhh 是字符的十六进制代码点。虽然生成的 65000 多个代码元素足以用于 编码世界上主要语言的大多数字符，但 Unicode 标准还提供了一种扩展机制，允许编码一百多万个字符。扩展机制使用一对高位和低位代用字符来对扩展字符或补充字符进行编码。第一个（或高位）代用字符具有 U+D800 和 U+DBFF 之间的代码值，而第二个（或低位）代用字符具有 U+DC00 和 U+DFFF 之间的代码值。 unicode码可以用2个字节表示世界上的绝大部分字符。 一个char是0-65535间的数字，一个String就是一串长长长的数字。 所以DataOutputStream.writeChars(str)的源码是这样的： 123456789101112131415161718192021/** * Writes a string to the underlying output stream as a sequence of * characters. Each character is written to the data output stream as * if by the &lt;code&gt;writeChar&lt;/code&gt; method. If no exception is * thrown, the counter &lt;code&gt;written&lt;/code&gt; is incremented by twice * the length of &lt;code&gt;s&lt;/code&gt;. * * @param s a &lt;code&gt;String&lt;/code&gt; value to be written. * @exception IOException if an I/O error occurs. * @see java.io.DataOutputStream#writeChar(int) * @see java.io.FilterOutputStream#out */public final void writeChars(String s) throws IOException &#123; int len = s.length(); for (int i = 0 ; i &lt; len ; i++) &#123; int v = s.charAt(i); out.write((v &gt;&gt;&gt; 8) &amp; 0xFF); // `out.wirte(int)` 是一个抽象方法，一次传入一个int，而`out.wirte(int)`的实现总是把他强转成byte。 out.write((v &gt;&gt;&gt; 0) &amp; 0xFF); &#125; incCount(len * 2);&#125; 那么回到标题，(v &gt;&gt;&gt; 8) &amp; 0xFF、(v &gt;&gt;&gt; 0) &amp; 0xFF是干嘛的？ 0（零）xFF是16进制的255，也就是二进制的 1111 1111&amp; AND 按位与操作，同时为1时才是1，否则为0.————位移运算计算机中存的都是数的补码，所以位移运算都是对补码而言的————&lt;&lt; 左移 右补0&gt;&gt; 有符号右移 左补符号位，即：如果符号位是1 就左补1，如果符号位是0 就左补0&gt;&gt;&gt; 无符号右移 ，顾名思义，统一左补0 位移操作是不会改变原来的数的，就像String的操作都是返回一个新的String int v = s.charAt(i)得到的v是一个char强转的int，这个int的有效信息其实是低16位（int是32位，char是16位）的两个byte的信息。 那么怎么获得这两个byte并一一入参呢？ 这里可以把&amp;0XFF看成一把剪刀，看下面的操作。 1000,0000,0000,0011 这是一个short（为什么不用char？）的二进制 0000,0000,1000,0000 这是&quot;&gt;&gt;&gt;8&quot;的结果 然后再 &amp;0XFF，得到 1000,0000 （准确的说是 0000 0000 1000 0000）这就是第一个byte(从高位开始)。 接着 1000,0000,0000,0011 short的二进制原码 1000,0000,0000,0011 &gt;&gt;&gt;0还是源码本身不变然后再 &amp;0XFF，得到 0000,0011（准确的说是 0000 0000 0000 0011）所以 &amp;0xFF 就像计算机中的一把剪刀，用来截取一个byte。同理，&amp;0x0F呢？得到4bits有效值。 &amp;0xFF和上面的bug什么关系？既然实际上Redis的java客户端Jedis的位图api是这样的 public void setbit(byte[] key, long offset, boolean value)offset是一个long值，那么传入一个int类型的hashcode必然会强转。如果一个ip是128.xxx.xxx.xxx，那么二进制是10000000 xxxxxxxx xxxxxxxx xxxxxxxx，hashcode就是一个负数，一个负的int转成long之后，对于计算机为了保持补码数值不变，高位得自动补1，所以得到 11111111 11111111 11111111 11111111 10000000 xxxxxxxx xxxxxxxx xxxxxxxx可我们想得到的期望数是 00000000 00000000 00000000 00000000 10000000 xxxxxxxx xxxxxxxx xxxxxxxx这时候我们就要一把剪刀&amp; 0x00000000FFFFFFFFL来剪一下，得到我们的期望数。 题外话既然我们的DataOutputstrem是要write一个byte，为什么要用int入参引来一把剪刀的麻烦，其实是java没有无符号数的麻烦。 这其实和read()对应，read()是返回0-255的数据，和 -1 代表文件末尾，所以没有无符号数的java只能用read返回int。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"碧油鸡","slug":"碧油鸡","permalink":"https://htchz.cc/tags/碧油鸡/"},{"name":"位运算","slug":"位运算","permalink":"https://htchz.cc/tags/位运算/"}],"author":"土川"},{"title":"[集合扩容]HashMap的扩容机制及jdk8优化——resize()","slug":"集合扩容-HashMap的扩容机制——resize","date":"2018-03-16T03:19:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"92838208.html","link":"","permalink":"https://htchz.cc/92838208.html","excerpt":"我们来讲讲jdk8的HashMap扩容机制。虽然《Java集合(八)HashMap》贴过代码了","text":"我们来讲讲jdk8的HashMap扩容机制。虽然《Java集合(八)HashMap》贴过代码了 什么时候扩容当向容器添加元素的时候，会判断当前容器的元素个数，如果大于等于阈值——即当前数组的长度乘以加载因子的值的时候，就要自动扩容啦。 扩容(resize)数组是不能扩容的，所以扩容方法自然是使用一个新的更大容量的数组代替已有的容量小的数组 分析下resize的源码，鉴于JDK1.8融入了红黑树，较复杂，为了便于理解我们仍然使用JDK1.7的代码，好理解一些，本质上区别不大，具体区别后文再说。 12345678910111213void resize(int newCapacity) &#123; //传入新的容量 Entry[] oldTable = table; //引用扩容前的Entry数组 int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; //扩容前的数组大小如果已经达到最大(2^30)了 threshold = Integer.MAX_VALUE; //修改阈值为int的最大值(2^31-1)，这样以后就不会扩容了 return; &#125; Entry[] newTable = new Entry[newCapacity]; //初始化一个新的Entry数组 transfer(newTable); //！！将数据转移到新的Entry数组里 table = newTable; //HashMap的table属性引用新的Entry数组 threshold = (int) (newCapacity * loadFactor);//修改阈值 &#125; 这里就是使用一个容量更大的数组来代替已有的容量小的数组，transfer()方法将原有Entry数组的元素拷贝到新的Entry数组里。 1234567891011121314151617void transfer(Entry[] newTable) &#123; Entry[] src = table; //src引用了旧的Entry数组 int newCapacity = newTable.length; for (int j = 0; j &lt; src.length; j++) &#123; //遍历旧的Entry数组 Entry&lt;K, V&gt; e = src[j]; //取得旧Entry数组的每个元素 if (e != null) &#123; src[j] = null;//释放旧Entry数组的对象引用（for循环后，旧的Entry数组不再引用任何对象） do &#123; Entry&lt;K, V&gt; next = e.next; // 保存要处理的entry的next对象 int i = indexFor(e.hash, newCapacity); //重新计算entry在数组中的位置 e.next = newTable[i]; //这个操作将把处理的entry插到新数组i位置的entry链头部，然后结果就是最终链表倒置可以看下图 newTable[i] = e; //将entry放在新数组i位置上 e = next; //访问下一个Entry链上的元素 &#125; while (e != null); &#125; &#125; &#125; 123static int indexFor(int h, int length) &#123; return h &amp; (length - 1); // 这是取模运算，看那篇《[JDK8]HashMap的tableSizeFor()》中有提到&#125; 假设了我们的hash算法就是简单的用key mod 一下表的大小（也就是数组的长度）。 其中的哈希桶数组table的size=2，现在有key = 3、7、5，put顺序依次为 5、7、3。在mod 2以后都冲突在table[1]这里了。这里假设负载因子 loadFactor=1，即当键值对的实际大小size 大于 table的实际大小时进行扩容。接下来的三个步骤是哈希桶数组 resize成4，然后所有的Node重新rehash的过程。 jdk1.7扩容例图 经过观测可以发现，我们使用的是2次幂的扩展(指长度扩为原来2倍，power of two)，所以， 经过rehash之后，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。所以，jdk7的对于处理后还在原位置的元素的操作，冗余的操作，于是jdk8有了以下优化。 12345678910/** * Initializes or doubles table size. If null, allocates in * accord with initial capacity target held in field threshold. * Otherwise, because we are using power-of-two expansion, the * elements from each bin must either stay at same index, or move * with a power of two offset in the new table. * * @return the table */ final Node&lt;K,V&gt;[] resize() &#123; 看下图可以明白这句话的意思，n为table的长度，图（a）表示扩容前的key1和key2两种key确定索引位置的示例，图（b）表示扩容后key1和key2两种key确定索引位置的示例，其中hash1是key1对应的哈希与高位运算结果。 元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化： 因此，我们在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”，可以看看下图为16扩充为32的resize示意图： 这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。这一块就是JDK1.8新增的优化点。有一点注意区别，JDK1.7中rehash的时候，旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置，但是从上图可以看出，JDK1.8不会倒置。有兴趣的同学可以研究下JDK1.8的resize源码，写的很赞，如下: 下面是他的实现: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182/** * Initializes or doubles table size. If null, allocates in * accord with initial capacity target held in field threshold. * Otherwise, because we are using power-of-two expansion, the * elements from each bin must either stay at same index, or move * with a power of two offset in the new table. * * @return the table */final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125;","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"jdk8","slug":"jdk8","permalink":"https://htchz.cc/tags/jdk8/"},{"name":"Java集合","slug":"Java集合","permalink":"https://htchz.cc/tags/Java集合/"}],"author":"土川"},{"title":"[集合扩容]HashMap的tableSizeFor()","slug":"JDK8-HashMap的tableSizeFor","date":"2018-03-15T08:51:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"2353864749.html","link":"","permalink":"https://htchz.cc/2353864749.html","excerpt":"jdk8的HashMap源码阅读的时候，发现一个tableSizeFor()方法是一串位运算，这个方法第一次出现是在HashMap指定容量的构造函数里出现","text":"jdk8的HashMap源码阅读的时候，发现一个tableSizeFor()方法是一串位运算，这个方法第一次出现是在HashMap指定容量的构造函数里出现 代码1234567891011 // Returns a power of two size for the given target capacity. // 这是方法的注释 // 大致意思就是找到大于等于指定容量(capacity)参数的2的幂 static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; &#125; 目的这段代码的目的注如注释所说：找到一个数，满足下面的条件 它是2的幂(有助于提高性能)， 它大于或者等于capacity 满足上面两个条件的数中最小(也就是最接近capacity) 个人瞎掰对一个数A，怎么找一个数B 满足上面条件呢 下面的方法不是代码对应的实现 把数转为二进制，找到A的最高位，那么数B就是数A最高位左移一位其余为0的数。举个例子。 比如要找给定的数7，满足条件的数明显是8。 8的2进制： 0000 1000 7的2进制： 0000 0111从7得到8： 我们把7的最高位第三位左移一位，得到0000 1110 其余清零，得到0000 1000，就是目标的8 但是这样有个问题，如果一个数刚好是2的幂，比如2对应的0000 0010，那么经过左移、清零操作，得到0000 0100，也就是4，明显比满足条件的数大了一倍（给定2满足条件的数还是2） 这样还得判断一个数是不是2的幂，烦不？ 代码的实现代码的逻辑是介样的： 我们先不看int n = cap - 1 直接说他的位移操作。通过位移操作，从最高位是1的位置开始，往低位置全部置为1(这个方法是通过或操作|和无符号右移&gt;&gt;&gt;来实现的，拿草稿纸按照代码写一下就清楚逻辑了)，然后+1。 从7得到8： 我们把7的最高位往低位置1，得到0000 0111 接着+1，得到0000 1000 这样还是没解决“一个数刚好是2的幂”的问题，于是有了那一行int n = cap - 1，这个减一操作可以完美避免“判断一个数是不是2的幂”。 如果一个数不是2的幂，减一操作后，最终会被置1操作补偿回来。 如果一个数是2的幂，减一操作后，可以把这个数缩小一倍，最后置1、+1操作会把数还原。 （完） ** 其实还没完，为什么这么执着于把容量改成2的幂？** 其实HashMap在根据hashcode取数组下标的时候，代码是这样的 123static int indexFor(int h, int length) &#123; return h &amp; (length - 1); &#125; 这个h &amp; (length - 1)这是一个取模操作 取模算法中的除法运算效率很低，在HashMap中通过h&amp;（n-1）替代取模，得到所在数组位置，效率会高很多。（前提是保证数组的容量是2的整数倍） （完）","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"Java集合","slug":"Java集合","permalink":"https://htchz.cc/tags/Java集合/"}],"author":"土川"},{"title":"Java集合(十四)Iterator和Enumeration的区别和对比","slug":"Java集合-十三-Iterator和Enumeration的区别和对比","date":"2018-03-15T07:21:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"3355313933.html","link":"","permalink":"https://htchz.cc/3355313933.html","excerpt":"","text":"Iterator和Enumeration区别在Java集合中，我们通常都通过 “Iterator(迭代器)” 或 “Enumeration(枚举类)” 去遍历集合。今天，我们就一起学习一下它们之间到底有什么区别。我们先看看 Enumeration.java 和 Iterator.java的源码，再说它们的区别。Enumeration是一个接口，它的源码如下： 12345678package java.util; public interface Enumeration&lt;E&gt; &#123; boolean hasMoreElements(); E nextElement();&#125; Iterator也是一个接口 ，它的源码如下 123456789package java.util; public interface Iterator&lt;E&gt; &#123; boolean hasNext(); E next(); void remove();&#125; 区别： 函数接口不同Enumeration只有2个函数接口。通过Enumeration，我们只能读取集合的数据，而不能对数据进行修改。Iterator只有3个函数接口。Iterator除了能读取集合的数据之外，也能数据进行删除操作。 Iterator支持fail-fast机制，而Enumeration不支持Enumeration 是JDK 1.0添加的接口。使用到它的函数包括Vector、Hashtable等类，这些类都是JDK 1.0中加入的，Enumeration存在的目的就是为它们提供遍历接口。Enumeration本身并没有支持同步，而在Vector、Hashtable实现Enumeration时，添加了同步。而Iterator 是JDK 1.2才添加的接口，它也是为了HashMap、ArrayList等集合提供遍历接口。Iterator是支持fail-fast机制的：当多个线程对同一个集合的内容进行操作时，就可能会产生fail-fast事件。 最后，最重要的就是不要使用 Enumeration","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"Java集合","slug":"Java集合","permalink":"https://htchz.cc/tags/Java集合/"}],"author":"土川"},{"title":"Java集合(十三)Map概括,总结","slug":"Java集合-十四-Iterator和Enumeration的区别和对比","date":"2018-03-15T07:07:00.000Z","updated":"2019-07-16T10:22:13.000Z","comments":true,"path":"3132613980.html","link":"","permalink":"https://htchz.cc/3132613980.html","excerpt":"","text":"Java集合(十二)Map概括,总结 Map概括Map 是“键值对”映射的抽象接口。AbstractMap 实现了Map中的绝大部分函数接口。它减少了“Map的实现类”的重复编码。SortedMap 有序的“键值对”映射接口。NavigableMap 是继承于SortedMap的，支持导航函数的接口。HashMap, Hashtable, TreeMap, WeakHashMap这4个类是“键值对”映射的实现类。它们各有区别！ HashMap 是基于“拉链法”实现的散列表。一般用于单线程程序中。Hashtable 也是基于“拉链法”实现的散列表。它一般用于多线程程序中。WeakHashMap 也是基于“拉链法”实现的散列表，它一般也用于单线程程序中。相比HashMap，WeakHashMap中的键是“弱键”，当“弱键”被GC回收时，它对应的键值对也会被从WeakHashMap中删除；而HashMap中的键是强键。TreeMap 是有序的散列表，它是通过红黑树实现的。它一般用于单线程中存储有序的映射。 HashMap和WeakHashMap异同HashMap和WeakHashMap的相同点 它们都是散列表，存储的是“键值对”映射。 它们都继承于AbstractMap，并且实现Map基础。 它们的构造函数都一样。它们都包括4个构造函数，而且函数的参数都一样。 默认的容量大小是16，默认的加载因子是0.75。 它们的“键”和“值”都允许为null。 它们都是“非同步的”。 HashMap和WeakHashMap的不同点HashMap实现了Cloneable和Serializable接口，而WeakHashMap没有。 HashMap实现Cloneable，意味着它能通过clone()克隆自己。HashMap实现Serializable，意味着它支持序列化，能通过序列化去传输。 HashMap的“键”是“强引用(StrongReference)”，而WeakHashMap的键是“弱引用(WeakReference)”。WeakReference的“弱键”能实现WeakReference对“键值对”的动态回收。当“弱键”不再被使用到时，GC会回收它，WeakReference也会将“弱键”对应的键值对删除。这个“弱键”实现的动态回收“键值对”的原理呢？其实，通过WeakReference(弱引用)和ReferenceQueue(引用队列)实现的。 首先，我们需要了解WeakHashMap中：第一，“键”是WeakReference，即key是弱键。第二，ReferenceQueue是一个引用队列，它是和WeakHashMap联合使用的。当弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 WeakHashMap中的ReferenceQueue是queue。第三，WeakHashMap是通过数组实现的，我们假设这个数组是table。 接下来，说说“动态回收”的步骤。 (01) 新建WeakHashMap，将“键值对”添加到WeakHashMap中。将“键值对”添加到WeakHashMap中时，添加的键都是弱键。实际上，WeakHashMap是通过数组table保存Entry(键值对)；每一个Entry实际上是一个单向链表，即Entry是键值对链表。(02) 当某“弱键”不再被其它对象引用，并被GC回收时。在GC回收该“弱键”时，这个“弱键”也同时会被添加到queue队列中。例如，当我们在将“弱键”key添加到WeakHashMap之后；后来将key设为null。这时，便没有外部外部对象再引用该了key。接着，当Java虚拟机的GC回收内存时，会回收key的相关内存；同时，将key添加到queue队列中。(03) 当下一次我们需要操作WeakHashMap时，会先同步table和queue。table中保存了全部的键值对，而queue中保存被GC回收的“弱键”；同步它们，就是删除table中被GC回收的“弱键”对应的键值对。例如，当我们“读取WeakHashMap中的元素或获取WeakReference的大小时”，它会先同步table和queue，目的是“删除table中被GC回收的‘弱键’对应的键值对”。删除的方法就是逐个比较“table中元素的‘键’和queue中的‘键’”，若它们相当，则删除“table中的该键值对” HashMap和WeakHashMap比较测试程序123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134import java.util.HashMap;import java.util.Map;import java.util.WeakHashMap;public class CompareHashmapAndWeakhashmap &#123; public static void main(String[] args) throws Exception &#123; // 当“弱键”是String时，比较HashMap和WeakHashMap compareWithString(); // 当“弱键”是自定义类型时，比较HashMap和WeakHashMap compareWithSelfClass(); &#125; /** * 遍历map，并打印map的大小 */ private static void iteratorAndCountMap(Map map) &#123; // 遍历map for (Object o : map.entrySet()) &#123; Map.Entry en = (Map.Entry) o; System.out.printf(\"map entry : %s - %s\\n\", en.getKey(), en.getValue()); &#125; // 打印HashMap的实际大小 System.out.printf(\"map size:%s\\n\\n\", map.size()); &#125; /** * 通过String对象测试HashMap和WeakHashMap */ private static void compareWithString() &#123; // 新建4个String字符串 String w1 = new String(\"W1\"); // 不是对象的话不会被gc回收 String w2 = new String(\"W2\"); String h1 = new String(\"H1\"); String h2 = new String(\"H2\"); // 新建 WeakHashMap对象，并将w1,w2添加到 WeakHashMap中 Map&lt;String, String&gt; wmap = new WeakHashMap&lt;&gt;(); wmap.put(w1, \"w1\"); wmap.put(w2, \"w2\"); // 新建 HashMap对象，并将h1,h2添加到 WeakHashMap中 Map&lt;String, String&gt; hmap = new HashMap&lt;&gt;(); hmap.put(h1, \"h1\"); hmap.put(h2, \"h2\"); // 删除HashMap中的“h1”。 // 结果：删除“h1”之后，HashMap中只有 h2 ！ hmap.remove(h1); // 将WeakHashMap中的w1设置null，并执行gc()。系统会回收w1 // 结果：w1是“弱键”，被GC回收后，WeakHashMap中w1对应的键值对，也会被从WeakHashMap中删除。 // w2是“弱键”，但它不是null，不会被GC回收；也就不会被从WeakHashMap中删除。 // 因此，WeakHashMap中只有 w2 // 注意：若去掉“w1=null” 或者“System.gc()”，结果都会不一样！ w1 = null; System.gc(); // 遍历并打印HashMap的大小 System.out.println(\" -- HashMap --\"); iteratorAndCountMap(hmap); // 遍历并打印WeakHashMap的大小 System.out.println(\" -- WeakHashMap --\"); iteratorAndCountMap(wmap); &#125; /** * 通过自定义类测试HashMap和WeakHashMap */ private static void compareWithSelfClass() &#123; // 新建4个自定义对象 Self s1 = new Self(10); Self s2 = new Self(20); Self s3 = new Self(30); Self s4 = new Self(40); // 新建 WeakHashMap对象，并将s1,s2添加到 WeakHashMap中 Map&lt;Self, String&gt; wmap = new WeakHashMap&lt;&gt;(); wmap.put(s1, \"s1\"); wmap.put(s2, \"s2\"); // 新建 HashMap对象，并将s3,s4添加到 WeakHashMap中 Map&lt;Self, String&gt; hmap = new HashMap&lt;&gt;(); hmap.put(s3, \"s3\"); hmap.put(s4, \"s4\"); // 删除HashMap中的s3。 // 结果：删除s3之后，HashMap中只有 s4 ！ hmap.remove(s3); // 将WeakHashMap中的s1设置null，并执行gc()。系统会回收w1 // 结果：s1是“弱键”，被GC回收后，WeakHashMap中s1对应的键值对，也会被从WeakHashMap中删除。 // w2是“弱键”，但它不是null，不会被GC回收；也就不会被从WeakHashMap中删除。 // 因此，WeakHashMap中只有 s2 // 注意：若去掉“s1=null” 或者“System.gc()”，结果都会不一样！ s1 = null; System.gc(); /* // 休眠500ms try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // */ // 遍历并打印HashMap的大小 System.out.println(\" -- Self-def HashMap --\"); iteratorAndCountMap(hmap); // 遍历并打印WeakHashMap的大小 System.out.println(\" -- Self-def WeakHashMap --\"); iteratorAndCountMap(wmap); &#125; private static class Self &#123; int id; Self(int id) &#123; this.id = id; &#125; // 覆盖finalize()方法 // 在GC回收时会被执行 protected void finalize() throws Throwable &#123; super.finalize(); System.out.printf(\"GC Self: id=%d addr=0x%s)\\n\", id, this); &#125; &#125;&#125; 运行结果： 12345678910111213141516-- HashMap --map entry : H2 - h2map size:1-- WeakHashMap --map entry : W2 - w2map size:1-- Self-def HashMap --map entry : CompareHashmapAndWeakhashmap$Self@5451c3a8 - s4map size:1-- Self-def WeakHashMap --GC Self: id=10 addr=0xCompareHashmapAndWeakhashmap$Self@49476842)map entry : CompareHashmapAndWeakhashmap$Self@78308db1 - s2map size:1","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"Java集合","slug":"Java集合","permalink":"https://htchz.cc/tags/Java集合/"}],"author":"土川"},{"title":"Java集合(十六)TreeSet源码分析和使用示例","slug":"Java集合-十五-TreeSet源码分析和使用示例","date":"2018-03-15T02:23:00.000Z","updated":"2019-07-16T10:14:54.000Z","comments":true,"path":"2771522404.html","link":"","permalink":"https://htchz.cc/2771522404.html","excerpt":"","text":"TreeSet介绍TreeSet简介TreeSet 是一个有序的集合，它的作用是提供有序的Set集合。它继承于AbstractSet抽象类，实现了NavigableSet, Cloneable, java.io.Serializable接口。TreeSet 继承于AbstractSet，所以它是一个Set集合，具有Set的属性和方法。TreeSet 实现了NavigableSet接口，意味着它支持一系列的导航方法。比如查找与指定目标最匹配项。TreeSet 实现了Cloneable接口，意味着它能被克隆。TreeSet 实现了java.io.Serializable接口，意味着它支持序列化。TreeSet是基于TreeMap实现的。TreeSet中的元素支持2种排序方式：自然排序 或者 根据创建TreeSet 时提供的 Comparator 进行排序。这取决于使用的构造方法。 TreeSet 会根据比较值进行去重，先加入的元素如果和后加入的元素一样则保留先加入的元素，不会覆盖 TreeSet为基本操作（add、remove 和 contains）提供受保证的 log(n) 时间开销。另外，TreeSet是非同步的。 它的iterator 方法返回的迭代器是fail-fast的 TreeSet的继承关系1234567java.lang.Object ? java.util.AbstractCollection&lt;E&gt; ? java.util.AbstractSet&lt;E&gt; ? java.util.TreeSet&lt;E&gt; public class TreeSet&lt;E&gt; extends AbstractSet&lt;E&gt; implements NavigableSet&lt;E&gt;, Cloneable, java.io.Serializable&#123;&#125; TreeSet的构造函数1234567891011// 默认构造函数。使用该构造函数，TreeSet中的元素按照自然排序进行排列。TreeSet() // 创建的TreeSet包含collectionTreeSet(Collection&lt;? extends E&gt; collection) // 指定TreeSet的比较器TreeSet(Comparator&lt;? super E&gt; comparator) // 创建的TreeSet包含setTreeSet(SortedSet&lt;E&gt; set) TreeSet的API1234567891011121314151617181920212223242526boolean add(E object)boolean addAll(Collection&lt;? extends E&gt; collection)void clear()Object clone()boolean contains(Object object)E first()boolean isEmpty()E last()E pollFirst()E pollLast()E lower(E e)E floor(E e)E ceiling(E e)E higher(E e)boolean remove(Object object)int size()Comparator&lt;? super E&gt; comparator()Iterator&lt;E&gt; iterator()Iterator&lt;E&gt; descendingIterator()SortedSet&lt;E&gt; headSet(E end)NavigableSet&lt;E&gt; descendingSet()NavigableSet&lt;E&gt; headSet(E end, boolean endInclusive)SortedSet&lt;E&gt; subSet(E start, E end)NavigableSet&lt;E&gt; subSet(E start, boolean startInclusive, E end, boolean endInclusive)NavigableSet&lt;E&gt; tailSet(E start, boolean startInclusive)SortedSet&lt;E&gt; tailSet(E start) 说明： TreeSet是有序的Set集合，因此支持add、remove、get等方法。 和NavigableSet一样，TreeSet的导航方法大致可以区分为两类，一类时提供元素项的导航方法，返回某个元素；另一类时提供集合的导航方法，返回某个集合。lower、floor、ceiling 和 higher 分别返回小于、小于等于、大于等于、大于给定元素的元素，如果不存在这样的元素，则返回 null。 TreeSet源码解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239package java.util; public class TreeSet&lt;E&gt; extends AbstractSet&lt;E&gt; implements NavigableSet&lt;E&gt;, Cloneable, java.io.Serializable&#123; // NavigableMap对象 private transient NavigableMap&lt;E,Object&gt; m; // TreeSet是通过TreeMap实现的， // PRESENT是键-值对中的值。 private static final Object PRESENT = new Object(); // 不带参数的构造函数。创建一个空的TreeMap public TreeSet() &#123; this(new TreeMap&lt;E,Object&gt;()); &#125; // 将TreeMap赋值给 &quot;NavigableMap对象m&quot; TreeSet(NavigableMap&lt;E,Object&gt; m) &#123; this.m = m; &#125; // 带比较器的构造函数。 public TreeSet(Comparator&lt;? super E&gt; comparator) &#123; this(new TreeMap&lt;E,Object&gt;(comparator)); &#125; // 创建TreeSet，并将集合c中的全部元素都添加到TreeSet中 public TreeSet(Collection&lt;? extends E&gt; c) &#123; this(); // 将集合c中的元素全部添加到TreeSet中 addAll(c); &#125; // 创建TreeSet，并将s中的全部元素都添加到TreeSet中 public TreeSet(SortedSet&lt;E&gt; s) &#123; this(s.comparator()); addAll(s); &#125; // 返回TreeSet的顺序排列的迭代器。 // 因为TreeSet时TreeMap实现的，所以这里实际上时返回TreeMap的“键集”对应的迭代器 public Iterator&lt;E&gt; iterator() &#123; return m.navigableKeySet().iterator(); &#125; // 返回TreeSet的逆序排列的迭代器。 // 因为TreeSet时TreeMap实现的，所以这里实际上时返回TreeMap的“键集”对应的迭代器 public Iterator&lt;E&gt; descendingIterator() &#123; return m.descendingKeySet().iterator(); &#125; // 返回TreeSet的大小 public int size() &#123; return m.size(); &#125; // 返回TreeSet是否为空 public boolean isEmpty() &#123; return m.isEmpty(); &#125; // 返回TreeSet是否包含对象(o) public boolean contains(Object o) &#123; return m.containsKey(o); &#125; // 添加e到TreeSet中 public boolean add(E e) &#123; return m.put(e, PRESENT)==null; &#125; // 删除TreeSet中的对象o public boolean remove(Object o) &#123; return m.remove(o)==PRESENT; &#125; // 清空TreeSet public void clear() &#123; m.clear(); &#125; // 将集合c中的全部元素添加到TreeSet中 public boolean addAll(Collection&lt;? extends E&gt; c) &#123; // Use linear-time version if applicable if (m.size()==0 &amp;&amp; c.size() &gt; 0 &amp;&amp; c instanceof SortedSet &amp;&amp; m instanceof TreeMap) &#123; SortedSet&lt;? extends E&gt; set = (SortedSet&lt;? extends E&gt;) c; TreeMap&lt;E,Object&gt; map = (TreeMap&lt;E, Object&gt;) m; Comparator&lt;? super E&gt; cc = (Comparator&lt;? super E&gt;) set.comparator(); Comparator&lt;? super E&gt; mc = map.comparator(); if (cc==mc || (cc != null &amp;&amp; cc.equals(mc))) &#123; map.addAllForTreeSet(set, PRESENT); return true; &#125; &#125; return super.addAll(c); &#125; // 返回子Set，实际上是通过TreeMap的subMap()实现的。 public NavigableSet&lt;E&gt; subSet(E fromElement, boolean fromInclusive, E toElement, boolean toInclusive) &#123; return new TreeSet&lt;E&gt;(m.subMap(fromElement, fromInclusive, toElement, toInclusive)); &#125; // 返回Set的头部，范围是：从头部到toElement。 // inclusive是是否包含toElement的标志 public NavigableSet&lt;E&gt; headSet(E toElement, boolean inclusive) &#123; return new TreeSet&lt;E&gt;(m.headMap(toElement, inclusive)); &#125; // 返回Set的尾部，范围是：从fromElement到结尾。 // inclusive是是否包含fromElement的标志 public NavigableSet&lt;E&gt; tailSet(E fromElement, boolean inclusive) &#123; return new TreeSet&lt;E&gt;(m.tailMap(fromElement, inclusive)); &#125; // 返回子Set。范围是：从fromElement(包括)到toElement(不包括)。 public SortedSet&lt;E&gt; subSet(E fromElement, E toElement) &#123; return subSet(fromElement, true, toElement, false); &#125; // 返回Set的头部，范围是：从头部到toElement(不包括)。 public SortedSet&lt;E&gt; headSet(E toElement) &#123; return headSet(toElement, false); &#125; // 返回Set的尾部，范围是：从fromElement到结尾(不包括)。 public SortedSet&lt;E&gt; tailSet(E fromElement) &#123; return tailSet(fromElement, true); &#125; // 返回Set的比较器 public Comparator&lt;? super E&gt; comparator() &#123; return m.comparator(); &#125; // 返回Set的第一个元素 public E first() &#123; return m.firstKey(); &#125; // 返回Set的最后一个元素 public E first() &#123; public E last() &#123; return m.lastKey(); &#125; // 返回Set中小于e的最大元素 public E lower(E e) &#123; return m.lowerKey(e); &#125; // 返回Set中小于/等于e的最大元素 public E floor(E e) &#123; return m.floorKey(e); &#125; // 返回Set中大于/等于e的最小元素 public E ceiling(E e) &#123; return m.ceilingKey(e); &#125; // 返回Set中大于e的最小元素 public E higher(E e) &#123; return m.higherKey(e); &#125; // 获取第一个元素，并将该元素从TreeMap中删除。 public E pollFirst() &#123; Map.Entry&lt;E,?&gt; e = m.pollFirstEntry(); return (e == null)? null : e.getKey(); &#125; // 获取最后一个元素，并将该元素从TreeMap中删除。 public E pollLast() &#123; Map.Entry&lt;E,?&gt; e = m.pollLastEntry(); return (e == null)? null : e.getKey(); &#125; // 克隆一个TreeSet，并返回Object对象 public Object clone() &#123; TreeSet&lt;E&gt; clone = null; try &#123; clone = (TreeSet&lt;E&gt;) super.clone(); &#125; catch (CloneNotSupportedException e) &#123; throw new InternalError(); &#125; clone.m = new TreeMap&lt;E,Object&gt;(m); return clone; &#125; // java.io.Serializable的写入函数 // 将TreeSet的“比较器、容量，所有的元素值”都写入到输出流中 private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException &#123; s.defaultWriteObject(); // 写入比较器 s.writeObject(m.comparator()); // 写入容量 s.writeInt(m.size()); // 写入“TreeSet中的每一个元素” for (Iterator i=m.keySet().iterator(); i.hasNext(); ) s.writeObject(i.next()); &#125; // java.io.Serializable的读取函数：根据写入方式读出 // 先将TreeSet的“比较器、容量、所有的元素值”依次读出 private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; // Read in any hidden stuff s.defaultReadObject(); // 从输入流中读取TreeSet的“比较器” Comparator&lt;? super E&gt; c = (Comparator&lt;? super E&gt;) s.readObject(); TreeMap&lt;E,Object&gt; tm; if (c==null) tm = new TreeMap&lt;E,Object&gt;(); else tm = new TreeMap&lt;E,Object&gt;(c); m = tm; // 从输入流中读取TreeSet的“容量” int size = s.readInt(); // 从输入流中读取TreeSet的“全部元素” tm.readTreeSet(size, s, PRESENT); &#125; // TreeSet的序列版本号 private static final long serialVersionUID = -2479143000061671589L;&#125; 总结： TreeSet实际上是TreeMap实现的。当我们构造TreeSet时；若使用不带参数的构造函数，则TreeSet的使用自然比较器；若用户需要使用自定义的比较器，则需要使用带比较器的参数。 TreeSet是非线程安全的。 TreeSet实现java.io.Serializable的方式。当写入到输出流时，依次写入“比较器、容量、全部元素”；当读出输入流时，再依次读取。TreeSet遍历方式Iterator顺序遍历123for(Iterator iter = set.iterator(); iter.hasNext(); ) &#123; iter.next();&#125; Iterator反序遍历1234// 假设set是TreeSet对象for(Iterator iter = set.descendingIterator(); iter.hasNext(); ) &#123; iter.next();&#125; for-each遍历1234// 假设set是TreeSet对象，并且set中元素是String类型String[] arr = (String[])set.toArray(new String[0]);for (String str:arr) System.out.printf(&quot;for each : %s\\n&quot;, str); TreeSet遍历测试程序如下： 123456789101112131415161718192021222324252627282930313233343536373839404142public class TreeSetIteratorTest &#123; public static void main(String[] args) &#123; TreeSet set = new TreeSet(); set.add(&quot;aaa&quot;); set.add(&quot;aaa&quot;); set.add(&quot;bbb&quot;); set.add(&quot;eee&quot;); set.add(&quot;ddd&quot;); set.add(&quot;ccc&quot;); // 顺序遍历TreeSet ascIteratorThroughIterator(set) ; // 逆序遍历TreeSet descIteratorThroughIterator(set); // 通过for-each遍历TreeSet。不推荐！此方法需要先将Set转换为数组 foreachTreeSet(set); &#125; // 顺序遍历TreeSet public static void ascIteratorThroughIterator(TreeSet set) &#123; System.out.print(&quot;\\n ---- Ascend Iterator ----\\n&quot;); for(Iterator iter = set.iterator(); iter.hasNext(); ) &#123; System.out.printf(&quot;asc : %s\\n&quot;, iter.next()); &#125; &#125; // 逆序遍历TreeSet public static void descIteratorThroughIterator(TreeSet set) &#123; System.out.printf(&quot;\\n ---- Descend Iterator ----\\n&quot;); for(Iterator iter = set.descendingIterator(); iter.hasNext(); ) System.out.printf(&quot;desc : %s\\n&quot;, (String)iter.next()); &#125; // 通过for-each遍历TreeSet。不推荐！此方法需要先将Set转换为数组 private static void foreachTreeSet(TreeSet set) &#123; System.out.printf(&quot;\\n ---- For-each ----\\n&quot;); String[] arr = (String[])set.toArray(new String[0]); for (String str:arr) System.out.printf(&quot;for each : %s\\n&quot;, str); &#125;&#125; TreeSet不支持快速随机遍历，只能通过迭代器进行遍历。 TreeSet示例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public class TreeSetTest &#123; public static void main(String[] args) &#123; testTreeSetAPIs(); &#125; // 测试TreeSet的api public static void testTreeSetAPIs() &#123; String val; // 新建TreeSet TreeSet tSet = new TreeSet(); // 将元素添加到TreeSet中 tSet.add(&quot;aaa&quot;); // Set中不允许重复元素，所以只会保存一个“aaa” tSet.add(&quot;aaa&quot;); tSet.add(&quot;bbb&quot;); tSet.add(&quot;eee&quot;); tSet.add(&quot;ddd&quot;); tSet.add(&quot;ccc&quot;); System.out.println(&quot;TreeSet:&quot;+tSet); // 打印TreeSet的实际大小 System.out.printf(&quot;size : %d\\n&quot;, tSet.size()); // 导航方法 // floor(小于、等于) System.out.printf(&quot;floor bbb: %s\\n&quot;, tSet.floor(&quot;bbb&quot;)); // lower(小于) System.out.printf(&quot;lower bbb: %s\\n&quot;, tSet.lower(&quot;bbb&quot;)); // ceiling(大于、等于) System.out.printf(&quot;ceiling bbb: %s\\n&quot;, tSet.ceiling(&quot;bbb&quot;)); System.out.printf(&quot;ceiling eee: %s\\n&quot;, tSet.ceiling(&quot;eee&quot;)); // ceiling(大于) System.out.printf(&quot;higher bbb: %s\\n&quot;, tSet.higher(&quot;bbb&quot;)); // subSet() System.out.printf(&quot;subSet(aaa, true, ccc, true): %s\\n&quot;, tSet.subSet(&quot;aaa&quot;, true, &quot;ccc&quot;, true)); System.out.printf(&quot;subSet(aaa, true, ccc, false): %s\\n&quot;, tSet.subSet(&quot;aaa&quot;, true, &quot;ccc&quot;, false)); System.out.printf(&quot;subSet(aaa, false, ccc, true): %s\\n&quot;, tSet.subSet(&quot;aaa&quot;, false, &quot;ccc&quot;, true)); System.out.printf(&quot;subSet(aaa, false, ccc, false): %s\\n&quot;, tSet.subSet(&quot;aaa&quot;, false, &quot;ccc&quot;, false)); // headSet() System.out.printf(&quot;headSet(ccc, true): %s\\n&quot;, tSet.headSet(&quot;ccc&quot;, true)); System.out.printf(&quot;headSet(ccc, false): %s\\n&quot;, tSet.headSet(&quot;ccc&quot;, false)); // tailSet() System.out.printf(&quot;tailSet(ccc, true): %s\\n&quot;, tSet.tailSet(&quot;ccc&quot;, true)); System.out.printf(&quot;tailSet(ccc, false): %s\\n&quot;, tSet.tailSet(&quot;ccc&quot;, false)); // 删除“ccc” tSet.remove(&quot;ccc&quot;); // 将Set转换为数组 String[] arr = (String[])tSet.toArray(new String[0]); for (String str:arr) System.out.printf(&quot;for each : %s\\n&quot;, str); // 打印TreeSet System.out.printf(&quot;TreeSet:%s\\n&quot;, tSet); // 遍历TreeSet for(Iterator iter = tSet.iterator(); iter.hasNext(); ) &#123; System.out.printf(&quot;iter : %s\\n&quot;, iter.next()); &#125; // 删除并返回第一个元素 val = (String)tSet.pollFirst(); System.out.printf(&quot;pollFirst=%s, set=%s\\n&quot;, val, tSet); // 删除并返回最后一个元素 val = (String)tSet.pollLast(); System.out.printf(&quot;pollLast=%s, set=%s\\n&quot;, val, tSet); // 清空HashSet tSet.clear(); // 输出HashSet是否为空 System.out.printf(&quot;%s\\n&quot;, tSet.isEmpty()?&quot;set is empty&quot;:&quot;set is not empty&quot;); &#125;&#125;","categories":[],"tags":[]},{"title":"Java集合(十二)LinkedHashMap","slug":"Java集合-十二-LinkedHashMap","date":"2018-03-14T10:44:00.000Z","updated":"2019-07-16T10:16:03.000Z","comments":true,"path":"4054277428.html","link":"","permalink":"https://htchz.cc/4054277428.html","excerpt":"","text":"LinkedHashMap简介概括的说，LinkedHashMap 是一个关联数组、哈希表，它是线程不安全的，允许key为null,value为null。它继承自HashMap，实现了Map&lt;K,V&gt;接口。其内部还维护了一个双向链表，在每次插入数据，或者访问、修改数据时，会增加节点、或调整链表的节点顺序。以决定迭代时输出的顺序。 默认情况，遍历时的顺序是按照插入节点的顺序。这也是其与HashMap最大的区别。也可以在构造时传入accessOrder参数，使得其遍历顺序按照访问的顺序输出。 因继承自HashMap,所以HashMap上文分析的特点，除了输出无序，其他LinkedHashMap都有，比如扩容的策略，哈希桶长度一定是2的N次方等等。LinkedHashMap在实现时，就是重写override了几个方法。以满足其输出序列有序的需求。 代码示例在每次插入数据，或者访问、修改数据时，会增加节点、或调整链表的节点顺序。以决定迭代时输出的顺序。 123456789101112131415161718192021222324252627Map&lt;String, String&gt; map = new LinkedHashMap&lt;&gt;();map.put(\"1\", \"a\");map.put(\"2\", \"b\");map.put(\"3\", \"c\");map.put(\"4\", \"d\");Iterator&lt;Map.Entry&lt;String, String&gt;&gt; iterator = map.entrySet().iterator();while (iterator.hasNext()) &#123; System.out.println(iterator.next());&#125;System.out.println(\"以下是accessOrder=true的情况:\");map = new LinkedHashMap&lt;String, String&gt;(10, 0.75f, true);map.put(\"1\", \"a\");map.put(\"2\", \"b\");map.put(\"3\", \"c\");map.put(\"4\", \"d\");map.get(\"2\");//2移动到了内部的链表末尾map.get(\"4\");//4调整至末尾map.put(\"3\", \"e\");//3调整至末尾map.put(null, null);//插入两个新的节点 nullmap.put(\"5\", null);//5iterator = map.entrySet().iterator();while (iterator.hasNext()) &#123; System.out.println(iterator.next());&#125; 输出： 12345678910111=a2=b3=c4=d以下是accessOrder=true的情况:1=a2=b4=d3=enull=null5=null 源码分析数据结构LinkedHashMap的节点Entry&lt;K,V&gt;继承自HashMap.Node&lt;K,V&gt;，在其基础上扩展了一下。改成了一个双向链表。 123456static class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; &#123; Entry&lt;K,V&gt; before, after; Entry(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; super(hash, key, value, next); &#125;&#125; 同时类里有两个成员变量head tail,分别指向内部双向链表的表头、表尾。 12345//双向链表的头结点transient LinkedHashMap.Entry&lt;K,V&gt; head;//双向链表的尾节点transient LinkedHashMap.Entry&lt;K,V&gt; tail; 构造函数1234567891011121314151617181920212223242526272829303132//默认是false，则迭代时输出的顺序是插入节点的顺序。若为true，则输出的顺序是按照访问节点的顺序。//为true时，可以在这基础之上构建一个LruCachfinal boolean accessOrder;public LinkedHashMap() &#123; super(); accessOrder = false;&#125;//指定初始化时的容量，public LinkedHashMap(int initialCapacity) &#123; super(initialCapacity); accessOrder = false;&#125;//指定初始化时的容量，和扩容的加载因子public LinkedHashMap(int initialCapacity, float loadFactor) &#123; super(initialCapacity, loadFactor); accessOrder = false;&#125;//指定初始化时的容量，和扩容的加载因子，以及迭代输出节点的顺序public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) &#123; super(initialCapacity, loadFactor); this.accessOrder = accessOrder;&#125;//利用另一个Map 来构建，public LinkedHashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; super(); accessOrder = false; //该方法上文分析过，批量插入一个map中的所有数据到 本集合中。 putMapEntries(m, false);&#125; 构造函数和HashMap相比，就是增加了一个accessOrder参数，用于在get操作之后回调函数的开关。 putLinkedHashMap并没有重写任何put方法。但是其重写了构建新节点的newNode()方法.newNode()会在HashMap的putVal()方法里被调用，putVal()方法会在批量插入数据putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict)或者插入单个数据public V put(K key, V value)时被调用。 LinkedHashMap重写了newNode(),在每次构建新节点时，通过linkNodeLast(p);将新节点链接在内部双向链表的尾部。 12345678910111213141516171819//在构建新节点时，构建的是`LinkedHashMap.Entry` 不再是`Node`.Node&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; e) &#123; LinkedHashMap.Entry&lt;K,V&gt; p = new LinkedHashMap.Entry&lt;K,V&gt;(hash, key, value, e); linkNodeLast(p); return p;&#125;//将新增的节点，连接在链表的尾部private void linkNodeLast(LinkedHashMap.Entry&lt;K,V&gt; p) &#123; LinkedHashMap.Entry&lt;K,V&gt; last = tail; tail = p; //集合之前是空的 if (last == null) head = p; else &#123;//将新节点连接在链表的尾部 p.before = last; last.after = p; &#125;&#125; 以及HashMap专门预留给LinkedHashMap的afterNodeAccess() afterNodeInsertion() afterNodeRemoval()方法。 1234// Callbacks to allow LinkedHashMap post-actionsvoid afterNodeAccess(Node&lt;K,V&gt; p) &#123; &#125;void afterNodeInsertion(boolean evict) &#123; &#125;void afterNodeRemoval(Node&lt;K,V&gt; p) &#123; &#125; 12345678910111213//回调函数，新节点插入之后回调 ， 根据evict 和 判断是否需要删除最老插入的节点。如果实现LruCache会用到这个方法。void afterNodeInsertion(boolean evict) &#123; // possibly remove eldest LinkedHashMap.Entry&lt;K,V&gt; first; //LinkedHashMap 默认返回false 则不删除节点 if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) &#123; K key = first.key; removeNode(hash(key), key, null, false, true); &#125;&#125;//LinkedHashMap 默认返回false 则不删除节点。 返回true 代表要删除最早的节点。通常构建一个LruCache会在达到Cache的上限是返回trueprotected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123; return false;&#125; void afterNodeInsertion(boolean evict)以及boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest)是构建LruCache需要的回调，在LinkedHashMap里可以忽略它们。 removeLinkedHashMap也没有重写remove()方法，因为它的删除逻辑和HashMap并无区别。但它重写了afterNodeRemoval()这个回调方法。该方法会在Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable)方法中回调，removeNode()会在所有涉及到删除节点的方法中被调用，上文分析过，是删除节点操作的真正执行者。 getLinkedHashMap重写了get()和getOrDefault()方法： 12345678910111213141516 public V get(Object key) &#123; Node&lt;K,V&gt; e; if ((e = getNode(hash(key), key)) == null) return null; if (accessOrder) afterNodeAccess(e); return e.value; &#125; public V getOrDefault(Object key, V defaultValue) &#123; Node&lt;K,V&gt; e; if ((e = getNode(hash(key), key)) == null) return defaultValue; if (accessOrder) afterNodeAccess(e); return e.value;&#125; 对比下面HashMap中的实现,LinkedHashMap只是增加了在成员变量(构造函数时赋值)accessOrder为true的情况下，要去回调void afterNodeAccess(Node&lt;K,V&gt; e)函数。 1234public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125; 在afterNodeAccess()函数中，会将当前被访问到的节点e，移动至内部的双向链表的尾部。 12345678910111213141516171819202122232425262728293031void afterNodeAccess(Node&lt;K,V&gt; e) &#123; // move node to last LinkedHashMap.Entry&lt;K,V&gt; last;//原尾节点 //如果accessOrder 是true ，且原尾节点不等于e if (accessOrder &amp;&amp; (last = tail) != e) &#123; //节点e强转成双向链表节点p LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; //p现在是尾节点， 后置节点一定是null p.after = null; //如果p的前置节点是null，则p以前是头结点，所以更新现在的头结点是p的后置节点a if (b == null) head = a; else//否则更新p的前直接点b的后置节点为 a b.after = a; //如果p的后置节点不是null，则更新后置节点a的前置节点为b if (a != null) a.before = b; else//如果原本p的后置节点是null，则p就是尾节点。 此时 更新last的引用为 p的前置节点b last = b; if (last == null) //原本尾节点是null 则，链表中就一个节点 head = p; else &#123;//否则 更新 当前节点p的前置节点为 原尾节点last， last的后置节点是p p.before = last; last.after = p; &#125; //尾节点的引用赋值成p tail = p; //修改modCount。 ++modCount; &#125;&#125; 值得注意的是，afterNodeAccess()函数中，会修改modCount,因此当你正在accessOrder=true的模式下,迭代LinkedHashMap时，如果同时查询访问数据，也会导致fail-fast，因为迭代的顺序已经改变。 containsValue它重写了该方法，相比HashMap的实现，更为高效。 123456789public boolean containsValue(Object value) &#123; //遍历一遍链表，去比较有没有value相等的节点，并返回 for (LinkedHashMap.Entry&lt;K,V&gt; e = head; e != null; e = e.after) &#123; V v = e.value; if (v == value || (value != null &amp;&amp; value.equals(v))) return true; &#125; return false;&#125; 对比下面HashMap，是用两个for循环遍历，相对低效。 12345678910111213public boolean containsValue(Object value) &#123; Node&lt;K,V&gt;[] tab; V v; if ((tab = table) != null &amp;&amp; size &gt; 0) &#123; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; if ((v = e.value) == value || (value != null &amp;&amp; value.equals(v))) return true; &#125; &#125; &#125; return false;&#125; entrySet()重写了entrySet()如下： 12345678910public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() &#123; Set&lt;Map.Entry&lt;K,V&gt;&gt; es; //返回LinkedEntrySet return (es = entrySet) == null ? (entrySet = new LinkedEntrySet()) : es;&#125;final class LinkedEntrySet extends AbstractSet&lt;Map.Entry&lt;K,V&gt;&gt; &#123; public final Iterator&lt;Map.Entry&lt;K,V&gt;&gt; iterator() &#123; return new LinkedEntryIterator(); &#125;&#125; LinkedEntryIterator 代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556final class LinkedEntryIterator extends LinkedHashIterator implements Iterator&lt;Map.Entry&lt;K,V&gt;&gt; &#123; public final Map.Entry&lt;K,V&gt; next() &#123; return nextNode(); &#125;&#125;abstract class LinkedHashIterator &#123; //下一个节点 LinkedHashMap.Entry&lt;K,V&gt; next; //当前节点 LinkedHashMap.Entry&lt;K,V&gt; current; int expectedModCount; LinkedHashIterator() &#123; //初始化时，next 为 LinkedHashMap内部维护的双向链表的扁头 next = head; //记录当前modCount，以满足fail-fast expectedModCount = modCount; //当前节点为null current = null; &#125; //判断是否还有next public final boolean hasNext() &#123; //就是判断next是否为null，默认next是head 表头 return next != null; &#125; //nextNode() 就是迭代器里的next()方法 。 //该方法的实现可以看出，迭代LinkedHashMap，就是从内部维护的双链表的表头开始循环输出。 final LinkedHashMap.Entry&lt;K,V&gt; nextNode() &#123; //记录要返回的e。 LinkedHashMap.Entry&lt;K,V&gt; e = next; //判断fail-fast if (modCount != expectedModCount) throw new ConcurrentModificationException(); //如果要返回的节点是null，异常 if (e == null) throw new NoSuchElementException(); //更新当前节点为e current = e; //更新下一个节点是e的后置节点 next = e.after; //返回e return e; &#125; //删除方法 最终还是调用了HashMap的removeNode方法 public final void remove() &#123; Node&lt;K,V&gt; p = current; if (p == null) throw new IllegalStateException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); current = null; K key = p.key; removeNode(hash(key), key, null, false, false); expectedModCount = modCount; &#125;&#125; 值得注意的就是：nextNode() 就是迭代器里的next()方法 。该方法的实现可以看出，迭代LinkedHashMap，就是从内部维护的双链表的表头开始循环输出。而双链表节点的顺序在LinkedHashMap的增、删、改、查时都会更新。以满足按照插入顺序输出，还是访问顺序输出。 总结 LinkedHashMap相对于HashMap的源码比，是很简单的。因为大树底下好乘凉。它继承了HashMap，仅重写了几个方法，以改变它迭代遍历时的顺序。这也是其与HashMap相比最大的不同。 在每次插入数据，或者访问、修改数据时，会增加节点、或调整链表的节点顺序。以决定迭代时输出的顺序。 accessOrder ,默认是false，则迭代时输出的顺序是插入节点的顺序。若为true，则输出的顺序是按照访问节点最少访问的顺序。为true时，可以在这基础之上构建一个LruCache. LinkedHashMap并没有重写任何put方法。但是其重写了构建新节点的newNode()方法.在每次构建新节点时，将新节点链接在内部双向链表的尾部accessOrder=true的模式下,在afterNodeAccess()函数中，会将当前被访问到的节点e，移动至内部的双向链表的尾部。值得注意的是，afterNodeAccess()函数中，会修改modCount,因此当你正在accessOrder=true的模式下,迭代LinkedHashMap时，如果同时查询访问数据，也会导致fail-fast，因为迭代的顺序已经改变。nextNode() 就是迭代器里的next()方法 。 该方法的实现可以看出，迭代LinkedHashMap，就是从内部维护的双链表的表头开始循环输出。而双链表节点的顺序在LinkedHashMap的增、删、改、查时都会更新。以满足按照插入顺序输出，还是访问顺序输出。 它与HashMap比，还有一个小小的优化，重写了containsValue()方法，直接遍历内部链表去比对value值是否相等。 那么，还有最后一个小问题？为什么它不重写containsKey()方法，也去循环比对内部链表的key是否相等呢？ 这是因为entry是根据key的hashcode放在数组对应的下标，数组的随机访问特性比链表的循环遍历效率高。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"Java集合","slug":"Java集合","permalink":"https://htchz.cc/tags/Java集合/"}],"author":"土川"},{"title":"Java集合(十一)WeakHashMap源码分析和使用示例","slug":"Java集合-十一-WeakHashMap源码分析和使用示例","date":"2018-03-14T10:43:00.000Z","updated":"2019-07-16T10:16:47.000Z","comments":true,"path":"2699170628.html","link":"","permalink":"https://htchz.cc/2699170628.html","excerpt":"","text":"WeakHashMap简介第1部分 WeakHashMap介绍WeakHashMap简介WeakHashMap 继承于AbstractMap，实现了Map接口。和HashMap一样，WeakHashMap 也是一个散列表，它存储的内容也是键值对(key-value)映射，而且键和值都可以是null。不过WeakHashMap的键是“弱键”。在 WeakHashMap 中，当某个键不再正常使用时，会被从WeakHashMap中被自动移除。更精确地说，对于一个给定的键，其映射的存在并不阻止垃圾回收器对该键的丢弃，这就使该键成为可终止的，被终止，然后被回收。某个键被终止时，它对应的键值对也就从映射中有效地移除了。这个“弱键”的原理呢？大致上就是，通过WeakReference和ReferenceQueue实现的 WeakHashMap的key是“弱键”，即是WeakReference类型的；ReferenceQueue是一个队列，它会保存被GC回收的“弱键”。实现步骤是： 新建WeakHashMap，将“键值对”添加到WeakHashMap中。实际上，WeakHashMap是通过数组table保存Entry(键值对)；每一个Entry实际上是一个单向链表，即Entry是键值对链表。 当某“弱键”不再被其它对象引用，并被GC回收时。在GC回收该“弱键”时，这个“弱键”也同时会被添加到ReferenceQueue(queue)队列中。 当下一次我们需要操作WeakHashMap时，会先同步table和queue。table中保存了全部的键值对，而queue中保存被GC回收的键值对；同步它们，就是删除table中被GC回收的键值对。 这就是“弱键”如何被自动从WeakHashMap中删除的步骤了。和HashMap一样，WeakHashMap是不同步的。可以使用 Collections.synchronizedMap 方法来构造同步的 WeakHashMap。 1234567java.lang.Object ? java.util.AbstractMap&lt;K, V&gt; ? java.util.WeakHashMap&lt;K, V&gt; public class WeakHashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt; &#123;&#125; WeakHashMap与Map关系如下图： Java集合(十一)WeakHashMap源码分析和使用示例 WeakHashMap的构造函数WeakHashMap共有4个构造函数,如下： 1234567891011// 默认构造函数。WeakHashMap() // 指定“容量大小”的构造函数WeakHashMap(int capacity) // 指定“容量大小”和“加载因子”的构造函数WeakHashMap(int capacity, float loadFactor) // 包含“子Map”的构造函数WeakHashMap(Map&lt;? extends K, ? extends V&gt; map) WeakHashMap的API 12345678910111213void clear()Object clone()boolean containsKey(Object key)boolean containsValue(Object value)Set&lt;Entry&lt;K, V&gt;&gt; entrySet()V get(Object key)boolean isEmpty()Set&lt;K&gt; keySet()V put(K key, V value)void putAll(Map&lt;? extends K, ? extends V&gt; map)V remove(Object key)int size()Collection&lt;V&gt; values() 源码分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677package java.util;import java.lang.ref.WeakReference;import java.lang.ref.ReferenceQueue; public class WeakHashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt; &#123; // 默认的初始容量是16，必须是2的幂。 private static final int DEFAULT_INITIAL_CAPACITY = 16; // 最大容量（必须是2的幂且小于2的30次方，传入容量过大将被这个值替换） private static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; // 默认加载因子 private static final float DEFAULT_LOAD_FACTOR = 0.75f; // 存储数据的Entry数组，长度是2的幂。 // WeakHashMap是采用拉链法实现的，每一个Entry本质上是一个单向链表 private Entry[] table; // WeakHashMap的大小，它是WeakHashMap保存的键值对的数量 private int size; // WeakHashMap的阈值，用于判断是否需要调整WeakHashMap的容量（threshold = 容量*加载因子） private int threshold; // 加载因子实际大小 private final float loadFactor; // queue保存的是“已被GC清除”的“弱引用的键”。 // 弱引用和ReferenceQueue 是联合使用的：如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中 private final ReferenceQueue&lt;K&gt; queue = new ReferenceQueue&lt;K&gt;(); // WeakHashMap被改变的次数 private volatile int modCount; // 指定“容量大小”和“加载因子”的构造函数 public WeakHashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal Initial Capacity: &quot;+ initialCapacity); // WeakHashMap的最大容量只能是MAXIMUM_CAPACITY if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal Load factor: &quot;+ loadFactor); // 找出“大于initialCapacity”的最小的2的幂 int capacity = 1; while (capacity &lt; initialCapacity) capacity &lt;&lt;= 1; // 创建Entry数组，用来保存数据 table = new Entry[capacity]; // 设置“加载因子” this.loadFactor = loadFactor; // 设置“WeakHashMap阈值”，当WeakHashMap中存储数据的数量达到threshold时，就需要将WeakHashMap的容量加倍。 threshold = (int)(capacity * loadFactor); &#125; // 指定“容量大小”的构造函数 public WeakHashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; // 默认构造函数。 public WeakHashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; threshold = (int)(DEFAULT_INITIAL_CAPACITY); table = new Entry[DEFAULT_INITIAL_CAPACITY]; &#125; // 包含“子Map”的构造函数 public WeakHashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this(Math.max((int) (m.size() / DEFAULT_LOAD_FACTOR) + 1, 16), DEFAULT_LOAD_FACTOR); // 将m中的全部元素逐个添加到WeakHashMap中 putAll(m); &#125; // 键为null的mask值。 // 因为WeakReference中允许“null的key”，若直接插入“null的key”，将其当作弱引用时，会被删除。 // 因此，这里对于“key为null”的清空，都统一替换为“key为NULL_KEY”，“NULL_KEY”是“静态的final常量”。 private static final Object NULL_KEY = new Object(); // 对“null的key”进行特殊处理 private static Object maskNull(Object key) &#123; return (key == null ? NULL_KEY : key); &#125; // 还原对“null的key”的特殊处理 private static &lt;K&gt; K unmaskNull(Object key) &#123; return (K) (key == NULL_KEY ? null : key); &#125; // 判断“x”和“y”是否相等 static boolean eq(Object x, Object y) &#123; return x == y || x.equals(y); &#125; // 返回索引值 // h &amp; (length-1)保证返回值的小于length static int indexFor(int h, int length) &#123; return h &amp; (length-1); &#125; // 清空table中无用键值对。原理如下： // (01) 当WeakHashMap中某个“弱引用的key”由于没有再被引用而被GC收回时， // 被回收的“该弱引用key”也被会被添加到&quot;ReferenceQueue(queue)&quot;中。 // (02) 当我们执行expungeStaleEntries时， // 就遍历&quot;ReferenceQueue(queue)&quot;中的所有key // 然后就在“WeakReference的table”中删除与“ReferenceQueue(queue)中key”对应的键值对 private void expungeStaleEntries() &#123; Entry&lt;K,V&gt; e; while ( (e = (Entry&lt;K,V&gt;) queue.poll()) != null) &#123; int h = e.hash; int i = indexFor(h, table.length); Entry&lt;K,V&gt; prev = table[i]; Entry&lt;K,V&gt; p = prev; while (p != null) &#123; Entry&lt;K,V&gt; next = p.next; if (p == e) &#123; if (prev == e) table[i] = next; else prev.next = next; e.next = null; // Help GC e.value = null; // &quot; &quot; size--; break; &#125; prev = p; p = next; &#125; &#125; &#125; // 获取WeakHashMap的table(存放键值对的数组) private Entry[] getTable() &#123; // 删除table中“已被GC回收的key对应的键值对” expungeStaleEntries(); return table; &#125; // 获取WeakHashMap的实际大小 public int size() &#123; if (size == 0) return 0; // 删除table中“已被GC回收的key对应的键值对” expungeStaleEntries(); return size; &#125; public boolean isEmpty() &#123; return size() == 0; &#125; // 获取key对应的value public V get(Object key) &#123; Object k = maskNull(key); // 获取key的hash值。 int h = HashMap.hash(k.hashCode()); Entry[] tab = getTable(); int index = indexFor(h, tab.length); Entry&lt;K,V&gt; e = tab[index]; // 在“该hash值对应的链表”上查找“键值等于key”的元素 while (e != null) &#123; if (e.hash == h &amp;&amp; eq(k, e.get())) return e.value; e = e.next; &#125; return null; &#125; // WeakHashMap是否包含key public boolean containsKey(Object key) &#123; return getEntry(key) != null; &#125; // 返回“键为key”的键值对 Entry&lt;K,V&gt; getEntry(Object key) &#123; Object k = maskNull(key); int h = HashMap.hash(k.hashCode()); Entry[] tab = getTable(); int index = indexFor(h, tab.length); Entry&lt;K,V&gt; e = tab[index]; while (e != null &amp;&amp; !(e.hash == h &amp;&amp; eq(k, e.get()))) e = e.next; return e; &#125; // 将“key-value”添加到WeakHashMap中 public V put(K key, V value) &#123; K k = (K) maskNull(key); int h = HashMap.hash(k.hashCode()); Entry[] tab = getTable(); int i = indexFor(h, tab.length); for (Entry&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; // 若“该key”对应的键值对已经存在，则用新的value取代旧的value。然后退出！ if (h == e.hash &amp;&amp; eq(k, e.get())) &#123; V oldValue = e.value; if (value != oldValue) e.value = value; return oldValue; &#125; &#125; // 若“该key”对应的键值对不存在于WeakHashMap中，则将“key-value”添加到table中 modCount++; Entry&lt;K,V&gt; e = tab[i]; tab[i] = new Entry&lt;K,V&gt;(k, value, queue, h, e); if (++size &gt;= threshold) resize(tab.length * 2); return null; &#125; // 重新调整WeakHashMap的大小，newCapacity是调整后的单位 void resize(int newCapacity) &#123; Entry[] oldTable = getTable(); int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; // 新建一个newTable，将“旧的table”的全部元素添加到“新的newTable”中， // 然后，将“新的newTable”赋值给“旧的table”。 Entry[] newTable = new Entry[newCapacity]; transfer(oldTable, newTable); table = newTable; if (size &gt;= threshold / 2) &#123; threshold = (int)(newCapacity * loadFactor); &#125; else &#123; // 删除table中“已被GC回收的key对应的键值对” expungeStaleEntries(); transfer(newTable, oldTable); table = oldTable; &#125; &#125; // 将WeakHashMap中的全部元素都添加到newTable中 private void transfer(Entry[] src, Entry[] dest) &#123; for (int j = 0; j &lt; src.length; ++j) &#123; Entry&lt;K,V&gt; e = src[j]; src[j] = null; while (e != null) &#123; Entry&lt;K,V&gt; next = e.next; Object key = e.get(); if (key == null) &#123; e.next = null; // Help GC e.value = null; // &quot; &quot; size--; &#125; else &#123; int i = indexFor(e.hash, dest.length); e.next = dest[i]; dest[i] = e; &#125; e = next; &#125; &#125; &#125; // 将&quot;m&quot;的全部元素都添加到WeakHashMap中 public void putAll(Map&lt;? extends K, ? extends V&gt; m) &#123; int numKeysToBeAdded = m.size(); if (numKeysToBeAdded == 0) return; // 计算容量是否足够， // 若“当前实际容量 &lt; 需要的容量”，则将容量x2。 if (numKeysToBeAdded &gt; threshold) &#123; int targetCapacity = (int)(numKeysToBeAdded / loadFactor + 1); if (targetCapacity &gt; MAXIMUM_CAPACITY) targetCapacity = MAXIMUM_CAPACITY; int newCapacity = table.length; while (newCapacity &lt; targetCapacity) newCapacity &lt;&lt;= 1; if (newCapacity &gt; table.length) resize(newCapacity); &#125; // 将“m”中的元素逐个添加到WeakHashMap中。 for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) put(e.getKey(), e.getValue()); &#125; // 删除“键为key”元素 public V remove(Object key) &#123; Object k = maskNull(key); // 获取哈希值。 int h = HashMap.hash(k.hashCode()); Entry[] tab = getTable(); int i = indexFor(h, tab.length); Entry&lt;K,V&gt; prev = tab[i]; Entry&lt;K,V&gt; e = prev; // 删除链表中“键为key”的元素 // 本质是“删除单向链表中的节点” while (e != null) &#123; Entry&lt;K,V&gt; next = e.next; if (h == e.hash &amp;&amp; eq(k, e.get())) &#123; modCount++; size--; if (prev == e) tab[i] = next; else prev.next = next; return e.value; &#125; prev = e; e = next; &#125; return null; &#125; // 删除“键值对” Entry&lt;K,V&gt; removeMapping(Object o) &#123; if (!(o instanceof Map.Entry)) return null; Entry[] tab = getTable(); Map.Entry entry = (Map.Entry)o; Object k = maskNull(entry.getKey()); int h = HashMap.hash(k.hashCode()); int i = indexFor(h, tab.length); Entry&lt;K,V&gt; prev = tab[i]; Entry&lt;K,V&gt; e = prev; // 删除链表中的“键值对e” // 本质是“删除单向链表中的节点” while (e != null) &#123; Entry&lt;K,V&gt; next = e.next; if (h == e.hash &amp;&amp; e.equals(entry)) &#123; modCount++; size--; if (prev == e) tab[i] = next; else prev.next = next; return e; &#125; prev = e; e = next; &#125; return null; &#125; // 清空WeakHashMap，将所有的元素设为null public void clear() &#123; while (queue.poll() != null) ; modCount++; Entry[] tab = table; for (int i = 0; i &lt; tab.length; ++i) tab[i] = null; size = 0; while (queue.poll() != null) ; &#125; // 是否包含“值为value”的元素 public boolean containsValue(Object value) &#123; // 若“value为null”，则调用containsNullValue()查找 if (value==null) return containsNullValue(); // 若“value不为null”，则查找WeakHashMap中是否有值为value的节点。 Entry[] tab = getTable(); for (int i = tab.length ; i-- &gt; 0 ;) for (Entry e = tab[i] ; e != null ; e = e.next) if (value.equals(e.value)) return true; return false; &#125; // 是否包含null值 private boolean containsNullValue() &#123; Entry[] tab = getTable(); for (int i = tab.length ; i-- &gt; 0 ;) for (Entry e = tab[i] ; e != null ; e = e.next) if (e.value==null) return true; return false; &#125; // Entry是单向链表。 // 它是 “WeakHashMap链式存储法”对应的链表。 // 它实现了Map.Entry 接口，即实现getKey(), getValue(), setValue(V value), equals(Object o), hashCode()这些函数 private static class Entry&lt;K,V&gt; extends WeakReference&lt;K&gt; implements Map.Entry&lt;K,V&gt; &#123; private V value; private final int hash; // 指向下一个节点 private Entry&lt;K,V&gt; next; // 构造函数。 Entry(K key, V value, ReferenceQueue&lt;K&gt; queue, int hash, Entry&lt;K,V&gt; next) &#123; super(key, queue); this.value = value; this.hash = hash; this.next = next; &#125; public K getKey() &#123; return WeakHashMap.&lt;K&gt;unmaskNull(get()); &#125; public V getValue() &#123; return value; &#125; public V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; // 判断两个Entry是否相等 // 若两个Entry的“key”和“value”都相等，则返回true。 // 否则，返回false public boolean equals(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry e = (Map.Entry)o; Object k1 = getKey(); Object k2 = e.getKey(); if (k1 == k2 || (k1 != null &amp;&amp; k1.equals(k2))) &#123; Object v1 = getValue(); Object v2 = e.getValue(); if (v1 == v2 || (v1 != null &amp;&amp; v1.equals(v2))) return true; &#125; return false; &#125; // 实现hashCode() public int hashCode() &#123; Object k = getKey(); Object v = getValue(); return ((k==null ? 0 : k.hashCode()) ^ (v==null ? 0 : v.hashCode())); &#125; public String toString() &#123; return getKey() + &quot;=&quot; + getValue(); &#125; &#125; // HashIterator是WeakHashMap迭代器的抽象出来的父类，实现了公共了函数。 // 它包含“key迭代器(KeyIterator)”、“Value迭代器(ValueIterator)”和“Entry迭代器(EntryIterator)”3个子类。 private abstract class HashIterator&lt;T&gt; implements Iterator&lt;T&gt; &#123; // 当前索引 int index; // 当前元素 Entry&lt;K,V&gt; entry = null; // 上一次返回元素 Entry&lt;K,V&gt; lastReturned = null; // expectedModCount用于实现fast-fail机制。 int expectedModCount = modCount; // 下一个键(强引用) Object nextKey = null; // 当前键(强引用) Object currentKey = null; // 构造函数 HashIterator() &#123; index = (size() != 0 ? table.length : 0); &#125; // 是否存在下一个元素 public boolean hasNext() &#123; Entry[] t = table; // 一个Entry就是一个单向链表 // 若该Entry的下一个节点不为空，就将next指向下一个节点; // 否则，将next指向下一个链表(也是下一个Entry)的不为null的节点。 while (nextKey == null) &#123; Entry&lt;K,V&gt; e = entry; int i = index; while (e == null &amp;&amp; i &gt; 0) e = t[--i]; entry = e; index = i; if (e == null) &#123; currentKey = null; return false; &#125; nextKey = e.get(); // hold on to key in strong ref if (nextKey == null) entry = entry.next; &#125; return true; &#125; // 获取下一个元素 protected Entry&lt;K,V&gt; nextEntry() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); if (nextKey == null &amp;&amp; !hasNext()) throw new NoSuchElementException(); lastReturned = entry; entry = entry.next; currentKey = nextKey; nextKey = null; return lastReturned; &#125; // 删除当前元素 public void remove() &#123; if (lastReturned == null) throw new IllegalStateException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); WeakHashMap.this.remove(currentKey); expectedModCount = modCount; lastReturned = null; currentKey = null; &#125; &#125; // value的迭代器 private class ValueIterator extends HashIterator&lt;V&gt; &#123; public V next() &#123; return nextEntry().value; &#125; &#125; // key的迭代器 private class KeyIterator extends HashIterator&lt;K&gt; &#123; public K next() &#123; return nextEntry().getKey(); &#125; &#125; // Entry的迭代器 private class EntryIterator extends HashIterator&lt;Map.Entry&lt;K,V&gt;&gt; &#123; public Map.Entry&lt;K,V&gt; next() &#123; return nextEntry(); &#125; &#125; // WeakHashMap的Entry对应的集合 private transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet = null; // 返回“key的集合”，实际上返回一个“KeySet对象” public Set&lt;K&gt; keySet() &#123; Set&lt;K&gt; ks = keySet; return (ks != null ? ks : (keySet = new KeySet())); &#125; // Key对应的集合 // KeySet继承于AbstractSet，说明该集合中没有重复的Key。 private class KeySet extends AbstractSet&lt;K&gt; &#123; public Iterator&lt;K&gt; iterator() &#123; return new KeyIterator(); &#125; public int size() &#123; return WeakHashMap.this.size(); &#125; public boolean contains(Object o) &#123; return containsKey(o); &#125; public boolean remove(Object o) &#123; if (containsKey(o)) &#123; WeakHashMap.this.remove(o); return true; &#125; else return false; &#125; public void clear() &#123; WeakHashMap.this.clear(); &#125; &#125; // 返回“value集合”，实际上返回的是一个Values对象 public Collection&lt;V&gt; values() &#123; Collection&lt;V&gt; vs = values; return (vs != null ? vs : (values = new Values())); &#125; // “value集合” // Values继承于AbstractCollection，不同于“KeySet继承于AbstractSet”， // Values中的元素能够重复。因为不同的key可以指向相同的value。 private class Values extends AbstractCollection&lt;V&gt; &#123; public Iterator&lt;V&gt; iterator() &#123; return new ValueIterator(); &#125; public int size() &#123; return WeakHashMap.this.size(); &#125; public boolean contains(Object o) &#123; return containsValue(o); &#125; public void clear() &#123; WeakHashMap.this.clear(); &#125; &#125; // 返回“WeakHashMap的Entry集合” // 它实际是返回一个EntrySet对象 public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() &#123; Set&lt;Map.Entry&lt;K,V&gt;&gt; es = entrySet; return es != null ? es : (entrySet = new EntrySet()); &#125; // EntrySet对应的集合 // EntrySet继承于AbstractSet，说明该集合中没有重复的EntrySet。 private class EntrySet extends AbstractSet&lt;Map.Entry&lt;K,V&gt;&gt; &#123; public Iterator&lt;Map.Entry&lt;K,V&gt;&gt; iterator() &#123; return new EntryIterator(); &#125; // 是否包含“值(o)” public boolean contains(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry e = (Map.Entry)o; Object k = e.getKey(); Entry candidate = getEntry(e.getKey()); return candidate != null &amp;&amp; candidate.equals(e); &#125; // 删除“值(o)” public boolean remove(Object o) &#123; return removeMapping(o) != null; &#125; // 返回WeakHashMap的大小 public int size() &#123; return WeakHashMap.this.size(); &#125; // 清空WeakHashMap public void clear() &#123; WeakHashMap.this.clear(); &#125; // 拷贝函数。将WeakHashMap中的全部元素都拷贝到List中 private List&lt;Map.Entry&lt;K,V&gt;&gt; deepCopy() &#123; List&lt;Map.Entry&lt;K,V&gt;&gt; list = new ArrayList&lt;Map.Entry&lt;K,V&gt;&gt;(size()); for (Map.Entry&lt;K,V&gt; e : this) list.add(new AbstractMap.SimpleEntry&lt;K,V&gt;(e)); return list; &#125; // 返回Entry对应的Object[]数组 public Object[] toArray() &#123; return deepCopy().toArray(); &#125; // 返回Entry对应的T[]数组(T[]我们新建数组时，定义的数组类型) public &lt;T&gt; T[] toArray(T[] a) &#123; return deepCopy().toArray(a); &#125; &#125;&#125; 说明：WeakHashMap和HashMap都是通过”拉链法”实现的散列表。它们的源码绝大部分内容都一样，这里就只是对它们不同的部分就是说明。 WeakReference是“弱键”实现的哈希表。它这个“弱键”的目的就是：实现对“键值对”的动态回收。当“弱键”不再被使用到时，GC会回收它，WeakReference也会将“弱键”对应的键值对删除。 “弱键”是一个“弱引用(WeakReference)”，在Java中，WeakReference和ReferenceQueue 是联合使用的。在WeakHashMap中亦是如此：如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 接着，WeakHashMap会根据“引用队列”，来删除“WeakHashMap中已被GC回收的‘弱键’对应的键值对”。另外，理解上面思想的重点是通过 expungeStaleEntries() 函数去理解。 示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class WeakHashMapTest &#123; public static void main(String[] args) throws Exception &#123; testWeakHashMapAPIs(); &#125; private static void testWeakHashMapAPIs() &#123; // 初始化3个“弱键” String w1 = new String(&quot;one&quot;); String w2 = new String(&quot;two&quot;); String w3 = new String(&quot;three&quot;); // 新建WeakHashMap Map wmap = new WeakHashMap(); // 添加键值对 wmap.put(w1, &quot;w1&quot;); wmap.put(w2, &quot;w2&quot;); wmap.put(w3, &quot;w3&quot;); // 打印出wmap System.out.printf(&quot;\\nwmap:%s\\n&quot;,wmap ); // containsKey(Object key) :是否包含键key System.out.printf(&quot;contains key two : %s\\n&quot;,wmap.containsKey(&quot;two&quot;)); System.out.printf(&quot;contains key five : %s\\n&quot;,wmap.containsKey(&quot;five&quot;)); // containsValue(Object value) :是否包含值value System.out.printf(&quot;contains value 0 : %s\\n&quot;,wmap.containsValue(new Integer(0))); // remove(Object key) ： 删除键key对应的键值对 wmap.remove(&quot;three&quot;); System.out.printf(&quot;wmap: %s\\n&quot;,wmap ); // ---- 测试 WeakHashMap 的自动回收特性 ---- // 将w1设置null。 // 这意味着“弱键”w1再没有被其它对象引用，调用gc时会回收WeakHashMap中与“w1”对应的键值对 w1 = null; // 内存回收。这里，会回收WeakHashMap中与“w1”对应的键值对 System.gc(); // 遍历WeakHashMap Iterator iter = wmap.entrySet().iterator(); while (iter.hasNext()) &#123; Map.Entry en = (Map.Entry)iter.next(); System.out.printf(&quot;next : %s - %s\\n&quot;,en.getKey(),en.getValue()); &#125; // 打印WeakHashMap的实际大小 System.out.printf(&quot; after gc WeakHashMap size:%s\\n&quot;, wmap.size()); &#125;&#125;","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[],"author":"土川"},{"title":"Java集合(十)TreeMap源码分析和使用示例","slug":"Java集合-十-TreeMap源码分析和使用示例","date":"2018-03-14T10:42:00.000Z","updated":"2019-07-16T10:07:08.000Z","comments":true,"path":"1776340888.html","link":"","permalink":"https://htchz.cc/1776340888.html","excerpt":"","text":"概述TreeMap 是一个有序的key-value集合，它是通过红黑树实现的。TreeMap 继承于AbstractMap，所以它是一个Map，即一个key-value集合。TreeMap 实现了NavigableMap接口，意味着它支持一系列的导航方法。比如返回有序的key集合。TreeMap 实现了Cloneable接口，意味着它能被克隆。TreeMap 实现了java.io.Serializable接口，意味着它支持序列化。TreeMap基于红黑树（Red-Black tree）实现。该映射根据其键的自然顺序进行排序，或者根据创建映射时提供的 Comparator 进行排序，具体取决于使用的构造方法。TreeMap的基本操作 containsKey、get、put 和 remove 的时间复杂度是 log(n) 。另外，TreeMap是非同步的。 它的iterator 方法返回的迭代器是fail-fastl的。 继承关系1234567java.lang.Object ? java.util.AbstractMap&lt;K, V&gt; ? java.util.TreeMap&lt;K, V&gt; public class TreeMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements NavigableMap&lt;K,V&gt;, Cloneable, java.io.Serializable &#123;&#125; 构造函数 1234567891011// 默认构造函数。使用该构造函数，TreeMap中的元素按照自然排序进行排列。TreeMap() // 创建的TreeMap包含MapTreeMap(Map&lt;? extends K, ? extends V&gt; copyFrom) // 指定Tree的比较器TreeMap(Comparator&lt;? super K&gt; comparator) // 创建的TreeSet包含copyFromTreeMap(SortedMap&lt;K, ? extends V&gt; copyFrom) api12345678910111213141516171819202122232425262728293031323334Entry&lt;K, V&gt; ceilingEntry(K key)K ceilingKey(K key)void clear()Object clone()Comparator&lt;? super K&gt; comparator()boolean containsKey(Object key)NavigableSet&lt;K&gt; descendingKeySet()NavigableMap&lt;K, V&gt; descendingMap()Set&lt;Entry&lt;K, V&gt;&gt; entrySet()Entry&lt;K, V&gt; firstEntry()K firstKey()Entry&lt;K, V&gt; floorEntry(K key)K floorKey(K key)V get(Object key)NavigableMap&lt;K, V&gt; headMap(K to, boolean inclusive)SortedMap&lt;K, V&gt; headMap(K toExclusive)Entry&lt;K, V&gt; higherEntry(K key)K higherKey(K key)boolean isEmpty()Set&lt;K&gt; keySet()Entry&lt;K, V&gt; lastEntry()K lastKey()Entry&lt;K, V&gt; lowerEntry(K key)K lowerKey(K key)NavigableSet&lt;K&gt; navigableKeySet()Entry&lt;K, V&gt; pollFirstEntry()Entry&lt;K, V&gt; pollLastEntry()V put(K key, V value)V remove(Object key)int size()SortedMap&lt;K, V&gt; subMap(K fromInclusive, K toExclusive)NavigableMap&lt;K, V&gt; subMap(K from, boolean fromInclusive, K to, boolean toInclusive)NavigableMap&lt;K, V&gt; tailMap(K from, boolean inclusive)SortedMap&lt;K, V&gt; tailMap(K fromInclusive) 源码分析在详细介绍TreeMap的代码之前，我们先建立一个整体概念。TreeMap是通过红黑树实现的，TreeMap存储的是key-value键值对，TreeMap的排序是基于对key的排序。TreeMap提供了操作“key”、“key-value”、“value”等方法，也提供了对TreeMap这颗树进行整体操作的方法，如获取子树、反向树。后面的解说内容分为几部分,首先，介绍TreeMap的核心，即红黑树相关部分；然后，介绍TreeMap的主要函数；再次，介绍TreeMap实现的几个接口；最后，补充介绍TreeMap的其它内容。 TreeMap本质上是一颗红黑树。要彻底理解TreeMap，建议读者先理解红黑树。 TreeMap的红黑树相关内容TreeMap中于红黑树相关的主要函数有:1 数据结构1.1 红黑树的节点颜色–红色 1private static final boolean RED = false; 1.2 红黑树的节点颜色–黑色 1private static final boolean BLACK = true; 1.3 “红黑树的节点”对应的类。 1static final class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; ... &#125; Entry包含了6个部分内容：key(键)、value(值)、left(左孩子)、right(右孩子)、parent(父节点)、color(颜色)Entry节点根据key进行排序，Entry节点包含的内容为value。2 相关操作2.1 左旋 1private void rotateLeft(Entry&lt;K,V&gt; p) &#123; ... &#125; 2.2 右旋 1private void rotateRight(Entry&lt;K,V&gt; p) &#123; ... &#125; 2.3 插入操作 1public V put(K key, V value) &#123; ... &#125; 2.4 插入修正操作红黑树执行插入操作之后，要执行“插入修正操作”。目的是：保红黑树在进行插入节点之后，仍然是一颗红黑树private void fixAfterInsertion(Entry&lt;K,V&gt; x) { … }2.5 删除操作 1private void deleteEntry(Entry&lt;K,V&gt; p) &#123; ... &#125; 2.6 删除修正操作红黑树执行删除之后，要执行“删除修正操作”。目的是保证：红黑树删除节点之后，仍然是一颗红黑树 1private void fixAfterDeletion(Entry&lt;K,V&gt; x) &#123; ... &#125; 关于红黑树部分，这里主要是指出了TreeMap中那些是红黑树的主要相关内容。具体的红黑树相关操作API，这里没有详细说明，因为它们仅仅只是将算法翻译成代码。 构造函数1 默认构造函数使用默认构造函数构造TreeMap时，使用java的默认的比较器比较Key的大小，从而对TreeMap进行排序。 123public TreeMap() &#123; comparator = null; &#125; 2 带比较器的构造函数 123public TreeMap(Comparator&lt;? super K&gt; comparator) &#123; this.comparator = comparator;&#125; 3 带Map的构造函数，Map会成为TreeMap的子集 1234public TreeMap(Map&lt;? extends K, ? extends V&gt; m) &#123; comparator = null; putAll(m);&#125; 该构造函数会调用putAll()将m中的所有元素添加到TreeMap中。putAll()源码如下： 1234public void putAll(Map&lt;? extends K, ? extends V&gt; m) &#123; for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) put(e.getKey(), e.getValue());&#125; 4 带SortedMap的构造函数，SortedMap会成为TreeMap的子集 12345678public TreeMap(SortedMap&lt;K, ? extends V&gt; m) &#123; comparator = m.comparator(); try &#123; buildFromSorted(m.size(), m.entrySet().iterator(), null, null); &#125; catch (java.io.IOException cannotHappen) &#123; &#125; catch (ClassNotFoundException cannotHappen) &#123; &#125;&#125; 该构造函数不同于上一个构造函数，在上一个构造函数中传入的参数是Map，Map不是有序的，所以要逐个添加。而该构造函数的参数是SortedMap是一个有序的Map，我们通过buildFromSorted()来创建对应的Map。buildFromSorted涉及到的代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061// 根据已经一个排好序的map创建一个TreeMap// 将map中的元素逐个添加到TreeMap中，并返回map的中间元素作为根节点。private final Entry&lt;K,V&gt; buildFromSorted(int level, int lo, int hi, int redLevel, Iterator it, java.io.ObjectInputStream str, V defaultVal) throws java.io.IOException, ClassNotFoundException &#123; if (hi &lt; lo) return null; // 获取中间元素 int mid = (lo + hi) / 2; Entry&lt;K,V&gt; left = null; // 若lo小于mid，则递归调用获取(middel的)左孩子。 if (lo &lt; mid) left = buildFromSorted(level+1, lo, mid - 1, redLevel, it, str, defaultVal); // 获取middle节点对应的key和value K key; V value; if (it != null) &#123; if (defaultVal==null) &#123; Map.Entry&lt;K,V&gt; entry = (Map.Entry&lt;K,V&gt;)it.next(); key = entry.getKey(); value = entry.getValue(); &#125; else &#123; key = (K)it.next(); value = defaultVal; &#125; &#125; else &#123; // use stream key = (K) str.readObject(); value = (defaultVal != null ? defaultVal : (V) str.readObject()); &#125; // 创建middle节点 Entry&lt;K,V&gt; middle = new Entry&lt;K,V&gt;(key, value, null); // 若当前节点的深度=红色节点的深度，则将节点着色为红色。 if (level == redLevel) middle.color = RED; // 设置middle为left的父亲，left为middle的左孩子 if (left != null) &#123; middle.left = left; left.parent = middle; &#125; if (mid &lt; hi) &#123; // 递归调用获取(middel的)右孩子。 Entry&lt;K,V&gt; right = buildFromSorted(level+1, mid+1, hi, redLevel, it, str, defaultVal); // 设置middle为left的父亲，left为middle的左孩子 middle.right = right; right.parent = middle; &#125; return middle;&#125; 要理解buildFromSorted，重点说明以下几点：第一，buildFromSorted是通过递归将SortedMap中的元素逐个关联。第二，buildFromSorted返回middle节点(中间节点)作为root。第三，buildFromSorted添加到红黑树中时，只将level == redLevel的节点设为红色。第level级节点，实际上是buildFromSorted转换成红黑树后的最底端(假设根节点在最上方)的节点；只将红黑树最底端的阶段着色为红色，其余都是黑色。 TreeMap的Entry相关函数TreeMap的 firstEntry()、 lastEntry()、 lowerEntry()、 higherEntry()、 floorEntry()、 ceilingEntry()、 pollFirstEntry() 、 pollLastEntry() 原理都是类似的；下面以firstEntry()来进行详细说明 我们先看看firstEntry()和getFirstEntry()的代码： 1234567891011public Map.Entry&lt;K,V&gt; firstEntry() &#123; return exportEntry(getFirstEntry());&#125; final Entry&lt;K,V&gt; getFirstEntry() &#123; Entry&lt;K,V&gt; p = root; if (p != null) while (p.left != null) p = p.left; return p;&#125; firstEntry() 是对外接口； getFirstEntry() 是内部接口。而且，firstEntry() 是通过 getFirstEntry() 来实现的。这么做的目的是：防止用户修改返回的Entry。getFirstEntry()返回的Entry是可以被修改的，但是经过firstEntry()返回的Entry不能被修改，只可以读取Entry的key值和value值。 firstEntry()返回的是exportEntry(getFirstEntry())。下面我们看看exportEntry()干了些什么？ 1234static &lt;K,V&gt; Map.Entry&lt;K,V&gt; exportEntry(TreeMap.Entry&lt;K,V&gt; e) &#123; return e == null? null : new AbstractMap.SimpleImmutableEntry&lt;K,V&gt;(e);&#125; SimpleImmutableEntry实际上是简化的key-value节点，实现在AbstractMap.java它只提供了getKey()、getValue()方法类获取节点的值；但不能修改value的值，因为调用 setValue() 会抛出异常UnsupportedOperationException(); TreeMap的key相关函数TreeMap的firstKey()、lastKey()、lowerKey()、higherKey()、floorKey()、ceilingKey()原理都是类似的；下面以ceilingKey()来进行详细说明 ceilingKey(K key)的作用是“返回大于/等于key的最小的键值对所对应的KEY，没有的话返回null”，它的代码如下： 123public K ceilingKey(K key) &#123; return keyOrNull(getCeilingEntry(key));&#125; ceilingKey()是通过getCeilingEntry()实现的。keyOrNull()的代码很简单，它是获取节点的key，没有的话，返回null。 123static &lt;K,V&gt; K keyOrNull(TreeMap.Entry&lt;K,V&gt; e) &#123; return e == null? null : e.key;&#125; getCeilingEntry(K key)的作用是“获取TreeMap中大于/等于key的最小的节点，若不存在(即TreeMap中所有节点的键都比key大)，就返回null”。它的实现代码如下： 12345678910111213141516171819202122232425262728293031323334353637final Entry&lt;K,V&gt; getCeilingEntry(K key) &#123; Entry&lt;K,V&gt; p = root; while (p != null) &#123; int cmp = compare(key, p.key); // 情况一：若“p的key” &gt; key。 // 若 p 存在左孩子，则设 p=“p的左孩子”； // 否则，返回p if (cmp &lt; 0) &#123; if (p.left != null) p = p.left; else return p; // 情况二：若“p的key” &lt; key。 &#125; else if (cmp &gt; 0) &#123; // 若 p 存在右孩子，则设 p=“p的右孩子” if (p.right != null) &#123; p = p.right; &#125; else &#123; // 若 p 不存在右孩子，则找出 p 的后继节点，并返回 // 注意：这里返回的 “p的后继节点”有2种可能性：第一，null；第二，TreeMap中大于key的最小的节点。 // 理解这一点的核心是，getCeilingEntry是从root开始遍历的。 // 若getCeilingEntry能走到这一步，那么，它之前“已经遍历过的节点的key”都 &gt; key。 // 能理解上面所说的，那么就很容易明白，为什么“p的后继节点”有2种可能性了。 Entry&lt;K,V&gt; parent = p.parent; Entry&lt;K,V&gt; ch = p; while (parent != null &amp;&amp; ch == parent.right) &#123; ch = parent; parent = parent.parent; &#125; return parent; &#125; // 情况三：若“p的key” = key。 &#125; else return p; &#125; return null;&#125; TreeMap的values()函数values() 返回“TreeMap中值的集合”values()的实现代码如下： 1234public Collection&lt;V&gt; values() &#123; Collection&lt;V&gt; vs = values; return (vs != null) ? vs : (values = new Values());&#125; 说明：从中，我们可以发现values()是通过 new Values() 来实现 “返回TreeMap中值的集合”。那么Values()是如何实现的呢？ 没错！由于返回的是值的集合，那么Values()肯定返回一个集合；而Values()正好是集合类Value的构造函数。Values继承于AbstractCollection，它的代码如下： 123456789101112131415161718192021222324252627282930313233// ”TreeMap的值的集合“对应的类，它集成于AbstractCollectionclass Values extends AbstractCollection&lt;V&gt; &#123; // 返回迭代器 public Iterator&lt;V&gt; iterator() &#123; return new ValueIterator(getFirstEntry()); &#125; // 返回个数 public int size() &#123; return TreeMap.this.size(); &#125; // \"TreeMap的值的集合\"中是否包含\"对象o\" public boolean contains(Object o) &#123; return TreeMap.this.containsValue(o); &#125; // 删除\"TreeMap的值的集合\"中的\"对象o\" public boolean remove(Object o) &#123; for (Entry&lt;K,V&gt; e = getFirstEntry(); e != null; e = successor(e)) &#123; if (valEquals(e.getValue(), o)) &#123; deleteEntry(e); return true; &#125; &#125; return false; &#125; // 清空删除\"TreeMap的值的集合\" public void clear() &#123; TreeMap.this.clear(); &#125;&#125; 说明：从中，我们可以知道Values类就是一个集合。而 AbstractCollection 实现了除 size() 和 iterator() 之外的其它函数，因此只需要在Values类中实现这两个函数即可。size() 的实现非常简单，Values集合中元素的个数=该TreeMap的元素个数。(TreeMap每一个元素都有一个值嘛！)iterator() 则返回一个迭代器，用于遍历Values。下面，我们一起可以看看iterator()的实现： 123public Iterator&lt;V&gt; iterator() &#123; return new ValueIterator(getFirstEntry());&#125; 说明： iterator() 是通过ValueIterator() 返回迭代器的，ValueIterator是一个类。代码如下： 12345678final class ValueIterator extends PrivateEntryIterator&lt;V&gt; &#123; ValueIterator(Entry&lt;K,V&gt; first) &#123; super(first); &#125; public V next() &#123; return nextEntry().value; &#125;&#125; 说明：ValueIterator的代码很简单，它的主要实现应该在它的父类PrivateEntryIterator中。下面我们一起看看PrivateEntryIterator的代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556abstract class PrivateEntryIterator&lt;T&gt; implements Iterator&lt;T&gt; &#123; // 下一节点 Entry&lt;K,V&gt; next; // 上一次返回的节点 Entry&lt;K,V&gt; lastReturned; // 修改次数统计数 int expectedModCount; PrivateEntryIterator(Entry&lt;K,V&gt; first) &#123; expectedModCount = modCount; lastReturned = null; next = first; &#125; // 是否存在下一个节点 public final boolean hasNext() &#123; return next != null; &#125; // 返回下一个节点 final Entry&lt;K,V&gt; nextEntry() &#123; Entry&lt;K,V&gt; e = next; if (e == null) throw new NoSuchElementException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); next = successor(e); lastReturned = e; return e; &#125; // 返回上一节点 final Entry&lt;K,V&gt; prevEntry() &#123; Entry&lt;K,V&gt; e = next; if (e == null) throw new NoSuchElementException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); next = predecessor(e); lastReturned = e; return e; &#125; // 删除当前节点 public void remove() &#123; if (lastReturned == null) throw new IllegalStateException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); // deleted entries are replaced by their successors if (lastReturned.left != null &amp;&amp; lastReturned.right != null) next = lastReturned; deleteEntry(lastReturned); expectedModCount = modCount; lastReturned = null; &#125;&#125; 说明：PrivateEntryIterator是一个抽象类，它的实现很简单，只只实现了Iterator的remove()和hasNext()接口，没有实现next()接口。而我们在ValueIterator中已经实现的next()接口。至此，我们就了解了iterator()的完整实现了。 entrySet（）函数entrySet() 返回“键值对集合”。顾名思义，它返回的是一个集合，集合的元素是“键值对”。 1234public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() &#123; EntrySet es = entrySet; return (es != null) ? es : (entrySet = new EntrySet());&#125; entrySet()返回的是一个EntrySet对象。 1234567891011121314151617181920212223242526272829303132333435363738394041// EntrySet是“TreeMap的所有键值对组成的集合”，// EntrySet集合的单位是单个“键值对”。class EntrySet extends AbstractSet&lt;Map.Entry&lt;K,V&gt;&gt; &#123; public Iterator&lt;Map.Entry&lt;K,V&gt;&gt; iterator() &#123; return new EntryIterator(getFirstEntry()); &#125; // EntrySet中是否包含“键值对Object” public boolean contains(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry&lt;K,V&gt; entry = (Map.Entry&lt;K,V&gt;) o; V value = entry.getValue(); Entry&lt;K,V&gt; p = getEntry(entry.getKey()); return p != null &amp;&amp; valEquals(p.getValue(), value); &#125; // 删除EntrySet中的“键值对Object” public boolean remove(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry&lt;K,V&gt; entry = (Map.Entry&lt;K,V&gt;) o; V value = entry.getValue(); Entry&lt;K,V&gt; p = getEntry(entry.getKey()); if (p != null &amp;&amp; valEquals(p.getValue(), value)) &#123; deleteEntry(p); return true; &#125; return false; &#125; // 返回EntrySet中元素个数 public int size() &#123; return TreeMap.this.size(); &#125; // 清空EntrySet public void clear() &#123; TreeMap.this.clear(); &#125;&#125; EntrySet是“TreeMap的所有键值对组成的集合”，而且它单位是单个“键值对”。EntrySet是一个集合，它继承于AbstractSet。而AbstractSet实现了除size() 和 iterator() 之外的其它函数，因此，我们重点了解一下EntrySet的size() 和 iterator() 函数size() 的实现非常简单，AbstractSet集合中元素的个数=该TreeMap的元素个数。 iterator() 则返回一个迭代器，用于遍历AbstractSet。从上面的源码中，我们可以发现iterator() 是通过EntryIterator实现的；下面我们看看EntryIterator的源码 12345678final class EntryIterator extends PrivateEntryIterator&lt;Map.Entry&lt;K,V&gt;&gt; &#123; EntryIterator(Entry&lt;K,V&gt; first) &#123; super(first); &#125; public Map.Entry&lt;K,V&gt; next() &#123; return nextEntry(); &#125;&#125; 和Values类一样，EntryIterator也继承于PrivateEntryIterator类。 Cloneable接口TreeMap实现了Cloneable接口，即实现了clone()方法。clone()方法的作用很简单，就是克隆一个TreeMap对象并返回。 1234567891011121314151617181920212223242526// 克隆一个TreeMap，并返回Object对象public Object clone() &#123; TreeMap&lt;K,V&gt; clone = null; try &#123; clone = (TreeMap&lt;K,V&gt;) super.clone(); &#125; catch (CloneNotSupportedException e) &#123; throw new InternalError(); &#125; // Put clone into &quot;virgin&quot; state (except for comparator) clone.root = null; clone.size = 0; clone.modCount = 0; clone.entrySet = null; clone.navigableKeySet = null; clone.descendingMap = null; // Initialize clone with our mappings try &#123; clone.buildFromSorted(size, entrySet().iterator(), null, null); &#125; catch (java.io.IOException cannotHappen) &#123; &#125; catch (ClassNotFoundException cannotHappen) &#123; &#125; return clone;&#125; Serializable接口TreeMap实现java.io.Serializable，分别实现了串行读取、写入功能。串行写入函数是writeObject()，它的作用是将TreeMap的“容量，所有的Entry”都写入到输出流中。而串行读取函数是readObject()，它的作用是将TreeMap的“容量、所有的Entry”依次读出。readObject() 和 writeObject() 正好是一对，通过它们，我能实现TreeMap的串行传输。 123456789101112131415161718192021222324252627282930// java.io.Serializable的写入函数// 将TreeMap的“容量，所有的Entry”都写入到输出流中private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException &#123; // Write out the Comparator and any hidden stuff s.defaultWriteObject(); // Write out size (number of Mappings) s.writeInt(size); // Write out keys and values (alternating) for (Iterator&lt;Map.Entry&lt;K,V&gt;&gt; i = entrySet().iterator(); i.hasNext(); ) &#123; Map.Entry&lt;K,V&gt; e = i.next(); s.writeObject(e.getKey()); s.writeObject(e.getValue()); &#125;&#125; // java.io.Serializable的读取函数：根据写入方式读出// 先将TreeMap的“容量、所有的Entry”依次读出private void readObject(final java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; // Read in the Comparator and any hidden stuff s.defaultReadObject(); // Read in size int size = s.readInt(); buildFromSorted(size, null, s, null);&#125; NavigableMap接口firstKey()、lastKey()、lowerKey()、higherKey()、ceilingKey()、floorKey();firstEntry()、 lastEntry()、 lowerEntry()、 higherEntry()、 floorEntry()、 ceilingEntry()、 pollFirstEntry() 、 pollLastEntry()上面已经讲解过这些API了，下面对其它的API进行说明。 反向TreeMapdescendingMap() 的作用是返回当前TreeMap的反向的TreeMap。所谓反向，就是排序顺序和原始的顺序相反。我们已经知道TreeMap是一颗红黑树，而红黑树是有序的。TreeMap的排序方式是通过比较器，在创建TreeMap的时候，若指定了比较器，则使用该比较器；否则，就使用Java的默认比较器。而获取TreeMap的反向TreeMap的原理就是将比较器反向即可！理解了descendingMap()的反向原理之后，再讲解一下descendingMap()的代码。 12345678// 获取TreeMap的降序Mappublic NavigableMap&lt;K, V&gt; descendingMap() &#123; NavigableMap&lt;K, V&gt; km = descendingMap; return (km != null) ? km : (descendingMap = new DescendingSubMap(this, true, null, true, true, null, true));&#125; 从中，我们看出descendingMap()实际上是返回DescendingSubMap类的对象。下面，看看DescendingSubMap的源码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091static final class DescendingSubMap&lt;K,V&gt; extends NavigableSubMap&lt;K,V&gt; &#123; private static final long serialVersionUID = 912986545866120460L; DescendingSubMap(TreeMap&lt;K,V&gt; m, boolean fromStart, K lo, boolean loInclusive, boolean toEnd, K hi, boolean hiInclusive) &#123; super(m, fromStart, lo, loInclusive, toEnd, hi, hiInclusive); &#125; // 反转的比较器：是将原始比较器反转得到的。 private final Comparator&lt;? super K&gt; reverseComparator = Collections.reverseOrder(m.comparator); // 获取反转比较器 public Comparator&lt;? super K&gt; comparator() &#123; return reverseComparator; &#125; // 获取“子Map”。 // 范围是从fromKey 到 toKey；fromInclusive是是否包含fromKey的标记，toInclusive是是否包含toKey的标记 public NavigableMap&lt;K,V&gt; subMap(K fromKey, boolean fromInclusive, K toKey, boolean toInclusive) &#123; if (!inRange(fromKey, fromInclusive)) throw new IllegalArgumentException(\"fromKey out of range\"); if (!inRange(toKey, toInclusive)) throw new IllegalArgumentException(\"toKey out of range\"); return new DescendingSubMap(m, false, toKey, toInclusive, false, fromKey, fromInclusive); &#125; // 获取“Map的头部”。 // 范围从第一个节点 到 toKey, inclusive是是否包含toKey的标记 public NavigableMap&lt;K,V&gt; headMap(K toKey, boolean inclusive) &#123; if (!inRange(toKey, inclusive)) throw new IllegalArgumentException(\"toKey out of range\"); return new DescendingSubMap(m, false, toKey, inclusive, toEnd, hi, hiInclusive); &#125; // 获取“Map的尾部”。 // 范围是从 fromKey 到 最后一个节点，inclusive是是否包含fromKey的标记 public NavigableMap&lt;K,V&gt; tailMap(K fromKey, boolean inclusive)&#123; if (!inRange(fromKey, inclusive)) throw new IllegalArgumentException(\"fromKey out of range\"); return new DescendingSubMap(m, fromStart, lo, loInclusive, false, fromKey, inclusive); &#125; // 获取对应的降序Map public NavigableMap&lt;K,V&gt; descendingMap() &#123; NavigableMap&lt;K,V&gt; mv = descendingMapView; return (mv != null) ? mv : (descendingMapView = new AscendingSubMap(m, fromStart, lo, loInclusive, toEnd, hi, hiInclusive)); &#125; // 返回“升序Key迭代器” Iterator&lt;K&gt; keyIterator() &#123; return new DescendingSubMapKeyIterator(absHighest(), absLowFence()); &#125; // 返回“降序Key迭代器” Iterator&lt;K&gt; descendingKeyIterator() &#123; return new SubMapKeyIterator(absLowest(), absHighFence()); &#125; // “降序EntrySet集合”类 // 实现了iterator() final class DescendingEntrySetView extends EntrySetView &#123; public Iterator&lt;Map.Entry&lt;K,V&gt;&gt; iterator() &#123; return new DescendingSubMapEntryIterator(absHighest(), absLowFence()); &#125; &#125; // 返回“降序EntrySet集合” public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() &#123; EntrySetView es = entrySetView; return (es != null) ? es : new DescendingEntrySetView(); &#125; TreeMap.Entry&lt;K,V&gt; subLowest() &#123; return absHighest(); &#125; TreeMap.Entry&lt;K,V&gt; subHighest() &#123; return absLowest(); &#125; TreeMap.Entry&lt;K,V&gt; subCeiling(K key) &#123; return absFloor(key); &#125; TreeMap.Entry&lt;K,V&gt; subHigher(K key) &#123; return absLower(key); &#125; TreeMap.Entry&lt;K,V&gt; subFloor(K key) &#123; return absCeiling(key); &#125; TreeMap.Entry&lt;K,V&gt; subLower(K key) &#123; return absHigher(key); &#125;&#125; 从中，我们看出DescendingSubMap是降序的SubMap，它的实现机制是将“SubMap的比较器反转”。 它继承于NavigableSubMap。而NavigableSubMap是一个继承于AbstractMap的抽象类；它包括2个子类——“(升序)AscendingSubMap”和”(降序)DescendingSubMap”。NavigableSubMap为它的两个子类实现了许多公共API。下面看看NavigableSubMap的源码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529static abstract class NavigableSubMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements NavigableMap&lt;K,V&gt;, java.io.Serializable &#123; // TreeMap的拷贝 final TreeMap&lt;K,V&gt; m; // lo是“子Map范围的最小值”，hi是“子Map范围的最大值”； // loInclusive是“是否包含lo的标记”，hiInclusive是“是否包含hi的标记” // fromStart是“表示是否从第一个节点开始计算”， // toEnd是“表示是否计算到最后一个节点 ” final K lo, hi; final boolean fromStart, toEnd; final boolean loInclusive, hiInclusive; // 构造函数 NavigableSubMap(TreeMap&lt;K,V&gt; m, boolean fromStart, K lo, boolean loInclusive, boolean toEnd, K hi, boolean hiInclusive) &#123; if (!fromStart &amp;&amp; !toEnd) &#123; if (m.compare(lo, hi) &gt; 0) throw new IllegalArgumentException(\"fromKey &gt; toKey\"); &#125; else &#123; if (!fromStart) // type check m.compare(lo, lo); if (!toEnd) m.compare(hi, hi); &#125; this.m = m; this.fromStart = fromStart; this.lo = lo; this.loInclusive = loInclusive; this.toEnd = toEnd; this.hi = hi; this.hiInclusive = hiInclusive; &#125; // 判断key是否太小 final boolean tooLow(Object key) &#123; // 若该SubMap不包括“起始节点”， // 并且，“key小于最小键(lo)”或者“key等于最小键(lo)，但最小键却没包括在该SubMap内” // 则判断key太小。其余情况都不是太小！ if (!fromStart) &#123; int c = m.compare(key, lo); if (c &lt; 0 || (c == 0 &amp;&amp; !loInclusive)) return true; &#125; return false; &#125; // 判断key是否太大 final boolean tooHigh(Object key) &#123; // 若该SubMap不包括“结束节点”， // 并且，“key大于最大键(hi)”或者“key等于最大键(hi)，但最大键却没包括在该SubMap内” // 则判断key太大。其余情况都不是太大！ if (!toEnd) &#123; int c = m.compare(key, hi); if (c &gt; 0 || (c == 0 &amp;&amp; !hiInclusive)) return true; &#125; return false; &#125; // 判断key是否在“lo和hi”开区间范围内 final boolean inRange(Object key) &#123; return !tooLow(key) &amp;&amp; !tooHigh(key); &#125; // 判断key是否在封闭区间内 final boolean inClosedRange(Object key) &#123; return (fromStart || m.compare(key, lo) &gt;= 0) &amp;&amp; (toEnd || m.compare(hi, key) &gt;= 0); &#125; // 判断key是否在区间内, inclusive是区间开关标志 final boolean inRange(Object key, boolean inclusive) &#123; return inclusive ? inRange(key) : inClosedRange(key); &#125; // 返回最低的Entry final TreeMap.Entry&lt;K,V&gt; absLowest() &#123; // 若“包含起始节点”，则调用getFirstEntry()返回第一个节点 // 否则的话，若包括lo，则调用getCeilingEntry(lo)获取大于/等于lo的最小的Entry; // 否则，调用getHigherEntry(lo)获取大于lo的最小Entry TreeMap.Entry&lt;K,V&gt; e = (fromStart ? m.getFirstEntry() : (loInclusive ? m.getCeilingEntry(lo) : m.getHigherEntry(lo))); return (e == null || tooHigh(e.key)) ? null : e; &#125; // 返回最高的Entry final TreeMap.Entry&lt;K,V&gt; absHighest() &#123; // 若“包含结束节点”，则调用getLastEntry()返回最后一个节点 // 否则的话，若包括hi，则调用getFloorEntry(hi)获取小于/等于hi的最大的Entry; // 否则，调用getLowerEntry(hi)获取大于hi的最大Entry TreeMap.Entry&lt;K,V&gt; e = TreeMap.Entry&lt;K,V&gt; e = (toEnd ? m.getLastEntry() : (hiInclusive ? m.getFloorEntry(hi) : m.getLowerEntry(hi))); return (e == null || tooLow(e.key)) ? null : e; &#125; // 返回\"大于/等于key的最小的Entry\" final TreeMap.Entry&lt;K,V&gt; absCeiling(K key) &#123; // 只有在“key太小”的情况下，absLowest()返回的Entry才是“大于/等于key的最小Entry” // 其它情况下不行。例如，当包含“起始节点”时，absLowest()返回的是最小Entry了！ if (tooLow(key)) return absLowest(); // 获取“大于/等于key的最小Entry” TreeMap.Entry&lt;K,V&gt; e = m.getCeilingEntry(key); return (e == null || tooHigh(e.key)) ? null : e; &#125; // 返回\"大于key的最小的Entry\" final TreeMap.Entry&lt;K,V&gt; absHigher(K key) &#123; // 只有在“key太小”的情况下，absLowest()返回的Entry才是“大于key的最小Entry” // 其它情况下不行。例如，当包含“起始节点”时，absLowest()返回的是最小Entry了,而不一定是“大于key的最小Entry”！ if (tooLow(key)) return absLowest(); // 获取“大于key的最小Entry” TreeMap.Entry&lt;K,V&gt; e = m.getHigherEntry(key); return (e == null || tooHigh(e.key)) ? null : e; &#125; // 返回\"小于/等于key的最大的Entry\" final TreeMap.Entry&lt;K,V&gt; absFloor(K key) &#123; // 只有在“key太大”的情况下，(absHighest)返回的Entry才是“小于/等于key的最大Entry” // 其它情况下不行。例如，当包含“结束节点”时，absHighest()返回的是最大Entry了！ if (tooHigh(key)) return absHighest(); // 获取\"小于/等于key的最大的Entry\" TreeMap.Entry&lt;K,V&gt; e = m.getFloorEntry(key); return (e == null || tooLow(e.key)) ? null : e; &#125; // 返回\"小于key的最大的Entry\" final TreeMap.Entry&lt;K,V&gt; absLower(K key) &#123; // 只有在“key太大”的情况下，(absHighest)返回的Entry才是“小于key的最大Entry” // 其它情况下不行。例如，当包含“结束节点”时，absHighest()返回的是最大Entry了,而不一定是“小于key的最大Entry”！ if (tooHigh(key)) return absHighest(); // 获取\"小于key的最大的Entry\" TreeMap.Entry&lt;K,V&gt; e = m.getLowerEntry(key); return (e == null || tooLow(e.key)) ? null : e; &#125; // 返回“大于最大节点中的最小节点”，不存在的话，返回null final TreeMap.Entry&lt;K,V&gt; absHighFence() &#123; return (toEnd ? null : (hiInclusive ? m.getHigherEntry(hi) : m.getCeilingEntry(hi))); &#125; // 返回“小于最小节点中的最大节点”，不存在的话，返回null final TreeMap.Entry&lt;K,V&gt; absLowFence() &#123; return (fromStart ? null : (loInclusive ? m.getLowerEntry(lo) : m.getFloorEntry(lo))); &#125; // 下面几个abstract方法是需要NavigableSubMap的实现类实现的方法 abstract TreeMap.Entry&lt;K,V&gt; subLowest(); abstract TreeMap.Entry&lt;K,V&gt; subHighest(); abstract TreeMap.Entry&lt;K,V&gt; subCeiling(K key); abstract TreeMap.Entry&lt;K,V&gt; subHigher(K key); abstract TreeMap.Entry&lt;K,V&gt; subFloor(K key); abstract TreeMap.Entry&lt;K,V&gt; subLower(K key); // 返回“顺序”的键迭代器 abstract Iterator&lt;K&gt; keyIterator(); // 返回“逆序”的键迭代器 abstract Iterator&lt;K&gt; descendingKeyIterator(); // 返回SubMap是否为空。空的话，返回true，否则返回false public boolean isEmpty() &#123; return (fromStart &amp;&amp; toEnd) ? m.isEmpty() : entrySet().isEmpty(); &#125; // 返回SubMap的大小 public int size() &#123; return (fromStart &amp;&amp; toEnd) ? m.size() : entrySet().size(); &#125; // 返回SubMap是否包含键key public final boolean containsKey(Object key) &#123; return inRange(key) &amp;&amp; m.containsKey(key); &#125; // 将key-value 插入SubMap中 public final V put(K key, V value) &#123; if (!inRange(key)) throw new IllegalArgumentException(\"key out of range\"); return m.put(key, value); &#125; // 获取key对应值 public final V get(Object key) &#123; return !inRange(key)? null : m.get(key); &#125; // 删除key对应的键值对 public final V remove(Object key) &#123; return !inRange(key)? null : m.remove(key); &#125; // 获取“大于/等于key的最小键值对” public final Map.Entry&lt;K,V&gt; ceilingEntry(K key) &#123; return exportEntry(subCeiling(key)); &#125; // 获取“大于/等于key的最小键” public final K ceilingKey(K key) &#123; return keyOrNull(subCeiling(key)); &#125; // 获取“大于key的最小键值对” public final Map.Entry&lt;K,V&gt; higherEntry(K key) &#123; return exportEntry(subHigher(key)); &#125; // 获取“大于key的最小键” public final K higherKey(K key) &#123; return keyOrNull(subHigher(key)); &#125; // 获取“小于/等于key的最大键值对” public final Map.Entry&lt;K,V&gt; floorEntry(K key) &#123; return exportEntry(subFloor(key)); &#125; // 获取“小于/等于key的最大键” public final K floorKey(K key) &#123; return keyOrNull(subFloor(key)); &#125; // 获取“小于key的最大键值对” public final Map.Entry&lt;K,V&gt; lowerEntry(K key) &#123; return exportEntry(subLower(key)); &#125; // 获取“小于key的最大键” public final K lowerKey(K key) &#123; return keyOrNull(subLower(key)); &#125; // 获取\"SubMap的第一个键\" public final K firstKey() &#123; return key(subLowest()); &#125; // 获取\"SubMap的最后一个键\" public final K lastKey() &#123; return key(subHighest()); &#125; // 获取\"SubMap的第一个键值对\" public final Map.Entry&lt;K,V&gt; firstEntry() &#123; return exportEntry(subLowest()); &#125; // 获取\"SubMap的最后一个键值对\" public final Map.Entry&lt;K,V&gt; lastEntry() &#123; return exportEntry(subHighest()); &#125; // 返回\"SubMap的第一个键值对\"，并从SubMap中删除改键值对 public final Map.Entry&lt;K,V&gt; pollFirstEntry() &#123; TreeMap.Entry&lt;K,V&gt; e = subLowest(); Map.Entry&lt;K,V&gt; result = exportEntry(e); if (e != null) m.deleteEntry(e); return result; &#125; // 返回\"SubMap的最后一个键值对\"，并从SubMap中删除改键值对 public final Map.Entry&lt;K,V&gt; pollLastEntry() &#123; TreeMap.Entry&lt;K,V&gt; e = subHighest(); Map.Entry&lt;K,V&gt; result = exportEntry(e); if (e != null) m.deleteEntry(e); return result; &#125; // Views transient NavigableMap&lt;K,V&gt; descendingMapView = null; transient EntrySetView entrySetView = null; transient KeySet&lt;K&gt; navigableKeySetView = null; // 返回NavigableSet对象，实际上返回的是当前对象的\"Key集合\"。 public final NavigableSet&lt;K&gt; navigableKeySet() &#123; KeySet&lt;K&gt; nksv = navigableKeySetView; return (nksv != null) ? nksv : (navigableKeySetView = new TreeMap.KeySet(this)); &#125; // 返回\"Key集合\"对象 public final Set&lt;K&gt; keySet() &#123; return navigableKeySet(); &#125; // 返回“逆序”的Key集合 public NavigableSet&lt;K&gt; descendingKeySet() &#123; return descendingMap().navigableKeySet(); &#125; // 排列fromKey(包含) 到 toKey(不包含) 的子map public final SortedMap&lt;K,V&gt; subMap(K fromKey, K toKey) &#123; return subMap(fromKey, true, toKey, false); &#125; // 返回当前Map的头部(从第一个节点 到 toKey, 不包括toKey) public final SortedMap&lt;K,V&gt; headMap(K toKey) &#123; return headMap(toKey, false); &#125; // 返回当前Map的尾部[从 fromKey(包括fromKeyKey) 到 最后一个节点] public final SortedMap&lt;K,V&gt; tailMap(K fromKey) &#123; return tailMap(fromKey, true); &#125; // Map的Entry的集合 abstract class EntrySetView extends AbstractSet&lt;Map.Entry&lt;K,V&gt;&gt; &#123; private transient int size = -1, sizeModCount; // 获取EntrySet的大小 public int size() &#123; // 若SubMap是从“开始节点”到“结尾节点”，则SubMap大小就是原TreeMap的大小 if (fromStart &amp;&amp; toEnd) return m.size(); // 若SubMap不是从“开始节点”到“结尾节点”，则调用iterator()遍历EntrySetView中的元素 if (size == -1 || sizeModCount != m.modCount) &#123; sizeModCount = m.modCount; size = 0; Iterator i = iterator(); while (i.hasNext()) &#123; size++; i.next(); &#125; &#125; return size; &#125; // 判断EntrySetView是否为空 public boolean isEmpty() &#123; TreeMap.Entry&lt;K,V&gt; n = absLowest(); return n == null || tooHigh(n.key); &#125; // 判断EntrySetView是否包含Object public boolean contains(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry&lt;K,V&gt; entry = (Map.Entry&lt;K,V&gt;) o; K key = entry.getKey(); if (!inRange(key)) return false; TreeMap.Entry node = m.getEntry(key); return node != null &amp;&amp; valEquals(node.getValue(), entry.getValue()); &#125; // 从EntrySetView中删除Object public boolean remove(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry&lt;K,V&gt; entry = (Map.Entry&lt;K,V&gt;) o; K key = entry.getKey(); if (!inRange(key)) return false; TreeMap.Entry&lt;K,V&gt; node = m.getEntry(key); if (node!=null &amp;&amp; valEquals(node.getValue(),entry.getValue()))&#123; m.deleteEntry(node); return true; &#125; return false; &#125; &#125; // SubMap的迭代器 abstract class SubMapIterator&lt;T&gt; implements Iterator&lt;T&gt; &#123; // 上一次被返回的Entry TreeMap.Entry&lt;K,V&gt; lastReturned; // 指向下一个Entry TreeMap.Entry&lt;K,V&gt; next; // “栅栏key”。根据SubMap是“升序”还是“降序”具有不同的意义 final K fenceKey; int expectedModCount; // 构造函数 SubMapIterator(TreeMap.Entry&lt;K,V&gt; first, TreeMap.Entry&lt;K,V&gt; fence) &#123; // 每创建一个SubMapIterator时，保存修改次数 // 若后面发现expectedModCount和modCount不相等，则抛出ConcurrentModificationException异常。 // 这就是所说的fast-fail机制的原理！ expectedModCount = m.modCount; lastReturned = null; next = first; fenceKey = fence == null ? null : fence.key; &#125; // 是否存在下一个Entry public final boolean hasNext() &#123; return next != null &amp;&amp; next.key != fenceKey; &#125; // 返回下一个Entry final TreeMap.Entry&lt;K,V&gt; nextEntry() &#123; TreeMap.Entry&lt;K,V&gt; e = next; if (e == null || e.key == fenceKey) throw new NoSuchElementException(); if (m.modCount != expectedModCount) throw new ConcurrentModificationException(); // next指向e的后继节点 next = successor(e); lastReturned = e; return e; &#125; // 返回上一个Entry final TreeMap.Entry&lt;K,V&gt; prevEntry() &#123; TreeMap.Entry&lt;K,V&gt; e = next; if (e == null || e.key == fenceKey) throw new NoSuchElementException(); if (m.modCount != expectedModCount) throw new ConcurrentModificationException(); // next指向e的前继节点 next = predecessor(e); lastReturned = e; return e; &#125; // 删除当前节点(用于“升序的SubMap”)。 // 删除之后，可以继续升序遍历；红黑树特性没变。 final void removeAscending() &#123; if (lastReturned == null) throw new IllegalStateException(); if (m.modCount != expectedModCount) throw new ConcurrentModificationException(); // 这里重点强调一下“为什么当lastReturned的左右孩子都不为空时，要将其赋值给next”。 // 目的是为了“删除lastReturned节点之后，next节点指向的仍然是下一个节点”。 // 根据“红黑树”的特性可知： // 当被删除节点有两个儿子时。那么，首先把“它的后继节点的内容”复制给“该节点的内容”；之后，删除“它的后继节点”。 // 这意味着“当被删除节点有两个儿子时，删除当前节点之后，'新的当前节点'实际上是‘原有的后继节点(即下一个节点)’”。 // 而此时next仍然指向\"新的当前节点\"。也就是说next是仍然是指向下一个节点；能继续遍历红黑树。 if (lastReturned.left != null &amp;&amp; lastReturned.right != null) next = lastReturned; m.deleteEntry(lastReturned); lastReturned = null; expectedModCount = m.modCount; &#125; // 删除当前节点(用于“降序的SubMap”)。 // 删除之后，可以继续降序遍历；红黑树特性没变。 final void removeDescending() &#123; if (lastReturned == null) throw new IllegalStateException(); if (m.modCount != expectedModCount) throw new ConcurrentModificationException(); m.deleteEntry(lastReturned); lastReturned = null; expectedModCount = m.modCount; &#125; &#125; // SubMap的Entry迭代器，它只支持升序操作，继承于SubMapIterator final class SubMapEntryIterator extends SubMapIterator&lt;Map.Entry&lt;K,V&gt;&gt; &#123; SubMapEntryIterator(TreeMap.Entry&lt;K,V&gt; first, TreeMap.Entry&lt;K,V&gt; fence) &#123; super(first, fence); &#125; // 获取下一个节点(升序) public Map.Entry&lt;K,V&gt; next() &#123; return nextEntry(); &#125; // 删除当前节点(升序) public void remove() &#123; removeAscending(); &#125; &#125; // SubMap的Key迭代器，它只支持升序操作，继承于SubMapIterator final class SubMapKeyIterator extends SubMapIterator&lt;K&gt; &#123; SubMapKeyIterator(TreeMap.Entry&lt;K,V&gt; first, TreeMap.Entry&lt;K,V&gt; fence) &#123; super(first, fence); &#125; // 获取下一个节点(升序) public K next() &#123; return nextEntry().key; &#125; // 删除当前节点(升序) public void remove() &#123; removeAscending(); &#125; &#125; // 降序SubMap的Entry迭代器，它只支持降序操作，继承于SubMapIterator final class DescendingSubMapEntryIterator extends SubMapIterator&lt;Map.Entry&lt;K,V&gt;&gt; &#123; DescendingSubMapEntryIterator(TreeMap.Entry&lt;K,V&gt; last, TreeMap.Entry&lt;K,V&gt; fence) &#123; super(last, fence); &#125; // 获取下一个节点(降序) public Map.Entry&lt;K,V&gt; next() &#123; return prevEntry(); &#125; // 删除当前节点(降序) public void remove() &#123; removeDescending(); &#125; &#125; // 降序SubMap的Key迭代器，它只支持降序操作，继承于SubMapIterator final class DescendingSubMapKeyIterator extends SubMapIterator&lt;K&gt; &#123; DescendingSubMapKeyIterator(TreeMap.Entry&lt;K,V&gt; last, TreeMap.Entry&lt;K,V&gt; fence) &#123; super(last, fence); &#125; // 获取下一个节点(降序) public K next() &#123; return prevEntry().key; &#125; // 删除当前节点(降序) public void remove() &#123; removeDescending(); &#125; &#125;&#125; 其实，读完NavigableSubMap的源码后，我们可以得出它的核心思想是：它是一个抽象集合类，为2个子类——“(升序)AscendingSubMap”和”(降序)DescendingSubMap”而服务；因为NavigableSubMap实现了许多公共API。它的最终目的是实现下面的一系列函数： 12345678headMap(K toKey, boolean inclusive)headMap(K toKey)subMap(K fromKey, K toKey)subMap(K fromKey, boolean fromInclusive, K toKey, boolean toInclusive)tailMap(K fromKey)tailMap(K fromKey, boolean inclusive)navigableKeySet()descendingKeySet() TreeMap其它函数顺序遍历和逆序遍历TreeMap的顺序遍历和逆序遍历原理非常简单。由于TreeMap中的元素是从小到大的顺序排列的。因此，顺序遍历，就是从第一个元素开始，逐个向后遍历；而倒序遍历则恰恰相反，它是从最后一个元素开始，逐个往前遍历。 我们可以通过 keyIterator() 和 descendingKeyIterator()来说明！keyIterator()的作用是返回顺序的KEY的集合，descendingKeyIterator()的作用是返回逆序的KEY的集合。 keyIterator() 的代码如下： 123Iterator&lt;K&gt; keyIterator() &#123; return new KeyIterator(getFirstEntry());&#125; 说明：从中我们可以看出keyIterator() 是返回以“第一个节点(getFirstEntry)” 为其实元素的迭代器。KeyIterator的代码如下： 12345678final class KeyIterator extends PrivateEntryIterator&lt;K&gt; &#123; KeyIterator(Entry&lt;K,V&gt; first) &#123; super(first); &#125; public K next() &#123; return nextEntry().key; &#125;&#125; 说明：KeyIterator继承于PrivateEntryIterator。当我们通过next()不断获取下一个元素的时候，就是执行的顺序遍历了。 descendingKeyIterator()的代码如下： 123Iterator&lt;K&gt; descendingKeyIterator() &#123; return new DescendingKeyIterator(getLastEntry());&#125; 说明：DescendingKeyIterator继承于PrivateEntryIterator。当我们通过next()不断获取下一个元素的时候，实际上调用的是prevEntry()获取的上一个节点，这样它实际上执行的是逆序遍历了。至此，TreeMap的相关内容就全部介绍完毕了。 TreeMap遍历方式遍历TreeMap的键值对第一步：根据entrySet()获取TreeMap的“键值对”的Set集合。第二步：通过Iterator迭代器遍历“第一步”得到的集合。 1234567891011// 假设map是TreeMap对象// map中的key是String类型，value是Integer类型Integer integ = null;Iterator iter = map.entrySet().iterator();while(iter.hasNext()) &#123; Map.Entry entry = (Map.Entry)iter.next(); // 获取key key = (String)entry.getKey(); // 获取value integ = (Integer)entry.getValue();&#125; 遍历TreeMap的键第一步：根据keySet()获取TreeMap的“键”的Set集合。第二步：通过Iterator迭代器遍历“第一步”得到的集合。 1234567891011// 假设map是TreeMap对象// map中的key是String类型，value是Integer类型String key = null;Integer integ = null;Iterator iter = map.keySet().iterator();while (iter.hasNext()) &#123; // 获取key key = (String)iter.next(); // 根据key，获取value integ = (Integer)map.get(key);&#125; 遍历TreeMap的值123456789// 假设map是TreeMap对象// map中的key是String类型，value是Integer类型Integer value = null;Collection c = map.values();Iterator iter= c.iterator();while (iter.hasNext()) &#123; value = (Integer)iter.next();&#125;` TreeMap示例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class TreeMapIteratorTest &#123; public static void main(String[] args) &#123; int val = 0; String key = null; Integer value = null; Random r = new Random(); TreeMap map = new TreeMap(); for (int i=0; i&lt;12; i++) &#123; // 随机获取一个[0,100)之间的数字 val = r.nextInt(100); key = String.valueOf(val); value = r.nextInt(5); // 添加到TreeMap中 map.put(key, value); System.out.println(\" key:\"+key+\" value:\"+value); &#125; // 通过entrySet()遍历TreeMap的key-value iteratorTreeMapByEntryset(map) ; // 通过keySet()遍历TreeMap的key-value iteratorTreeMapByKeyset(map) ; // 单单遍历TreeMap的value iteratorTreeMapJustValues(map); &#125; /* * 通过entry set遍历TreeMap * 效率高! */ private static void iteratorTreeMapByEntryset(TreeMap map) &#123; if (map == null) return ; System.out.println(\"\\niterator TreeMap By entryset\"); String key = null; Integer integ = null; Iterator iter = map.entrySet().iterator(); while(iter.hasNext()) &#123; Map.Entry entry = (Map.Entry)iter.next(); key = (String)entry.getKey(); integ = (Integer)entry.getValue(); System.out.println(key+\" -- \"+integ.intValue()); &#125; &#125; /* * 通过keyset来遍历TreeMap * 效率低! */ private static void iteratorTreeMapByKeyset(TreeMap map) &#123; if (map == null) return ; System.out.println(\"\\niterator TreeMap By keyset\"); String key = null; Integer integ = null; Iterator iter = map.keySet().iterator(); while (iter.hasNext()) &#123; key = (String)iter.next(); integ = (Integer)map.get(key); System.out.println(key+\" -- \"+integ.intValue()); &#125; &#125; /* * 遍历TreeMap的values */ private static void iteratorTreeMapJustValues(TreeMap map) &#123; if (map == null) return ; Collection c = map.values(); Iterator iter= c.iterator(); while (iter.hasNext()) &#123; System.out.println(iter.next()); &#125; &#125;&#125;","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"Java集合","slug":"Java集合","permalink":"https://htchz.cc/tags/Java集合/"}],"author":"土川"},{"title":"Java集合(九)应该弃用的Hashtable","slug":"Java集合-九-应该弃用的Hashtable","date":"2018-03-14T10:41:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"1453986082.html","link":"","permalink":"https://htchz.cc/1453986082.html","excerpt":"","text":"Hashtable 简介和HashMap一样，Hashtable 也是一个散列表，它存储的内容是键值对(key-value)映射。Hashtable 继承于Dictionary，实现了Map、Cloneable、java.io.Serializable接口。Hashtable 的函数都是同步的，这意味着它是线程安全的。它的key、value都可以为null。此外，Hashtable中的映射不是有序的。但是HashTable是属于java1.0的旧容器。使用HashTable而不是使用HashMap的唯一理由就是HashTable是同步的。但jdk1.5 在util并发包下有专门的ConcurrentHashMap供使用。所以我们没有任何理由去使用HashTable。除了hashtable是java1.0，1.1的老容器，【Vector和Enumeration，以及vector的子类stack】也是，我们应该避免使用。虽然不太明白为什么java没标注过期。但我们不应该使用。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"Java集合","slug":"Java集合","permalink":"https://htchz.cc/tags/Java集合/"}],"author":"土川"},{"title":"Java集合(八)HashMap","slug":"Java集合-八-HashMap","date":"2018-03-14T09:32:00.000Z","updated":"2019-07-20T12:59:21.000Z","comments":true,"path":"279970476.html","link":"","permalink":"https://htchz.cc/279970476.html","excerpt":"","text":"概述HashMap是基于哈希表的Map接口实现的,此实现提供所有可选的映射操作。存储的是&lt;key，value&gt;对的映射，允许多个null值和一个null键。但此类不保证映射的顺序，特别是它不保证该顺序恒久不变。 除了HashMap是非同步以及允许使用null外，HashMap 类与 Hashtable大致相同。 此实现假定哈希函数将元素适当地分布在各桶之间，可为基本操作（get 和 put）提供稳定的性能。迭代collection 视图所需的时间与 HashMap 实例的“容量”（桶的数量）及其大小（键-值映射关系数）成比例。所以，如果迭代性能很重要，则不要将初始容量设置得太高（或将加载因子设置得太低）。 HashMap 的实例有两个参数影响其性能：初始容量 和加载因子。容量 是哈希表中桶的数量，初始容量只是哈希表在创建时的容量。加载因子 是哈希表在其容量自动增加之前可以达到多满的一种尺度。当哈希表中的条目数超出了加载因子与当前容量的乘积时，则要对该哈希表进行 rehash 操作（即重建内部数据结构），从而哈希表将具有大约两倍的桶数。 通常，默认加载因子 (0.75) 在时间和空间成本上寻求一种折衷。加载因子过高虽然减少了空间开销，但同时也增加了查询成本（在大多数 HashMap 类的操作中，包括 get 和 put 操作，都反映了这一点）。在设置初始容量时应该考虑到映射中所需的条目数及其加载因子，以便最大限度地减少 rehash 操作次数。如果初始容量大于最大条目数除以加载因子，则不会发生 rehash 操作。 注意，此实现不是同步的。 如果多个线程同时访问一个HashMap实例，而其中至少一个线程从结构上修改了列表，那么它必须保持外部同步。这通常是通过同步那些用来封装列表的 对象来实现的。但如果没有这样的对象存在，则应该使用{@link Collections#synchronizedMap Collections.synchronizedMap}来进行“包装”，该方法最好是在创建时完成，为了避免对映射进行意外的非同步操作。· 1Map m = Collections.synchronizedMap(new HashMap(...)); 数据结构HashMap实际上是一个“链表的数组”的数据结构，每个元素存放链表头结点的数组，即数组和链表的结合体。 HashMap底层就是一个数组结构，数组中的每一项又是一个链表，链表中的每个元素为一个包含可以值，key哈希码，value值的Node节点。该数组的下标索引为key的哈希码 源码解析映射项Node&lt;K,V&gt;结构12345678910111213141516171819202122232425262728293031323334353637383940414243//实现Map.Entry&lt;K,V&gt;接口 static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; //hash码 final K key; V value; Node&lt;K,V&gt; next; //指向链表中下一个实例 Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + \"=\" + value; &#125; //返回此映射项的哈希值:key值的哈希码与value值的哈希码按位异或的结果 public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; //用指定值替换对应于此项的值,并返回旧值 public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; //比较指定对象与此项的相等性 public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125; &#125; 类结构1234567891011121314151617181920212223242526272829303132333435363738//通过HahMap实现的接口可知，其支持所有映射操作，能被克隆，支持序列化public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; private static final long serialVersionUID = 362498820763181265L; //默认初始容量16，必须为2的幂 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 //最大容量 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; //默认加载因子 static final float DEFAULT_LOAD_FACTOR = 0.75f; //table是一个Node&lt;K,V&gt;[]数组类型，而Node&lt;K,V&gt;实际上就是一个元素值为&lt;key,value&gt;对的单向链表。 //哈希表的\"key-value键值对\"都是存储在Node&lt;K,V&gt;数组中的。 transient Node&lt;K,V&gt;[] table; //用来指向entrySet()返回的set集合 transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; //HashMap的大小,即保存的键值对的数量 transient int size; //用来实现fail-fast机制的，记录HashMap结构化修改的次数 transient int modCount; //下次需扩容的临界值，size&gt;=threshold就会扩容 //如果table数组没有被分配，则该值为初始容量值16；或若该值为0，也表明该值为初始容量值 int threshold; //加载因子 final float loadFactor; ......&#125; HashMap包含了几个重要的成员变量：table, size, threshold, loadFactor。 (01) table是一个Node[]数组类型，而Node实际上就是一个单向链表。哈希表的”key-value键值对”都是存储在Node数组中的。 (02) size是HashMap的大小，它是HashMap保存的键值对的数量。 (03) threshold是HashMap的阈值，用于判断是否需要调整HashMap的容量。threshold的值=”容量*加载因子”，当HashMap中存储数据的数量达到threshold时（size&gt;=threshold），就需要将HashMap的容量加倍。(04) loadFactor就是加载因子。 冲突解决方法通过HashMap数据存储数组Node&lt;K,V&gt;[] table，及数据节点Node&lt;K,V&gt;的数据结构可知：HashMap是实现”key-value键值对”的映射关系的，是通过“拉链法”解决哈希冲突的。简单的构造图如下所示： 构造函数1234567891011121314151617181920212223242526272829303132333435363738394041//找出“大于Capacity”的最小的2的幂,使Hash表的容量保持为2的次方倍//算法的思想：通过使用逻辑运算来替代取余，这里有一个规律，就是当N为2的次方（Power of two），那么X％N==X&amp;(N-1)。static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; //&gt;&gt;&gt; 无符号右移,高位补0 n |= n &gt;&gt;&gt; 2; //a|=b的意思就是把a和b按位或然后赋值给a n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125;//构造一个带指定初始容量和加载因子的空HashMappublic HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125;//构造一个带指定初始容量和默认加载因子(0.75)的空 HashMappublic HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;//构造一个具有默认初始容量 (16)和默认加载因子 (0.75)的空 HashMappublic HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted&#125;//构造一个映射关系与指定 Map相同的新 HashMap,容量与指定Map容量相同，加载因子为默认的0.75public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);&#125; resize()方法在HashMap的四种构造函数中并没有对其成员变量Node&lt;K,V&gt;[] table进行任何初始化的工作，那么HashMap是如何构造一个默认初始容量为16的空表的？该初始化的诱发条件是在向HashMap中添加第一对&lt;key,value&gt;时，通过put(K key, V value) -&gt; putVal(hash(key), key, value, false, true) -&gt; resize()方法。故HashMap中尤其重要的resize()方法主要实现了两个功能： 1.在table数组为null时，对其进行初始化，默认容量为16；2.当tables数组非空，但需要调整HashMap的容量时，将hash表容量翻倍。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182//resize()方法作用有两种：1.初始化hash表的容量，为16； 2.将hash表容量翻倍final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; //旧hash表 int oldCap = (oldTab == null) ? 0 : oldTab.length; //旧hash表容量 int oldThr = threshold; //旧hash表阈值 int newCap, newThr = 0; //新hash表容量与扩容临界值 //2.旧hash表非空，则表容量翻倍 if (oldCap &gt; 0) &#123; //如果当前的hash表长度已经达到最大值，则不在进行调整 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; //更新新hash表容量：翻倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) //更新扩容临界值 newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; //1. 初始化hash表容量，设为默认值16 else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) //创建一个初始容量为新hash表长度的newTab数组 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; //如果旧hash表非空，则按序将旧hash表中的元素重定向到新hash表 if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; //e按序指向oldTab数组中的元素，即每个链表中的头结点 if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) //如果链表只有一个头节点 newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); //对链表进行顺序维护：因为我们使用的是两倍扩容的方法，所以每个桶里面的元素必须要么待在原来的 //索引所对应的位置，要么在新的桶中位置偏移两倍 else &#123; Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 查找123456789101112131415161718192021222324252627282930313233343536373839404142434445464748 //返回指定key所映射的value；如果对于该键来说，此映射不包含任何映射关系，则返回 null public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; //key的哈希值为数组下标 if (first.hash == hash &amp;&amp; //检查第一个节点 ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; //如果第一个节点不对，则向后检查 if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; //如果此映射包含对于指定键的映射关系，则返回 true。 public boolean containsKey(Object key) &#123; return getNode(hash(key), key) != null; &#125; //如果此映射将一个或多个键映射到指定值，则返回 true。 public boolean containsValue(Object value) &#123; Node&lt;K,V&gt;[] tab; V v; if ((tab = table) != null &amp;&amp; size &gt; 0) &#123; //外层循环搜索数组 for (int i = 0; i &lt; tab.length; ++i) &#123; //内层循环搜索链表 for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; if ((v = e.value) == value || (value != null &amp;&amp; value.equals(v))) return true; &#125; &#125; &#125; return false; &#125; 添加HashMap提供了put(K key, V value)、putAll(Map&lt;? extends K, ? extends V&gt; m)这些添加键值对的方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394/** * 在此映射中关联指定值与指定键。如果该映射以前包含了一个该键的映射关系，则旧值被替换。 * * @param key 指定值将要关联的键 * @param value 指定键将要关联的值 * @return 与 key关联的旧值；如果 key没有任何映射关系，则返回 null。（返回 null 还可能表示该映射之前将null与 key关联。） */public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;/** * 用于实现 Map.put()和相关的方法 * * @param hash 键的hash码 * @param key 键 * @param value 值 * @param onlyIfAbsent if true, don't change existing value * @param evict evict=false：表明该hash表处于初始化创建的过程中 * @return previous value, or null if none */final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //此处分两种情况：1.当table为null时，用默认容量16初始化table数组；2.当table非空时 if ((tab = table) == null || (n = tab.length) == 0) //旧hash表为null或旧hash表长度为0 n = (tab = resize()).length; //初始化hash表的长度（16） //此处又分为两种情况：1.key的hash值对应的那个节点为空；2.key的hash值对应的那个节点不为空 if ((p = tab[i = (n - 1) &amp; hash]) == null) //该key的hash值对应的那个节点为空，即表示还没有元素被散列至此 tab[i] = newNode(hash, key, value, null); //则创建一个新的new Node&lt;&gt;(hash, key, value, next); else &#123; //该key的hash值对应的那个节点不为空，先与链表上的第一个节点p比较 Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; //向后查找 &#125; &#125; //若该key对应的value已经存在，则用新的value取代旧的value if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) //如果加入该键值对后超过最大阀值，则进行resize操作 resize(); afterNodeInsertion(evict); return null;&#125;//将指定映射的所有映射关系复制到此映射中，这些映射关系将替换此映射目前针对指定映射中所有键的所有映射关系。public void putAll(Map&lt;? extends K, ? extends V&gt; m) &#123; putMapEntries(m, true);&#125;//用于帮助实现Map.putAll()方法 和Map构造器，当evict=false时表示构造初始HashMap。final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123; int s = m.size(); //得到指定Map的大小 if (s &gt; 0) &#123; if (table == null) &#123; // pre-size float ft = ((float)s / loadFactor) + 1.0F; int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); //得到按指定Map大小计算出的HashMap所需的容量 if (t &gt; threshold) //如果容量大于阈值 threshold = tableSizeFor(t); &#125; else if (s &gt; threshold) //指定Map的大小&gt;扩容临界值,扩容 resize(); //通过迭代器，将“m”中的元素逐个添加到HashMap中 for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); &#125; &#125;&#125; HashMap的取模方法HashMap的取模方法主要用一个扰动算法得出哈希值，然后和数组长度取模得到数组索引 hash1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 取模由于HashMap始终都是2的幂，所以取模操作都是hash值与（数组size-1），这个（length-1）相当一个低位掩码hash(key) &amp; (length - 1) 清空与删除12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970//从此映射中移除指定键的映射关系（如果存在）public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;/** * 用于实现 Map.remove()方法和其他相关的方法 * * @param hash 键的hash值 * @param key 键 * @param value the value to match if matchValue, else ignored * @param matchValue if true only remove if value is equal * @param movable if false do not move other nodes while removing * @return the node, or null if none */final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; //table数组非空，键的hash值所指向的数组中的元素非空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; //node指向最终的结果结点，e为链表中的遍历指针 if (p.hash == hash &amp;&amp; //检查第一个节点，如果匹配成功 ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; //如果第一个节点匹配不成功，则向后遍历链表查找 else if ((e = p.next) != null) &#123; if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e;// 记录前驱结点 &#125; while ((e = e.next) != null); &#125; &#125; if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) //删除node结点，node为p则说明是链表头 tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null;&#125;//从此映射中移除所有映射关系public void clear() &#123; Node&lt;K,V&gt;[] tab; modCount++; if ((tab = table) != null &amp;&amp; size &gt; 0) &#123; size = 0; for (int i = 0; i &lt; tab.length; ++i) tab[i] = null; &#125;&#125; 其他公开的方法size()、isEmpty()、clone() 1234567891011121314151617181920212223//返回此映射中的键-值映射关系数public int size() &#123; return size;&#125;//如果此映射不包含键-值映射关系，则返回 truepublic boolean isEmpty() &#123; return size == 0;&#125;//返回此 HashMap 实例的浅表副本public Object clone() &#123; HashMap&lt;K,V&gt; result; try &#123; result = (HashMap&lt;K,V&gt;)super.clone(); //调用父类clone方法 &#125; catch (CloneNotSupportedException e) &#123; // this shouldn't happen, since we are Cloneable throw new InternalError(e); &#125; result.reinitialize(); result.putMapEntries(this, false); //将此HashMap元素放入result中 return result;&#125; 支持序列化的写入函数writeObject(java.io.ObjectOutputStream s)和读取函数readObject(java.io.ObjectInputStream s)： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364//java.io.Serializable的写入函数,将HashMap的“总的容量，实际容量，所有的Entry”都写入到输出流中private void writeObject(java.io.ObjectOutputStream s) throws IOException &#123; int buckets = capacity(); // Write out the threshold, loadfactor, and any hidden stuff s.defaultWriteObject(); s.writeInt(buckets); s.writeInt(size); internalWriteEntries(s); &#125; //java.io.Serializable的读取函数：根据写入方式读出,将HashMap的“总的容量，实际容量，所有的Entry”依次读出private void readObject(java.io.ObjectInputStream s) throws IOException, ClassNotFoundException &#123; // Read in the threshold (ignored), loadfactor, and any hidden stuff s.defaultReadObject(); reinitialize(); if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new InvalidObjectException(\"Illegal load factor: \" + loadFactor); s.readInt(); // Read and ignore number of buckets int mappings = s.readInt(); // Read number of mappings (size) if (mappings &lt; 0) throw new InvalidObjectException(\"Illegal mappings count: \" + mappings); else if (mappings &gt; 0) &#123; // (if zero, use defaults) // Size the table using given load factor only if within // range of 0.25...4.0 float lf = Math.min(Math.max(0.25f, loadFactor), 4.0f); float fc = (float)mappings / lf + 1.0f; int cap = ((fc &lt; DEFAULT_INITIAL_CAPACITY) ? DEFAULT_INITIAL_CAPACITY : (fc &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)fc)); float ft = (float)cap * lf; threshold = ((cap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; MAXIMUM_CAPACITY) ? (int)ft : Integer.MAX_VALUE); @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) Node&lt;K,V&gt;[] tab = (Node&lt;K,V&gt;[])new Node[cap]; table = tab; // Read the keys and values, and put the mappings in the HashMap for (int i = 0; i &lt; mappings; i++) &#123; @SuppressWarnings(\"unchecked\") K key = (K) s.readObject(); @SuppressWarnings(\"unchecked\") V value = (V) s.readObject(); putVal(hash(key), key, value, false, false); &#125; &#125;&#125;// Called only from writeObject, to ensure compatible ordering.void internalWriteEntries(java.io.ObjectOutputStream s) throws IOException &#123; Node&lt;K,V&gt;[] tab; if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; s.writeObject(e.key); s.writeObject(e.value); &#125; &#125; &#125; HashMap带来的线程问题多线程put的时候可能导致元素丢失主要问题出在addEntry方法的new Entry (hash, key, value, e)，如果两个线程都同时取得了e,则他们下一个元素都是e，然后赋值给table元素的时候有一个成功有一个丢失。 put非null元素后get出来的却是null问题出在线程一put非null元素后，线程二将key的value置为null，导致线程一get到null 多线程put后可能导致get死循环这个问题在jdk7会出现，但是jdk8不会了。虽然jdk8不会出现死循环，但在多线程环境下还是不能用HashMap。我想这只是避免了实习生用错数据结构带崩整个应用吧（滑稽）。 这个问题和上面比都是弟弟。要知道上面的问题只是会出错，而导致死循环的话是会引起CPU空转的。详见老生常谈，HashMap的死循环。这篇文章的代码是jdk7的，死循环主要是因为jdk7的resize会导致新链表逆序，多个线程下resize将逆序链表和正序链表瞎鸡儿操作，就诞生出环形链表了（还会丢数据）。这样一旦get进行递归链表的时候就死循环。而jdk8保证了链表的顺序，避免了出现环形链表。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[],"author":"土川"},{"title":"Java集合(七)Map架构分析","slug":"Java集合-七-Map架构分析","date":"2018-03-14T09:31:00.000Z","updated":"2019-07-16T10:19:01.000Z","comments":true,"path":"2230471019.html","link":"","permalink":"https://htchz.cc/2230471019.html","excerpt":"","text":"先学习Map，再学习Set；因为Set的实现类都是基于Map来实现的(如，HashSet是通过HashMap实现的，TreeSet是通过TreeMap实现的)Map架构: Map 是映射接口，Map中存储的内容是键值对(key-value)。AbstractMap 是继承于Map的抽象类，它实现了Map中的大部分API。其它Map的实现类可以通过继承AbstractMap来减少重复编码。SortedMap 是继承于Map的接口。SortedMap中的内容是排序的键值对，排序的方法是通过比较器(Comparator)。NavigableMap 是继承于SortedMap的接口。相比于SortedMap，NavigableMap有一系列的导航方法；如”获取大于/等于某对象的键值对”、“获取小于/等于某对象的键值对”等等。TreeMap 继承于AbstractMap，且实现了NavigableMap接口；因此，TreeMap中的内容是“有序的键值对”！HashMap 继承于AbstractMap，但没实现NavigableMap接口；因此，HashMap的内容是“键值对，但不保证次序”！Hashtable 虽然不是继承于AbstractMap，但它继承于Dictionary(Dictionary也是键值对的接口)，而且也实现Map接口；因此，Hashtable的内容也是“键值对，也不保证次序”。但和HashMap相比，Hashtable是线程安全的，而且它支持通过Enumeration去遍历。WeakHashMap 继承于AbstractMap。它和HashMap的键类型不同，WeakHashMap的键是“弱键”。 定义1public interface Map&lt;K,V&gt; &#123; &#125; Map 是一个键值对(key-value)映射接口。Map映射中不能包含重复的键；每个键最多只能映射到一个值。Map 接口提供三种collection 视图，允许以键集、值集或键-值映射关系集的形式查看某个映射的内容。Map 映射顺序。有些实现类，可以明确保证其顺序，如 TreeMap；另一些映射实现则不保证顺序，如 HashMap 类。Map 的实现类应该提供2个“标准的”构造方法：第一个，void（无参数）构造方法，用于创建空映射；第二个，带有单个 Map 类型参数的构造方法，用于创建一个与其参数具有相同键-值映射关系的新映射。实际上，后一个构造方法允许用户复制任意映射，生成所需类的一个等价映射。尽管无法强制执行此建议（因为接口不能包含构造方法），但是 JDK 中所有通用的映射实现都遵从它。 api1234567891011121314abstract void clear()abstract boolean containsKey(Object key)abstract boolean containsValue(Object value)abstract Set&lt;Entry&lt;K, V&gt;&gt; entrySet()abstract boolean equals(Object object)abstract V get(Object key)abstract int hashCode()abstract boolean isEmpty()abstract Set&lt;K&gt; keySet()abstract V put(K key, V value)abstract void putAll(Map&lt;? extends K, ? extends V&gt; map)abstract V remove(Object key)abstract int size()abstract Collection&lt;V&gt; values() Map提供接口分别用于返回 键集、值集或键-值映射关系集。entrySet()用于返回键-值集的Set集合keySet()用于返回键集的Set集合values()用户返回值集的Collection集合因为Map中不能包含重复的键；每个键最多只能映射到一个值。所以，键-值集、键集都是Set，值集时Collection。 Map提供了“键-值对”、“根据键获取值”、“删除键”、“获取容量大小”等方法。 Map.Entry定义1interface Entry&lt;K,V&gt; &#123; &#125; Map.Entry是Map中内部的一个接口，Map.Entry是键值对，Map通过 entrySet() 获取Map.Entry的键值对集合，从而通过该集合实现对键值对的操作。 api12345abstract boolean equals(Object object)abstract K getKey()abstract V getValue()abstract int hashCode()abstract V setValue(V object) AbstractMap定义1public abstract class AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt; &#123;&#125; AbstractMap类提供 Map 接口的骨干实现，以最大限度地减少实现此接口所需的工作。要实现不可修改的映射，编程人员只需扩展此类并提供 entrySet 方法的实现即可，该方法将返回映射的映射关系 set 视图。通常，返回的 set 将依次在 AbstractSet 上实现。此 set 不支持 add() 或 remove() 方法，其迭代器也不支持 remove() 方法。要实现可修改的映射，编程人员必须另外重写此类的 put 方法（否则将抛出 UnsupportedOperationException），entrySet().iterator() 返回的迭代器也必须另外实现其 remove 方法。 AbstractMap的API12345678910111213141516abstract Set&lt;Entry&lt;K, V&gt;&gt; entrySet() void clear() boolean containsKey(Object key) boolean containsValue(Object value) boolean equals(Object object) V get(Object key) int hashCode() boolean isEmpty() Set&lt;K&gt; keySet() V put(K key, V value) void putAll(Map&lt;? extends K, ? extends V&gt; map) V remove(Object key) int size() String toString() Collection&lt;V&gt; values() Object clone() SortedMap定义1public interface SortedMap&lt;K,V&gt; extends Map&lt;K,V&gt; &#123; &#125; SortedMap是一个继承于Map接口的接口。它是一个有序的SortedMap键值映射。SortedMap的排序方式有两种：自然排序 或者 用户指定比较器。 插入有序 SortedMap 的所有元素都必须实现 Comparable 接口（或者被指定的比较器所接受）。另外，所有SortedMap 实现类都应该提供 4 个“标准”构造方法：(01) void（无参数）构造方法，它创建一个空的有序映射，按照键的自然顺序进行排序。(02) 带有一个 Comparator 类型参数的构造方法，它创建一个空的有序映射，根据指定的比较器进行排序。(03) 带有一个 Map 类型参数的构造方法，它创建一个新的有序映射，其键-值映射关系与参数相同，按照键的自然顺序进行排序。(04) 带有一个 SortedMap 类型参数的构造方法，它创建一个新的有序映射，其键-值映射关系和排序方法与输入的有序映射相同。无法保证强制实施此建议，因为接口不能包含构造方法。 api12345678910111213141516171819202122// 继承于Map的APIabstract void clear()abstract boolean containsKey(Object key)abstract boolean containsValue(Object value)abstract Set&lt;Entry&lt;K, V&gt;&gt; entrySet()abstract boolean equals(Object object)abstract V get(Object key)abstract int hashCode()abstract boolean isEmpty()abstract Set&lt;K&gt; keySet()abstract V put(K key, V value)abstract void putAll(Map&lt;? extends K, ? extends V&gt; map)abstract V remove(Object key)abstract int size()abstract Collection&lt;V&gt; values()// SortedMap新增的APIabstract Comparator&lt;? super K&gt; comparator()abstract K firstKey()abstract SortedMap&lt;K, V&gt; headMap(K endKey)abstract K lastKey()abstract SortedMap&lt;K, V&gt; subMap(K startKey, K endKey)abstract SortedMap&lt;K, V&gt; tailMap(K startKey) NavigableMap定义1public interface NavigableMap&lt;K,V&gt; extends SortedMap&lt;K,V&gt; &#123; &#125; NavigableMap是继承于SortedMap的接口。它是一个可导航的键-值对集合，具有了为给定搜索目标报告最接近匹配项的导航方法。NavigableMap分别提供了获取“键”、“键-值对”、“键集”、“键-值对集”的相关方法。 api123456789101112131415161718192021abstract Entry&lt;K, V&gt; ceilingEntry(K key)abstract Entry&lt;K, V&gt; firstEntry()abstract Entry&lt;K, V&gt; floorEntry(K key)abstract Entry&lt;K, V&gt; higherEntry(K key)abstract Entry&lt;K, V&gt; lastEntry()abstract Entry&lt;K, V&gt; lowerEntry(K key)abstract Entry&lt;K, V&gt; pollFirstEntry()abstract Entry&lt;K, V&gt; pollLastEntry()abstract K ceilingKey(K key)abstract K floorKey(K key)abstract K higherKey(K key)abstract K lowerKey(K key)abstract NavigableSet&lt;K&gt; descendingKeySet()abstract NavigableSet&lt;K&gt; navigableKeySet()abstract NavigableMap&lt;K, V&gt; descendingMap()abstract NavigableMap&lt;K, V&gt; headMap(K toKey, boolean inclusive)abstract SortedMap&lt;K, V&gt; headMap(K toKey)abstract SortedMap&lt;K, V&gt; subMap(K fromKey, K toKey)abstract NavigableMap&lt;K, V&gt; subMap(K fromKey, boolean fromInclusive, K toKey, boolean toInclusive)abstract SortedMap&lt;K, V&gt; tailMap(K fromKey)abstract NavigableMap&lt;K, V&gt; tailMap(K fromKey, boolean inclusive) NavigableMap除了继承SortedMap的特性外，它的提供的功能可以分为4类：第1类，提供操作键-值对的方法。lowerEntry、floorEntry、ceilingEntry 和 higherEntry 方法，它们分别返回与小于、小于等于、大于等于、大于给定键的键关联的 Map.Entry 对象。firstEntry、pollFirstEntry、lastEntry 和 pollLastEntry 方法，它们返回和/或移除最小和最大的映射关系（如果存在），否则返回 null。第2类，提供操作键的方法。这个和第1类比较类似lowerKey、floorKey、ceilingKey 和 higherKey 方法，它们分别返回与小于、小于等于、大于等于、大于给定键的键。第3类，获取键集。navigableKeySet、descendingKeySet分别获取正序/反序的键集。第4类，获取键-值对的子集。 Dictionary定义1public abstract class Dictionary&lt;K,V&gt; &#123;&#125; JDK 1.0定义的键值对的接口，它也包括了操作键值对的基本函数。 api1234567abstract Enumeration&lt;V&gt; elements()abstract V get(Object key)abstract boolean isEmpty()abstract Enumeration&lt;K&gt; keys()abstract V put(K key, V value)abstract V remove(Object key)abstract int","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"Java集合","slug":"Java集合","permalink":"https://htchz.cc/tags/Java集合/"}],"author":"土川"},{"title":"Java集合(六)List总结","slug":"Java集合-六-List总结","date":"2018-03-14T09:27:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"784197853.html","link":"","permalink":"https://htchz.cc/784197853.html","excerpt":"","text":"通过上面对ArrayList和LinkedList的分析，可以理解List的3个特性 是按顺序查找 允许存储项为空 允许多个存储项的值相等 然后对比LinkedList和ArrayList的实现方式不同，可以在不同的场景下使用不同的ListArrayList是由数组实现的，方便查找，返回数组下标对应的值即可，适用于多查找的场景LinkedList由链表实现，插入和删除方便，适用于多次数据替换的场景","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"Java集合","slug":"Java集合","permalink":"https://htchz.cc/tags/Java集合/"}],"author":"土川"},{"title":"Java集合(五)应该弃用的Vector和Stack","slug":"Java集合-五-应该弃用的Vector和Stack","date":"2018-03-13T08:59:00.000Z","updated":"2019-07-16T07:04:58.000Z","comments":true,"path":"2291640158.html","link":"","permalink":"https://htchz.cc/2291640158.html","excerpt":"这些古老的类性能太差","text":"这些古老的类性能太差 stack继承了vector 1public class Stack&lt;E&gt;extends Vector&lt;E&gt; 这两个都是jdk1.0的过时API,应该避免使用.因此不再对其源码进行解析学习.jdk1.5新增了很多多线程情况下使用的集合类.位于java.util.concurrent.如果你说,Vector是同步的,你要在多线程使用.那你应该使用java.util.concurrent.CopyOnWriteArrayList等而不是Vector.如果你要使用Stack做类似的业务.那么单线程的你可以选择linkedList,多线程情况你可以选择java.util.concurrent.ConcurrentLinkedDeque 或者java.util.concurrent.ConcurrentLinkedQueue多线程情况下,应尽量使用java.util.concurrent包下的类.","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"Java集合","slug":"Java集合","permalink":"https://htchz.cc/tags/Java集合/"}],"author":"土川"},{"title":"Java集合(四)LinkedList","slug":"Java集合-四-LinkedList","date":"2018-03-13T08:55:00.000Z","updated":"2019-07-16T10:04:02.000Z","comments":true,"path":"1699163374.html","link":"","permalink":"https://htchz.cc/1699163374.html","excerpt":"","text":"LinkedList介绍LinkedList 是一个继承于AbstractSequentialList的双向链表。它也可以被当作堆栈、队列或双端队列进行操作。LinkedList 实现 List 接口，能对它进行队列操作。LinkedList 实现 Deque 接口，即能将LinkedList当作双端队列使用。LinkedList 实现了Cloneable接口，即覆盖了函数clone()，能克隆。LinkedList 实现java.io.Serializable接口，这意味着LinkedList支持序列化，能通过序列化去传输。LinkedList 是非同步的。 123456789java.lang.Objectjava.util.AbstractCollection&lt;E&gt;java.util.AbstractList&lt;E&gt;java.util.AbstractSequentialList&lt;E&gt;java.util.LinkedList&lt;E&gt; public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable &#123;&#125; AbstractSequentialListLinkedList是AbstractSequentialList的子类。 AbstractSequentialList 实现了get(int index)、set(int index, E element)、add(int index, E element) 和 remove(int index)这些函数。这些接口都是随机访问List的，LinkedList是双向链表；既然它继承于AbstractSequentialList，就相当于已经实现了“get(int index)这些接口”。此外，我们若需要通过AbstractSequentialList自己实现一个列表，只需要扩展此类，并提供 listIterator() 和 size() 方法的实现即可。若要实现不可修改的列表，则需要实现列表迭代器的 hasNext、next、hasPrevious、previous 和 index 方法即可。 LinkedList源码解析数据结构12345678910private static class Node&lt;E&gt; &#123; E item; // 当前节点所包含的值 Node&lt;E&gt; next; //下一个节点 Node&lt;E&gt; prev; //上一个节点 Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125; &#125; 类结构123456789101112131415161718192021222324//通过LinkedList实现的接口可知，其支持队列操作，双向列表操作，能被克隆，支持序列化public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable&#123; // LinkedList的大小（指其所含的元素个数） transient int size = 0; /** * 指向第一个节点 * 不变的: (first == null &amp;&amp; last == null) || * (first.prev == null &amp;&amp; first.item != null) */ transient Node&lt;E&gt; first; /** * 指向最后一个节点 * 不变的: (first == null &amp;&amp; last == null) || * (last.next == null &amp;&amp; last.item != null) */ transient Node&lt;E&gt; last; ......&#125; LinkedList包含了三个重要的对象：first、last 和 size。(1) first 是双向链表的表头，它是双向链表节点所对应的类Node的实例(2) last 是双向链表的最后一个元素，它是双向链表节点所对应的类Node的实例(3) size 是双向链表中节点的个数。 构造函数1234567891011121314//构建一个空列表public LinkedList() &#123;&#125;/** * 构造一个包含指定collection的元素的列表，这些元素按照该collection的迭代器返回的顺序排列的 * @param c 包含用于去构造LinkedList的元素的collection * @throws NullPointerException 如果指定的collection为空 *///构建一个包含指定集合c的列表public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c);&#125; 添加元素LinkedList提供了头插入addFirst(E e)、尾插入addLast(E e)、add(E e)、addAll(Collection&lt;? extends E&gt; c)、addAll(int index, Collection&lt;? extends E&gt; c)、add(int index, E element)这些添加元素的方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127//头插入，在列表首部插入节点值epublic void addFirst(E e) &#123; linkFirst(e);&#125;//头插入，即将节点值为e的节点设置为链表首节点private void linkFirst(E e) &#123; final Node&lt;E&gt; f = first; //构建一个prev值为null,节点值为e,next值为f的新节点newNode final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f); //将newNode作为首节点 first = newNode; //如果原首节点为null，即原链表为null，则链表尾节点也设置为newNode if (f == null) last = newNode; else //否则，原首节点的prev设置为newNode f.prev = newNode; size++; modCount++;&#125;//尾插入，在列表尾部插入节点值e，该方法等价于add()public void addLast(E e) &#123; linkLast(e);&#125;//尾插入，在列表尾部插入节点值epublic boolean add(E e) &#123; linkLast(e); return true;&#125; //尾插入，即将节点值为e的节点设置为链表的尾节点void linkLast(E e) &#123; final Node&lt;E&gt; l = last; //构建一个prev值为l,节点值为e,next值为null的新节点newNode final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); //将newNode作为尾节点 last = newNode; //如果原尾节点为null，即原链表为null，则链表首节点也设置为newNode if (l == null) first = newNode; else //否则，原尾节点的next设置为newNode l.next = newNode; size++; modCount++;&#125;//中间插入，在非空节点succ之前插入节点值evoid linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; final Node&lt;E&gt; pred = succ.prev; //构建一个prev值为succ.prev,节点值为e,next值为succ的新节点newNode final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); //设置newNode为succ的前节点 succ.prev = newNode; //如果succ.prev为null，即如果succ为首节点，则将newNode设置为首节点 if (pred == null) first = newNode; else //如果succ不是首节点 pred.next = newNode; size++; modCount++;&#125;/** * 按照指定collection的迭代器所返回的元素顺序，将该collection中的所有元素添加到此链表的尾部 * 如果指定的集合添加到链表的尾部的过程中，集合被修改，则该插入过程的后果是不确定的。 * 一般这种情况发生在指定的集合为该链表的一部分，且其非空。 * @throws NullPointerException 指定集合为null */public boolean addAll(Collection&lt;? extends E&gt; c) &#123; return addAll(size, c);&#125;//从指定的位置开始，将指定collection中的所有元素插入到此链表中，新元素的顺序为指定collection的迭代器所返回的元素顺序public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; checkPositionIndex(index); //index &gt;= 0 &amp;&amp; index &lt;= size Object[] a = c.toArray(); int numNew = a.length; if (numNew == 0) return false; Node&lt;E&gt; pred, succ; //succ指向当前需要插入节点的位置，pred指向其前一个节点 if (index == size) &#123; //说明在列表尾部插入集合元素 succ = null; pred = last; &#125; else &#123; succ = node(index); //得到索引index所对应的节点 pred = succ.prev; &#125; //指定collection中的所有元素依次插入到此链表中指定位置的过程 for (Object o : a) &#123; @SuppressWarnings(\"unchecked\") E e = (E) o; //将元素值e，前继节点pred“封装”为一个新节点newNode Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null); if (pred == null) //如果原链表为null，则新插入的节点作为链表首节点 first = newNode; else pred.next = newNode; pred = newNode; //pred指针向后移动，指向下一个需插入节点位置的前一个节点 &#125; //集合元素插入完成后，与原链表index位置后面的子链表链接起来 if (succ == null) &#123; //说明之前是在列表尾部插入的集合元素 last = pred; //pred指向的是最后插入的那个节点 &#125; else &#123; pred.next = succ; succ.prev = pred; &#125; size += numNew; modCount++; return true;&#125;//将指定的元素(E element)插入到列表的指定位置(index)public void add(int index, E element) &#123; checkPositionIndex(index); //index &gt;= 0 &amp;&amp; index &lt;= size if (index == size) linkLast(element); //尾插入 else linkBefore(element, node(index)); //中间插入&#125; 删除元素123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121//移除首节点，并返回该节点的元素值public E removeFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return unlinkFirst(f);&#125;//删除非空的首节点fprivate E unlinkFirst(Node&lt;E&gt; f) &#123; // assert f == first &amp;&amp; f != null; final E element = f.item; final Node&lt;E&gt; next = f.next; f.item = null; f.next = null; // help GC first = next; //将原首节点的next节点设置为首节点 if (next == null) //如果原链表只有一个节点，即原首节点，删除后，链表为null last = null; else next.prev = null; size--; modCount++; return element;&#125;//移除尾节点，并返回该节点的元素值public E removeLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return unlinkLast(l);&#125;//删除非空的尾节点lprivate E unlinkLast(Node&lt;E&gt; l) &#123; // assert l == last &amp;&amp; l != null; final E element = l.item; final Node&lt;E&gt; prev = l.prev; l.item = null; l.prev = null; // help GC last = prev; //将原尾节点的prev节点设置为尾节点 if (prev == null) //如果原链表只有一个节点,则删除后，链表为null first = null; else prev.next = null; size--; modCount++; return element;&#125;//移除此列表中指定位置上的元素public E remove(int index) &#123; checkElementIndex(index); //index &gt;= 0 &amp;&amp; index &lt; size return unlink(node(index));&#125;//删除非空节点xE unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; if (prev == null) &#123; //如果被删除节点为头节点 first = next; &#125; else &#123; prev.next = next; x.prev = null; &#125; if (next == null) &#123; //如果被删除节点为尾节点 last = prev; &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; // help GC size--; modCount++; return element;&#125;//移除列表中首次出现的指定元素(如果存在)，LinkedList中允许存放重复的元素public boolean remove(Object o) &#123; //由于LinkedList中允许存放null，因此下面通过两种情况来分别处理 if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; //顺序访问 if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false;&#125;//清除列表中所有节点public void clear() &#123; // Clearing all of the links between nodes is \"unnecessary\", but: // - helps a generational GC if the discarded nodes inhabit // more than one generation // - is sure to free memory even if there is a reachable Iterator for (Node&lt;E&gt; x = first; x != null; ) &#123; Node&lt;E&gt; next = x.next; x.item = null; x.next = null; x.prev = null; x = next; &#125; first = last = null; size = 0; modCount++;&#125; 修改元素12345678//替换指定索引位置节点的元素值，并返回旧值public E set(int index, E element) &#123; checkElementIndex(index); //index &gt;= 0 &amp;&amp; index &lt; size Node&lt;E&gt; x = node(index); E oldVal = x.item; x.item = element; return oldVal;&#125; 查找元素1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283//返回列表首节点元素值public E getFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) //如果首节点为null throw new NoSuchElementException(); return f.item;&#125;//返回列表尾节点元素值public E getLast() &#123; final Node&lt;E&gt; l = last; if (l == null) //如果尾节点为null throw new NoSuchElementException(); return l.item;&#125;//判断列表中是否包含有元素值o，返回true当列表中至少存在一个元素值e，使得(o==null?e==null:o.equals(e))public boolean contains(Object o) &#123; return indexOf(o) != -1;&#125;//返回指定索引处的元素值public E get(int index) &#123; checkElementIndex(index); //index &gt;= 0 &amp;&amp; index &lt; size return node(index).item; //node(index)返回指定索引位置index处的节点&#125;//返回指定索引位置的节点Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); //折半思想，当index &lt; size/2时，从列表首节点向后查找 if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; //当index &gt;= size/2时，从列表尾节点向前查找 Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125;//正向查找，返回LinkedList中元素值Object o第一次出现的位置，如果元素不存在，则返回-1public int indexOf(Object o) &#123; int index = 0; //由于LinkedList中允许存放null，因此下面通过两种情况来分别处理 if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; //顺序向后 if (x.item == null) return index; index++; &#125; &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) return index; index++; &#125; &#125; return -1;&#125;//逆向查找，返回LinkedList中元素值Object o最后一次出现的位置，如果元素不存在，则返回-1public int lastIndexOf(Object o) &#123; int index = size; //由于LinkedList中允许存放null，因此下面通过两种情况来分别处理 if (o == null) &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; //逆向向前 index--; if (x.item == null) return index; &#125; &#125; else &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; index--; if (o.equals(x.item)) return index; &#125; &#125; return -1;&#125; 随机访问如果大于二分之一size，就从逆序查找，否则正序查找 12345678910111213141516//返回指定索引位置的节点Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); //折半思想，当index &lt; size/2时，从列表首节点向后查找 if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; //当index &gt;= size/2时，从列表尾节点向前查找 Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; 其他public方法clone()、toArray()、toArray(T[] a) 123456789101112131415161718192021222324252627282930313233343536373839404142//返回此 LinkedList实例的浅拷贝public Object clone() &#123; LinkedList&lt;E&gt; clone = superClone(); // Put clone into \"virgin\" state clone.first = clone.last = null; clone.size = 0; clone.modCount = 0; // Initialize clone with our elements for (Node&lt;E&gt; x = first; x != null; x = x.next) clone.add(x.item); return clone;&#125;//返回一个包含LinkedList中所有元素值的数组public Object[] toArray() &#123; Object[] result = new Object[size]; int i = 0; for (Node&lt;E&gt; x = first; x != null; x = x.next) result[i++] = x.item; return result;&#125;//如果给定的参数数组长度足够，则将ArrayList中所有元素按序存放于参数数组中，并返回//如果给定的参数数组长度小于LinkedList的长度，则返回一个新分配的、长度等于LinkedList长度的、包含LinkedList中所有元素的新数组@SuppressWarnings(\"unchecked\")public &lt;T&gt; T[] toArray(T[] a) &#123; if (a.length &lt; size) a = (T[])java.lang.reflect.Array.newInstance( a.getClass().getComponentType(), size); int i = 0; Object[] result = a; for (Node&lt;E&gt; x = first; x != null; x = x.next) result[i++] = x.item; if (a.length &gt; size) a[size] = null; return a;&#125; 支持序列化的写入函数writeObject(java.io.ObjectOutputStream s)和读取函数readObject(java.io.ObjectInputStream s) 123456789101112131415161718192021222324252627282930private static final long serialVersionUID = 876323262645176354L;//序列化：将linkedList的“大小，所有的元素值”都写入到输出流中private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException &#123; // Write out any hidden serialization magic s.defaultWriteObject(); // Write out size s.writeInt(size); // Write out all elements in the proper order. for (Node&lt;E&gt; x = first; x != null; x = x.next) s.writeObject(x.item);&#125;//反序列化：先将LinkedList的“大小”读出，然后将“所有的元素值”读出@SuppressWarnings(\"unchecked\")private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; // Read in any hidden serialization magic s.defaultReadObject(); // Read in size int size = s.readInt(); // Read in all elements in the proper order. for (int i = 0; i &lt; size; i++) linkLast((E)s.readObject()); //以尾插入的方式&#125; Queue操作Queue操作提供了peek()、element()、poll()、remove()、offer(E e)这些方法。 1234567891011121314151617181920212223242526//获取但不移除此队列的头；如果此队列为空，则返回 nullpublic E peek() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : f.item;&#125;//获取但不移除此队列的头；如果此队列为空，则抛出NoSuchElementException异常public E element() &#123; return getFirst();&#125;//获取并移除此队列的头，如果此队列为空，则返回 nullpublic E poll() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : unlinkFirst(f);&#125;//获取并移除此队列的头，如果此队列为空，则抛出NoSuchElementException异常public E remove() &#123; return removeFirst();&#125;//将指定的元素值(E e)插入此列表末尾public boolean offer(E e) &#123; return add(e);&#125; Deque（双端队列）操作Deque操作提供了offerFirst(E e)、offerLast(E e)、peekFirst()、peekLast()、pollFirst()、pollLast()、push(E e)、pop()、removeFirstOccurrence(Object o)、removeLastOccurrence(Object o)这些方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100//获取但不移除此队列的头；如果此队列为空，则返回 nullpublic E peek() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : f.item;&#125;//获取但不移除此队列的头；如果此队列为空，则抛出NoSuchElementException异常public E element() &#123; return getFirst();&#125;//获取并移除此队列的头，如果此队列为空，则返回 nullpublic E poll() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : unlinkFirst(f);&#125;//获取并移除此队列的头，如果此队列为空，则抛出NoSuchElementException异常public E remove() &#123; return removeFirst();&#125;//将指定的元素值(E e)插入此列表末尾public boolean offer(E e) &#123; return add(e);&#125;// Deque operations//将指定的元素插入此双端队列的开头public boolean offerFirst(E e) &#123; addFirst(e); return true;&#125;//将指定的元素插入此双端队列的末尾public boolean offerLast(E e) &#123; addLast(e); return true;&#125;//获取，但不移除此双端队列的第一个元素；如果此双端队列为空，则返回 nullpublic E peekFirst() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : f.item; &#125;//获取，但不移除此双端队列的最后一个元素；如果此双端队列为空，则返回 nullpublic E peekLast() &#123; final Node&lt;E&gt; l = last; return (l == null) ? null : l.item;&#125;//获取并移除此双端队列的第一个元素；如果此双端队列为空，则返回 nullpublic E pollFirst() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : unlinkFirst(f);&#125;//获取并移除此双端队列的最后一个元素；如果此双端队列为空，则返回 nullpublic E pollLast() &#123; final Node&lt;E&gt; l = last; return (l == null) ? null : unlinkLast(l);&#125;//将一个元素推入此双端队列所表示的堆栈（换句话说，此双端队列的头部）public void push(E e) &#123; addFirst(e);&#125;//从此双端队列所表示的堆栈中弹出一个元素（换句话说，移除并返回此双端队列的头部）public E pop() &#123; return removeFirst();&#125;//从此双端队列移除第一次出现的指定元素，如果列表中不包含次元素，则没有任何改变public boolean removeFirstOccurrence(Object o) &#123; return remove(o);&#125;//从此双端队列移除最后一次出现的指定元素,如果列表中不包含次元素，则没有任何改变public boolean removeLastOccurrence(Object o) &#123; //由于LinkedList中允许存放null，因此下面通过两种情况来分别处理 if (o == null) &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; //逆向向前 if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false;&#125; 常用的遍历方式 LinkedList不提倡运用随机访问的方式进行元素遍历。通过迭代器Iterator遍历 12345Iterator iter = list.iterator();while (iter.hasNext())&#123; System.out.println(iter.next());&#125; 通过迭代器ListIterator遍历 123456789 ListIterator&lt;String&gt; lIter = list.listIterator(); //顺向遍历 while(lIter.hasNext())&#123; System.out.println(lIter.next()); &#125; //逆向遍历 while(lIter.hasPrevious())&#123; System.out.println(lIter.previous()); &#125; foreach循环遍历 1234for(String str:list) &#123; System.out.println(str); &#125;","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"Java集合","slug":"Java集合","permalink":"https://htchz.cc/tags/Java集合/"}],"author":"土川"},{"title":"Java集合(三)Iterator的fail-fast机制了解一下","slug":"Java集合-三-Iterator的fail-fast机制了解分析","date":"2018-03-13T08:53:00.000Z","updated":"2019-07-16T10:05:07.000Z","comments":true,"path":"983000280.html","link":"","permalink":"https://htchz.cc/983000280.html","excerpt":"","text":"fail-fast简介fail-fast 机制是java集合(Collection)中的一种错误机制。当多个线程对同一个集合的内容进行操作时，就可能会产生fail-fast事件。例如：当某一个线程A通过iterator去遍历某集合的过程中，若该集合的内容被其他线程所改变了；那么线程A访问集合时，就会抛出ConcurrentModificationException异常，产生fail-fast事件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package java.util; public abstract class AbstractList&lt;E&gt; extends AbstractCollection&lt;E&gt; implements List&lt;E&gt; &#123; ... // AbstractList中唯一的属性 // 用来记录List修改的次数：每修改一次(添加/删除等操作)，将modCount+1 protected transient int modCount = 0; // 返回List对应迭代器。实际上，是返回Itr对象。 public Iterator&lt;E&gt; iterator() &#123; return new Itr(); &#125; // Itr是Iterator(迭代器)的实现类 private class Itr implements Iterator&lt;E&gt; &#123; int cursor = 0; int lastRet = -1; // 修改数的记录值。 // 每次新建Itr()对象时，都会保存新建该对象时对应的modCount； // 以后每次遍历List中的元素的时候，都会比较expectedModCount和modCount是否相等； // 若不相等，则抛出ConcurrentModificationException异常，产生fail-fast事件。 int expectedModCount = modCount; public boolean hasNext() &#123; return cursor != size(); &#125; public E next() &#123; // 获取下一个元素之前，都会判断“新建Itr对象时保存的modCount”和“当前的modCount”是否相等； // 若不相等，则抛出ConcurrentModificationException异常，产生fail-fast事件。 checkForComodification(); try &#123; E next = get(cursor); lastRet = cursor++; return next; &#125; catch (IndexOutOfBoundsException e) &#123; checkForComodification(); throw new NoSuchElementException(); &#125; &#125; public void remove() &#123; if (lastRet == -1) throw new IllegalStateException(); checkForComodification(); try &#123; AbstractList.this.remove(lastRet); if (lastRet &lt; cursor) cursor--; lastRet = -1; expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException e) &#123; throw new ConcurrentModificationException(); &#125; &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125; &#125; ...&#125; 在调用 next() 和 remove()时，都会执行 checkForComodification()。若 “modCount 不等于 expectedModCount”，则抛出ConcurrentModificationException异常，产生fail-fast事件。 无论是add()、remove()，还是clear()，只要涉及到修改集合中的元素个数时，都会改变modCount的值。 解决fail-fast的原理上面，说明了“解决fail-fast机制的办法”，也知道了“fail-fast产生的根本原因”。接下来，我们再进一步谈谈java.util.concurrent包中是如何解决fail-fast事件的。还是以和ArrayList对应的CopyOnWriteArrayList进行说明。我们先看看CopyOnWriteArrayList的源码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273package java.util.concurrent;import java.util.*;import java.util.concurrent.locks.*;import sun.misc.Unsafe; public class CopyOnWriteArrayList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable &#123; ... // 返回集合对应的迭代器 public Iterator&lt;E&gt; iterator() &#123; return new COWIterator&lt;E&gt;(getArray(), 0); &#125; ... private static class COWIterator&lt;E&gt; implements ListIterator&lt;E&gt; &#123; private final Object[] snapshot; private int cursor; private COWIterator(Object[] elements, int initialCursor) &#123; cursor = initialCursor; // 新建COWIterator时，将集合中的元素保存到一个新的拷贝数组中。 // 这样，当原始集合的数据改变，拷贝数据中的值也不会变化。 snapshot = elements; &#125; public boolean hasNext() &#123; return cursor &lt; snapshot.length; &#125; public boolean hasPrevious() &#123; return cursor &gt; 0; &#125; public E next() &#123; if (! hasNext()) throw new NoSuchElementException(); return (E) snapshot[cursor++]; &#125; public E previous() &#123; if (! hasPrevious()) throw new NoSuchElementException(); return (E) snapshot[--cursor]; &#125; public int nextIndex() &#123; return cursor; &#125; public int previousIndex() &#123; return cursor-1; &#125; public void remove() &#123; throw new UnsupportedOperationException(); &#125; public void set(E e) &#123; throw new UnsupportedOperationException(); &#125; public void add(E e) &#123; throw new UnsupportedOperationException(); &#125; &#125; ... &#125; 和ArrayList继承于AbstractList不同，CopyOnWriteArrayList没有继承于AbstractList，它仅仅只是实现了List接口。 ArrayList的iterator()函数返回的Iterator是在AbstractList中实现的；而CopyOnWriteArrayList是自己实现Iterator。 ArrayList的Iterator实现类中调用next()时，会“调用checkForComodification()比较‘expectedModCount’和‘modCount’的大小”；但是，CopyOnWriteArrayList的Iterator实现类中，没有所谓的checkForComodification()，更不会抛出ConcurrentModificationException异常！","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"Java集合","slug":"Java集合","permalink":"https://htchz.cc/tags/Java集合/"}],"author":"土川"},{"title":"Java集合(二)ArrayList","slug":"Java集合-二-ArrayList","date":"2018-03-13T08:51:00.000Z","updated":"2019-07-16T10:19:42.000Z","comments":true,"path":"544394887.html","link":"","permalink":"https://htchz.cc/544394887.html","excerpt":"","text":"ArrayList介绍ArrayList 是一个数组队列，相当于 动态数组。与Java中的数组相比，它的容量能动态增长。它继承于AbstractList，实现了List, RandomAccess, Cloneable, java.io.Serializable这些接口。ArrayList 继承了AbstractList，实现了List。它是一个数组队列，提供了相关的添加、删除、修改、遍历等功能。ArrayList 实现了RandmoAccess接口，即提供了随机访问功能。RandmoAccess是java中用来被List实现，为List提供快速访问功能的。在ArrayList中，我们即可以通过元素的序号快速获取元素对象；这就是快速随机访问。稍后，我们会比较List的“快速随机访问”和“通过Iterator迭代器访问”的效率。ArrayList 实现了Cloneable接口，即覆盖了函数clone()，能被克隆。ArrayList 实现java.io.Serializable接口，这意味着ArrayList支持序列化，能通过序列化去传输。和Vector不同，ArrayList中的操作不是线程安全的。所以，建议在单线程中才使用ArrayList，而在多线程中可以选择Vector或者CopyOnWriteArrayList。 ArrayList的继承关系 12public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt;implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable &#123;&#125; ArrayList构造函数 123456789// 默认构造函数ArrayList() // capacity是ArrayList的默认容量大小。当由于增加数据导致容量不足时，容量会添加上一次容量大小的一半。// 也就是说，扩容时差不多扩容1.5倍ArrayList(int capacity) // 创建一个包含collection的ArrayListArrayList(Collection&lt;? extends E&gt; collection) ArrayList的API 1234567891011121314151617181920212223242526272829303132// Collection中定义的APIboolean add(E object)boolean addAll(Collection&lt;? extends E&gt; collection)void clear()boolean contains(Object object)boolean containsAll(Collection&lt;?&gt; collection)boolean equals(Object object)int hashCode()boolean isEmpty()Iterator&lt;E&gt; iterator()boolean remove(Object object)boolean removeAll(Collection&lt;?&gt; collection)boolean retainAll(Collection&lt;?&gt; collection)int size()&lt;T&gt; T[] toArray(T[] array)Object[] toArray()// AbstractCollection中定义的APIvoid add(int location, E object)boolean addAll(int location, Collection&lt;? extends E&gt; collection)E get(int location)int indexOf(Object object)int lastIndexOf(Object object)ListIterator&lt;E&gt; listIterator(int location)ListIterator&lt;E&gt; listIterator()E remove(int location)E set(int location, E object)List&lt;E&gt; subList(int start, int end)// ArrayList新增的APIObject clone()void ensureCapacity(int minimumCapacity)void trimToSize()void removeRange(int fromIndex, int toIndex) ArrayList源码解析ArrayList是通过数组实现的 默认大小为10 ArrayList的克隆函数，即是将全部元素克隆到一个数组中。 ArrayList实现java.io.Serializable的方式。当写入到输出流时，先写入“容量”，再依次写入“每一个元素”；当读出输入流时，先读取“容量”，再依次读取“每一个元素”。 当ArrayList容量不足以容纳全部元素时，ArrayList会重新设置容量：新的容量=oldCapacity + (oldCapacity &gt;&gt; 1) = 1.5倍oldCapacity 遍历ArrayList时，使用随机访问(即，通过索引序号访问)效率最高，而使用迭代器的效率最低！","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"Java集合","slug":"Java集合","permalink":"https://htchz.cc/tags/Java集合/"}],"author":"土川"},{"title":"Java集合(一)总体框架介绍","slug":"Java集合-一-总体框架介绍","date":"2018-03-13T08:47:00.000Z","updated":"2019-07-16T10:07:45.000Z","comments":true,"path":"3605321898.html","link":"","permalink":"https://htchz.cc/3605321898.html","excerpt":"","text":"概要 Collection是一个接口，是高度抽象出来的集合，它包含了集合的基本操作和属性Collection包含了List和Set两大分支。 list接口 List是一个有序的队列，每一个元素都有它的索引。第一个元素的索引值是0。List的实现类有LinkedList, ArrayList, Vector, Stack。 set接口 Set是一个不允许有重复元素的集合。Set的实现类有HastSet和TreeSet。HashSet依赖于HashMap，它实际上是通过HashMap实现的；TreeSet依赖于TreeMap，它实际上是通过TreeMap实现的。 Map是一个映射接口，即key-value键值对 AbstractMap是个抽象类，它实现了Map接口中的大部分API。而HashMap，TreeMap，WeakHashMap都是继承于AbstractMap。Hashtable虽然继承于Dictionary接口，但它实现了Map接口。 Iterator 遍历集合的工具，即我们通常通过Iterator迭代器来遍历集合。我们说Collection依赖于Iterator，是因为Collection的实现类都要实现iterator()函数，返回一个Iterator对象。ListIterator是专门为遍历List而存在的。 Enumeration JDK 1.0引入的抽象类。作用和Iterator一样，也是遍历集合；但是Enumeration的功能要比Iterator少。在上面的框图中，Enumeration只能在Hashtable, Vector, Stack中使用。 Arrays和Collections 操作数组、集合的两个工具类 说明Collection是一个接口，它主要的两个分支是：List 和 Set。 List和Set都是接口，它们继承于Collection。List是有序的队列，List中可以有重复的元素；而Set是数学概念中的集合，Set中没有重复元素！ 我们抽象出了AbstractCollection抽象类，它实现了Collection中的绝大部分函数；在Collection的实现类中，我们就可以通过继承AbstractCollection省去重复编码。 AbstractList和AbstractSet都继承于AbstractCollection，具体的List实现类继承于AbstractList，而Set的实现类则继承于AbstractSet。 另外，Collection中有一个iterator()函数，它的作用是返回一个Iterator接口。通常，我们通过Iterator迭代器来遍历集合。ListIterator是List接口所特有的，在List接口中，通过ListIterator()返回一个ListIterator对象。 详细介绍Collection定义如下： public interface Collection&lt;E&gt; extends Iterable&lt;E&gt; {}包括添加、删除、清空、遍历(读取)、是否为空、获取大小、是否保护某元素等等。 Collection接口的所有子类(直接子类和间接子类)都必须实现2种构造函数：不带参数的构造函数 和 参数为Collection的构造函数。带参数的构造函数，可以用来转换Collection的类型。 12345678910111213141516// Collection的APIabstract boolean add(E object)abstract boolean addAll(Collection&lt;? extends E&gt; collection)abstract void clear()abstract boolean contains(Object object)abstract boolean containsAll(Collection&lt;?&gt; collection)abstract boolean equals(Object object)abstract int hashCode()abstract boolean isEmpty()abstract Iterator&lt;E&gt; iterator()abstract boolean remove(Object object)abstract boolean removeAll(Collection&lt;?&gt; collection)abstract boolean retainAll(Collection&lt;?&gt; collection)abstract int size()abstract &lt;T&gt; T[] toArray(T[] array)abstract Object[] toArray() list定义如下： public interface List&lt;E&gt; extends Collection&lt;E&gt; {}List是一个继承于Collection的接口，即List是集合中的一种。List是有序的队列，List中的每一个元素都有一个索引；第一个元素的索引值是0，往后的元素的索引值依次+1。和Set不同，List中允许有重复的元素。 关于API方面。既然List是继承于Collection接口，它自然就包含了Collection中的全部函数接口；由于List是有序队列，它也额外的有自己的API接口。主要有“添加、删除、获取、修改指定位置的元素”、“获取List中的子队列”等。 123456789101112131415161718192021222324252627// Collection的APIabstract boolean add(E object)abstract boolean addAll(Collection&lt;? extends E&gt; collection)abstract void clear()abstract boolean contains(Object object)abstract boolean containsAll(Collection&lt;?&gt; collection)abstract boolean equals(Object object)abstract int hashCode()abstract boolean isEmpty()abstract Iterator&lt;E&gt; iterator()abstract boolean remove(Object object)abstract boolean removeAll(Collection&lt;?&gt; collection)abstract boolean retainAll(Collection&lt;?&gt; collection)abstract int size()abstract &lt;T&gt; T[] toArray(T[] array)abstract Object[] toArray()// 相比与Collection，List新增的API：abstract void add(int location, E object)abstract boolean addAll(int location, Collection&lt;? extends E&gt; collection)abstract E get(int location)abstract int indexOf(Object object)abstract int lastIndexOf(Object object)abstract ListIterator&lt;E&gt; listIterator(int location)abstract ListIterator&lt;E&gt; listIterator()abstract E remove(int location)abstract E set(int location, E object)abstract List&lt;E&gt; subList(int start, int end) set定义如下 public interface Set&lt;E&gt; extends Collection&lt;E&gt; {}Set是一个继承于Collection的接口，即Set也是集合中的一种。Set是没有重复元素的集合。 关于API方面。Set的API和Collection完全一样。 12345678910111213141516// Set的APIabstract boolean add(E object)abstract boolean addAll(Collection&lt;? extends E&gt; collection)abstract void clear()abstract boolean contains(Object object)abstract boolean containsAll(Collection&lt;?&gt; collection)abstract boolean equals(Object object)abstract int hashCode()abstract boolean isEmpty()abstract Iterator&lt;E&gt; iterator()abstract boolean remove(Object object)abstract boolean removeAll(Collection&lt;?&gt; collection)abstract boolean retainAll(Collection&lt;?&gt; collection)abstract int size()abstract &lt;T&gt; T[] toArray(T[] array)abstract Object[] toArray() AbstractCollection1public abstract class AbstractCollection&lt;E&gt; implements Collection&lt;E&gt; &#123;&#125; AbstractCollection是一个抽象类，它实现了Collection中除iterator()和size()之外的函数。AbstractCollection的主要作用：它实现了Collection接口中的大部分函数。从而方便其它类实现Collection，比如ArrayList、LinkedList等，它们这些类想要实现Collection接口，通过继承AbstractCollection就已经实现了大部分的接口了。 AbstractList1public abstract class AbstractList&lt;E&gt; extends AbstractCollection&lt;E&gt; implements List&lt;E&gt; &#123;&#125; AbstractList是一个继承于AbstractCollection，并且实现List接口的抽象类。它实现了List中除size()、get(int location)之外的函数。AbstractList的主要作用：它实现了List接口中的大部分函数。从而方便其它类继承List。另外，和AbstractCollection相比，AbstractList抽象类中，实现了iterator()接口。 AbstractSet1public abstract class AbstractSet&lt;E&gt; extends AbstractCollection&lt;E&gt; implements Set&lt;E&gt; &#123;&#125; AbstractSet是一个继承于AbstractCollection，并且实现Set接口的抽象类。由于Set接口和Collection接口中的API完全一样，Set也就没有自己单独的API。和AbstractCollection一样，它实现了List中除iterator()和size()之外的函数。AbstractSet的主要作用：它实现了Set接口中的大部分函数。从而方便其它类实现Set接口。 Iterator1public interface Iterator&lt;E&gt; &#123;&#125; Iterator是一个接口，它是集合的迭代器。集合可以通过Iterator去遍历集合中的元素。Iterator提供的API接口，包括：是否存在下一个元素、获取下一个元素、删除当前元素。注意：Iterator遍历Collection时，是fail-fast机制的。即，当某一个线程A通过iterator去遍历某集合的过程中，若该集合的内容被其他线程所改变了；那么线程A访问集合时，就会抛出ConcurrentModificationException异常，产生fail-fast事件。关于fail-fast的详细内容，我们会在后面专门进行说明。 1234// Iterator的APIabstract boolean hasNext()abstract E next()abstract void remove() ListIterator1public interface ListIterator&lt;E&gt; extends Iterator&lt;E&gt; &#123;&#125; ListIterator是一个继承于Iterator的接口，它是队列迭代器。专门用于便利List，能提供向前/向后遍历。相比于Iterator，它新增了添加、是否存在上一个元素、获取上一个元素等等API接口。 123456789101112// ListIterator的API// 继承于Iterator的接口abstract boolean hasNext()abstract E next()abstract void remove()// 新增API接口abstract void add(E object)abstract boolean hasPrevious()abstract int nextIndex()abstract E previous()abstract int previousIndex()abstract void set(E object)","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"Java集合","slug":"Java集合","permalink":"https://htchz.cc/tags/Java集合/"}],"author":"土川"},{"title":"[Java基础]Integer与int","slug":"ava基础-Integer与int","date":"2018-03-13T02:27:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"1834665960.html","link":"","permalink":"https://htchz.cc/1834665960.html","excerpt":"贴代码:","text":"贴代码: 1234567891011121314151617181920public static void main(String[] args) &#123; int i = 128; Integer i2 = 128; Integer i3 = new Integer(128); //Integer会自动拆箱为int，所以为true System.out.println(i == i2); System.out.println(i == i3); System.out.println(&quot;**************&quot;); Integer i5 = 127;//java在编译的时候,被翻译成-&gt; Integer i5 = Integer.valueOf(127); Integer i6 = 127; System.out.println(i5 == i6);//true /*Integer i5 = 128; Integer i6 = 128; System.out.println(i5 == i6);//false*/ Integer ii5 = new Integer(127); System.out.println(i5 == ii5); //false Integer i7 = new Integer(128); Integer i8 = new Integer(123); System.out.println(i7 == i8); //false&#125; 11 行为true，16行为false，是因为： java在编译Integer i5 = 127的时候,被翻译成-&gt; Integer i5 = Integer.valueOf(127);所以关键就是看valueOf()函数了。只要看看valueOf()函数的源码就会明白了。JDK源码的valueOf函数式这样的： 123456public static Integer valueOf(int i) &#123; assert IntegerCache.high &gt;= 127; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);&#125; 总结 无论如何，Integer与new Integer不会相等。不会经历拆箱过程，i3的引用指向堆，而i4指向专门存放他的内存（常量池），他们的内存地址不一样，所以为false 两个都是非new出来的Integer，如果数在-128到127之间，则是true,否则为false（Integer的缓存）java在编译Integer i2 = 128的时候,被翻译成-&gt; Integer i2 = Integer.valueOf(128);而valueOf()函数会对-128到127之间的数进行缓存 两个都是new出来的,都为false int和integer(无论new否)比，都为true，因为会把Integer自动拆箱为int再去比","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[],"author":"土川"},{"title":"[Java基础]LongAdder","slug":"Java基础-LongAdder","date":"2018-03-13T02:07:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"973885938.html","link":"","permalink":"https://htchz.cc/973885938.html","excerpt":"","text":"LongAdder是jdk8新增的用于并发环境的计数器，目的是为了在高并发情况下，代替AtomicLong/AtomicInt，成为一个用于高并发情况下的高效的通用计数器。高并发下计数，一般最先想到的应该是AtomicLong/AtomicInt，AtmoicXXX使用硬件级别的指令 CAS 来更新计数器的值，这样可以避免加锁，机器直接支持的指令，效率也很高。但是AtomicXXX中的 CAS 操作在出现线程竞争时，失败的线程会白白地循环一次，在并发很大的情况下，因为每次CAS都只有一个线程能成功，竞争失败的线程会非常多。失败次数越多，循环次数就越多，很多线程的CAS操作越来越接近 自旋锁（spin lock）。计数操作本来是一个很简单的操作，实际需要耗费的cpu时间应该是越少越好，AtomicXXX在高并发计数时，大量的cpu时间都浪费会在 自旋 上了，这很浪费，也降低了实际的计数效率。 12345678910// jdk1.8的AtomicLong的实现代码，这段代码在sun.misc.Unsafe中 // 当线程竞争很激烈时，while判断条件中的CAS会连续多次返回false，这样就会造成无用的循环，循环中读取volatile变量的开销本来就是比较高的 // 因为这样，在高并发时，AtomicXXX并不是那么理想的计数方式 public final long getAndAddLong(Object o, long offset, long delta) &#123; long v; do &#123; v = getLongVolatile(o, offset); &#125; while (!compareAndSwapLong(o, offset, v, v + delta)); return v; &#125; 现在，在处理高并发计数时，应该优先使用LongAdder，而不是继续使用AtomicLong。当然，线程竞争很低的情况下进行计数，使用Atomic还是更简单更直接，并且效率稍微高一些。其他情况，比如序号生成，这种情况下需要准确的数值，全局唯一的AtomicLong才是正确的选择，此时不应该使用LongAdder。 下面简要分析下LongAdder的源码，有了ConcurrentHashMap（LongAdder比较像1.6和1.7的，可以看下1.7的）的基础，这个类的源码看起来也不复杂。 一、类的关系 公共父类Striped64是实现中的核心，它实现一些核心操作，处理64位数据，很容易就能转化为其他基本类型，是个通用的类。二元算术运算累积，指的是你可以给它提供一个二元算术方式，这个类按照你提供的方式进行算术计算，并保存计算结果。二元运算中第一个操作数是累积器中某个计数单元当前的值，另外一个值是外部提供的。举几个例子：假设每次操作都需要把原来的数值加上某个值，那么二元运算为 (x, y) -&gt; x+y，这样累积器每次都会加上你提供的数字y，这跟LongAdder的功能基本上是一样的；假设每次操作都需要把原来的数值变为它的某个倍数，那么可以指定二元运算为 (x, y) -&gt; xy，累积器每次都会乘以你提供的数字y，y=2时就是通常所说的每次都翻一倍；假设每次操作都需要把原来的数值变成它的5倍，再加上3，再除以2，再减去4，再乘以你给定的数，最后还要加上6，那么二元运算为 (x, y) -&gt; ((x5+3)/2 - 4)y +6，累积器每次累积操作都会按照你说的做；……LongAccumulator是标准的实现类，LongAdder是特化的实现类，它的功能等价于LongAccumulator((x, y) -&gt; x+y, 0L)。它们的区别很简单，前者可以进行任何二元算术操作，后者只能进行加减两种算术操作。Double版本是Long版本的简单改装，相对Long版本，主要的变化就是用Double.longBitsToDouble 和Double.doubleToRawLongBits对底层的8字节数据进行long &lt;—&gt; double转换，存储的时候使用long型，计算的时候转化为double型。这是因为CAS是sun.misc.Unsafe中提供的操作，只对int、long、对象类型（引用或者指针）提供了这种操作，其他类型都需要转化为这三种类型才能进行CAS操作。这里的long型也可以认为是8字节的原始类型，因为把它视为long类型是无意义的。java中没有C语言中的 void 无类型（或者叫原始类型），只能用最接近的long类型来代替。 四个实现类的区别就上面这两句话，这里只讲LongAdder一个类。 二、核心实现Striped64四个类的核心实现都在Striped64中，这个类使用分段的思想，来尽量平摊并发压力。类似1.7及以前版本的ConcurrentHashMap.Segment，Striped64中使用了一个叫Cell的类，是一个普通的二元算术累积单元，线程也是通过hash取模操作映射到一个Cell上进行累积。为了加快取模运算效率，也把Cell数组的大小设置为2^n，同时大量使用Unsafe提供的底层操作。基本的实现桶1.7的ConcurrentHashMap非常像，而且更简单。 1、累积单元Cell看到这里我想了一个看似简单的问题：既然Cell这么简单，只有一个long型变量，为什么不直接用long value？首先声明下，Unsafe提供的操作很强大，也能对数组的元素进行volatile读写，同时数组计算某个元素的offset偏移量本身就很简单，因此volatile、cas这种站不住脚。这个问题是因为：（用对象封装，保证对象的引用改变时，能保证改变的value不会丢失） 1234567891011121314151617181920212223// 很简单的一个类，这个类可以看成是一个简化的AtomicLong // 通过cas操作来更新value的值 // @sun.misc.Contended是一个高端的注解，代表使用缓存行填来避免伪共享，可以自己网上搜下，这个我就不细说了 @sun.misc.Contended static final class Cell &#123; volatile long value; Cell(long x) &#123; value = x; &#125; final boolean cas(long cmp, long val) &#123; return UNSAFE.compareAndSwapLong(this, valueOffset, cmp, val); &#125; // Unsafe mechanics Unsafe相关的初始化 private static final sun.misc.Unsafe UNSAFE; private static final long valueOffset; static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; ak = Cell.class; valueOffset = UNSAFE.objectFieldOffset (ak.getDeclaredField(\"value\")); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125; &#125; 2、Striped64主体代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159abstract class Striped64 extends Number &#123; @sun.misc.Contended static final class Cell &#123; ... &#125; /** Number of CPUS, to place bound on table size */ static final int NCPU = Runtime.getRuntime().availableProcessors(); // cell数组，长度一样要是2^n，可以类比为jdk1.7的ConcurrentHashMap中的segments数组 transient volatile Cell[] cells; // 累积器的基本值，在两种情况下会使用： // 1、没有遇到并发的情况，直接使用base，速度更快； // 2、多线程并发初始化table数组时，必须要保证table数组只被初始化一次，因此只有一个线程能够竞争成功，这种情况下竞争失败的线程会尝试在base上进行一次累积操作 transient volatile long base; // 自旋标识，在对cells进行初始化，或者后续扩容时，需要通过CAS操作把此标识设置为1（busy，忙标识，相当于加锁），取消busy时可以直接使用cellsBusy = 0，相当于释放锁 transient volatile int cellsBusy; Striped64() &#123; &#125; // 使用CAS更新base的值 final boolean casBase(long cmp, long val) &#123; return UNSAFE.compareAndSwapLong(this, BASE, cmp, val); &#125; // 使用CAS将cells自旋标识更新为1 // 更新为0时可以不用CAS，直接使用cellsBusy就行 final boolean casCellsBusy() &#123; return UNSAFE.compareAndSwapInt(this, CELLSBUSY, 0, 1); &#125; // 下面这两个方法是ThreadLocalRandom中的方法，不过因为包访问关系，这里又重新写一遍 // probe翻译过来是探测/探测器/探针这些，不好理解，它是ThreadLocalRandom里面的一个属性， // 不过并不影响对Striped64的理解，这里可以把它理解为线程本身的hash值 static final int getProbe() &#123; return UNSAFE.getInt(Thread.currentThread(), PROBE); &#125; // 相当于rehash，重新算一遍线程的hash值 static final int advanceProbe(int probe) &#123; probe ^= probe &lt;&lt; 13; // xorshift probe ^= probe &gt;&gt;&gt; 17; probe ^= probe &lt;&lt; 5; UNSAFE.putInt(Thread.currentThread(), PROBE, probe); return probe; &#125; /** * 核心方法的实现，此方法建议在外部进行一次CAS操作（cell != null时尝试CAS更新base值，cells != null时，CAS更新hash值取模后对应的cell.value） * @param x the value 前面我说的二元运算中的第二个操作数，也就是外部提供的那个操作数 * @param fn the update function, or null for add (this convention avoids the need for an extra field or function in LongAdder). * 外部提供的二元算术操作，实例持有并且只能有一个，生命周期内保持不变，null代表LongAdder这种特殊但是最常用的情况，可以减少一次方法调用 * @param wasUncontended false if CAS failed before call 如果为false，表明调用者预先调用的一次CAS操作都失败了 */ final void longAccumulate(long x, LongBinaryOperator fn, boolean wasUncontended) &#123; int h; // 这个if相当于给线程生成一个非0的hash值 if ((h = getProbe()) == 0) &#123; ThreadLocalRandom.current(); // force initialization h = getProbe(); wasUncontended = true; &#125; boolean collide = false; // True if last slot nonempty 如果hash取模映射得到的Cell单元不是null，则为true，此值也可以看作是扩容意向，感觉这个更好理解 for (;;) &#123; Cell[] as; Cell a; int n; long v; if ((as = cells) != null &amp;&amp; (n = as.length) &gt; 0) &#123; // cells已经被初始化了 if ((a = as[(n - 1) &amp; h]) == null) &#123; // hash取模映射得到的Cell单元还为null（为null表示还没有被使用） if (cellsBusy == 0) &#123; // Try to attach new Cell 如果没有线程正在执行扩容 Cell r = new Cell(x); // Optimistically create 先创建新的累积单元 if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123; // 尝试加锁 boolean created = false; try &#123; // Recheck under lock 在有锁的情况下再检测一遍之前的判断 Cell[] rs; int m, j; if ((rs = cells) != null &amp;&amp; (m = rs.length) &gt; 0 &amp;&amp; rs[j = (m - 1) &amp; h] == null) &#123; // 考虑别的线程可能执行了扩容，这里重新赋值重新判断 rs[j] = r; // 对没有使用的Cell单元进行累积操作（第一次赋值相当于是累积上一个操作数，求和时再和base执行一次运算就得到实际的结果） created = true; &#125; &#125; finally &#123; cellsBusy = 0; 清空自旋标识，释放锁 &#125; if (created) // 如果原本为null的Cell单元是由自己进行第一次累积操作，那么任务已经完成了，所以可以退出循环 break; continue; // Slot is now non-empty 不是自己进行第一次累积操作，重头再来 &#125; &#125; collide = false; // 执行这一句是因为cells被加锁了，不能往下继续执行第一次的赋值操作（第一次累积），所以还不能考虑扩容 &#125; else if (!wasUncontended) // CAS already known to fail 前面一次CAS更新a.value（进行一次累积）的尝试已经失败了，说明已经发生了线程竞争 wasUncontended = true; // Continue after rehash 情况失败标识，后面去重新算一遍线程的hash值 else if (a.cas(v = a.value, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) // 尝试CAS更新a.value（进行一次累积） ------ 标记为分支A break; // 成功了就完成了累积任务，退出循环 else if (n &gt;= NCPU || cells != as) // cell数组已经是最大的了，或者中途发生了扩容操作。因为NCPU不一定是2^n，所以这里用 &gt;= collide = false; // At max size or stale 长度n是递增的，执行到了这个分支，说明n &gt;= NCPU会永远为true，下面两个else if就永远不会被执行了，也就永远不会再进行扩容 // CPU能够并行的CAS操作的最大数量是它的核心数（CAS在x86中对应的指令是cmpxchg，多核需要通过锁缓存来保证整体原子性），当n &gt;= NCPU时，再出现几个线程映射到同一个Cell导致CAS竞争的情况，那就真不关扩容的事了，完全是hash值的锅了 else if (!collide) // 映射到的Cell单元不是null，并且尝试对它进行累积时，CAS竞争失败了，这时候把扩容意向设置为true // 下一次循环如果还是跟这一次一样，说明竞争很严重，那么就真正扩容 collide = true; // 把扩容意向设置为true，只有这里才会给collide赋值为true，也只有执行了这一句，才可能执行后面一个else if进行扩容 else if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123; // 最后再考虑扩容，能到这一步说明竞争很激烈，尝试加锁进行扩容 ------ 标记为分支B try &#123; if (cells == as) &#123; // Expand table unless stale 检查下是否被别的线程扩容了（CAS更新锁标识，处理不了ABA问题，这里再检查一遍） Cell[] rs = new Cell[n &lt;&lt; 1]; // 执行2倍扩容 for (int i = 0; i &lt; n; ++i) rs[i] = as[i]; cells = rs; &#125; &#125; finally &#123; cellsBusy = 0; // 释放锁 &#125; collide = false; // 扩容意向为false continue; // Retry with expanded table 扩容后重头再来 &#125; h = advanceProbe(h); // 重新给线程生成一个hash值，降低hash冲突，减少映射到同一个Cell导致CAS竞争的情况 &#125; else if (cellsBusy == 0 &amp;&amp; cells == as &amp;&amp; casCellsBusy()) &#123; // cells没有被加锁，并且它没有被初始化，那么就尝试对它进行加锁，加锁成功进入这个else if boolean init = false; try &#123; // Initialize table if (cells == as) &#123; // CAS避免不了ABA问题，这里再检测一次，如果还是null，或者空数组，那么就执行初始化 Cell[] rs = new Cell[2]; // 初始化时只创建两个单元 rs[h &amp; 1] = new Cell(x); // 对其中一个单元进行累积操作，另一个不管，继续为null cells = rs; init = true; &#125; &#125; finally &#123; cellsBusy = 0; // 清空自旋标识，释放锁 &#125; if (init) // 如果某个原本为null的Cell单元是由自己进行第一次累积操作，那么任务已经完成了，所以可以退出循环 break; &#125; else if (casBase(v = base, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) // cells正在进行初始化时，尝试直接在base上进行累加操作 break; // Fall back on using base 直接在base上进行累积操作成功了，任务完成，可以退出循环了 &#125; &#125; // double的不讲，更long的逻辑基本上是一样的 final void doubleAccumulate(double x, DoubleBinaryOperator fn, boolean wasUncontended); // Unsafe mechanics Unsafe初始化 private static final sun.misc.Unsafe UNSAFE; private static final long BASE; private static final long CELLSBUSY; private static final long PROBE; static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; sk = Striped64.class; BASE = UNSAFE.objectFieldOffset (sk.getDeclaredField(\"base\")); CELLSBUSY = UNSAFE.objectFieldOffset (sk.getDeclaredField(\"cellsBusy\")); Class&lt;?&gt; tk = Thread.class; PROBE = UNSAFE.objectFieldOffset (tk.getDeclaredField(\"threadLocalRandomProbe\")); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125; &#125; 三、LongAdder看完了Striped64的讲解，这部分就很简单了，只是一些简单的封装。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182public class LongAdder extends Striped64 implements Serializable &#123; // 构造方法，什么也不做，直接使用默认值，base = 0, cells = null public LongAdder() &#123; &#125; // add方法，根据父类的longAccumulate方法的要求，这里要进行一次CAS操作 // （虽然这里有两个CAS，但是第一个CAS成功了就不会执行第二个，要执行第二个，第一个就被“短路”了不会被执行） // 在线程竞争不激烈时，这样做更快 public void add(long x) &#123; Cell[] as; long b, v; int m; Cell a; //首先判断cells是否还没被初始化，并且尝试对value值进行cas操作 if ((as = cells) != null || !casBase(b = base, b + x)) &#123; boolean uncontended = true; //此处有多个判断条件，依次是 //1.cell[]数组还未初始化 //2.cell[]数组虽然初始化了但是数组长度为0 //3.该线程所对应的cell为null，其中要注意的是，当n为2的n次幂时，（(n - 1) &amp; h）等效于h%n //4.尝试对该线程对应的cell单元进行cas更新（加上x) if (as == null || (m = as.length - 1) &lt; 0 || (a = as[getProbe() &amp; m]) == null || !(uncontended = a.cas(v = a.value, v + x))) // 表示第一次cas成功情况 longAccumulate(x, null, uncontended); &#125; &#125; public void increment() &#123; add(1L); &#125; public void decrement() &#123; add(-1L); &#125; // 返回累加的和，也就是“当前时刻”的计数值 // 此返回值可能不是绝对准确的，因为调用这个方法时还有其他线程可能正在进行计数累加， // 方法的返回时刻和调用时刻不是同一个点，在有并发的情况下，这个值只是近似准确的计数值 // 高并发时，除非全局加锁，否则得不到程序运行中某个时刻绝对准确的值，但是全局加锁在高并发情况下是下下策 // 在很多的并发场景中，计数操作并不是核心，这种情况下允许计数器的值出现一点偏差，此时可以使用LongAdder // 在必须依赖准确计数值的场景中，应该自己处理而不是使用通用的类 public long sum() &#123; Cell[] as = cells; Cell a; long sum = base; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum; &#125; // 重置计数器，只应该在明确没有并发的情况下调用，可以用来避免重新new一个LongAdder public void reset() &#123; Cell[] as = cells; Cell a; base = 0L; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) a.value = 0L; &#125; &#125; &#125; // 相当于sum()后再调用reset() public long sumThenReset() &#123; Cell[] as = cells; Cell a; long sum = base; base = 0L; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) &#123; sum += a.value; a.value = 0L; &#125; &#125; &#125; return sum; &#125; // 其他的不说了 &#125; 简单总结下：这个类是jdk1.8新增的类，目的是为了提供一个通用的，更高效的用于并发场景的计数器。可以网上搜下一些关于LongAdder的性能测试，有很多现成的，我自己就不写了。jdk1.8的ConcurrentHashMap中，没有再使用Segment，使用了一个简单的仿造LongAdder实现的计数器，这样能够保证计数效率不低于使用Segment的效率。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}],"author":"土川"},{"title":"[Java基础]BitSet","slug":"Java基础-BitSet","date":"2018-03-13T02:02:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"4146306917.html","link":"","permalink":"https://htchz.cc/4146306917.html","excerpt":"","text":"BitSet类大小可动态改变, 取值为true或false的位集合。用于表示一组布尔标志。 此类实现了一个按需增长的位向量。位 set 的每个组件都有一个 boolean 值。用非负的整数将 BitSet 的位编入索引。可以对每个编入索引的位进行测试、设置或者清除。通过逻辑与、逻辑或和逻辑异或操作，可以使用一个 BitSet 修改另一个 BitSet 的内容。默认情况下，set 中所有位的初始值都是 false。每个位 set 都有一个当前大小，也就是该位 set 当前所用空间的位数。注意，这个大小与位 set 的实现有关，所以它可能随实现的不同而更改。位 set 的长度与位 set 的逻辑长度有关，并且是与实现无关而定义的。除非另行说明，否则将 null 参数传递给 BitSet 中的任何方法都将导致 NullPointerException。 在没有外部同步的情况下，多个线程操作一个 BitSet 是不安全的。 构造函数:BitSet() or BitSet(int nbits) 一些方法12345678910111213141516public void set(int pos): 位置pos的字位设置为true。 public void set(int bitIndex, boolean value) 将指定索引处的位设置为指定的值。 public void clear(int pos): 位置pos的字位设置为false。public void clear() : 将此 BitSet 中的所有位设置为 false。 public int cardinality() 返回此 BitSet 中设置为 true 的位数。 public boolean get(int pos): 返回位置是pos的字位值。 public void and(BitSet other): other同该字位集进行与操作，结果作为该字位集的新值。 public void or(BitSet other): other同该字位集进行或操作，结果作为该字位集的新值。 public void xor(BitSet other): other同该字位集进行异或操作，结果作为该字位集的新值。public void andNot(BitSet set) 清除此 BitSet 中所有的位,set - 用来屏蔽此 BitSet 的 BitSetpublic int size(): 返回此 BitSet 表示位值时实际使用空间的位数。public int length() 返回此 BitSet 的“逻辑大小”：BitSet 中最高设置位的索引加 1。 public int hashCode(): 返回该集合Hash 码， 这个码同集合中的字位值有关。 public boolean equals(Object other): 如果other中的字位同集合中的字位相同，返回true。 public Object clone() 克隆此 BitSet，生成一个与之相等的新 BitSet。 public String toString() 返回此位 set 的字符串表示形式。 解释Java.util.BitSet可以按位存储。计算机中一个字节（byte）占8位（bit），我们java中数据至少按字节存储的，比如一个int占4个字节。如果遇到大的数据量，这样必然会需要很大存储空间和内存。如何减少数据占用存储空间和内存可以用算法解决。java.util.BitSet就提供了这样的算法。比如有一堆数字，需要存储，source=[3,5,6,9]用int就需要4*4个字节。java.util.BitSet可以存true/false。如果用java.util.BitSet，则会少很多，其原理是： 先找出数据中最大值maxvalue=9 声明一个BitSet bs,它的size是maxvalue+1=10 遍历数据source，bs[source[i]]设置成true. 最后的值是：(0为false;1为true) bs [0,0,0,1,0,1,1,0,0,1] 这样一个本来要int型需要占4字节共32位的数字现在只用了1位！比例32:1 ,这样就省下了很大空间。 默认的构造函数声明一个64位的BitSet，值都是false。如果你要用的位超过了默认size,它会再申请64位，而不是报错。 123456789101112131415/** * @param args */ public static void main(String[] args) &#123; BitSet bm=new BitSet(); System.out.println(bm.isEmpty()+\"--\"+bm.size()); // true--64 bm.set(0); System.out.println(bm.isEmpty()+\"--\"+bm.size()); // false--64 bm.set(1); System.out.println(bm.isEmpty()+\"--\"+bm.size()); // false--64 System.out.println(bm.get(65)); // false System.out.println(bm.isEmpty()+\"--\"+bm.size()); // false--64 bm.set(65); System.out.println(bm.isEmpty()+\"--\"+bm.size()); // false--128 &#125; 申请的位都是以64为倍数的，就是说你申请不超过一个64的就按64算，超过一个不超过2个的就按128算。 12345678910111213public static void main(String[] args) &#123; BitSet bm1=new BitSet(7); System.out.println(bm1.isEmpty()+&quot;--&quot;+bm1.size()); // true-64 BitSet bm2=new BitSet(63); System.out.println(bm2.isEmpty()+&quot;--&quot;+bm2.size()); // true-64 BitSet bm3=new BitSet(65); System.out.println(bm3.isEmpty()+&quot;--&quot;+bm3.size()); // true-128 BitSet bm4=new BitSet(111); System.out.println(bm4.isEmpty()+&quot;--&quot;+bm4.size()); // true-128&#125; 来看一个小代码: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package com; import java.util.BitSet; public class MainTestFive &#123; /** * @param args */ public static void main(String[] args) &#123; int[] shu=&#123;2,42,5,6,6,18,33,15,25,31,28,37&#125;; BitSet bm1=new BitSet(MainTestFive.getMaxValue(shu)); System.out.println(&quot;bm1.size()--&quot;+bm1.size()); MainTestFive.putValueIntoBitSet(shu, bm1); printBitSet(bm1); &#125; //初始全部为false，这个你可以不用，因为默认都是false public static void initBitSet(BitSet bs)&#123; for(int i=0;i&lt;bs.size();i++)&#123; bs.set(i, false); &#125; &#125; //打印 public static void printBitSet(BitSet bs)&#123; StringBuffer buf=new StringBuffer(); buf.append(&quot;[\\n&quot;); for(int i=0;i&lt;bs.size();i++)&#123; if(i&lt;bs.size()-1)&#123; buf.append(MainTestFive.getBitTo10(bs.get(i))+&quot;,&quot;); &#125;else&#123; buf.append(MainTestFive.getBitTo10(bs.get(i))); &#125; if((i+1)%8==0&amp;&amp;i!=0)&#123; buf.append(&quot;\\n&quot;); &#125; &#125; buf.append(&quot;]&quot;); System.out.println(buf.toString()); &#125; //找出数据集合最大值 public static int getMaxValue(int[] zu)&#123; int temp=0; temp=zu[0]; for(int i=0;i&lt;zu.length;i++)&#123; if(temp&lt;zu[i])&#123; temp=zu[i]; &#125; &#125; System.out.println(&quot;maxvalue:&quot;+temp); return temp; &#125; //放值 public static void putValueIntoBitSet(int[] shu,BitSet bs)&#123; for(int i=0;i&lt;shu.length;i++)&#123; bs.set(shu[i], true); &#125; &#125; //true,false换成1,0为了好看 public static String getBitTo10(boolean flag)&#123; String a=&quot;&quot;; if(flag==true)&#123; return &quot;1&quot;; &#125;else&#123; return &quot;0&quot;; &#125; &#125; &#125; 输出: maxvalue:42 bm1.size()--64 0,0,1,0,0,1,1,0, 0,0,0,0,0,0,0,1, 0,0,1,0,0,0,0,0, 0,1,0,0,1,0,0,1, 0,1,0,0,0,1,0,0, 0,0,1,0,0,0,0,0, 0,0,0,0,0,0,0,0, 0,0,0,0,0,0,0,0这样便完成了存值和取值。注意它会对重复的数字过滤，就是说，一个数字出现过超过2次的它都记成1.出现的次数这个信息就丢了。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"位图","slug":"位图","permalink":"https://htchz.cc/tags/位图/"}],"author":"土川"},{"title":"[多线程]一个线程饥饿死锁的例子","slug":"一个线程饥饿死锁的例子","date":"2018-03-10T12:44:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"45692816.html","link":"","permalink":"https://htchz.cc/45692816.html","excerpt":"简单地说，就是循环阻塞，互相抢占资源。","text":"简单地说，就是循环阻塞，互相抢占资源。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.htc.test;import java.util.concurrent.*;/** * Created by Zack.Huang on 2017/8/24. */public class ThreadDeadlock &#123; ExecutorService exec = Executors.newSingleThreadScheduledExecutor();// ExecutorService exec = Executors.newCachedThreadPool(); //如果添加给线程池中添加足够多的线程，就可以让所有任务都执行，避免饥饿死锁。 /** * 模拟页面加载的例子 * * 产生死锁分析： * RenderPageTask任务中有2个子任务分别是“加载页眉”和“加载页脚”。当提交RenderPageTask任务时，实际上是向线程池中添加了3个任务， * 但是由于线程池是单一线程池，同时只会执行一个任务，2个子任务就会在阻塞在线程池中。而RenderPageTask任务由于得不到返回，也会 * 一直堵塞，不会释放线程资源让子线程执行。这样就导致了线程饥饿死锁。 * * 在一个Callable任务中，要返回2个子任务 * @author hadoop * */ class RenderPageTask implements Callable&lt;String&gt; &#123; @Override public String call() throws Exception &#123; Future&lt;String&gt; header,footer; header = exec.submit(() -&gt; &#123; System.out.println(\"加载页眉\"); Thread.sleep(2*1000); return \"页眉\"; &#125;); footer = exec.submit(() -&gt; &#123; System.out.println(\"加载页脚\"); Thread.sleep(3*1000); return \"页脚\"; &#125;); System.out.println(\"渲染页面主体\"); return header.get() + footer.get();//return \"you bad bad\"; 这里改为这样就可以不阻塞 &#125; &#125; public static void main(String[] args) throws InterruptedException, ExecutionException &#123; ThreadDeadlock td = new ThreadDeadlock(); Future&lt;String&gt; futre = td.exec.submit(td.new RenderPageTask()); String result = futre.get(); System.out.println(\"执行结果为：\" + result); &#125;&#125;","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://htchz.cc/categories/Java基础/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://htchz.cc/tags/multithread/"}],"author":"土川"},{"title":"[老司机]BT协议学习笔记","slug":"BT协议学习笔记","date":"2018-03-10T08:01:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"2501905798.html","link":"","permalink":"https://htchz.cc/2501905798.html","excerpt":"","text":"编码 B encode在说明网络流程之前，先简单介绍下B encode，因为在BitTorrent协议中的数据几乎都是用B encode进行编码的。它是一种作用类似于XML和JSON的数据组织格式，可以表达字符串、整数两种基本类型，列表、字典两种数据结构，它的语法规则十分简单。 字节串按如下方式编码： &lt;以十进制ASCII编码的串长度&gt;：&lt;串数据&gt;例：“4:spam”表示字节串“spam” 整数按如下方式编码： i&lt;以十进制ASCII编码的整数&gt;e例：“i3e”表示整数“3” 列表按如下方式编码： l&lt;内容&gt;e开始的“l”与结尾的“e”分别是开始和结束分隔符。lists可以包含任何B编码的类型，包括整数、串、dictionaries和其他的lists。例：l4:spam4:eggse 表示含有两个串的lists:[“spam”、“eggs”] 字典按如下方式编码： d&lt;内容&gt;e开始的“d”与结尾的“e”分别是开始和结束分隔符。注意键（key）必须被B编码为串。值可以是任何B编码的类型，包括整数、串、lists和其他的dictionaries。键（key）必须是串，并且以排序的顺序出现（以原始串排列，而不是以字母数字顺序）。例1：d3:cow3:moo4:spam4:eggse 表示dictionary { “cow” =&gt; “moo”, “spam” =&gt; “eggs” } 元信息文件 .torrent作为发布者，首先需要有一个域名，一台作为Tracker的服务器，一台发布.torrent文件的服务器，一台保存资源的服务器，当然这些可以共用一台服务器。使用BitTorrent工具选择“海贼王712集.mkv”文件，指定Tracker服务器的URL，会生成一个.torrent文件。 .torrent文件使用B encode表示，整个是一个字典数据结构，它有多个key值，包括一些是可选的，这里介绍最关键的几个键值对。 info：存储资源文件的元信息 piece length pieces name/path announce：描述tracker服务器的URL info键对应的值又是一个字典结构，BT协议将一个文件分成若干片，便于客户端从各个主机下载各个片。其中的piece length键值对表示一个片的长度，通畅情况下是2的n次方，根据文件大小有所权衡，通长越大的文件piece length越大以减少piece的数量，降低数量一方面降低了.torrent保存piece信息的大小，一方面也减少了下载需要对片做的确认操作，加快下载速度。目前通常是256kB,512kB或者1MB。 pieces则是每个piece的正确性验证信息，每一片均对应一个唯一的SHA1散列值，该键对应的值是所有的20字节SHA1散列值连接而成的字符串。 name/path比较笼统的说，就是具体文件的信息。因为BitTorrent协议允许将数个文件和文件夹作为一个BitTorrent下载进行发布，因此下载方可以根据需要勾选某一些下载文件。注意，这里将数个文件也砍成一个数据流，因此一个piece如果在文件边界上，可能包含不同文件的信息。 announce保存的是tracker服务器的URL，也就是客户端拿到.torrent文件首先要访问的服务器，在一些扩展协议中，announce可以保存多个tracker服务器作为备选。 生成好.torrent文件之后，发布者需要先作为下载者一样根据.torrent文件进行下载，这样就会连接到tracker服务器。由于发布者已经有了完整的资源文件，tracker服务器会得知这是一个完全下载完成的用户，会把发布者的信息保存在tracker服务器中，这之间的协议在后面讲客户端和tracker服务器的通信协议的时候再说。 发布者还要做的最后一件事就是将.torrent文件放在服务器上，可以通过HTTP或者FTP协议供用户下载这个.torrent文件。相比于直接将整个资源文件提供给用户下载，只传输一个.torrent文件大大降低了服务器的负荷。 这样，发布者的任务就完成了，只需要在资源传播开前保证资源服务器，也就是保存了“海贼王712集.mkv”文件的服务器在开启状态，能够持续上传直到资源传播开来。 客户端和Tracker服务器现在我是一个动漫爱好者，我发现了漫游上有新的“海贼王712集.mkv”的BT资源，我需要怎样才能下载到这个视频呢？ 首先，可以通过HTTP或者FTP协议直接从服务器上得到.torrent文件。然后使用BitTorrent软件客户端打开.torrent文件，软件会根据.torrent的name/path元信息告诉我这个.torrent文件可以下载到一个.mkv文件，一个字幕文件，在这个阶段我可以进行一些勾选，选择下载某些而不是全部的资源。 资源选择确定后，BitTorrent软件客户端就开始了下载。客户端的第一步任务根据.torrent上的URL使用HTTP GET请求，这个请求包含了很多参数，这里只介绍从客户端发送到Tracker的请求最关键的几个参数。 info_hash peer_id ip port info_hash是元信息.torrent文件中info键所对应的值的SHA1散列，可以被Tracker服务器用来索引唯一的对应资源。 peer_id是20byte的串，没有任何要求，被Tracker服务器用于记录客户端的名字。 ip可以从HTTP GET请求中直接获取，放在参数中可以解决使用代理进行HTTP GET的情况，Tracker服务器可以记录客户端的IP地址。 port客户端监听的端口号，用于接收response。一般情况下为BitTorrent协议保留的端口号是6881-6889，Tracker服务器会记录下端口号用于通知其他客户端。 在Tracker服务器收到客户端的HTTP GET请求后，会返回B encode形式的text/plain文本，同样是一个字典数据结构，其中最关键的一个键值对是peers，它的值是个字典列表结构，列表中的每一项都是如下的字典结构。 peers peer_id ip port 这些信息在每个客户端连接Tracker服务器的时候都发送过，并且被Tracker服务器保存了下来。新来的客户端自然要获取到这些下载中或者已下载完的客户端的ip，port等信息，有了这些信息，客户端就不需要像FTP或者HTTP协议一样持续找服务器获取资源，可以从这些其他客户端上请求获取资源。 peer to peerpeer to peer，简称P2P，就是从其他的下载用户那里获取数据，也就是BitTorrent下载的核心特点。客户端从Tracker服务器获取到若干其他下载者(peer)的ip和port信息，会进行请求并维持跟每一个peer的连接状态。一个客户端和每一个peer的状态主要有下列状态信息： choked：远程客户端拒绝响应任何本客户端的请求。 interested：远程客户端对本客户端的数据感兴趣，当本客户端unchoked远程客户端后，远程客户端会请求数据。 所以应该有4个参数，分别表示本客户端对远程客户端是否chock，是否interested，远程客户端对本客户端是否chock，是否interested。当一个客户端对一个远程peer感兴趣并且那个远程peer没有choke这个客户端，那么这个客户端就可以从远程peer下载块(block)。当一个客户端没有choke一个peer，并且那个peer对这个客户端这个感兴趣时，这个客户端就会上传块(block)。 第一次通信会先发送握手报文，告诉远程客户端本客户端的一些信息，包括info_hash和peer_id。接下来的所有报文有如下几种类型： keep-alive：告诉远程客户端这个通信还在维持，否则超过2分钟没有任何报文远程客户端会将通信关闭 choke unchoke interested not interested bitfield：告诉对方我已经有的piece have：告诉对方某个piece已经成功下载并且通过hash校验 request：请求某个块(block) index: 整数，指定从零开始的piece索引 begin: 整数，指定piece中从零开始的字节偏移 length: 整数，指定请求的长度 piece：返回请求的块(block)的数据，是真正的资源信息 index: 整数，指定从零开始的piece索引 begin: 整数，指定piece中从零开始的字节偏移 block: 数据块经过这些报文在本地客户端和若干个远程客户端之间的来回传递，就能够获取到资源文件。 经过前面的简单描述，可以看到这种P2P信息传递的有诸多可以进行挖掘和优化的地方。比如每次tracker服务器返回多少个peer，多了无用并且增加网络负荷，少了又不够。客户端同时和多少个peer保持通信最好。客户端应该优先请求哪些piece，如何请求连续的piece能够提高缓存的使用率。为什么下载接近完成最后的一些数据总是非常慢。这些都是值得优化和研究的地方。","categories":[{"name":"网络","slug":"网络","permalink":"https://htchz.cc/categories/网络/"}],"tags":[{"name":"BT","slug":"BT","permalink":"https://htchz.cc/tags/BT/"}],"author":"土川"},{"title":"[Nginx]Nginx location 匹配原则","slug":"Nginx-location-匹配原则","date":"2018-03-10T07:16:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"3180078468.html","link":"","permalink":"https://htchz.cc/3180078468.html","excerpt":"","text":"Location block 的基本语法形式是：location [=|~|~*|^~|@] pattern { ... } [=|~|~*|^~|@]被称作 location modifier ，这会定义 Nginx 如何去匹配其后的 pattern ，以及该 pattern 的最基本的属性（简单字符串或正则表达式） location modifier详解 1、= 123456server &#123; server_name htchz.com; location = /abcd &#123; […] &#125;&#125; 匹配情况： http://website.com/abcd # 正好完全匹配 http://website.com/ABCD # 如果运行 Nginx server 的系统本身对大小写不敏感，比如 Windows ，那么也匹配 http://website.com/abcd?param1m2 # 忽略查询串参数（query string arguments），这里就是 /abcd 后面的 ?param1m2 http://website.com/abcd/ # 不匹配，因为末尾存在反斜杠（trailing slash），Nginx 不认为这种情况是完全匹配 http://website.com/abcde # 不匹配，因为不是完全匹配 2、(None) 不写 location modifier ，Nginx 仍然能去匹配 pattern 。这种情况下，匹配那些以指定的 patern 开头的 URI，注意这里的 URI 只能是普通字符串，不能使用正则表达式。 123456server &#123; server_name website.com; location /abcd &#123; […] &#125;&#125; 匹配情况： http://website.com/abcd # 正好完全匹配 http://website.com/ABCD # 如果运行 Nginx server 的系统本身对大小写不敏感，比如 Windows ，那么也匹配 http://website.com/abcd?param1m2 # 忽略查询串参数（query string arguments），这里就是 /abcd 后面的 ?param1m2 http://website.com/abcd/ # 末尾存在反斜杠（trailing slash）也属于匹配范围内 http://website.com/abcde # 仍然匹配，因为 URI 是以 pattern 开头的 3、~ 123456server &#123; server_name website.com; location ~ ^/abcd$ &#123; […] &#125;&#125; 匹配情况： http://website.com/abcd # 完全匹配 http://website.com/ABCD # 不匹配，~ 对大小写是敏感的 http://website.com/abcd?param1m2 # 忽略查询串参数（query string arguments），这里就是 /abcd 后面的 ?param1m2 http://website.com/abcd/ # 不匹配，因为末尾存在反斜杠（trailing slash），并不匹配正则表达式 ^/abcd$ http://website.com/abcde # 不匹配正则表达式 ^/abcd$ 对于一些对大小写不敏感的系统，比如 Windows ，~ 和 ~* 都是不起作用的，这主要是操作系统的原因。 4、~* 与 ~ 类似，但这个 location modifier 不区分大小写，pattern 须是正则表达式 123456server &#123; server_name website.com; location ~* ^/abcd$ &#123; […] &#125;&#125; http://website.com/abcd # 完全匹配 http://website.com/ABCD # 匹配，这就是它不区分大小写的特性 http://website.com/abcd?param1m2 # 忽略查询串参数（query string arguments），这里就是 /abcd 后面的 ?param1m2 http://website.com/abcd/ # 不匹配，因为末尾存在反斜杠（trailing slash），并不匹配正则表达式 ^/abcd$ http://website.com/abcde # 不匹配正则表达式 ^/abcd$ 5、^~ 匹配情况类似 2. (None) 的情况，以指定匹配模式开头的 URI 被匹配，不同的是，一旦匹配成功，那么 Nginx 就停止去寻找其他的 Location 块进行匹配了（与 Location 匹配顺序有关） 6、@ 用于定义一个 Location 块，且该块不能被外部 Client 所访问，只能被 Nginx 内部配置指令所访问，比如 try_files or error_page 搜索顺序以及生效优先级因为可以定义多个 Location 块，每个 Location 块可以有各自的 pattern 。因此就需要明白（不管是 Nginx 还是你），当 Nginx 收到一个请求时，它是如何去匹配 URI 并找到合适的 Location 的。 要注意的是，写在配置文件中每个 Server 块中的 Location 块的次序是不重要的，Nginx 会按 location modifier 的优先级来依次用 URI 去匹配 pattern ，顺序如下： 1. = 2. (None) 如果 pattern 完全匹配 URI（不是只匹配 URI 的头部） 3. ^~ 4. ~ 或 ~* 5. (None) pattern 匹配 URI 的头部实际使用建议所以实际使用中，个人觉得至少有三个匹配规则定义，如下：直接匹配网站根，通过域名访问网站首页比较频繁，使用这个会加速处理，官网如是说。这里是直接转发给后端应用服务器了，也可以是一个静态首页 第一个必选规则 123location = / &#123; proxy_pass http://tomcat:8080/index&#125; 第二个必选规则是处理静态文件请求，这是nginx作为http服务器的强项,有两种配置模式，目录匹配或后缀匹配,任选其一或搭配使用 123location ^~ /static/ &#123; root /webroot/static/;&#125; 123location ~* \\.(gif|jpg|jpeg|png|css|js|ico)$ &#123; root /webroot/res/;&#125; 第三个规则就是通用规则，用来转发动态请求到后端应用服务器，非静态文件请求就默认是动态请求，自己根据实际把握 123location / &#123; proxy_pass http://tomcat:8080/&#125;","categories":[{"name":"服务器","slug":"服务器","permalink":"https://htchz.cc/categories/服务器/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://htchz.cc/tags/Nginx/"}],"author":"土川"},{"title":"[Spring]Spring加载参数那些事","slug":"Spring加载参数那些事","date":"2018-03-10T07:06:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"298553133.html","link":"","permalink":"https://htchz.cc/298553133.html","excerpt":"","text":"通过&lt;context:property-placeholder location=”classpath:conn.properties” &gt;1234567 &lt;context:property-placeholder location=\"classpath:conn.properties\"/&gt;&lt;bean id=\"dataSource\" class=\"$&#123;dataSource&#125;\"&gt; &lt;!-- 这些配置Spring在启动时会去conn.properties中找 --&gt; &lt;property name=\"driverClass\" value=\"$&#123;driverClass&#125;\" /&gt; &lt;property name=\"jdbcUrl\" value=\"$&#123;jdbcUrl&#125;\" /&gt; &lt;property name=\"user\" value=\"$&#123;user&#125;\" /&gt; &lt;property name=\"password\" value=\"$&#123;password&#125;\" /&gt; &lt;/bean&gt; 通过@Value注解@Value注解有两种Configurer可以使用，一种是PropertiesFactoryBean，另一种是PropertyPlaceholderConfigurer，后者注重于模板${} 123456789&lt;!-- 第二种方式是使用注解的方式注入，主要用在java代码中使用注解注入properties文件中相应的value值 --&gt; &lt;bean id=\"prop\" class=\"org.springframework.beans.factory.config.PropertyPlaceholderConfigurer\"&gt; &lt;!-- 或者使用&lt;bean id=\"prop\" class=\"org.springframework.beans.factory.config.PropertiesFactoryBean\"&gt; --&gt; &lt;property name=\"locations\"&gt;&lt;!-- 这里是PropertiesFactoryBean类，它也有个locations属性，也是接收一个数组，跟上面一样 &lt;array&gt; &lt;value&gt;classpath:public.properties&lt;/value&gt; &lt;/array&gt; &lt;/property&gt; &lt;/bean&gt; 然后在bean里使用@Value(“#{beanId[property_name]}”)(PropertiesFactoryBean)或者@Value(“${xxxxx}”)(PropertyPlaceholderConfigurer)即可，如public.properties里有 username=htc 那么在bean里使用@Value(“${username}”) String username 注入在方法参数 注意要有set方法才能被注入进来，注解写在set方法上即可。在setFilePath方法中通过控制台打印filePath是为了在启动tomcat的时候，观察控制台有没有输出来，如果有，说明Spring在启动时，已经将filePath给加载好了，我们看一下控制台的启动信息：重要：第三种@ConfigurationProperties 123456@Bean(value = \"dataSource\", destroyMethod = \"close\", initMethod = \"init\")@Primary@ConfigurationProperties(prefix = \"druid\")public DataSource getDataSource(@Value(\"$&#123;jdbcUrl&#125;\") String jdbcUrl,@Value(\"$&#123;user&#125;\") String user,@Value(\"$&#123;password&#125;\") String password)&#123; return DataSourceBuilder.create().username(user).password(password).type(DruidDataSource.class).url(jdbcUrl).build();&#125; 这里使用了@ConfigurationProperties在使得在处理bean的时候可以自动根据fieldname注入值然而使用上面的配置是不会注入的，因为读不到！上面的配置是用PropertyPlaceholderConfigurer这个类来存储配置文件，而@ConfigurationProperties是使用这个类 org.springframework.context.support.PropertySourcesPlaceholderConfigurer所以要配置的话得这么配置 1234567&lt;bean id=\"resourcePropertyConfigurer\" class=\"org.springframework.context.support.PropertySourcesPlaceholderConfigurer\"&gt; &lt;property name=\"locations\"&gt; &lt;list&gt; &lt;value&gt;classpath*:druid.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt; 实际上PropertySourcesPlaceholderConfigurer是springframework后来出的，相当于PropertyPlaceholderConfigurer的升级版 druid.properties里的内容类似于 druid.initialSize=10 druid.minIdle=1 ...如上，spring还可以自动根据前缀装配，根据属性名模糊匹配。 spring使用了模糊匹配，对于一个属性可以生成几十个变种，如有个属性叫”serverPort”，可以有“serverPort“、“server-port“、“serverport“等很多变种，是一种松懈的匹配，然后对于生成的几十种变种遍历，逐一和properties匹配，匹配到第一个就返回 以上就是Spring加载properties配置文件的几种方式。实际上，上面基于xml方式中的PropertyPlaceholderConfigurer类和这里基于注解方式的PropertiesFactoryBean类都是继承PropertiesLoaderSupport，都是用来加载properties配置文件的。 在spring配置文件中，对于bean的配置有这样一个配置：&lt;property name=”ignoreUnresolvablePlaceholders” value=”true” /&gt;这个主要是为了解决抛出cannot be resolved的异常。","categories":[{"name":"Spring","slug":"Spring","permalink":"https://htchz.cc/categories/Spring/"}],"tags":[{"name":"properties","slug":"properties","permalink":"https://htchz.cc/tags/properties/"}],"author":"土川"},{"title":"[qps]HystrixRollingNumber,可作为一个qps计数器","slug":"HystrixRollingNumber-可作为一个qps计数器","date":"2018-03-10T06:53:00.000Z","updated":"2019-06-24T07:32:04.000Z","comments":true,"path":"10902277.html","link":"","permalink":"https://htchz.cc/10902277.html","excerpt":"","text":"Hystrix是Netflix开源的一款容错系统，能帮助使用者码出具备强大的容错能力和鲁棒性的程序。 前言考虑到一种需求场景，我们需要统计系统qps、每秒平均错误率等。qps表示每秒的请求数目，能想到的最简单的方法就是统计一定时间内的请求总数然后除以总统计时间，所以计数是其中最核心的部分。通常我们的额系统是工作在多线程的环境下，所以计数我们可以考虑使用AtomicInteger/AtomicLong系列，AtomXXX中没有使用锁，使用的是循环+CAS，在多线程的条件下可以在一定程度上减少锁带来的性能损失。但是在竞争特别激烈的情况，会大量出现cas不成功的情况带来性能上的开销。为了更进一步分散线程写的压力，JDK8中引入了LongAdder，LongAdder会分成多个桶，将每个线程绑定到固定的桶空间中进行读写，计数可以对所有的桶中的值求总数。前面提到求qps最简单的方法就是统计一定时间内的请求总数然后除以总统计时间，这样的方法虽然简单但是对有一定的问题，比如说统计出的qps跳跃性会比较大，不够平滑等。在本文中将介绍HystrixRollingNumber，这是Hystrix的一个工具类，这个数据结构在统计qps等类似的求和统计的场景下非常有用。 要我自己写的话。。要么粒度太大，不够平滑，要么粒度小了，一堆锁竞争。 基本原理如前所说，HystrixRollingNumber中利用了LongAdder，也借鉴了LongAdder分段的思想。HystrixRollingNumber基本思想就是分段统计，比如说要统计qps，即1秒内的请求总数。如下图所示，我们可以将1s的时间分成10段，每段100ms。在第一个100ms内，写入第一个段中进行计数，在第二个100ms内，写入第二个段中进行计数，这样如果要统计当前时间的qps，我们总是可以通过统计当前时间前1s（共10段）的计数总和值。让我们来看看HystrixRollingNumber中具体是怎么做的。 BucketHystrixRollingNumber中对Bucket的描述是“Counters for a given ‘bucket’ of time”，即“给定时间桶内的计数器”，也即是我们上面所说的“段”。Bucket中有三个重要的属性值 final long windowStart; final LongAdder[] adderForCounterType; final LongMaxUpdater[] updaterForCounterType;windowStart记录了该Bucket所属的时间段的开始时间，adderForCounterType是一个LongAdder数组，每个元素代表了一种事件类型的计数值。updaterForCounterType同理。adderForCounterType数组的长度等于事件类型的个数，具体的事件类型可以参考HystrixRollingNumberEvent枚举类。相关的方法介绍如下(以下代码去掉了LongMaxUpdater相关，LongMaxUpdater用来统计最大值，和LongAdder类似可类比)： long get(HystrixRollingNumberEvent type):获取事件对应的LongAdder的总和 LongAdder getAdder(HystrixRollingNumberEvent type):获取事件对应的LongAdder对象 ListStateHystrixRollingNumber中对ListState的描述是“Immutable object that is atomically set every time the state of the BucketCircularArray changes，This handles the compound operations”，即“ListState是个不可变类，每次BucketCircularArray状态改变的时候，会新建一个并且会原子地设置到BucketCircularArray中，它用来处理复合操作”。ListState中比较重要的的属性值介绍如下： private final AtomicReferenceArray data:官方的说明是“this is an AtomicReferenceArray and not a normal Array because we’re copying the reference between ListState objects and multiple threads could maintain references across these compound operations so I want the visibility/concurrency guarantees”，意思是说“ListState持有Bucket数组对象，但是这个数组不是普通的数组而是AtomicReferenceArray，这是因为我们会在ListState对象之间拷贝reference，多个线程之间会通过复合操作持有引用，我们想要保证可见性/并发性”（AtomicXXX是原子操作） private final int size;（持有的Bucket数组大小，可以增加，但是最大值是numBuckets） private final int tail;（数组的尾部地址） private final int head;（数组的头部地址）ListState中有几个比较重要的方法 public Bucket tail():返回数组尾部的元素 public ListState clear():清空数组元素 public ListState addBucket(Bucket b):在尾部增加一个BucketListState是个不可变类，遵循者不可变类的原则 Fields为final，在构造方法中全部发布一次copy on write，写方法（addBucket）返回新的ListStateListState算是个助手类，维持了一个Bucket数组，定义了一些围绕着Bucket数组的有用操作，并且自身是个不可变类，天然的线程安全属性。 BucketCircularArray从名字上来说是一个环形数组，数组中的每个元素是一个Bucket，事实上大部分操作都是落到了ListState数据结构上BucketCircularArray中比较重要的属性值介绍如下： private final AtomicReference state: 维持了一个ListState的AtomicReference private final int numBuckets:环的大小 其中主要的比较重要的一个方法是：public void addLast(Bucket o) : 12345678910111213141516171819public void addLast(Bucket o) &#123; ListState currentState = state.get(); // create new version of state (what we want it to become) ListState newState = currentState.addBucket(o); //这里返回新的ListState实例 /* * use compareAndSet to set in case multiple threads are attempting (which shouldn&apos;t be the case because since addLast will ONLY be called by a single thread at a time due to protection * provided in &lt;code&gt;getCurrentBucket&lt;/code&gt;) */ if (state.compareAndSet(currentState, newState)) &#123; // we succeeded return; &#125; else &#123; // we failed, someone else was adding or removing // instead of trying again and risking multiple addLast concurrently (which shouldn&apos;t be the case) // we&apos;ll just return and let the other thread &apos;win&apos; and if the timing is off the next call to getCurrentBucket will fix things return; &#125;&#125; 这个方法主要就是为了在ListState的尾部添加一个Bucket，并且将新返回的ListState对象CAS到state中，但是其中有个比较特殊的处理，就是在一次CAS不成功的时候，程序完全忽略这次失败。注释是这么解释的“we failed, someone else was adding or removing instead of trying again and risking multiple addLast concurrently (which shouldn’t be the case) we’ll just return and let the other thread ‘win’ and if the timing is off the next call to getCurrentBucket will fix things”。大概意思就是说如果CAS失败是因为其他线程正在执行adding或者removing操作。我们不重试，而只是返回让其他线程“win”(这只是一个创建桶的操作)，如果时间片流逝了，我们可以通过下次调用getCurrentBucket进行补偿（详细的请看下面对于getCurrentBucket的分析） HystrixRollingNumber官方doc中给其的定义是“A number which can be used to track counters (increment) or set values over time.”，用来统计一段时间内的计数。其中比较重要的的属性值如下： private final Time time: 获取当前时间毫秒值 final int timeInMilliseconds: 统计的时间长度（毫秒单位） final int numberOfBuckets: Bucket的数量（分成多少段进行统计） final int bucketSizeInMillseconds: 每个Bucket所对应的时间片（毫秒单位） final BucketCircularArray buckets: 使用BucketCircularArray帮助维持环形数组桶 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374Bucket getCurrentBucket() &#123; // 获取当前的毫秒时间 long currentTime = time.getCurrentTimeInMillis(); //获取最后一个Bucket（即最新一个Bucket） Bucket currentBucket = buckets.peekLast(); if (currentBucket != null &amp;&amp; currentTime &lt; currentBucket.windowStart + this.bucketSizeInMillseconds) &#123; //如果当前时间是在currentBucket对应的时间窗口内，直接返回currentBucket return currentBucket; &#125; /* if we didn&apos;t find the current bucket above, then we have to create one */ //如果当前时间对应的Bucket不存在，我们需要创建一个 if (newBucketLock.tryLock()) &#123; //尝试获取一次锁 try &#123; if (buckets.peekLast() == null) &#123; // the list is empty so create the first bucket //首次创建 Bucket newBucket = new Bucket(currentTime); buckets.addLast(newBucket); return newBucket; &#125; else &#123; // We go into a loop so that it will create as many buckets as needed to catch up to the current time // as we want the buckets complete even if we don&apos;t have transactions during a period of time. // 将创建一个或者多个Bucket，直到Bucket代表的时间窗口赶上当前时间 for (int i = 0; i &lt; numberOfBuckets; i++) &#123; // we have at least 1 bucket so retrieve it Bucket lastBucket = buckets.peekLast(); if (currentTime &lt; lastBucket.windowStart + this.bucketSizeInMillseconds) &#123; // if we&apos;re within the bucket &apos;window of time&apos; return the current one // NOTE: We do not worry if we are BEFORE the window in a weird case of where thread scheduling causes that to occur, // we&apos;ll just use the latest as long as we&apos;re not AFTER the window return lastBucket; &#125; else if (currentTime - (lastBucket.windowStart + this.bucketSizeInMillseconds) &gt; timeInMilliseconds) &#123; // the time passed is greater than the entire rolling counter so we want to clear it all and start from scratch reset(); // recursively call getCurrentBucket which will create a new bucket and return it return getCurrentBucket(); &#125; else &#123; // we&apos;re past the window so we need to create a new bucket // create a new bucket and add it as the new &apos;last&apos; buckets.addLast(new Bucket(lastBucket.windowStart + this.bucketSizeInMillseconds)); // add the lastBucket values to the cumulativeSum cumulativeSum.addBucket(lastBucket); &#125; &#125; // we have finished the for-loop and created all of the buckets, so return the lastBucket now return buckets.peekLast(); &#125; &#125; finally &#123; //释放锁 newBucketLock.unlock(); &#125; &#125; else &#123; //如果获取不到锁，尝试获取最新一个Bucket currentBucket = buckets.peekLast(); if (currentBucket != null) &#123; //如果不为null，直接返回最新Bucket // we didn&apos;t get the lock so just return the latest bucket while another thread creates the next one return currentBucket; &#125; else &#123; //多个线程同时创建第一个Bucket，尝试等待，递归调用getCurrentBucket // the rare scenario where multiple threads raced to create the very first bucket // wait slightly and then use recursion while the other thread finishes creating a bucket try &#123; Thread.sleep(5); &#125; catch (Exception e) &#123; // ignore &#125; return getCurrentBucket(); &#125; &#125;&#125; 其实HystrixRollingNumber中写了很多有用的注释，解释了为什么要这么做。上述getCurrentBucket主要是为了获取当前时间窗所对应的Bucket，但是为了减少竞争，其中只使用了tryLock()，如果不成功则直接返回最新的一个不为空的Bucket。如果获取了锁则尝试增加Bucket（增加Bucket会一直增加到Bucket对应的时间窗口覆盖当前时间）。这样处理会有个小问题，就是获取的Bucket可能没有覆盖当前时间（原因是 currentTime只获取一次，在for循环的过程中会过时），这是为了减少竞争，提高效率，而且未创建的bucket最终还是会被创建（下一次getCurrentBucket()），这在统计的场景下可以容忍，将计数统计到之前的时间窗口内在计算qps等数值时通常不会有太大影响（numberOfBuckets通常不止一个）。 总结HystrixRollingNumber这个数据结构用于统计qps很有用，通常这种统计需求（限流监控统计qps的场景下）不能影响主要业务，对性能要求比较高，HystrixRollingNumber中采取了很多技巧避免使用锁，避免多个线程竞争，所以HystrixRollingNumber效率会非常高。","categories":[{"name":"微服务","slug":"微服务","permalink":"https://htchz.cc/categories/微服务/"}],"tags":[{"name":"服务限流","slug":"服务限流","permalink":"https://htchz.cc/tags/服务限流/"},{"name":"Hystrix","slug":"Hystrix","permalink":"https://htchz.cc/tags/Hystrix/"}],"author":"土川"},{"title":"[碧油鸡]Hexo-admin的404探索","slug":"Hexo","date":"2018-03-10T02:58:00.000Z","updated":"2018-10-22T03:34:46.000Z","comments":true,"path":"3915904827.html","link":"","permalink":"https://htchz.cc/3915904827.html","excerpt":"","text":"作为一个不懂js的后端开始了瞎搞。。 hexo-admin在写的时候，一般是把图片放到图床，再获得图片链接加入md，但是我习惯了为知笔记直接把图片复制粘贴进md里。不过hexo-admin确实加入了这个直接粘贴图片的功能，把图片复制进md里，有时会出现一个404的问题，一直百度谷歌无果，同事老哥一直叫我用gitbook，但是不找出这个404的谜底我很难受，于是有了下面的记录。 First Blood 第一张图如上图，上传成功后出现了404，点击404发生的代码，如下：hexo-admin直接生成html进行html内容的替换。可以看到我把图片粘贴之后，hexo-admin做了三个操作： 上传图片，返回![upload successful](/images/pasted-8.png)的字符串给客户端 客户端根据返回的字符串重新渲染 把新的文章内容post到服务器 为什么上传成功还404???这时我点开图片的链接 没问题啊，诡异。 第二张图粘贴第二张图片的时候 可以看到第一次获取失败的Nubia Z17获取成功了，证明图片是上传成功，然而林允儿在上传完成后，并没有404 第三张图片粘贴Gakki，又是404 其他现象 上面是在宿舍的操作，在公司操作的时候完全没出现这种404。不过有一个现象是，公司网络ping这台vps的时候有点慢，宿舍网ping这台vps非常快。 新建了另一台vps，同样的环境，也没有404。但是这台vps在洛杉矶，网络时延有点大。 各种小动作于是我在404的js打上断点， 运行到这里之后，继续执行所有js，没发生404。 于是乎我猜想： 服务器保存图片的接下来，返回了response，肯定还进行了某个操作，但是短时间内这个操作没完成，导致短时间内访问的时候还不能通。 这可以解释上面： 第一次操作是404，第二次却是两张图片都成功请求到。原因是第二次访问时，由于我的Nubia没成功加载，他会去再访问一次，这就导致了林允儿的请求会稍晚一点，而这点时间间隔里，对林允儿的某个操作已经完成，所以第二次操作不存在404，而第三次操作，Gakki又没给某个操作留时间完成，请求结果明显404。 公司访问我的vps比较慢，网络上的时延足够某个操作完成 断点的时延足够某个操作完成 那么上vps看日志，三次操作依次三张图。 hexo server --debug可以输出日志 利用小学找规律题目的尿性，我发觉404发生在这坨Generator操作之前 规律不是3次操作总结的，其实复现了很多次了 网上看到hexo-server会jian视source文件夹的变动，我手动把一张图片加入source/images目录下，他也自动跑出Generator日志。于是我猜想这个Generator不跑完，就不能通过hexo-server访问到图片。 怎么验证，琢磨去改hexo-admin代码，上github，不懂node.js，看到一个api.js的就点进去，惊喜找到这个接口 推荐个看GitHub的神器Octotree，我在chrome商店装的，可以直接看到GitHub的目录。 这个方法拉到最底 12345678910111213141516... var dataURI = req.body.data.slice('data:image/png;base64,'.length) var buf = new Buffer(dataURI, 'base64') hexo.log.d(`saving image to $&#123;outpath&#125;`) fs.writeFile(outpath, buf, function (err) &#123; if (err) &#123; console.log(err) &#125; hexo.source.process().then(function () &#123; res.done(&#123; src: path.join(hexo.config.root + filename), msg: msg &#125;) &#125;); &#125;)... 把服务器发送响应res.done语句延迟50ms执行后，再也没有发生过过404 123456789101112131415161718... var dataURI = req.body.data.slice('data:image/png;base64,'.length) var buf = new Buffer(dataURI, 'base64') hexo.log.d(`saving image to $&#123;outpath&#125;`) fs.writeFile(outpath, buf, function (err) &#123; if (err) &#123; console.log(err) &#125; hexo.source.process().then(function () &#123; setTimeout(function()&#123; // 百度来的延迟执行的方法。。 res.done(&#123; src: path.join(hexo.config.root + filename), msg: msg &#125;) &#125;, 50); &#125;); &#125;)... 为什么是50ms？看日志的时间，100ms左右可以保证Generator操作完成，于是我直接设置50ms，到现在也没再404过。 后记我看hexo-admin也没人提这个issue，估计直接粘贴图片的人不多，毕竟这种方法不能清理md不再引用的图片。我能想到的解决方法就是延迟执行再响应请求了，毕竟这个线程也不清楚Generator什么时候才执行完。。。","categories":[{"name":"建站","slug":"建站","permalink":"https://htchz.cc/categories/建站/"}],"tags":[{"name":"碧油鸡","slug":"碧油鸡","permalink":"https://htchz.cc/tags/碧油鸡/"}],"author":"土川"},{"title":"[建站]Hexo+Nginx+VPS实现HTTPS建站","slug":"hello-world","date":"2018-03-08T10:02:00.000Z","updated":"2019-01-29T02:42:34.000Z","comments":true,"path":"711179553.html","link":"","permalink":"https://htchz.cc/711179553.html","excerpt":"","text":"拿人家hexo来建站，参考hexo建站写的，加上一些自己的东西 系统：centos6，是vultr的一个vps，1000g流量100m带宽可以跑满，最低每个月5美刀，点击就送屠龙宝刀嘿嘿vultr.com使用工具：nginx用来做反向代理和https重定向、certbot来做免费证书申请、GitHub pages 同步博客、hexo做静态资源、hey hexo做博客管理 GitHub Pageshexo可以将文件同步到GitHub page上，可以同步后，输入[你的帐户名].github.io 来访问 没有GitHub账号吗，现在你有了 命名格式是:[你的帐户名].github.io，不然不行哦 Hexo最好照着官网来，因为这个东西更新有点快,链接已经说明一切装node curl --silent --location https://rpm.nodesource.com/setup_9.x | sudo bash - yum -y install nodejs装git yum -y install git安装完后，正常情况下的hexo命令会加入/usr/bin中， 不正常情况下…我的的命令在/etc/node/lib/node_modules/hexo/bin下且没加入环境变量，找了半天，第二次安装就正常了，可能是第一次没有npm没加-g参数。 这时建个站点，执行hexo init your_blog_name，这里假设你要建立一个叫叫foo的博客，执行hexo init foo | cd foo | npm install, ls可以看到foo目录。 这里foo路径是相对于你执行命令的路径。 进入foo目录，vim打开_config.yml，并滚动到最下面添加如下配置信息（注意最下边有deploy和type字段，覆盖这两个字段或者删除这两个字段然后复制下面的四个字段也行。）： deploy: type: git repo: git@github.com:hz8080/hz8080.github.io.git branch: master 我配了ssh验证，避免密码登陆 foo目录的结构 ├── _config.yml ├── package.json ├── scaffolds ├── source | ├── _drafts | └── _posts └── themesthemes是我们待会主题放的地方 接着在foo目录执行hexo s -p 5000看到输出，输入ip:5000就可以看到你的博客了。 s是server的意思，-p是端口，默认4000。不要把s写成-s，-s可以加，但是s 是启动必须的。 发布 hexo cleanhexo ghexo d hexo clean是清楚缓存hexo g是生成本地发布文件夹hexo d是发布到deploy到 _config.yml设置的目标地址 可以把三条写进bash脚本~ #!/bin/bash hexo clean hexo g hexo d hexo d 遇到not found 问题, 输入npm install hexo-deployer-git --save，再执行hexo d 主题hexo有很多主题，比如我用的是next 给菜单增加标签、类目在站点内，执行hexo new page tags，这时在sources/tags有index.md，vim编辑之， --- title: tags date: 2016-11-11 21:40:58 type: &quot;tags&quot; ---在站点的_config.yml把标签打开 menu: home: / #categories: /categories #about: /about archives: /archives tags: /tags //确保标签页已打开 #schedule: /schedule #commonweal: /404.html 分类同理，在站点内，执行hexo new page categories，这时在sources/categories有index.md，vim编辑之，然后在_config.yml把# 去掉 最后！在主题文件里（themes/next/）的_config.yml的tags和categories记得把注释去掉，菜单栏才会显示标签和分类 123456789menu: home: / || home #about: /about/ || user tags: /tags/ || tags categories: /categories/ || th archives: /archives/ || archive #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat 重新部署，即可生效。 其他换图标、头像什么的可以搞搞 hexo 修改了站点名字、介绍什么的，好像重启才生效，不知道是不是bug 设置‘阅读全文’hexo默认显示全部，设置阅读全文有两种方法， 第一种，在主题的_config.yml的auto_excerpt.enable改为true，length是预览长度 第二种，在文章加入&lt;!--more--&gt;，首页就会预览到&lt;!--more--&gt;的位置 第一种会有...，且预览长度是一样的 域名我从godaddy 买了一个.me后缀的，年费挺便宜的，不过续费就不便宜了，可以试用一波。具体绑定方法自找。 买完后在dns管理把A类名指向自己的服务器ip，配置完毕浏览器打开你的域名:hexo端口试试 博客文章管理 hexo-hey，不推荐，已经停止更新，有莫名其妙的bug hexo-admin ，用法简单粗暴，还能自动保存，用的这个 nginx安装安装不赘述，直接从配置动手在/etc/nginx/conf.d/default.conf是一个配置模板，在/etc/nginx/conf.d/下的*.conf都会被nginx读取。我只有一个应用，直接在default.conf动手 123456789101112131415161718192021222324252627282930313233upstream hexo_host&#123; server localhost:4000;&#125;## The default serveserver &#123; server_name htchz.me; # root /usr/share/nginx/html; # Load configuration files for the default server block. # include /etc/nginx/default.d/*.conf; location /admin &#123; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://hexo_host; &#125; // 非后台管理直接走静态文件 location / &#123; root /root/htc/public/; expires 30m; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; 执行nginx -s reload， 重启nginx，输入域名（http默认80端口），验证nginx转发端口是否生效 如果请求资源报403权限不足，可能是/etc/nginx/nginx.conf的user权限不足，改成root就可以 certbot申请证书 为什么要博客升级https，其实只是为了装逼。chrome打开的时候地址栏一个绿色的安全|https 看着挺舒服的 终端输入 wget https://dl.eff.org/certbot-auto chmod a+x certbot-auto ./certbot-auto --nginx期间要输入你的邮箱，选择申请证书的域名，选择是否原端口重定向到https（443），选是 然后certbot会自动申请证书、修改你的nginx配置。 下边是80转443的配置。 123456789server &#123; if ($host = htchz.me) &#123; return 301 https://$host$request_uri; &#125; # managed by Certbot listen 80; server_name htchz.me; return 404; # managed by Certbot&#125; 也可以这么写 12345server &#123; listen 80; server_name htchz.me; return 301 https://$server_name$request_uri;&#125; 记得开通你的80、443端口。。。 自动续期certbot申请的证书只有三个月，这里写个定时任务，命令行： crontab -e写入 0 0 * * 0 /root/www/certbot-auto renew这条命令的意思是每周日的0点0分执行/root/www/certbot-auto renew这条命令。执行下面这条命令查看定时任务列表中是否有刚才添加的任务 [root@California_VPS etc]# crontab -l 0 0 * * 0 /root/www/certbot-auto renew后来发现的问题到这里整个博客差不多了。 但还是有问题。没加图片的时候，chrome还是一把小绿锁，知道加了图片之后，小绿锁就没了。打开chrome控制台，看到类似下面warning， Mixed Content: The page at &apos;https://domain.com/w/a?id=074ac65d-70db-422d-a6d6-a534b0f410a4&apos; was loaded over HTTPS, but requested an insecure image &apos;http://img.domain.com/images/2016/5/3/2016/058c5085-21b0-4b1d-bb64-23a119905c84_cf0d97ab-bbdf-4e25-bc5b-868bdfb581df.jpg&apos;. This content should also be served over HTTPS.原来是https站点下，图片依旧是http访问。 解决方法这个简单，在服务器返回响应时加响应头，nginx配置如下 server { ... add_header Content-Security-Policy upgrade-insecure-requests; ... }还有一个方法是在html加入meta &lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;upgrade-insecure-requests&quot; /&gt;在hexo这个要去改模板太麻烦 然后重新加载配置文件，顺利解决~ 优化 优化url过长 标题自动编号","categories":[{"name":"建站","slug":"建站","permalink":"https://htchz.cc/categories/建站/"}],"tags":[{"name":"Https","slug":"Https","permalink":"https://htchz.cc/tags/Https/"},{"name":"Hexo","slug":"Hexo","permalink":"https://htchz.cc/tags/Hexo/"}]}]}